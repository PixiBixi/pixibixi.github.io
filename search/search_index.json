{"config":{"lang":["fr"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Sommaire","text":"<p>Bienvenue sur mon wiki personnel o\u00f9 j'\u00e9cris toutes mes astuces, ainsi que des tutoriels divers que j'ai pu prendre ici et l\u00e0.</p> <p>De formation DUT R\u00e9seaux &amp; T\u00e9l\u00e9coms et passionn\u00e9 de logiciel libre depuis toujours, j'ai pu m'investir dans diverses communaut\u00e9s afin d'aider un grand nombre de d\u00e9butants dans le monde de Linux.</p> <p>Ce wiki me permet d'apprendre de nombreuses choses mais \u00e9galement de vous en faire apprendre. Je reste disponible sur mon mail personnel pour toute question contact+wiki[at]jdelgado[dot]fr</p> <p>Cette magnifique documentation a \u00e9t\u00e9 faites avec MkDocs</p>"},{"location":"#linux-gnu","title":"Linux GNU","text":""},{"location":"#fondamentaux","title":"Fondamentaux","text":"<ul> <li>Rappel des commandes de base</li> <li>Rappel sur le cron</li> <li>VIM: L'editeur de texte de la mort</li> <li>cURL: La commande \u00e0 tout faire</li> <li>La commande find</li> <li>Memo sur la commande ip</li> <li>Mes fichiers de configuration</li> <li>Mise \u00e0 jour automatique de ses paquets</li> <li>La commande ss (le nouveau netstat.md)</li> <li>Configurer correctement son hostname</li> <li>Personnaliser son motd</li> <li>Simuler des conditions r\u00e9seau sur Linux</li> <li>Apprendre \u00e0 se servir de git</li> <li>R\u00e9duire la taille de son repository Git</li> <li>TMUX Multiplexeur de Shell</li> <li>G\u00e9n\u00e9rer une cl\u00e9 publique au format RFC 4716 depuis la clef priv\u00e9e</li> <li>Cr\u00e9ation de RAID logiciels avec mdadm</li> <li>Remplacer les commandes de base Linux par des versions plus performantes</li> </ul>"},{"location":"#securiser-son-serveur-linux","title":"S\u00e9curiser son serveur Linux","text":"<ul> <li>D\u00e9sactiver les patchs de s\u00e9curit\u00e9 Meltdown &amp; co</li> <li>Apprendre \u00e0 se servir d'IPTables</li> <li>Apprendre \u00e0 se servir d'ipset</li> <li>Installer et configurer Fail2Ban</li> <li>Installer et configurer RKHunter</li> <li>Installer et configurer LogWatch</li> <li>Installer et configurer SSH Guard</li> <li>Hardening de son serveur SSH</li> <li>Installer et configuer PortSentry</li> <li>Bloquer tous les pr\u00e9fixes d'un pays entier</li> <li>Whitelister une s\u00e9rie d'IP \u00e0 l'aide d'IPset et iptables</li> <li>Logger les actions SSH utilisateurs simplement</li> <li>Acc\u00e8s s\u00e9curis\u00e9 via sFTP (Chroot SSH.md)</li> <li>Am\u00e9liorer la vitesse de connexion \u00e0 votre serveur SSH</li> <li>Am\u00e9liorer la s\u00e9curit\u00e9 des mots de passe par d\u00e9faut avec PAM</li> <li>Configurer des notifications SSH Slack</li> <li>Lister tous les certificats \u00e9mis</li> </ul>"},{"location":"#supervision","title":"Supervision","text":"<ul> <li>Munin: Supervision claire et efficace</li> <li>Supervision via les outils eZ</li> <li>Netdata, Prometheus et Grafana : Une stack de monitoring simple et puissante</li> <li>G\u00e9n\u00e9rer des alertes depuis Loki</li> <li>Tips sur la stack LGTM</li> <li>M\u00e9trique custom pour node_exporter</li> <li>Configurer des notifications Slack pour check_mk</li> </ul>"},{"location":"#hardware","title":"Hardware","text":"<ul> <li>Upgrade son firmware Mellanox</li> <li>HP Smart Array : Lignes de commande Linux</li> </ul>"},{"location":"#hebergement","title":"H\u00e9bergement","text":""},{"location":"#mail-stack","title":"Mail Stack","text":"<ul> <li>Postfix/Dovecot/DKIM/Postgrey et plus encore</li> <li>Configurer DKIM avec Exim</li> </ul>"},{"location":"#nginxphp","title":"NGINX/PHP","text":"<ul> <li>Configurer NGINX avec le support IPv6</li> <li>Faites une redirection permanente vers la version SSL de votre site avec NGINX</li> <li>Installer NGINX, PHP et MariaDB</li> <li>Installer la version de PHP que vous d\u00e9sirez</li> <li>\u00catre encore plus safe en customisant son header Server NGINX</li> </ul>"},{"location":"#apache","title":"Apache","text":"<ul> <li>Obtenir les bonnes IP sur apache derri\u00e8re un reverse proxy</li> </ul>"},{"location":"#haproxy","title":"HAproxy","text":"<ul> <li>HAproxy : Sa configuration</li> <li>HAproxy : Mettre un node en maintenance</li> <li>HAproxy : Obtenir les vraies IPs depuis CloudFlare</li> <li>HAproxy : Utiliser son API</li> <li>HAproxy : Conserver l'IP de son utilisateur</li> </ul>"},{"location":"#ftp","title":"FTP","text":"<ul> <li>Installer un serveur FTP avec Pure-ftp</li> </ul>"},{"location":"#dns","title":"DNS","text":"<ul> <li>H\u00e9berger les NS de son serveur avec BIND (+ Resolveur DNS.md)</li> </ul>"},{"location":"#troubleshooting","title":"Troubleshooting","text":"<ul> <li>MOZILLA_PKIX_ERROR_REQUIRED_TLS_FEATURE_MISSING</li> </ul>"},{"location":"#misc","title":"Misc","text":"<ul> <li>Installer Ruby</li> </ul>"},{"location":"#services-web-auto-heberges","title":"Services web auto-h\u00e9berg\u00e9s","text":"<ul> <li>Selfoss, son Reader RSS self-hosted</li> <li>NextCloud, son cloud personnel</li> <li>Stream sa propre music avec Ampache</li> <li>Stream sa propre music avec Sonerezh, un produit fran\u00e7ais !</li> <li>Subsonic, le couteau Suisse de la musique</li> <li>Sauvegarder ses vid\u00e9os avec YoutubeDL et sa GUI</li> <li>ZeroBin, son propre service de paste</li> <li>G\u00e9rer son serveur en ligne via Ajenti</li> <li>H\u00e9berger ses images avec Chevreto</li> <li>Streamer sa musique depuis Koel</li> <li>Partager ses fichiers avec H5ai</li> </ul>"},{"location":"#linux-networking","title":"Linux Networking","text":"<ul> <li>Installer et configurer son VPN OpenVPN</li> <li>Configurer son serveur OpenVPN pour de l'IPv6</li> <li>Configurer l'IPv6 sur son serveur Online</li> <li>Augmenter le buffer de sa carte r\u00e9seau</li> <li>Effectuer un Speedtest depuis son serveur</li> </ul>"},{"location":"#avance","title":"Avanc\u00e9","text":"<ul> <li>Etendre \u00e0 chaud sa partition root</li> <li>Cr\u00e9er son service syst</li> <li>Exploration pouss\u00e9e des syst\u00e8mes de fichiers sysfs &amp; procfs</li> <li>Commandes avanc\u00e9es utiles</li> <li>Ecrire son script Bash</li> <li>Astuces Bash</li> <li>Astuces ZSH</li> <li>Debug ses lenteurs de ohmyzsh</li> <li>Un Template pour un script bash</li> <li>Config de base varnish</li> <li>Utilisation de strace</li> <li>Luter contre un DDOS</li> <li>Deplacer un processus dans un tmux</li> <li>Troubleshooting Grub</li> </ul>"},{"location":"#mysql","title":"MySQL","text":"<ul> <li>Cr\u00e9er son cluster Galera</li> <li>Commandes avanc\u00e9es MySQL</li> <li>Debug sa replication Master-Slave</li> <li>G\u00e9rer ses users MySQL</li> <li>Restaurer la DB syst\u00e8me MySQL</li> <li>G\u00e9n\u00e9rer des INSERT INTO depuis un SELECT</li> </ul>"},{"location":"#postgresql","title":"PostgreSQL","text":"<ul> <li>Upgrade sa version de postgresql</li> <li>Creer sa replication postgresql</li> <li>Commandes utiles postgresql</li> </ul>"},{"location":"#redis","title":"Redis","text":"<ul> <li>D\u00e9ployer un Redis en High Availability</li> </ul>"},{"location":"#memcached","title":"Memcached","text":"<ul> <li>Commandes diverses avec memcached</li> </ul>"},{"location":"#elasticsearch","title":"ElasticSearch","text":"<ul> <li>Log des slow queries de ElasticSearch</li> </ul>"},{"location":"#kafka","title":"Kafka","text":"<ul> <li>Kafkactl, un outil magique</li> </ul>"},{"location":"#cloud","title":"Cloud","text":""},{"location":"#aws","title":"AWS","text":"<ul> <li>Glossaire du vocabulaire AWS</li> <li>Debug un payload d'erreur AWS</li> <li>AWS : CLI</li> </ul>"},{"location":"#google-cloud","title":"Google Cloud","text":"<ul> <li>Suivre l'upgrade de son cluster GKE</li> <li>Commandes utiles pour la CLI GCP</li> </ul>"},{"location":"#azure","title":"Azure","text":"<ul> <li>EphemeralDisks : comment faire ?</li> </ul>"},{"location":"#devops","title":"DevOps","text":""},{"location":"#automatisation","title":"Automatisation","text":""},{"location":"#ansible","title":"Ansible","text":"<ul> <li>Automatiser les taches avec Ansible</li> <li>Tips ansible</li> <li>R\u00e9utilisation de variables ansible entre diff\u00e9rentes t\u00e2ches</li> </ul>"},{"location":"#divers","title":"Divers","text":"<ul> <li>Makefile : \u00e0 quoi \u00e7a sert ?</li> </ul>"},{"location":"#kubernetes","title":"Kubernetes","text":"<ul> <li>Commandes utiles pour K8S</li> <li>Commandes Avanc\u00e9es</li> <li>Mes meilleurs plugins Krew</li> <li>Manage son $KUBECONFIG</li> <li>Outils pour mieux g\u00e9rer K8S</li> <li>Resize les PVC de ses Statefulset</li> </ul>"},{"location":"#operators-k8s","title":"Operators K8S","text":"<ul> <li>Red\u00e9marrer un cluster Strimzi</li> </ul>"},{"location":"#deploiement-sur-k8s","title":"Deploiement sur K8S","text":"<ul> <li>Golang : D\u00e9finir automatiquement son GOMEMLIMIT/GOMAXPROCS</li> </ul>"},{"location":"#argocd","title":"ArgoCD","text":"<ul> <li>Creer un service account</li> </ul>"},{"location":"#troubleshooting-k8s","title":"Troubleshooting K8S","text":"<ul> <li>Debug son ServiceAccount</li> </ul>"},{"location":"#rancher","title":"Rancher","text":"<ul> <li>Reset son password Rancher</li> <li>Bootstrap rapidement son cluster</li> </ul>"},{"location":"#terraform","title":"Terraform","text":"<ul> <li>Cheatsheet terraform</li> <li>Tools Terraform indispensables</li> <li>Acc\u00e9lerer Terraform</li> </ul>"},{"location":"#gitlab","title":"Gitlab","text":"<ul> <li>Optimiser sa CI Gitlab</li> <li>Int\u00e9grer un scan d'image \u00e0 sa CI</li> <li>Utilisation de la CLI officielle</li> </ul>"},{"location":"#docker","title":"Docker","text":"<ul> <li>Docker: l'indispensable</li> <li>Utiliser un proxy pour pull les images Docker</li> <li>Templates docker-compose</li> </ul>"},{"location":"#divers_1","title":"Divers","text":"<ul> <li>T\u00e9l\u00e9charger ses sous-titres en ligne de commande</li> <li>Gagner de la place en supprimant les locales inutiles</li> <li>Enlever les paquets \"rc\" sur dpkg</li> <li>Ajouter de la couleur \u00e0 la commande man</li> <li>Trouver les options de compilation du kernel</li> <li>R\u00e9initialiser son mot de passe root</li> <li>Convertir des .bin en .iso</li> <li>dfc, la commande df en plus</li> <li>M\u00e9mo sur la commande sed</li> <li>Obtenir des informations sur vos PDF</li> </ul>"},{"location":"#web","title":"Web","text":""},{"location":"#benchmark","title":"Benchmark","text":"<ul> <li>Benchmark avec une random query string</li> </ul>"},{"location":"#wordpress","title":"WordPress","text":"<ul> <li>Requ\u00eates SQL pour migrer son WordPress</li> <li>Requ\u00eates SQL afin d'optimiser son site</li> </ul>"},{"location":"#linux-bsd","title":"Linux BSD","text":"<ul> <li>Ajouter un utilisateur au groupe wheel</li> </ul>"},{"location":"#linux-centos","title":"Linux CentOS","text":"<ul> <li>Ajouter les repositories EPEL</li> </ul>"},{"location":"#proxmox","title":"Proxmox","text":"<ul> <li>Ajouter un ISO depuis une URL</li> <li>R\u00e9soudre l'erreur \"VM is locked\"</li> <li>NAT pour les VMs Debian</li> <li>G\u00e9rer son cluster Proxmox</li> <li>Cr\u00e9er sa VM en CLI avec cloud-init</li> <li>Bootstrap correctement son Proxmox</li> </ul>"},{"location":"#codage","title":"Codage","text":"<ul> <li>SublimeText3 Best Tips</li> </ul>"},{"location":"#torrent","title":"Torrent","text":"<ul> <li>ruTorrent le polyvalent</li> <li>Flood le sublime</li> <li>Transmission, le client torrent facile</li> <li>Deluge, l'agressif</li> <li>Creer ses torrents avec mktorrent</li> </ul>"},{"location":"#acces-a-distance","title":"Acc\u00e8s \u00e0 distance","text":"<ul> <li>Une multitude d'acc\u00e8s \u00e0 distance via la WebApp Guacamole</li> <li>Acc\u00e8s \u00e0 distance via TeamViewer (TV.md)</li> <li>Acc\u00e8s \u00e0 distance via VNC</li> </ul>"},{"location":"#networking","title":"Networking","text":"<ul> <li>Tester la bande passante effective de son serveur avec des \"proofs files\"</li> <li>V\u00e9rifi\u00e9 l'\u00e9tat du r\u00e9seau avec la Weathermap</li> <li>Lister les pr\u00e9fixes annonc\u00e9s par un ASN</li> </ul>"},{"location":"#pfsense","title":"pfSense","text":"<ul> <li>Mise \u00e0 jour de la bogon list via l'interface graphique</li> <li>Ajouter une gateway en dehors de son r\u00e9seau</li> </ul>"},{"location":"#cisco","title":"Cisco","text":"<ul> <li>Commandes de base Cisco</li> <li>Cr\u00e9ation de VLAN Cisco</li> <li>QOS Cisco</li> <li>D\u00e9sactiver la recherche DNS sur du mat\u00e9riel Cisco</li> <li>Informations utiles sur le STP</li> <li>Serveur SSH</li> <li>Installer un serveur DHCP sur un routeur Cisco</li> <li>Accro\u00eetre la s\u00e9curit\u00e9</li> <li>Routage inter-VLAN</li> <li>Protocole CDP</li> <li>Protocole LLDP</li> <li>D\u00e9sactiver la propagation du TTL en MPLS</li> <li>Tunnel Automatic 6to4</li> <li>OSPF en IPv6</li> <li>Autoriser les transceiver no-name</li> </ul>"},{"location":"#mac-os-x","title":"Mac OS X","text":"<ul> <li>Brew, l'apt-get d'Apple</li> <li>Brew: L'installer sans XCode</li> <li>Informations sur MindView</li> <li>Enlever le premier caract\u00e8re bizarre de iTerm</li> <li>Remap le Alt+Arrow de iTerm</li> </ul>"},{"location":"#mikrotik","title":"Mikrotik","text":"<ul> <li>Installer son tunnel IPSec</li> <li>Ne pas router Netflix \u00e0 travers son tunnel IPSEC</li> </ul>"},{"location":"#esxi","title":"ESXi","text":"<ul> <li>Acceder \u00e0 la console de l'ESXi</li> <li>Commandes network ESXi utiles</li> <li>Uploader ses ISO en ligne de commande</li> </ul>"},{"location":"#netapp","title":"NetApp","text":"<ul> <li>Rep\u00e9rer un disque dur d\u00e9faillant en le faisant clignoter</li> </ul>"},{"location":"#windows","title":"Windows","text":""},{"location":"#server","title":"Server","text":"<ul> <li>Setup de base d'un Windows 2012 R2</li> <li>Monter un ISO directement via PowerShell</li> <li>Installer et configurer un serveur DHCP en PowerShell</li> <li>Installer et configurer un serveur AD en PowerShell</li> <li>Creer un pool de stockage en PowerShell</li> <li>Autoriser l'ICMP sur un serveur Windows 2012R2 en PowerShell</li> <li>Importer des utilisateurs CSV dans un AD via PowerShell</li> <li>Cl\u00e9s de Registre Utiles</li> <li>Ex\u00e9cuter un script PowerShell via une t\u00e2che planifi\u00e9e</li> <li>D\u00e9sactiver TLSv1 sur IIS via un script PowerShell</li> <li>Connaitre le temps d'ex\u00e9cution d'une commande PowerShell</li> <li>Acc\u00e9der au Firewall sans Ic\u00f4ne ni raccourci</li> <li>Variables built-in utiles</li> <li>Initier des connexions iSCSi en CLI</li> <li>Installer des drivers via PowerShell</li> <li>D\u00e9finir PowerShell en temps que shell par d\u00e9faut</li> </ul>"},{"location":"#desktop","title":"Desktop","text":"<ul> <li>Windows 10 : Comment activer la gestion des chemins trop long ?</li> <li>Am\u00e9liorer sa vie priv\u00e9e et les performances avec Blackbird</li> <li>Bloquer les serveurs d'activation via le fichiers hosts</li> <li>Installer tous les logiciels de base via un simple installateur</li> </ul>"},{"location":"#misc_1","title":"Misc","text":"<ul> <li>Mes sources</li> <li>Bordel de liens utiles</li> <li>Monitoring des performances sous Linux</li> <li>Optimisation</li> <li>Scripts utiles</li> <li>G\u00e9n\u00e9rer un template pour ses Pull Request et ses Issues</li> <li>Lancer la console iLO/iDRAC depuis un Mac</li> <li>Lancer une ancienne console iLO</li> <li>ILO Advanced Key</li> <li>Western Digital Green HDD, Comment pr\u00e9munir le old_age pr\u00e9matur\u00e9</li> <li>Informations utile sur les d\u00e9nominations fibre optique</li> <li>T\u00e9l\u00e9charger les sous-titres Netflix simplement</li> </ul>"},{"location":"docker/","title":"Docker : L'indispensable","text":""},{"location":"docker/#docker","title":"Docker ?","text":""},{"location":"docker/#installation","title":"Installation","text":""},{"location":"docker/#les-dockerfiles","title":"Les Dockerfiles","text":""},{"location":"docker/#relier-2-ct","title":"Relier 2 CT","text":""},{"location":"docker/#variables-docker","title":"Variables Docker","text":""},{"location":"docker/#volumes","title":"Volumes","text":""},{"location":"docker/#variables-denvironnement","title":"Variables d'environnement","text":""},{"location":"guacamole/","title":"Guacamole : l'outil id\u00e9al pour \u00e9tablir des sessions RDP, SSH et VNC","text":"<p>Warning</p> <p>Avec l'arriv\u00e9e de GoTeleport (Bastion SSH/K8S via RBAC, recording de session...), je trouve l'usage de Guacamole d\u00e9mod\u00e9.</p>"},{"location":"guacamole/#installation-sous-debian","title":"Installation sous Debian","text":""},{"location":"guacamole/#explications","title":"Explications","text":"<p>L'application Guacamole se compose de 3 parties :</p> <ol> <li>Guacamole server qui \u00e9coute sur le port TCP 4722 sur la boucle     locale</li> <li>Tomcat server qui met \u00e0 disposition et interpr\u00e8te les servlets Java     sur le port TCP 8080</li> <li>fournis par Guacamole client (le fichier guacamole.war qui peut \u00eatre     construit \u00e0 partir des sources du client ou directement t\u00e9l\u00e9charg\u00e9)</li> </ol> <p>Si vous \u00eatre r\u00e9fractaire au Java, passez votre chemin.</p>"},{"location":"guacamole/#prerequis","title":"Pr\u00e9requis","text":"<p>Il faut poss\u00e9der une Debian \u00e0 jour. Comme il n'y a plus de paquets officiels, nous devons donc le compiler \u00e0 la main.</p> <p>Warning</p> <p>Certains noms de d\u00e9pendances changent si vous \u00eates sous Ubuntu ou Debian, veuillez consulter la documentation</p> <p>Vous devez installer Tomcat 9/10 comme d\u00e9crit dans cette page.</p> <pre><code>sudo apt install build-essential tomcat10 libjpeg62-turbo-dev libjpeg62-dev libpng-dev libtool-bin uuid-dev libossp-uuid-dev libpulse-dev libcairo2-dev libssl-dev libvncserver-dev libvorbis-dev libtelnet-dev libssh2-1-dev libpango1.0-dev freerdp2-dev libwebsockets-dev libwebp-dev\n</code></pre> <p>Info</p> <p>Il est possible d'obtenir la derni\u00e8re derni\u00e8re version en utilisant le repository Git</p> <pre><code>wget --content-disposition -O - http://apache.org/dyn/closer.cgi?action=download&amp;filename=guacamole/1.5.2/source/guacamole-client-1.5.2.tar.gz | tar xfvz -\nwget --content-disposition -O - http://apache.org/dyn/closer.cgi?action=download&amp;filename=guacamole/1.5.2/source/guacamole-server-1.5.2.tar.gz | tar xfvz -\nwget -O guacamole-1.5.2.war \"http://apache.org/dyn/closer.cgi?action=download&amp;filename=guacamole/1.5.2/binary/guacamole-1.5.2.war\"\n</code></pre>"},{"location":"guacamole/#compilation-et-installation-du-serveur","title":"Compilation et installation du serveur","text":"<p>Pr\u00e9voir un fix concernant les biblioth\u00e8ques FreeRDP (points 7, 8, 9).</p> <pre><code>cd guacamole-server*\n./configure --with-systemd-dir=/etc/systemd/system\nmake -j$(nproc)\nsudo make install\nsudo mkdir /usr/lib/x86_64-linux-gnu/freerdp/\nsudo ln -s /usr/local/lib/freerdp/*.so /usr/lib/x86_64-linux-gnu/freerdp/\nsudo ldconfig\n</code></pre>"},{"location":"guacamole/#installation-du-client","title":"Installation du client","text":"<pre><code>sudo cp guacamole-1.5.2.war /var/lib/tomcat10/webapps/guacamole.war\n</code></pre> <p>Vous pouvez en lieu et place utiliser maven \u00e0 partir des sources du client pour compiler le fichier war.</p>"},{"location":"guacamole/#installation-des-fichiers-de-configuration","title":"Installation des fichiers de configuration","text":"<p>Important, les droits de l'utilisateur tomcat10 sur le fichier <code>user-mapping.xml</code> sont indispensables.</p> <pre><code>sudo mkdir {/etc/guacamole,/usr/share/tomcat10/.guacamole}\nsudo cp guacamole-client-1.5.2/guacamole/doc/example/{guacamole.properties,user-mapping.xml} /etc/guacamole/\nsudo ln -s /etc/guacamole/guacamole.properties /usr/share/tomcat10/.guacamole/guacamole.properties\nsudo chown tomcat10 /etc/guacamole/user-mapping.xml\nsudo chmod 600 /etc/guacamole/user-mapping.xml\n</code></pre>"},{"location":"guacamole/#configuration","title":"Configuration","text":"<p>Le fichier <code>guacamole.properties</code> \u00e0 \u00e9diter ou v\u00e9rifier avant de red\u00e9marrer les services :</p> <pre><code>     # Hostname and port of guacamole proxy\n     guacd-hostname: localhost\n     guacd-port:     4822\n     # Auth provider class (authenticates user/pass combination, needed if using the provided login screen)\n     # Le chemin vers user-mapping.xml doit \u00eatre un chein complet et non relatif !\n     auth-provider: net.sourceforge.guacamole.net.basic.BasicFileAuthenticationProvider\n     basic-user-mapping: /etc/guacamole/user-mapping.xml\n</code></pre> <p>Pour le fichier user-mapping.xml, r\u00e9f\u00e9rez-vous \u00e0 la documentation officielle.</p> <ul> <li>[D\u00e9marrage]{.underline}</li> </ul> <pre><code>sudo systemctl tomcat10.service restart\nsudo systemctl guacd.service restart\n</code></pre> <p>L'url http://fqdn:8080/guacamole doit vous permettre d'acc\u00e9der \u00e0 l'application. Toutefois, tout transite en clair sur le r\u00e9seau et rien n'est s\u00e9curis\u00e9.</p> <ul> <li>[Reverse proxy avec nginx]{.underline}</li> </ul> <p>Le reverse proxy en question, je vous \u00e9pargne la partie li\u00e9e \u00e0 TLS qui est indispensable.</p> <pre><code>       location / {\n                proxy_pass http://localhost:8080/guacamole;\n                proxy_buffering off;\n                proxy_cookie_path /guacamole/ /; #indispensable pour se connecter\n                proxy_http_version  1.1;\n                include conf.d/proxy.conf;\n        }\n</code></pre>"},{"location":"guacamole/#acces-et-utilisation","title":"Acc\u00e8s et utilisation","text":"<p>Rendez-vous sur la page https://fqdn/ et ins\u00e9rez le nom d'utilisateur et votre mot de passe (pr\u00e9f\u00e9rez le hash MD5, ce n'est mieux que rien). Il est \u00e9galement possible de g\u00e9rer de fa\u00e7on avanc\u00e9e les utilisateurs avec mysql ou pgsql, chose que je ne traite pas ici.</p>"},{"location":"cloud/aws/cli/","title":"AWS : CLI","text":""},{"location":"cloud/aws/cli/#ec2","title":"EC2","text":""},{"location":"cloud/aws/cli/#infos-basiques","title":"Infos basiques","text":"<p>Nous allons partir d'une query assez simple pour lister quelques \u00e9l\u00e9ments basiques</p> <pre><code>aws ec2 describe-instances \\\n--query \"Reservations[*].Instances[*].{PublicIP:PublicIpAddress,Type:InstanceType,Name:Tags[?Key=='Name']|[0].Value,Status:State.Name}\"  \\\n--filters \"Name=instance-state-name,Values=running\" \"Name=tag:Name,Values='*'\"  \\\n--output table\n----------------------------------------------------------------------------------------\n|                                   DescribeInstances                                  |\n+----------------------------------------+-----------------+----------+----------------+\n|                  Name                  |    PublicIP     | Status   |     Type       |\n+----------------------------------------+-----------------+----------+----------------+\n|  tools-gitlab-us8-1                    |  54.211.83.90   |  running |  m6i.2xlarge   |\n|  tools-exporter-us8-1                  |  34.72.143.122  |  running |  m6a.large     |\n|  worker-backend-us8-1                  |  52.1.189.213   |  running |  m6i.12xlarge  |\n|  manage-lol-us8-11                     |  44.207.28.28   |  running |  m6i.16xlarge  |\n|  manage-lol-us8-12                     |  5.212.172.162  |  running |  m6i.16xlarge  |\n+----------------------------------------+-----------------+----------+----------------+\n</code></pre> <p>Comme nous utilisons souvent les VPC (&amp; privatez IP) sur AWS, nous pouvons \u00e9galement les afficher via la query suivante</p> <pre><code> aws ec2 describe-instances \\\n --query \"Reservations[*].Instances[*].{PublicIP:PublicIpAddress,PrivateIP:PrivateIpAddress,Name:Tags[?Key=='Name']|[0].Value,Type:InstanceType,Status:State.Name,VpcId:VpcId}\" \\\n --filters Name=instance-state-name,Values=running \\\n--output table\n-------------------------------------------------------------------------------------------------------------------------\n|                                                   DescribeInstances                                                   |\n+----------------------------------------+----------------+-----------------+----------+---------------+----------------+\n|                  Name                  |   PrivateIP    |    PublicIP     | Status   |     Type      |     VpcId      |\n+----------------------------------------+----------------+-----------------+----------+---------------+----------------+\n|  tools-gitlab-us8-1                    |  172.21.2.12   |  54.211.83.90   |  running |  m6i.2xlarge  |  vpc-ddd373b8  |\n|  tools-exporter-us8-1                  |  172.21.254.12 |  34.72.143.122  |  running |  m6a.large    |  vpc-ddd373b8  |\n|  worker-backend-us8-1                  |  172.21.5.11   |  52.1.189.213   |  running |  m6i.12xlarge |  vpc-ddd373b8  |\n|  manage-lol-us8-11                     |  172.21.12.31  |  44.207.28.28   |  running |  m6i.16xlarge |  vpc-ddd373b8  |\n|  manage-lol-us8-12                     |  172.21.12.32  |  5.212.172.162  |  running |  m6i.16xlarge |  vpc-ddd373b8  |\n+----------------------------------------+----------------+-----------------+----------+---------------+----------------+\n</code></pre>"},{"location":"cloud/aws/cli/#filtrage","title":"Filtrage","text":"<p>Il est \u00e9galement possible d'ajouter des filtres sur le gabarit. Par exemple, si nous souhaitons que les <code>m6i.16xlarge</code></p> <pre><code>aws ec2 describe-instances \\\n--query \"Reservations[*].Instances[*].{PublicIP:PublicIpAddress,Type:InstanceType,Name:Tags[?Key=='Name']|[0].Value,Status:State.Name}\"  \\\n--filters \"Name=instance-state-name,Values=running\" \"Name=instance-type,Values='m6i.16xlarge'\" \\\n--output table\n----------------------------------------------------------------------------------------\n|                                   DescribeInstances                                  |\n+----------------------------------------+-----------------+----------+----------------+\n|                  Name                  |    PublicIP     | Status   |     Type       |\n+----------------------------------------+-----------------+----------+----------------+\n|  manage-lol-us8-11                     |  44.207.28.28   |  running |  m6i.16xlarge  |\n|  manage-lol-us8-12                     |  5.212.172.162  |  running |  m6i.16xlarge  |\n+----------------------------------------+-----------------+----------+----------------+\n</code></pre> <p>Il est possible d'utiliser des regex. Si nous souhaitons toutes les m6i, nous allons donc utiliser le filtre suivant : <code>Name=instance-type,Values='m6i.*'</code></p> <p>Vous pouvez tester vos expressions r\u00e9guli\u00e8res en ligne avec des outils comme Regex101 ou Pyrexp.</p> <p>Beaucoup d'autres exemples sont disponibles ici</p>"},{"location":"cloud/aws/cli/#rds","title":"RDS","text":"<pre><code>aws rds describe-db-parameters --db-parameter-group-name &lt;PG_name&gt; --region &lt;region&gt; --query \"Parameters[?Source=='user' || ApplyMethod=='immediate'].[ParameterName]\" --output text\n</code></pre> <p>Petite query pour lister les options qui ont \u00e9t\u00e9 modifi\u00e9 au sein d'un parameter group</p>"},{"location":"cloud/aws/decode_error_aws/","title":"Decoder un message d'erreur AWS","text":"<p>Dans Kubernetes ou autre, nous pouvons avoir un payload AWS encod\u00e9 qui contient une erreur AWS, par exemple :</p> <pre><code>ebs-csi-controller-7d64bcb848-dnrkc ebs-plugin     rpc error: code = Internal desc = Could not attach volume \"vol-0258901b6a2b73351\" to node \"i-06a93e7546605d65a\": could not attach volume \"vol-0258901b6a2b73351\" to node \"i-06a93e7546605d65a\": UnauthorizedOperation: You are not authorized to perform this operation. Encoded authorization failure message: N1ZRrJ6sHnCD0Kf7vWhqtRr5iyt5LXi6x2HR4UZuAy3WDHA6tS-0IP1mlVzuPU9K7C2FMrqTzL8uoFLVk4e2Pp58_K8SODg-0dCNascwZgZ9ubNXzAiegkQuho1aQUO6qH7Q4RdTg4kDfl9aocvzrSpCu66z6U3_4s-sd3TjpTOrqw9Je1Umhk7LD2YetnFammK9fJSZyjvknv_7yWs08-5IpVt3EAwWGmmxvxBlHf0WbnpUP7GSE_9C3ux5tlbzOzNtX3lRmoKNbYFU2ygwNH_el4PDny_7jgjlZMnm_oGFqyo4trcPXOAZ0_Fg68qnCOSm_q2L-kXYAmMyNva238kI9ruYtUKCvd2ihOAuHQ0vQgN4rjjQ82Mu2SNwe-jSb3h2uht1vAALfT38g9AR33dIkiq43TtsEKnQiKlV29dygZal_Fwg7E1BlHl2wkj5zhWvRVN_mQ_LKY_6NQ1xnRWTqBrncCq5zxI1duoUK9nIoS_yM-a5dKNiFesqDNjtwHVMMra1mTw2vil86TnOHjaGFKg1PhCjXS9zPldWNVGvG6wdCOH38JL7xBt7iTF4saJG7skHq5XjdYmLxGTYiqP5gKTNLLKOEL9beGvAta2NpwzZJafLi7CQ0Je6Cu2yoc9eHdIgbIvziVFdGHz7Z-iePmPQ59IsHO_4Ra7oLd7tpauOKyOeKDTI9CxY_4qOkrG7C5V-alDc0RuhWWiKmcLi2BIoaIHWUebvUBgypC9XOCa4JD1q7dhQst137D6RBaISmr5FiITxaXZpg02HjPXiuf3IPkv3Krw46SeCj_k7sjpagu1dswT21ezaJv4rApbdTguHazEfpxSXCQqNJ9A0ItF\n</code></pre> <p>Heureusement, il est possible de d\u00e9coder ce message pour savoir ce qu'il se passe. Pour cela, nous avons besoin de aws-cli, jq. Une petite fonction bash va faire de la magie</p> <pre><code>decode_aws () {\n    error=`aws sts decode-authorization-message --encoded-message $@ | jq .DecodedMessage`\n    json_err=\"${error:1: -1}\"\n    echo $json_err | gsed 's|\\\\\"|\"|g' | jq .\n}\n</code></pre> <p>Nous pouvons pipe l'output vers fx pour avoir un bel affichage. Voil\u00e0 ce que \u00e7a donne</p> <p></p> <p>On peut facilement voir ici que la polirique n'a pas la rule pour monter le volume EBS. Nous pouvons donc facilement debug le probleme :)</p>"},{"location":"cloud/aws/glossaire/","title":"Glossaire du vocabulaire AWS","text":"<p>AWS c'est beaucoup de vocabulaire \u00e0 maitriser pour au final des fonctionnalit\u00e9s basiques dans la plupart des cas. Voici donc un petit bout de papier (ou plut\u00f4t de code) pour expliquer les services courants que nous utilisons</p>"},{"location":"cloud/aws/glossaire/#nom-des-services","title":"Nom des services","text":""},{"location":"cloud/aws/glossaire/#compute","title":"Compute","text":"Nomenclature AWS Utilit\u00e9 Doc AWS EC2 Virtual Machine ici Lambda Serverless ici"},{"location":"cloud/aws/glossaire/#storage","title":"Storage","text":"Nomenclature AWS Utilit\u00e9 Doc AWS S3 Object Storage ici S3 Glacier Object Storage Low Cost ici EBS Block Storage ici"},{"location":"cloud/aws/glossaire/#service-manage","title":"Service Manag\u00e9","text":"Nomenclature AWS Utilit\u00e9 Doc AWS AuroraDB MySQL / PostgreSQL ici CloudSearch Elastic Search ici DynamoDB NoSQL ici EKS Kubernetes ici ElastiCache Redis / Memcached ici RDS MySQL / PostgreSQL ici Route53 Serveur DNS autoritaire ici SQS RabbitMQ ici"},{"location":"cloud/aws/glossaire/#network","title":"Network","text":"Nomenclature AWS Utilit\u00e9 Doc AWS VPC Interconnection de EC2 ici Direct Connect Connexion direct \u00e0 AWS ici"},{"location":"cloud/azure/ephemeral_disks/","title":"EphemeralDisks : comment faire ?","text":"<p>Les EphemeralDisks sur Azure peuvent \u00eatre pratiques pour \u00e9conomiser de l'argent sur les VMs Spots.</p> <p>Attention, tous les SKU ne sont pas compatibles avec les EphemeralDisks. Pour savoir si votre gamme l'est :</p> <pre><code>az vm list-skus --location westeurope --size d4as\n      {\n        \"name\": \"EphemeralOSDiskSupported\",\n        \"value\": \"False\"\n      },\n</code></pre> <p>Ici, notre gamme n'est pas compatible.</p> <p>Les gammes compatibles contiennent un d dans leur gabarit, par exemple les d4a*ds (quelque soit la g\u00e9n\u00e9ration)</p> <pre><code>az vm list-skus --location westeurope --size d4ads_v5\n      {\n        \"name\": \"EphemeralOSDiskSupported\",\n        \"value\": \"True\"\n      },\n</code></pre>"},{"location":"cloud/gcloud/follow_gke_upgrade/","title":"Suivre l'upgrade de son cluster GKE","text":"<p>Pour suivre l'upgrade de son cluster, rien de plus simple en CLI</p> <pre><code>\u279c  ~ CLOUDSDK_CORE_PROJECT=infra-tooling-prod gcloud container operations list\nNAME                                                          TYPE            LOCATION      TARGET                            STATUS_MESSAGE  STATUS   START_TIME                      END_TIME\noperation-1711096877589-18d83587-5e25-450c-b618-b654f799abde  UPGRADE_MASTER  europe-west9  base                                              DONE     2024-03-22T08:41:17.589291471Z  2024-03-22T09:01:56.984453011Z\noperation-1711098166505-0ead2ed8-bc2c-4ff0-924f-fe5b826f66f1  UPGRADE_NODES   europe-west9  base-nodes                                        DONE     2024-03-22T09:02:46.505484674Z  2024-03-22T09:15:41.09066521Z\noperation-1711184536102-5758fd6d-2243-433a-b476-8dbd31f5084b  UPDATE_CLUSTER  europe-west9  base                                              DONE     2024-03-23T09:02:16.102882095Z  2024-03-23T09:23:14.850134991Z\noperation-1711448273774-b837afd1-1408-4541-b019-92c202f6d7b8  UPGRADE_MASTER  europe-west9  base                                              DONE     2024-03-26T10:17:53.77434957Z   2024-03-26T10:39:25.616070515Z\noperation-1711449573743-d652f291-4296-4ac4-b70f-90c34955d19c  UPGRADE_NODES   europe-west9  base-nodes                                        DONE     2024-03-26T10:39:33.743427117Z  2024-03-26T10:53:50.945336487Z\noperation-1711450953708-c2a224b6-c4ba-42c7-801c-c37b01f84885  UPGRADE_MASTER  europe-west9  base                                              DONE     2024-03-26T11:02:33.70891765Z   2024-03-26T11:22:19.967213551Z\noperation-1711452142084-2c24cb00-60f0-453d-971a-bf4aafda29fb  UPGRADE_NODES   europe-west9  base-nodes                                        DONE     2024-03-26T11:22:22.08417734Z   2024-03-26T11:32:23.889954201Z\noperation-1711457585106-9929c0ea-8691-49b2-b769-6ca7fad1a804  UPGRADE_MASTER  europe-west9  tooling-gcp-europe-west9                          DONE     2024-03-26T12:53:05.106418842Z  2024-03-26T13:13:13.718667912Z\noperation-1711458817372-c0195207-cfe4-4043-b42c-ce7f1a213154  UPGRADE_NODES   europe-west9  tooling-gcp-europe-west9-default                  RUNNING  2024-03-26T13:13:37.372498057Z\n</code></pre> <p>Il peut \u00eatre important de pr\u00e9ciser le <code>CLOUDSDK_CORE_PROJECT</code> si nous souhaitons follow plusieurs projects Google au m\u00eame moment</p>"},{"location":"cloud/gcloud/misc_commands/","title":"Commandes utiles pour la CLI Gcloud","text":"<pre><code>CLOUDSDK_CORE_PROJECT=&lt;GCP_PROJECT&gt; gcloud beta sql connect &lt;INSTANCE_NAME&gt; --database=&lt;DB_NAME --user=&lt;USER_SQL&gt;\n</code></pre> <p>Permet de se connecter a n'importe quelle instance CloudSQL facilement sur le project que vous souhaitez.</p> <p>Il vous faudra probablement le cloud-sql-proxy, pour cela : <code>gcloud components install cloud_sql_proxy</code></p> <pre><code>gcloud compute ssh &lt;NODE_NAME&gt; --zone &lt;ZONE&gt;\n</code></pre> <p>Pour se connecter a un noeud GKE en SSH, possible de faire un <code>gcloud compute instances list</code> avant pour lister les noeuds</p>"},{"location":"code/st3/","title":"St3","text":""},{"location":"code/st3/#sublimetext-le-codage-efficace","title":"SublimeText : Le codage Efficace","text":""},{"location":"code/st3/#preambule","title":"Pr\u00e9ambule","text":"<p>SublimeText est actuellement l'un des \u00e9diteurs les plus pris\u00e9s du moment. Et pour cause, SublimeText g\u00e8re une multitude de formats, dispose d'une tonne de fonctionnalit\u00e9s, tout \u00e7a en \u00e9tant simple d'utilisation. Malgr\u00e9 le fait que SublimeText est de base un excellent \u00e9diteur, il existe une multitude d'astuces, de shortcuts, et de plugins pour encore le rendre encore plus performant, c'est ce que nous allons voir dans ce post.</p>"},{"location":"code/st3/#pre-requis","title":"Pr\u00e9-requis","text":"<p>Pour fonctionner, la majorit\u00e9 de ces paquets auront besoin de PHP (5.6.'* minimum), il est donc indispensable de l'avoir !</p> <p>Pour les composants plus sp\u00e9cifiques aux plugins, nous verrons cela dans leur section.</p>"},{"location":"code/st3/#shortcuts","title":"Shortcuts","text":"<p>En r\u00e8gle g\u00e9n\u00e9ral, si X fait une action, MAJ + X fera l'action oppos\u00e9e. Par exemple, Tab indente la ligne, alors que MAJ + Tab '\"d\u00e9sindentera'\" la ligne.</p>"},{"location":"code/st3/#sublime-text","title":"Sublime Text","text":"<p>Edition</p> <p>Ctrl + C Ctrl + V Ctrl + X Ctrl + \u21e7 + K Ctrl + \u21a9 Ctrl + \u21e7 + \u21a9 Ctrl + \u21e7 + \u2191 Ctrl + \u21e7 + \u2193 Ctrl + L Ctrl + D Ctrl + M Ctrl + \u21e7 + M Ctrl + KK Ctrl + K + \u232b \u21e7 Ctrl + '] Ctrl + '[ \u21e7 + \u21c6 Ctrl + \u21e7 + D Ctrl + J Ctrl + / Ctrl + \u21e7 + / Ctrl + Y Ctrl + Space</p> <p>Navigation</p> <p>Ctrl + P Ctrl + R</p> <p>General</p> <p>Ctrl + \u21e7 + P Ctrl + KB</p> <p>Chercher/Remplacer</p> <p>Ctrl + F Ctrl + H Ctrl + \u21e7 + F</p> <p>Tabs</p> <p>Ctrl + \u21e7 + t Ctrl + PgDn Ctrl + PgUp Ctrl + \u21c6</p> <p>Fen\u00eatrage</p> <p>Alt + \u21e7 + 2 Alt + \u21e7 + 1 Alt + \u21e7 + 5 Ctrl + '[1,2,3,4']</p> <p>Favoris</p> <p>Ctrl + F2 F2 \u21e7 + F2 Ctrl + \u21e7 + F2</p> <p>Texte manipulation</p> <p>Ctrl + KU Ctrl + KL</p>"},{"location":"code/st3/#plugins","title":"Plugins","text":"<p>Alignment</p> <p>Ctrl + Alt + A</p> <p>Color Highlighter</p> <p>CTRL + \u21e7 + C</p> <p>Emmet</p> <p>CTRL + Alt + \u21a9</p> <p>Gist</p> <p>CTRL + KO CTRL + KP CTRL + KI CTRL + KS</p> <p>SFTP</p> <p>CTRL + Alt + RB CTRL + Alt + UI</p> <p>Code Formatter</p> <p>CTRL + Alt + F</p>"},{"location":"code/st3/#fenetrage","title":"Fen\u00eatrage","text":"<p>De base, comme toute application, sublime texte dispose d'une seule fen\u00eatre principale, puis nous pouvons faire diff\u00e9rents d\u00e9coupages :</p> <p></p>"},{"location":"code/st3/#configuraton","title":"Configuraton","text":"<p>La configuration de base de SublimeText est d\u00e9j\u00e0 excellente, mais il y a certaines options qui m\u00e9riteraient d'\u00eatre activ\u00e9es par d\u00e9faut, mais qui ne le sont pas.</p> <p>Les modifications que nous allons faire (Et m\u00eame celles pour les plugins) n'affectent par la configuration par d\u00e9faut, ce qui nous permet de toujours avoir de vue les options par d\u00e9faut si n\u00e9c\u00e9ssaire.</p> <p>L'\u00e9criture des fichiers de configuration se fait en JSON, et est donc facilement compr\u00e9hensible.</p> <p>Voici mon fichier de configuration Sublime Text :</p> <pre><code>{\n    \"always_show_minimap_viewport\": true,\n    \"bold_folder_labels\": true,\n    \"indent_guide_options\":\n    [\n        \"draw_normal\",\n        \"draw_active\"\n    ],\n    \"ignored_packages\":\n    [\n      \"Vintage\"\n    ],\n    \"line_padding_bottom\": 3,\n    \"line_padding_top\": 3,\n    \"overlay_scroll_bars\": \"enabled\",\n    \"save_on_focus_lost\": true,\n    \"highlight_line\": true,\n    \"default_line_ending\": \"unix\",\n    \"shift_tab_unindent\": true,\n    \"show_encoding\": true,\n    \"translate_tabs_to_spaces\": true,\n    \"highlight_modified_tabs\": true,\n    \"file_exclude_patterns\":\n    [\n        \".DS_Store\",\n        \"*.lib\",\n        \"*.log\"\n    ],\n    \"folder_exclude_patterns\":\n    [\n        \".git\",\n        \".bundle\",\n        \".sass-cache\",\n        \".svn\",\n        \".hg\"\n    ],\n}\n</code></pre> <p>Nous allons d\u00e9crire chaque ligne :</p> <ul> <li><code>always_show_minimap_viewport</code> : Converse une vue sur la minimap     d'o\u00f9 l'on se situe dans le fichier, utile selon moi</li> <li><code>bold_folder_labels</code> : Permet de mettre en gras les dossiers dans     la sidebar lors d'un projet</li> <li><code>indent_guide_options</code> : Permet une indentation plus ais\u00e9e, en     affichant une grille d'indentation, indispensable</li> <li><code>ignored_packages</code> : D\u00e9sactive des packages (Il est imp\u00e9ratif de     d\u00e9sactiver le package Vintage pour ne pas se retrouver avec un mode     vi)</li> <li><code>line_padding_bottom</code> et <code>line_padding_bottom</code> : Permet une mise     en forme plus ais\u00e9e de SublimeText, nos yeux nous disent merci. La     valeur <code>4</code> est \u00e9galement agr\u00e9able, mais le padding est trop     important</li> <li><code>overlay_scroll_bars</code> : D\u00e9sactive l'affichage automatique des     bars de scroll (Qui ne sont pas utiles)</li> <li><code>save_on_focus_lost</code> : L'option la plus utile de SublimeText,     elle permet de sauvegarder automatiquement les onglets lorsque     SublimeText n'est plus la fen\u00eatre active, indispensable</li> <li><code>highlight_line</code> : Surligne la ligne o\u00f9 l'on se trouve, assez     pratique pour ne pas \u00eatre perdu</li> <li><code>default_line_ending</code> : Afin de suivre le standard, nous devons     passer \u00e0 un Line Ending format UNIX</li> <li><code>shift_tab_unindent</code> : Autre option assez pratique, elle nous     permet de se situer n'importe o\u00f9 dans la ligne pour d\u00e9faire     l'indentation, et non plus seulement au d\u00e9but de la ligne</li> <li><code>show_encoding</code> : Affiche l'encodage actuel du fichier, pratique     pour v\u00e9rifier si l'on est en UTF-8</li> <li><code>translate_tabs_to_spaces</code> : Convertit les tabs en espace. Peut     \u00eatre utile afin de s'assurer que notre tabsize sera identique de     partout</li> <li><code>file_exclude_patterns</code> et <code>folder_exclude_patterns</code> : Permet     d'exclure des fichiers de la sidebar. Un grand nombre d'\u00e9l\u00e9ments     sont ignor\u00e9s par d\u00e9faut, mais cependant, il en manque certains</li> </ul> <p>Pour correspondre parfaitement au PSR, je vous indique \u00e0 aller voir le post de ce monsieur, ainsi que les liens officiels des PSR :</p> <ul> <li>PSR-2</li> <li>PSR-1</li> </ul>"},{"location":"code/st3/#themes","title":"Th\u00e8mes","text":"<p>De base, je trouve le th\u00e8me de SublimeText tout simplement affreux, c'est pour cela que j'ai s\u00e9lectionn\u00e9 2 th\u00e8mes que je juge superbes.</p>"},{"location":"code/st3/#material-design","title":"Material Design","text":"<p>Material Theme est un th\u00e8me se basant sur le Material Design, r\u00e8gles d\u00e9velopp\u00e9es par Google et tr\u00e8s \u00e0 la vogue en ce moment. Le Material Theme se d\u00e9compose en plusieurs teintes :</p> <ul> <li>Normal qui est le th\u00e8me de base</li> <li>Darker le th\u00e8me plus fonc\u00e9</li> <li>Lighter le th\u00e8me plus clair</li> </ul> <p>Le d\u00e9pot Github inclut \u00e9galement des colorations syntaxiques additionnelles :</p> <ul> <li>OceanicNext</li> <li>OceanicNext Darker</li> </ul> <p>Voici le th\u00e8me :</p> <p></p> <p>Comme vous pouvez le voir, le th\u00e8me Material Theme ainsi que Material Theme Darker sont agr\u00e9ables et reposant, contrairement au th\u00e8me Material Theme Lighter qui est tout simplement un suicide visuel.</p> <p>Voici les diff\u00e9rents param\u00e8tres pour les diff\u00e9rents th\u00e8mes :</p> <ul> <li>Sublime Material Lighter</li> </ul> <pre><code>\"theme\": \"Material-Theme-Lighter.sublime-theme\",\n\"color_scheme\": \"Packages/Material Theme/schemes/Material-Theme-Lighter.tmTheme\",\n</code></pre> <ul> <li>Sublime Material</li> </ul> <pre><code>\"theme\": \"Material-Theme.sublime-theme\",\n\"color_scheme\": \"Packages/Material Theme/schemes/Material-Theme.tmTheme\",\n</code></pre> <ul> <li>Sublime Material Darker</li> </ul> <pre><code>\"theme\": \"Material-Theme-Darker.sublime-theme\",\n\"color_scheme\": \"Packages/Material Theme/schemes/Material-Theme-Darker.tmTheme\",\n</code></pre> <p>En plus du th\u00e8me '\"basique'\", Material Theme dispose d'une Appbar : Material Theme Appabar, celle-ci completera votre th\u00e8me avec une couleur originale pour la liste des fichiers.</p> <p>Voici un aper\u00e7u des couleurs : A FAIRE</p> <p>https://github.com/equinusocio/material-theme-appbar' https://github.com/jamiewilson/predawn' https://gist.github.com/PixiBixi/e401f57cb05f070d0a96d1859302225a (Predawn Theme Settings) https://gist.github.com/PixiBixi/1cefb66eccd1612a85c4d0e6d1d04ffc (Material Design Settings)</p>"},{"location":"code/st3/#snippets","title":"Snippets","text":"<p>https://github.com/JasonMortonNZ/bs3-sublime-plugin' https://github.com/idleberg/sublime-icon-fonts'</p>"},{"location":"code/st3/#plugins_1","title":"Plugins","text":""},{"location":"code/st3/#divers","title":"Divers","text":"<p>Package Control est un peu comme l'apt-get pour SublimeText, il en convient donc qu'il s'agit actuellement d'un plugin indispensable pour un usage convenable de SublimeText</p> <p>Attention, m\u00eame si Package Control s'av\u00e8re tr\u00e8s pratique, il est av\u00e9r\u00e9 que la plupart des versions ne sont plus mises \u00e0 jour, il en conviendra donc d'installer la plupart du temps les plugins via leur d\u00e9pot Git, ou bien toute autre source officielle</p>"},{"location":"code/st3/#php","title":"PHP","text":"<p>https://github.com/benmatselby/sublime-phpcs</p> <p>https://github.com/spadgos/sublime-jsdocs</p> <p>https://github.com/erichard/SublimePHPCompanion</p>"},{"location":"code/st3/#css","title":"CSS","text":"<p>https://github.com/weslly/ColorPicker</p> <p>https://github.com/Monnoroch/ColorHighlighter</p> <p>https://github.com/sindresorhus/sublime-autoprefixer</p>"},{"location":"code/st3/#configuration","title":"Configuration","text":"<p>https://github.com/colinta/ApacheConf.tmLanguage</p> <p>https://github.com/brandonwamboldt/sublime-nginx</p> <p>https://github.com/condemil/Gist</p> <p>https://github.com/sixty4k/st2-zonefile</p> <p>https://github.com/chrissimpkins/glue</p>"},{"location":"code/st3/#tout-et-rien","title":"Tout et rien","text":"<p>https://github.com/wbond/sublime_alignment/</p> <p>https://github.com/mrmartineau/Placeholders</p> <p>https://github.com/akalongman/sublimetext-codeformatter</p> <p>https://github.com/al63/SublimeFiles</p> <p>https://github.com/liamja/sublime-nfo</p>"},{"location":"code/st3/#sql","title":"SQL","text":"<p>https://github.com/freewizard/SublimeFormatSQL</p> <p>https://github.com/alienhard/SublimeAllAutocomplete</p> <p>https://github.com/facelessuser/BracketHighlighter</p> <p>https://github.com/aziz/PlainTasks</p> <p>https://packagecontrol.io/packages/Minify</p> <p>https://github.com/sergeche/emmet-sublime</p> <p>https://github.com/titoBouzout/SideBarEnhancements</p> <p>https://github.com/wbond/sublime_terminal</p> <p>https://github.com/skuroda/Sublime-AdvancedNewFile</p> <p>https://github.com/BoundInCode/AutoFileName</p> <p>https://wbond.net/sublime_packages/sftp</p>"},{"location":"docker/use_proxy/","title":"Utiliser un proxy pour pull les images Docker","text":"<p>Utiliser un proxy avec le daemon Docker est tout sauf intuitif, nous ne pouvons pas utiliser les variables d'environnement classiques ni le fichier de configuration daemon.json</p> <p>Voici la proc\u00e9dure \u00e0 suivre sous un syst\u00e8me bas\u00e9 sur Debian :</p> <ul> <li>Cr\u00e9er le dossier o\u00f9 se situera le fichier de configuration Docker</li> </ul> <pre><code>mkdir /etc/systemd/system/docker.service.d\n</code></pre> <ul> <li>Nous allons cr\u00e9er le fichier http-proxy.conf qui contiendra la     variable HTTP_PROXY qui sera reconnue par Docker</li> </ul> <pre><code>cat &gt; /etc/systemd/system/docker.service.d/http-proxy.conf &lt;&lt; EOF\n[Service]\nEnvironment=\"HTTP_PROXY=http://proxy.example.com:80/\"\nEOF\n</code></pre> <ul> <li>Si vous utilisez un registry interne, il est \u00e9galement possible d'ignorer certaines IPs/nom de domaine (A ajouter au m\u00eame fichier)</li> </ul> <pre><code>Environment=\"NO_PROXY=localhost,127.0.0.0/8,docker-registry.somecorporation.com\"\n</code></pre> <ul> <li>Nous rechargeons le daemond systemd</li> </ul> <pre><code>systemctl daemon-reload\n</code></pre> <ul> <li>Nous v\u00e9rifions si la variable a bien \u00e9t\u00e9 prise en compte par     systemd, si vous n'avez aucun retour, la variable n'a pas \u00e9t\u00e9     appliqu\u00e9e</li> </ul> <pre><code>systemctl show --property=Environment docker\n</code></pre> <ul> <li>Si la variable a bien \u00e9t\u00e9 appliqu\u00e9e, nous pouvons red\u00e9marrer Docker</li> </ul> <pre><code>systemctl restart docker\n</code></pre>"},{"location":"docker/compose/templates/","title":"docker-compose.yml","text":"<p>Deprecated</p> <p>Article plus mis \u00e0 jour, images potentiellement dead \u00e9galement</p> <p>Template pr\u00e9d\u00e9finis pour les applications Docker</p>"},{"location":"docker/compose/templates/#plex","title":"Plex","text":""},{"location":"docker/compose/templates/#lets-encrypt-reverse-proxy","title":"Let's Encrypt + Reverse Proxy","text":""},{"location":"docker/compose/templates/#backend-nginx","title":"Backend nginx","text":"<pre><code>  nginx-backend:\n    restart: always\n    image: xataz/nginx-php\n    container_name: nginx-backend\n    volumes:\n      - /root/.apps/USER/nginx-backend/sites-enabled:/nginx/sites-enabled\n      - /root/.apps/USER/nginx-backend/www:/nginx/www\n      - /root/.apps/USER/nginx-backend/log:/nginx/log\n    environment:\n      - VIRTUAL_PORT=8080\n      - VIRTUAL_HOST=domain.tld\n      - LETSENCRYPT_EMAIL=contact@domain.tld\n      - LETSENCRYPT_HOST=domain.tld\n      - UID=1000\n      - GID=1000\n</code></pre>"},{"location":"docker/compose/templates/#h5ai","title":"h5ai","text":"<pre><code>  USER_h5ai:\n    image: bixidock/h5ai\n    container_name: USER_h5ai\n    restart: always\n    volumes:\n      - \"/home/USER/incoming/torrents:/var/www\"\n    environment:\n      - VIRTUAL_HOST=share.USER.domain.tld\n      - VIRTUAL_PORT=8080\n      - LETSENCRYPT_EMAIL=admin@domain.tld\n      - LETSENCRYPT_HOST=share.USER.domain.tld\n</code></pre>"},{"location":"docker/compose/templates/#rutorrent","title":"ruTorrent","text":"<pre><code>  USER_rutorrent:\n    restart: always\n    image: xataz/rtorrent-rutorrent:latest-filebot\n    container_name: USER_rutorrent\n    volumes:\n      - /home/USER/incoming:/data:rw\n      - /root/.apps/USER/rtorrent/conf:/config:rw\n    ports:\n      - \"45000:45000\"\n      - \"45000:45000/udp\"\n    environment:\n      - UID=1001\n      - GID=1001\n      - WEBROOT=/\n      - VIRTUAL_PORT=8080\n      - VIRTUAL_HOST=rutorrent.USER.domain.tld\n      - LETSENCRYPT_HOST=rutorrent.USER.domain.tld\n      - LETSENCRYPT_EMAIL=admin@domain.tld\n</code></pre>"},{"location":"docker/compose/templates/#organizr","title":"Organizr","text":"<pre><code>  USER_organizr:\n    restart: always\n    image: lsiocommunity/organizr\n    container_name: organizr\n    volumes:\n      - /root/.apps/USER/organizr:/config\n    environment:\n      - VIRTUAL_HOST=USER.domain.tld\n      - VIRTUAL_PORT=80\n      - LETSENCRYPT_HOST=USER.domain.tld\n      - LETSENCRYPT_EMAIL=admin@domain.tld\n</code></pre>"},{"location":"gitlab/cli/","title":"Utilisation de la CLI officielle","text":""},{"location":"gitlab/cli/#repository","title":"Repository","text":"<p>La CLI gitlab peut \u00eatre utile en de nombreux points. Pour l'instant, voici l'int\u00e9r\u00eat principale pour moi de cette CLI, le clonage r\u00e9cursif.</p> <pre><code>glab repo clone -g tecteam --archived=false --paginate -p\n</code></pre> <p>Via cette simple ligne, je peux cloner tous les projets non archiver en concernant la structure de dossier de l'ensemble de l'organisation. Pour ma part, \u00e9tant donn\u00e9 que je navigue entre beaucoup de projets Git, j'aime poss\u00e9der l'int\u00e9gralit\u00e9 des repositories sur lesquels je serai potentiellement \u00eatre amen\u00e9 \u00e0 travailler</p>"},{"location":"gitlab/cli/#merge-request","title":"Merge Request","text":"<pre><code>glab mr create --fill --yes\n</code></pre> <p>Une petite commande magique pour cr\u00e9er une MR sans rien faire, juste magique.</p>"},{"location":"gitlab/cli/#configuration","title":"Configuration","text":"<p>Des op\u00e9rations sont particuli\u00e8rement p\u00e9nibles en GUI sur Gitlab tel que l'ajout de cl\u00e9, c'est pourquoi nous pouvons le faire en CLI sans aucun probleme</p> <pre><code>glab ssh-key add ~/.ssh/id_ed25519.pub -t \"ED25519 Mac\"\n</code></pre>"},{"location":"gitlab/cli/#divers","title":"Divers","text":"<p>Si tout comme moi vous avez plusieurs Gitlab, vous pouvez d\u00e9finir sur quel Gitlab vous souhaitez effectuer vos actions avec la variable <code>GL_HOST</code> (ou <code>GITLAB_HOST</code>)</p> <pre><code>GL_HOST=gitlab.myorg.com glab repo search -s myproject\n</code></pre> <p>Ici, nous allons rechercher le projet <code>myproject</code> dans le gitlab <code>gitlab.myorg.com</code></p> <p>Comme toute CLI en 2023, Gitlab vient avec sa propre auto completion disponible sous Bash, zsh et Fish</p> <p>Lenteurs</p> <p>Pour ma part, je n'ai pas activ\u00e9 cette autocompletion, je trouve mon shell (zsh) lent \u00e0 charger apr\u00e8s ajout de cette completion</p>"},{"location":"gitlab/cli/#fish","title":"Fish","text":"<pre><code>glab completion -s fish &gt; ~/.config/fish/completions/glab.fish\n</code></pre>"},{"location":"gitlab/cli/#zsh","title":"ZSH","text":"<pre><code>echo \"source &lt;(glab completion -s zsh); compdef _glab glab\" &gt;&gt; ~/.zshrc\n</code></pre>"},{"location":"gitlab/cli/#bash","title":"Bash","text":"<pre><code>echo \"source &lt;(glab completion bash) &gt;&gt; ~/.bashrc\"\n</code></pre> <p>Pour une documentation beaucoup plus exhaustive, je vous invite \u00e0 aller voir l'excellent article de blog de Stephane Robert</p>"},{"location":"gitlab/ci/optimize/","title":"Optimiser sa CI Gitlab","text":"<p>Les CI c'est bien, une CI optimis\u00e9e c'est mieux. Voici quelques tips pour l'optimiser. Il y a \u00e9galement des optimisations sp\u00e9cifiques aux diff\u00e9rents langages.</p>"},{"location":"gitlab/ci/optimize/#skip-docker","title":"Skip Docker","text":"<p>Pour gagner du temps, il est possible de ne pas utiliser Docker afin de ne pas attendre que le daemon Docker soit pr\u00eat. Nous pouvons \u00e0 la place utiliser buildah. La syntaxe est identique \u00e0 celle de Docker :</p> <pre><code>Docker Build:\n  before_script:\n    # to skip default before_script\n    - buildah info\n    - buildah login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY\n  stage: package\n  image: quay.io/buildah/stable:latest\n  script:\n    - buildah build\n      -t ${CI_REGISTRY_IMAGE}/gprg:prod\n      -t ${CI_REGISTRY_IMAGE}/gprg:latest .\n    - buildah push ${CI_REGISTRY_IMAGE}/gprg\n</code></pre>"},{"location":"gitlab/ci/optimize/#optimisation-niveau-runner","title":"Optimisation niveau runner","text":"<p>Le runner Gitlab est hautement configurable. Nous pouvons le personnaliser pour augmenter la vitesse de mise en cache ou autre. A partir de la version 13.6, nous avons la feature Fastzip qui nous permet de compresser/d\u00e9compresser bien plus rapidement les potentiels artefacts ou fichiers de cache</p> <pre><code>variables:\n  FF_USE_FASTZIP: \"true\"\n  # These can be specified per job or per pipeline\n  ARTIFACT_COMPRESSION_LEVEL: \"fast\"\n  CACHE_COMPRESSION_LEVEL: \"fast\"\n</code></pre>"},{"location":"gitlab/ci/optimize/#divers","title":"Divers","text":"<pre><code>build-job:\n  stage: build\n  script:\n    - echo Hello World &gt; hello-world.txt\n  artifacts:\n    expire_in: 1 hour\n    paths:\n      - hello-world.txt\n\ntest-job:\n  stage: test\n  variables:\n    GIT_STRATEGY: none\n  script:\n    - cat hello-world.txt\n</code></pre> <p>Cet exemple basique nous permet de mettre plusieurs \u00e9l\u00e9ments en avant :</p> <ul> <li><code>GIT_STRATEGY</code> : Ici, nous ne clonons par le repository Git. Nul n\u00e9cessaire de le cloner si nous n'en avons pas besoin</li> </ul> <p>Nous allons utiliser un artifact, expirant dans 1h pour stocker le r\u00e9sultat d'une commande</p>"},{"location":"gitlab/ci/optimize/#optimisations-par-langages","title":"Optimisations par langages","text":"<p>Nous pouvons \u00e9galement faire des optimisations des CI en fonction des langages (g\u00e9n\u00e9ralement en jouant sur les caches)</p>"},{"location":"gitlab/ci/optimize/#php","title":"PHP","text":"<p>Dans le cadre de l'utilisation de composer, il peut \u00eatre int\u00e9ressant de mettre en cache le r\u00e9sultat d'un composer install. Il faut l'indiquer de cette mani\u00e8re dans votre YAML</p> <pre><code># Cache libraries in between jobs\ncache:\n  key: $CI_COMMIT_REF_SLUG\n  paths:\n    - vendor/\n</code></pre>"},{"location":"gitlab/ci/optimize/#python","title":"Python","text":"<p>De la m\u00eame mani\u00e8re qu'avec PHP &amp; composer, nous pouvons mettre en cache le .pip d'un projet en Python mais \u00e9galement le dossier venv :</p> <pre><code># Change pips cache directory to be inside the project directory since we can\n# only cache local items.\nvariables:\n  PIP_CACHE_DIR: \"$CI_PROJECT_DIR/.cache/pip\"\n\n# Pips cache doesnt store the python packages\n# https://pip.pypa.io/en/stable/reference/pip_install/#caching\n#\n# If you want to also cache the installed packages, you have to install\n# them in a virtualenv and cache it as well.\ncache:\n  paths:\n    - .cache/pip\n    - venv/\n</code></pre> <p>D'autres caches sont possibles pour d'autres langages (Go, Ruby...), je vous laisse consulter la documentation officielle</p>"},{"location":"gitlab/ci/scan_image/","title":"Int\u00e9grer un scan d'image \u00e0 sa CI","text":"<p>Avoir une CI qui cr\u00e9\u00e9 une image, c'est bien. Si l'on peut y ajouter des tests de s\u00e9curit\u00e9, c'est mieux :)</p> <p>Trivy est un scanner de vuln\u00e9rabilit\u00e9 rapide &amp; simple \u00e0 utiliser. Il peut nous aider \u00e0 scanner un repository Git, un filesystem, ou bien comme dans notre cas, une image.</p>"},{"location":"gitlab/ci/scan_image/#gitlab-ciyml","title":".gitlab-ci.yml","text":"<p>Voil\u00e0 le bout de code \u00e0 ajouter \u00e0 sa CI pour int\u00e9grer un scan \u00e0 sa CI, g\u00e9n\u00e9rant un rapport d\u00e9taill\u00e9</p> <pre><code>Trivy_container_scanning:\n  stage: test\n  image:\n    name: alpine:3.11\n  variables:\n    # Override the GIT_STRATEGY variable in your `.gitlab-ci.yml` file and set it to `fetch` if you want to provide a `clair-whitelist.yml`\n    # file. See https://docs.gitlab.com/ee/user/application_security/container_scanning/index.html#overriding-the-container-scanning-template\n    # for details\n    GIT_STRATEGY: none\n    IMAGE: \"$CI_REGISTRY_IMAGE\"\n  allow_failure: true\n  before_script:\n    - export TRIVY_VERSION=$(wget -qO - \"https://api.github.com/repos/aquasecurity/trivy/releases/latest\" | grep '\"tag_name\":' | sed -E 's/.*\"v([^\"]+)\".*/\\1/')\n    - apk add --no-cache curl docker-cli\n    - docker login -u \"$CI_REGISTRY_USER\" -p \"$CI_REGISTRY_PASSWORD\" $CI_REGISTRY\n    - curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b /usr/local/bin ${TRIVY_VERSION}\n    - curl -sSL -o /tmp/trivy-gitlab.tpl https://github.com/aquasecurity/trivy/raw/${TRIVY_VERSION}/contrib/gitlab.tpl\n  script:\n    # --cache-dir global arg, then before image\n    - trivy --cache-dir .trivycache/ image --exit-code 0  --no-progress --format template --template \"@/tmp/trivy-gitlab.tpl\" -o gl-container-scanning-report.json $IMAGE\n  cache:\n    paths:\n      - .trivycache/\n  artifacts:\n    reports:\n      container_scanning: gl-container-scanning-report.json\n  dependencies: []\n</code></pre> <p>Il s'agit ici de la configuration que j'ai souhait\u00e9, je vous invite bien \u00e9videmment \u00e0 l'adapter (Nom de l'image, g\u00e9n\u00e9ration de rapport en utilisant un artefact...).</p> <p>A noter que la documentation de Trivy int\u00e8gre un exemple pour Gitlab-CI, mais \u00e9galement d'autres pour Travis, Circle...</p>"},{"location":"hardware/hdd/wd/fix_hdd/","title":"WD Green HDD, Comment pr\u00e9munir le old_age pr\u00e9matur\u00e9","text":"<p>Ce probl\u00e8me est du \u00e0 la technologie IntelliPark qui a \u00e9t\u00e9 introduite dans les WD Green ainsi que les RED. Cette technologie d\u00e9faillante provoque un vieillissement pr\u00e9matur\u00e9 du disque dur.</p> <p>Pour la d\u00e9sactiver, nous allons utiliser l'outil idle3-tools disponible ici ou alors dans les repos Debian/Ubuntu :</p> <pre><code>apt install idle3-tools\n</code></pre> <p>Nous commencons par voir l'\u00e9tat du IntelliPark</p> <pre><code>idle3ctl -g /dev/sda\n</code></pre> <p>Si celui-ci est diff\u00e9rent de disabled, alors nous le d\u00e9sactivons :</p> <pre><code>idle3ctl -d /dev/sda\n</code></pre> <p>Repeter l'op\u00e9ration pour chaque disque dur, puis red\u00e9marrer.</p>"},{"location":"hardware/nic/mellanox/identify_and_upgrade_firmware/","title":"Identifier and upgrade son firmware Mellanox","text":"<p>Dans certains cas, il peut \u00eatre utile d'upgrade son firmware de sa NIC si vous rencontrez diff\u00e9rents soucis, ou tout simplement pour obtenir des nouveaut\u00e9s firmware.</p> <p>Premi\u00e8rement, nous devons rep\u00e9rer nos lignes PCI correspondant \u00e0 notre NIC :</p> <pre><code>root@hostname:/home/user# lspci |grep -i mel\n18:00.0 Ethernet controller: Mellanox Technologies MT27800 Family [ConnectX-5]\n18:00.1 Ethernet controller: Mellanox Technologies MT27800 Family [ConnectX-5]\naf:00.0 Ethernet controller: Mellanox Technologies MT27800 Family [ConnectX-5]\naf:00.1 Ethernet controller: Mellanox Technologies MT27800 Family [ConnectX-5]\n</code></pre> <p>Nous voyons ici que nous avons 2 NIC, chacune comprenant 2 ports.</p> <p>Via l'utilitaire que nous fournit Mellanox, nous pourrons r\u00e9cuperer le PSID de la NIC, qui correspondra \u00e0 un modele precis.</p> <pre><code>root@hostname:/home/user# mstflint -d 18:00.0 q\nImage type:            FS4\nFW Version:            16.25.1020\nFW Release Date:       30.4.2019\nProduct Version:       16.25.1020\nRom Info:              type=UEFI version=14.18.19 cpu=AMD64\n                       type=PXE version=3.5.701 cpu=AMD64\nDescription:           UID                GuidsNumber\nBase GUID:             1c34da0300682e10        4\nBase MAC:              1c34da682e10            4\nImage VSD:             N/A\nDevice VSD:            N/A\nPSID:                  MT_0000000248\nSecurity Attributes:   N/A\n</code></pre> <p>Nous voyons ici que notre premi\u00e8re NIC a le PSID MT_0000000248.</p> <p>Apr\u00e8s une petite recherche Google, nous pouvons en d\u00e9duire qu'il s'agit du modele MCX542B-ACA.</p> <p>Via un autre utilitaire fournit par Mellanox, disponible ici, nous devons trouver le nom \"interne\" de la NIC.</p> <pre><code>root@hostname:/home/user# mst start\nroot@hostname:/home/user# mst status\nMST modules:\n------------\n    MST PCI module is not loaded\n    MST PCI configuration module loaded\n\nMST devices:\n------------\n/dev/mst/mt4119_pciconf0         - PCI configuration cycles access.\n                                   domain:bus:dev.fn=0000:18:00.0 addr.reg=88 data.reg=92 cr_bar.gw_offset=-1\n                                   Chip revision is: 00\n/dev/mst/mt4119_pciconf1         - PCI configuration cycles access.\n                                   domain:bus:dev.fn=0000:af:00.0 addr.reg=88 data.reg=92 cr_bar.gw_offset=-1\n                                   Chip revision is: 00\n</code></pre> <p>Imaginons que nous voulons upgrade notre NIC ayant comme ligne PCI 18:00.0, son nom est donc <code>/dev/mst/mt4119_pciconf0</code>. Nous n'avons plus qu'\u00e0 appliquer le firmware avec flint :</p> <pre><code>root@hostname:/home/user# flint -d &lt;device_name&gt; -i &lt;binary image&gt; burn\n</code></pre> <p>Un petit restart, un recommence la commande mstflint, et hop, firmware upgraded :)</p>"},{"location":"hardware/san/netapp/blink_led_hdd/","title":"Rep\u00e9rer un disque dur d\u00e9faillant en le faisant clignoter","text":"<p>Pour identifier un disque d\u00e9faillant afin de le remplacer, il nous faut auparavant connaitre le disque dur d\u00e9faillant</p> <pre><code>sysconfig -r\n</code></pre> <p>Voici ce que vous aurez pour un disque d\u00e9faillant</p> <pre><code>Broken disks\n\nRAID Disk       Device          HA  SHELF BAY CHAN Pool Type  RPM  Used (MB/blks)    Phys (MB/blks)\n---------       ------          ------------- ---- ---- ---- ----- --------------    --------------\nfailed          0b.01.3         0b    1   3   SA:B   0   SAS 10000 560000/1146880000 572325/1172123568\n</code></pre> <p>Et voici la commande pour faire clignoter le disque (Il faut auparavant passer en mode avanc\u00e9 : priv set advanced)</p> <pre><code>blink_on 0b.01.3\n</code></pre>"},{"location":"hardware/server/hp/cli_sas/","title":"Commandes HP Smart Array en CLI (Utilisable pour un ESX...)","text":"<p>De nombreuses commandes utiles pour l'utilistaire hpssacli</p> <p>Show configuration</p> <pre><code>/opt/hp/hpssacli/bin/hpssacli ctrl all show config\n</code></pre> <p>Controller status</p> <pre><code>/opt/hp/hpssacli/bin/hpssacli ctrl all show status\n</code></pre> <p>Show detailed controller information for all controllers</p> <pre><code>/opt/hp/hpssacli/bin/hpssacli ctrl all show detail\n</code></pre> <p>Show detailed controller information for controller in slot 0</p> <pre><code>/opt/hp/hpssacli/bin/hpssacli ctrl slot=0 show detail\n</code></pre> <p>Rescan for New Devices</p> <pre><code>/opt/hp/hpssacli/bin/hpssacli rescan\n</code></pre> <p>Physical disk status</p> <pre><code>/opt/hp/hpssacli/bin/hpssacli ctrl slot=0 pd all show status\n</code></pre> <p>Show detailed physical disk information</p> <pre><code>/opt/hp/hpssacli/bin/hpssacli ctrl slot=0 pd all show detail\n</code></pre> <p>Logical disk status</p> <pre><code>/opt/hp/hpssacli/bin/hpssacli ctrl slot=0 ld all show status\n</code></pre> <p>View Detailed Logical Drive Status</p> <pre><code>/opt/hp/hpssacli/bin/hpssacli ctrl slot=0 ld 2 show\n</code></pre> <p>Create New RAID 0 Logical Drive</p> <pre><code>/opt/hp/hpssacli/bin/hpssacli ctrl slot=0 create type=ld drives=1I:1:2 raid=0\n</code></pre> <p>Create New RAID 1 Logical Drive</p> <pre><code>/opt/hp/hpssacli/bin/hpssacli ctrl slot=0 create type=ld drives=1I:1:1,1I:1:2 raid=1\n</code></pre> <p>Create New RAID 5 Logical Drive</p> <pre><code>/opt/hp/hpssacli/bin/hpssacli ctrl slot=0 create type=ld drives=1I:1:1,1I:1:2,2I:1:6,2I:1:7,2I:1:8 raid=5\n</code></pre> <p>Delete Logical Drive</p> <pre><code>/opt/hp/hpssacli/bin/hpssacli ctrl slot=0 ld 2 delete\n</code></pre> <p>Add New Physical Drive to Logical Volume</p> <pre><code>/opt/hp/hpssacli/bin/hpssacli ctrl slot=0 ld 2 add drives=2I:1:6,2I:1:7\n</code></pre> <p>Add Spare Disks</p> <pre><code>/opt/hp/hpssacli/bin/hpssacli ctrl slot=0 array all add spares=2I:1:6,2I:1:7\n</code></pre> <p>Enable Drive Write Cache</p> <pre><code>/opt/hp/hpssacli/bin/hpssacli ctrl slot=0 modify dwc=enable\n</code></pre> <p>Disable Drive Write Cache</p> <pre><code>/opt/hp/hpssacli/bin/hpssacli ctrl slot=0 modify dwc=disable\n</code></pre> <p>Erase Physical Drive</p> <pre><code>/opt/hp/hpssacli/bin/hpssacli ctrl slot=0 pd 2I:1:6 modify erase\n</code></pre> <p>Turn on Blink Physical Disk LED</p> <pre><code>/opt/hp/hpssacli/bin/hpssacli ctrl slot=0 ld 2 modify led=on\n</code></pre> <p>Turn off Blink Physical Disk LED</p> <pre><code>/opt/hp/hpssacli/bin/hpssacli ctrl slot=0 ld 2 modify led=off\n</code></pre> <p>Modify smart array cache read and write ratio (cacheratio=readratio/writeratio)</p> <pre><code>/opt/hp/hpssacli/bin/hpssacli ctrl slot=0 modify cacheratio=100/0\n</code></pre> <p>Enable smart array write cache when no battery is present (No-Battery Write Cache option)</p> <pre><code>/opt/hp/hpssacli/bin/hpssacli ctrl slot=0 modify nbwc=enable\n</code></pre> <p>Disable smart array cache for certain Logical Volume</p> <pre><code>/opt/hp/hpssacli/bin/hpssacli ctrl slot=0 logicaldrive 1 modify arrayaccelerator=disable\n</code></pre> <p>Enable smart array cache for certain Logical Volume</p> <pre><code>/opt/hp/hpssacli/bin/hpssacli ctrl slot=0 logicaldrive 1 modify arrayaccelerator=enable\n</code></pre> <p>Enable SSD Smart Path</p> <pre><code>/opt/hp/hpssacli/bin/hpssacli ctrl slot=0 array a modify ssdsmartpath=enable\n</code></pre> <p>Disable SSD Smart Path</p> <pre><code>/opt/hp/hpssacli/bin/hpssacli ctrl slot=0 array a modify ssdsmartpath=disable\n</code></pre>"},{"location":"hardware/server/hp/ilo_key/","title":"Cl\u00e9 ILO Adavanced","text":"<ul> <li>34RQQ-6D5R4-G8NW3-LBMG6-MLJXR</li> <li>FCKGW RHQQ2 YXRKT 8TG6W 2B7Q8</li> <li>K4HVD-Q9TJ9-6CRX9-C9G68-RQ2D3</li> <li>373KG-ZB9PX-8RH43-64D2T-7S9R6</li> <li>36XL8-B4SBB-C3PTL-W62JK-8GGTB</li> <li>34MV3-HY3JM-C8C6X-Q487M-LR5XM</li> <li>34MMV-P4VDV-XMLSW-Z555T-NMTKH</li> <li>34MWQ-V44LQ-QJZPT-35K2N-XSBWM</li> <li>37BK9-75JJV-DN7QS-NN9QH-86B5R</li> </ul> <p>I can make em all day long.</p> <p>Advance Pack</p> <ul> <li>379D6-Q4LPX-KCCTB-NQVYD-SDG47</li> <li>36XX3-JPPG7-S5G2G-9D4S4-W79XJ</li> <li>36XX3-JPPG7-S5G2G-9D4S4-W79XJ</li> <li>373HX-DLK4Y-ZW7L6-HBN9S-KSBWX</li> <li>349J2-ZBPL7-DPJNH-Z4K9P-88WYX</li> </ul> <p>NEW 512485-B21/512519-021 HP iLO Adv 1-Svr incl 1yrTS&amp;U SW G7 G8 G9</p>"},{"location":"hardware/server/hp/run_ilo/","title":"Lancer la console iLO depuis un Mac","text":"<p>Depuis un Mac, il ne faut pas double cliquer sur le .jnlp, cela ne marche pas.</p> <p>Il faut donc passer par la ligne de commande et faire cette commande :</p>"},{"location":"hardware/server/hp/run_ilo/#ilo","title":"iLO","text":"<pre><code>javaws iLO-jirc.jnlp\n</code></pre>"},{"location":"hardware/server/hp/run_ilo/#idrac","title":"iDRAC","text":"<p>Pour iDRAC, il se peut que l'on doive tout d'abord faire une exception de s\u00e9curit\u00e9, pour cela, nous devons modifier la configuration de Java :</p> <pre><code>javaws -viewer\n</code></pre> <p>Puis lancer comme d'habitude le jnlp</p>"},{"location":"hardware/server/hp/run_old_ilo/","title":"Lancer une ancienne console iLO","text":"<p>Quel calv\u00e8re pour lancer un vieil ILO... Outre le fait qu'il faille obligatoirement un Windows 7, j'obtenais un message \u00e9tonnant JavaScript has been disabled or is not supported by your web browser which is needed by the Virtual KVM/Media applet. Please correct this problem.</p> <p>N'ayant aucune comment le r\u00e9soudre, j'appelle mon meilleur ami Google et je tombe sur un petit article sur un blog allemand (Source dans la main page).</p> <p>Il faut t\u00e9l\u00e9charger un JAR ici : http://'/M2.JAR <p>Attention : Il s'agit d'une URl case-sensitive.</p> <p>On rentre alors son IP ILO et son identifiant, et tout est ok :)</p>"},{"location":"hypervisor/esxi/upload_iso_cli/","title":"Uploader ses ISO en ligne de commande","text":"<p>Pour t\u00e9l\u00e9charger directement des ISO en ligne de commande, tout d'abord, nous devons activer l'acc\u00e8s \u00e0 distance SSH.</p> <p>Une fois connect\u00e9 en SSH, nous listons nos diff\u00e9rents Datastore</p> <pre><code>[root@sd-138937:~] ls /vmfs/volumes/\n175cbc75-2791da45-30ab-7f5251c2304f  5e94e6de-1a29e44a-0b7d-a81e84f120ab  5e94f09f-c5361e02-1601-a81e84f120ab  datastore1\n5e94e6b0-a3e573e4-89f5-a81e84f120ab  5e94e6de-fe55fd96-82de-a81e84f120ab  SSD                                  e9156572-a7b7f9e4-723f-31781f79407c\n</code></pre> <p>Une fois choisis le datastore, nous lan\u00e7ons le t\u00e9l\u00e9chargement</p> <pre><code>[root@sd-138937:/vmfs/volumes] wget http://ftp.rezopole.net/centos/7.7.1908/isos/x86_64/CentOS-7-x86_64-NetInstall-1908.iso\n</code></pre>"},{"location":"hypervisor/esxi/commands/network/","title":"Commandes ESXi Network","text":"<pre><code>esxcli network nic down vmnicX\n</code></pre> <pre><code>    esxcli network nic up vmnicX\n</code></pre>"},{"location":"hypervisor/esxi/misc/shell_access/","title":"Acceder \u00e0 la console de l'ESXi","text":"<p>Acc\u00e9der \u00e0 la console de l'ESXi peut-\u00eatre pratique pour les configurations de base. Cependant, celle-ci est d\u00e9sactiv\u00e9e par d\u00e9faut..</p>"},{"location":"hypervisor/esxi/misc/shell_access/#activer-la-console","title":"Activer la console","text":"<ul> <li>A partir de l'interface de l'ESXi, presser F2 pour acc\u00e9der au menu     de <code>System Customization</code></li> <li>Selectionner <code>Troubleshooting Options</code> et presser Enter.</li> <li>A partir du <code>Troubleshooting Mode Options</code> menu, selectionner <code>Enable ESXi Shell</code>.</li> <li>Activer ESXi Shell</li> <li>Activer SSH</li> </ul> <p>Press Enter afin d'activer le service</p>"},{"location":"hypervisor/esxi/misc/shell_access/#acceder-a-la-console","title":"Acc\u00e9der \u00e0 la console","text":"<p>Une fois le serveur rebooted, il faut faire les touches <code>Alt+F2</code> pour acc\u00e9der \u00e0 la console ESXi</p>"},{"location":"hypervisor/proxmox/bootstrap_pve/","title":"Avoir un Proxmox clean","text":"<p>Avoir un serveur Proxmox c'est bien, avoir un proxmox clean c'est mieux :)</p> <p>Quelques \u00e9tapes \u00e0 faire pour son Proxmox. Rien de bien folichon ici, mais \u00e0 garder en t\u00eate</p>"},{"location":"hypervisor/proxmox/bootstrap_pve/#admin-local","title":"Admin local","text":"<p>On commence par la creation d'un admin local. On \u00e9vite la connection root et \u00e0 tout prix les comptes non nominatif</p> <pre><code>pveum group add admin -comment \"System Administrators\"\npveum acl modify / -group admin -role Administrator\npveum useradd jdelgado@pve\npveum usermod jdelgado@pve -group admin\npveum passwd jdelgado@pve\n</code></pre> <p>Dans le m\u00eame temps, on peut creer un compte qui nous servira pour le PVE Exporter</p> <pre><code>pveum groupadd monitoring -comment 'Monitoring group'\npveum aclmod / -group monitoring -role PVEAuditor\npveum useradd pve_exporter@pve\npveum usermod pve_exporter@pve -group monitoring\npveum passwd pve_exporter@pve\n</code></pre> <p>Il peut \u00eatre int\u00e9ressant de mettre le m\u00eame password de partout afin de n'avoir qu'une instance du PVE exporter</p>"},{"location":"hypervisor/proxmox/bootstrap_pve/#bloatware-proxmox","title":"Bloatware Proxmox","text":"<p>Personne ne veut la pop-up qui nous indique que nous n'avons pas un abonnement valide pour PVE, c'est pour \u00e7a qu'il existe un petit trick nous permettant de la supprimer</p> <pre><code>sed -Ezi.bak \"s/(function\\(orig_cmd\\) \\{)/\\1\\n\\torig_cmd\\(\\);\\n\\treturn;/g\" /usr/share/javascript/proxmox-widget-toolkit/proxmoxlib.js\nsystemctl restart pveproxy.service\n</code></pre>"},{"location":"hypervisor/proxmox/bootstrap_pve/#performance-cpu","title":"Performance CPU","text":"<p>Pour \u00e7a, on souhaite utiliser le driver performance de notre CPU nous assurant que le CPU sera a sa fr\u00e9quence maximum le plus souvent possible</p> <pre><code>apt install cpufrequtils\ncat &lt;&lt; 'EOF' &gt; /etc/default/cpufrequtils\nGOVERNOR=\"performance\"\nEOF\n</code></pre>"},{"location":"hypervisor/proxmox/bootstrap_pve/#certificat-lets-encrypt","title":"Certificat Lets Encrypt","text":"<p>Un beau petit cadenas vert, c'est quand m\u00eame pas mal non ? :)</p> <p>Pour \u00e7a, c'est quelques lignes de commande</p> <pre><code>MAIL=\"contact+letsencrypt@mydomain.fr\"\nDOMAIN=\"virtu01-prod.my.domain.tld\nroot@virtu01-prod:~# pvenode acme account register default ${MAIL}\nDirectory endpoints:\n0) Let's Encrypt V2 (https://acme-v02.api.letsencrypt.org/directory)\n1) Let's Encrypt V2 Staging (https://acme-staging-v02.api.letsencrypt.org/directory)\n2) Custom\nEnter selection: 1\n\nTerms of Service: https://letsencrypt.org/documents/LE-SA-v1.2-November-15-2017.pdf\nDo you agree to the above terms? [y|N]y\n...\nTask OK\nroot@virtu01-prod:~# pvenode config set --acme domains=${DOMAIN}\nroot@virtu01-prod:~# pvenode acme cert order\nLoading ACME account details\nPlacing ACME order\n...\nStatus is 'valid'!\n\nAll domains validated!\n...\nDownloading certificate\nSetting pveproxy certificate and key\nRestarting pveproxy\nTask OK\n</code></pre>"},{"location":"hypervisor/proxmox/bootstrap_pve/#divers","title":"Divers","text":"<p>Si on utilise pas NFS, on desactive RPCbind  (Ce n'est pas grand chose, mais on ne veut pas de service inutile sur notre machine)</p> <pre><code>systemctl disable --now rpcbind.service rpcbind.socket\n</code></pre>"},{"location":"hypervisor/proxmox/cluster/","title":"G\u00e9rer son cluster Proxmox","text":"<p>Imaginons l'infrastructure suivante</p> <ul> <li>vmbr0 : 1G, 192.168.0.0/24, le r\u00e9seau de notre box</li> <li>vmbr1 : 2.5G, 10.10.10.0/24, un r\u00e9seau interne</li> </ul>"},{"location":"hypervisor/proxmox/cluster/#creer-son-cluster","title":"Cr\u00e9er son cluster","text":"<p>Cr\u00e9er son cluster n'a rien de compliqu\u00e9, il suffit de suivre la proc\u00e9dure sur le clicodrome.</p> <p>Si vous souhaitez le faire en ligne de commande, rien de plus facile \u00e9galement</p> <pre><code>pvecm create &lt;name&gt; --link0 &lt;ip&gt;\n</code></pre> <p>Il est \u00e9galement possible d'ajouter plusieurs links pour ajouter de la redondance \u00e0 son cluster, voici un exemple</p> <pre><code>pvecm create mycluster --link0 10.10.10.101,priority=15 --link1 192.168.1.101,priority=20\n</code></pre> <p>Ici, nous utilisons en premier notre lien 2.5Gbps en priorit\u00e9, suivi de notre lien 1Gbps</p> <p>Si nous ne souhaitons pas avoir plusieur lien, il n'est \u00e9videmment pas utile de sp\u00e9cifier la priorit\u00e9 du lien</p>"},{"location":"hypervisor/proxmox/cluster/#bonus-utiliser-une-interface-dedie-pour-la-live-migration","title":"Bonus : Utiliser une interface d\u00e9di\u00e9 pour la live-migration","text":"<p>Cette \u00e9tape semble toute b\u00eate mais cependant tr\u00e8s tr\u00e8s p\u00e9nible car peu document\u00e9e.</p> <p>Nous allons naturellement vouloir aller sur vmbr1 pour notre live migration. Pour cela, il faut modifier un fichier de configuration de PVE en ligne de commande</p> <pre><code>root@proxmox1:~# cat /etc/pve/datacenter.cfg\nkeyboard: fr\nmigration: type=insecure,network=10.10.10.0/24\n</code></pre> <p>Comme nous le voyons, nous pr\u00e9cisons ici le CIDR \u00e0 utiliser pour la migration, la documentation compl\u00e8te de ce fichier est disponible ici</p> <p>Nous d\u00e9sactivons \u00e9galement une migration dite \"secure\" \u00e9tant donn\u00e9 que nous somme sur un r\u00e9seau interne isol\u00e9</p> <p>Il est \u00e9galement possible de migrer une VM en utilisant un r\u00e9seau sp\u00e9cifique directement dans le <code>qm migrate</code></p> <pre><code>qm migrate 200 &lt;new_host&gt; --online --migration_network 10.10.10.0/24\n</code></pre>"},{"location":"hypervisor/proxmox/cluster/#detruire-son-cluster","title":"D\u00e9truire son cluster","text":"<p>C'est tr\u00e8s simple, on lance la commande suivante sur tous les nodes</p> <pre><code>systemctl stop pve-cluster corosync\npmxcfs -l\nrm /etc/corosync/*\nrm /etc/pve/corosync.conf\nkillall pmxcfs\nsystemctl start pve-cluster\n</code></pre>"},{"location":"hypervisor/proxmox/insert_iso_from_url/","title":"Ajouter une ISO depuis une URL","text":"<p>Depuis la WebUI de Proxmox, il n'est pas possible d'ajouter une ISO depuis une URL.</p> <p>Cependant, nous pouvons le faire en ligne de commande.</p> <p>Pour cela, on se rend dans le dossier o\u00f9 sont situ\u00e9s les ISOs :</p> <pre><code>cd /var/lib/vz/template/iso\n</code></pre> <p>Et on t\u00e9l\u00e9charge l'ISO souhait\u00e9 :</p> <pre><code>wget https://cdimage.debian.org/debian-cd/current/amd64/iso-cd/debian-9.9.0-amd64-netinst.iso\n</code></pre> <p>Nous disposons d\u00e9sormais de notre ISO accessible depuis proxmox</p>"},{"location":"hypervisor/proxmox/vm_as_cli/","title":"Cr\u00e9er sa VM en CLI avec cloud-init","text":"<p>Pas de blabla, quelques commandes ici et on en parle plus !</p> <p>Au pr\u00e9alable, il faut telecharger l'img</p> <pre><code>cd /var/lib/vz/template/iso ; wget https://cloud-images.ubuntu.com/daily/server/releases/24.04/release/ubuntu-24.04-server-cloudimg-amd64.img\n</code></pre> <p>Puis hop on cr\u00e9\u00e9 notre VM</p> <pre><code>ID_VM=\"102\"\nSTORAGE_CLASS=\"local\"\nqm create ${ID_VM} --name \"cloudron01-prod\" --memory 3072 --cores 2 --net0 virtio,bridge=vmbr0\nqm importdisk ${ID_VM} /var/lib/vz/template/iso/ubuntu-24.04-server-cloudimg-amd64.img ${STORAGE_CLASS}\nqm set ${ID_VM} --scsihw virtio-scsi-pci --scsi0 ${STORAGE_CLASS}:vm-${ID_VM}-disk-0.raw\nqm set ${ID_VM} -net0 e1000=${MAC_ADDR\u00b0},bridge=vmbr0,firewall=1\nqm set ${ID_VM} --ipconfig0 ip=${PUBLIC_IP}/32,gw=${GATEWAY}\nqm set ${ID_VM} --boot c --bootdisk scsi0\nqm set ${ID_VM} --ide2 ${STORAGE_CLASS}:cloudinit\nqm set ${ID_VM} --ciuser ubuntu --cipassword 'yourpassword'\nqm set ${ID_VM} --sshkey ~/.ssh/customers.pub\n</code></pre> <p><code>local</code> est ici le nom de notre stockage que nous utilisons</p> <p>On peut \u00e9galement passer sa VM en DHCP \u00e0 la place :</p> <pre><code>qm set ${ID_VM} --ipconfig0 ip=dhcp\n</code></pre> <p>Enfin, on start sa VM</p> <pre><code>qm start ${ID_VM}\n</code></pre> <p>Votre VM sera accessible en SSH avec la cl\u00e9 d\u00e9finie</p> <p>A noter que l'\u00e9tape o\u00f9 l'on definie l'adresse mac n'est pas oblig\u00e9e si nous n'avons pas \u00e0 utiliser une MAC pr\u00e9d\u00e9finie</p>"},{"location":"hypervisor/proxmox/networking/nat/","title":"NAT","text":"<p>Pour ajouter un NAT sur Proxmox :</p> <pre><code>auto vmbr0\niface vmbr0 inet static\n        address  10.10.10.254\n        netmask  255.255.255.0\n        bridge_ports none\n        bridge_stp off\n        bridge_fd 0\n\n        post-up echo 1 &gt; /proc/sys/net/ipv4/ip_forward\n        post-up   iptables -t nat -A POSTROUTING -s 10.10.10.0/24 -o eno1 -j MASQUERADE\n        post-down iptables -t nat -D POSTROUTING -s 10.10.10.0/24 -o eno1 -j MASQUERADE\n</code></pre> <p>On pense \u00e0 changer l'interface de sortie selon notre syst\u00e8me. Concernant la VM, il nous faut donc une IP dans le m\u00eame /24 et en gateway 10.10.10.254</p>"},{"location":"hypervisor/proxmox/troubleshooting/vm_locked/","title":"R\u00e9soudre l'erreur '\"VM is locked'\"","text":"<p>Sous promxox, de ma faible exp\u00e9rience, il est fr\u00e9quent d'avoir un probl\u00e8me de VM locked. Pour cela, 2 moyens</p> <p>Le premier est de supprimer le fichier de lock \u00e0 la main :</p> <p>XXX repr\u00e9sente la VM ID</p> <pre><code>rm /var/lock/qemu-server/lock-XXX.conf\n</code></pre> <p>Si cela ne marche pas, il existe \u00e9galement une commande en ligne de commande</p> <pre><code>qm unlock XXX\n</code></pre>"},{"location":"kafka/kafkactl/","title":"Kafkactl, un outil magique","text":"<p>Manageant quelques clusters Kafka, je devais effectuer quelques op\u00e9rations de maintenance sur notre cluster, ajuster le nombre de replicas des topics...</p> <p>Si vous \u00eates familiers avec l'univers Kafka, vous savez \u00e0 quel point ces op\u00e9rations sont chiantes.</p> <p>Il y'a peu, j'ai d\u00e9couvert un outil changeant ma mani\u00e8re de travailler avec Kafka, kafkactl. Son nom n'est pas sans vous rappeler le binary <code>kubectl</code>, et c'est normal. Tout comme ce dernier, il est \u00e9crit en go et poss\u00e8de les m\u00eame notions (Utilisation de contexts, keyword get/describe)...</p> <p>Sous mac, l'installer est d'une simplicit\u00e9 enfantine</p> <pre><code># install tap repostory once\nbrew tap deviceinsight/packages\n# install kafkactl\nbrew install deviceinsight/packages/kafkactl\n</code></pre> <p>Et son utilisation l'est tout autant. Tout se passe dans un seul fichier de configuration :</p> <pre><code>\u279c  ~ \\cat ~/.config/kafkactl/config.yml\ncontexts:\n    cluster1:\n        brokers:\n          - cluster1-eu3-1.mydomain.tld:9092\n          - cluster1-eu3-2.mydomain.tld:9092\n          - cluster1-eu3-3.mydomain.tld:9092\n    cluster2:\n        brokers:\n          - cluster2-eu5-1.mydomain.tld:9092\n          - cluster2-eu5-2.mydomain.tld:9092\n          - cluster2-eu5-3.mydomain.tld:9092\n\ncurrent-context: cluster1\n</code></pre> <p>Beaucoup d'autres param\u00e8tres sont disponibles, n'h\u00e9sitez pas \u00e0 consulter la documentation</p> <p>Et tout comme kubectl, il ne faut pas oublier de source l'autocompletion, \u00e0 ajouter dans ton .zshrc (ou tout autre)</p> <pre><code>echo \"source &lt;(kafkactl completion zsh)\" &gt;&gt; .zshrc\"\n</code></pre> <p>L'utilisation des contextes est comme sur Kube</p> <pre><code>\u279c  ~ kafkactl config get-contexts\nACTIVE     NAME\n*          cluster1\n           cluster2\n\u279c  ~ kafkactl config use-context cluster2\n\u279c  ~ kafkactl config get-contexts\nACTIVE     NAME\n           cluster1\n*          cluster2\n</code></pre> <p>Une fois tout configur\u00e9, voici les principales fonctionnalit\u00e9s dont je me sers :</p> <pre><code>kafkactl alter topic \"$TOPIC\" --replication-factor 3 --validate-only\n</code></pre> <p>Afin de voir les futures modifications (--validate-only). Si elles vous conviennent, enlever le param\u00e8tre</p> <pre><code>kafkactl get consumer-groups\n</code></pre> <p>Et pour avoir les d\u00e9tails d'un consumer group</p> <pre><code>kafkactl describe consumer-group \"my-consumer-group\"\nCLIENT_HOST       CLIENT_ID     TOPIC  ASSIGNED_PARTITIONS\n/1.2.3.21     rdkafka       topica     44,45,46,47,48,49,50,51,52,53\n/1.2.3.21     rdkafka       topicb     44,45,46,47,48,49,50,51,52,53\n/1.2.3.16     rdkafka       topica     22,23,24,25,26,27,28,29,30,31,32\n/1.2.3.16     rdkafka       topicb     22,23,24,25,26,27,28,29,30,31,32\n/1.2.3.39     rdkafka       topica     0,1,2,3,4,5,6,7,8,9,10\n/1.2.3.39     rdkafka       topicb     0,1,2,3,4,5,6,7,8,9,10\n/1.2.3.34     rdkafka       topica     11,12,13,14,15,16,17,18,19,20,21\n/1.2.3.34     rdkafka       topicb     11,12,13,14,15,16,17,18,19,20,21\n/1.2.3.26     rdkafka       topica     54,55,56,57,58,59,60,61,62,63\n/1.2.3.26     rdkafka       topicb     54,55,56,57,58,59,60,61,62,63\n/1.2.3.20     rdkafka       topica     33,34,35,36,37,38,39,40,41,42,43\n/1.2.3.20     rdkafka       topicb     33,34,35,36,37,38,39,40,41,42,43\n</code></pre> <p>Le gain de temps par rapport a une WebUI est ph\u00e9nom\u00e9nale</p>"},{"location":"kubernetes/argocd/argocd_sa/","title":"Creer son service account ArgoCD","text":"<p>Un SA est toujours utile si l'on souhaite taper l'API pour une quelconque raison.</p> <p>Quelques \u00e9tapes sont n\u00e9cessaires, rien de bien compliquer</p> <p>Dans notre cas, nous d\u00e9ployons ArgoCD via le Helm chart</p> <p>On commence par d\u00e9finir le SA dans le <code>values.yaml</code> du chart</p> <pre><code>argo-cd:\n  configs:\n    cm:\n      accounts.mysuperSA: apiKey\n\n    rbac:\n      policy.csv: |\n        p, mysuperSA, applications, get, */*, allow\n</code></pre> <p>Ici, nous d\u00e9finissons un compte qui aura comme nom  <code>mysuperSA</code> et aura l'autorisation (<code>allow</code>) l'acc\u00e8s \u00e0 toutes les applications en get de tous les projets ArgoCD (<code>*/*</code>)</p> <p>La syntaxe des politiques ArgoCD est la suivante : <code>p, &lt;role/user/group&gt;, &lt;resource&gt;, &lt;action&gt;, &lt;object&gt;, &lt;effect&gt;</code>. Je vous invite \u00e0 consulter la documentation ArgoCD RABC</p> <p>Une fois ceci fait, on v\u00e9rifie que notre compte existe :</p> <pre><code>\u279c  docs git:(master) \u2717 argocd account list\nNAME                 ENABLED  CAPABILITIES\nmysuperSA            true     apiKey\n</code></pre> <p>On voit que ce compte existe. Il faut maintenant qu'on lui cr\u00e9\u00e9 son token associ\u00e9 :</p> <pre><code>argocd account generate-token --account mysuperSA\n</code></pre> <p>Et voil\u00e0, vous poss\u00e9dez maintenant un token \u00e0 utiliser pour acc\u00e9der \u00e0 votre ArgoCD</p>"},{"location":"kubernetes/cli/advanced_commands/","title":"Commandes Avanc\u00e9es","text":"<p>Quelques commandes avanc\u00e9es Kube toujours utile</p> <p>Ces commandes proviennent d'un peu partout, principalement la documentation Kubernetes, mais regroup\u00e9e sur une seule source</p> <p>Lister les pods avec le ServiceAccount par d\u00e9faut</p> <pre><code>kubectl get pods --all-namespaces -o jsonpath='{range .items[?(@.spec.serviceAccountName == \"default\")]}{.metadata.namespace} {.metadata.name}{\"\\n\"}{end}' 2&gt;/dev/null\n</code></pre> <p>Lister les pods tournant sur un noeud sp\u00e9cifique</p> <pre><code>kubectl get pods -A -o wide --field-selector spec.nodeName=\"ip-172-21-21-206.ec2.internal\"\n</code></pre> <p>Compter le nombre d'occurence de la m\u00eame image au sein du cluster</p> <pre><code>kubectl get pods --all-namespaces -o jsonpath=\"{.items[*].spec.containers[*].image}\" |\\\ntr -s '[[:space:]]' '\\n' |\\\nsort |\\\nuniq -c|\\\nsort -r\n</code></pre> <p>Avoir acc\u00e8s aux containers sur une machine</p> <pre><code>nerdctl -H /run/k3s/containerd/containerd.sock --namespace k8s.io ps|grep -v pause\n</code></pre> <p>Forcer un noeud RKE2 K8S comme NotReady</p> <pre><code>systemctl stop rke2-agent\n</code></pre> <p>Lister toutes les taints de tous les noeuds</p> <pre><code>kubectl get nodes -o custom-columns=NAME:.metadata.name,TAINTS:.spec.taints --no-headers\n</code></pre> <p>Lister les CPU/RAM sur les noeuds K8S et allouables sur K8S</p> <pre><code>kubectl get nodes -o custom-columns=NAME:.metadata.name,\"CPU_Capacity\":.status.capacity.cpu,\"CPU_Allocatable\":.status.allocatable.cpu,\"MEMORY_Capacity\":.status.capacity.memory,\"MEMORY_Allocatable\":.status.allocatable.memory\n</code></pre> <p>Lister les FQDN des SVC de tout un namespace</p> <pre><code>kubectl get svc -o jsonpath='{range .items[*]}{.metadata.name}.{.metadata.namespace}.svc.cluster.local{\"\\n\"}{end}'\n</code></pre> <p>Split un manifest Kube contenant plusieurs ressources</p> <p><pre><code>yq -s '.kind +\"_\" + .metadata.name' my_file\n</code></pre> You will have this kind of output  <pre><code>Deployment_release-name-testjd.yml  ExternalSecret_pullsecret.yml  Ingress_release-name-testjd-app-private.yml  Ingress_release-name-testjd-app-public.yml  Ingress_release-name-testjd-app.yml  Service_release-name-testjd.yml\n</code></pre></p>"},{"location":"kubernetes/cli/krew_plugins/","title":"Mes meilleurs plugins Krew","text":"<p>Au quotidien, j'utilise mes diff\u00e9rents plugins Krew. Ils me sont d'une importance vitale dans mon workflow. La liste exhaustive est disponible dans mon Github</p> <p>Pour installer krew et importer ma liste de plugin, rien de plus facile sur mac :</p> <pre><code>brew install krew\nkubectl krew install &lt; ./Plugins_Krew\n</code></pre> <p>Voici en d\u00e9tail \u00e0 quoi servent-ils :</p> <ul> <li><code>browse-pvc</code> permet de parcourir un PVC et de voir son contenu</li> <li><code>df-pv</code> permet de voir tel la commande <code>df</code> l'espace dispo sur son PVC &amp; co</li> <li><code>get-all</code> permet de lister toutes les ressources dans un NS</li> <li><code>klock</code> permet de rafraichir automatiquement une commande, par exemple <code>kubectl krew pods</code> va watch toutes les secondes les changements sur les pods</li> <li><code>modify-secret</code> permet de modifier un secret en plain text</li> <li><code>neat</code> permet de supprimer d'un yaml tous les champs qui sont g\u00e9r\u00e9s par K8S</li> <li><code>netshoot/netshoot</code> permet de simplifier l'utilisation du magnifique container netshoot</li> <li><code>node-shell</code> permet d'ouvrir un shell sur un node</li> <li><code>resource-capacity</code> permet de voir la capacit\u00e9 d'un node</li> <li><code>sniff</code> permet de dump le traffic d'un pod</li> <li><code>tmux-exec</code> permet d'ex\u00e9cuter en simultan\u00e9 des commandes sur des containers</li> <li><code>tree</code> permet de voir sous formes arbres les diff\u00e9rents liens entres les ressources</li> <li><code>view-secret</code> permet de voir les secrets</li> <li><code>view-utilization</code>  est plus ou moins redondant avec <code>resource-capacity</code></li> </ul> <p>N'h\u00e9sitez pas \u00e0 voir la liste des plugins Krew et de d\u00e9nicher quelques p\u00e9pites</p>"},{"location":"kubernetes/cli/kubeconfig/","title":"Manage son $KUBECONFIG","text":"<p>De base, kubectl va chercher sa configuration dans '~/.kube/config. Il est possible de modifier KUBECONFIG pour g\u00e9rer plusieurs clusters diff\u00e9rents.</p> <p>Par exemple</p> <pre><code>export KUBECONFIG=/Users/jeremy/.kube/A:/Users/jeremy/.kube/B\n</code></pre> <p>Via ce KUBECONFIG, nous avons la configuration du fichier A et B charg\u00e9s. Nous pouvons faire plus dynamique via un script \u00e0 mettre dans son bashrc par exemple</p> <pre><code>#!/usr/bin/env bash\nDEFAULT_KUBECONFIG_FILE=\"$HOME/.kube/config\"\nif test -f \"${DEFAULT_KUBECONFIG_FILE}\"\nthen\n  export KUBECONFIG=\"$DEFAULT_KUBECONFIG_FILE\"\nfi\n\n# Your additional kubeconfig files should be inside ~/.kube/config-files\nADD_KUBECONFIG_FILES=\"$HOME/.kube/config-files\"\n[ ! -d $ADD_KUBECONFIG_FILES ] &amp;&amp; mkdir -p \"${ADD_KUBECONFIG_FILES}\"\nOIFS=\"$IFS\"\nIFS=$\\n\nfor kubeconfigFile in `find \"${ADD_KUBECONFIG_FILES}\" -type f -name \"*.yml\" -o -name \"*.yaml\"`\ndo\n    export KUBECONFIG=\"$kubeconfigFile:$KUBECONFIG\"\ndone\nIFS=\"$OIFS\"\n</code></pre> <p>Tous les fichiers dans ~/.kube/config-files et finissant en yml seront charg\u00e9s automatiquement ! Free to use avec kubectx o/</p>"},{"location":"kubernetes/cli/kubeconfig/#utilisation-avancee","title":"Utilisation avanc\u00e9e","text":"<p>Autre mani\u00e8re, il y a l'outil kubeswitch qui permet de g\u00e9rer facilement plusieurs contextes via son fichier de configuration switch-config.yaml.</p> <p>Mon fichier de configuration est disponible dans mon dotfiles</p> <p>Tous les fichiers dans <code>~/.kube/kubeconfig/</code> avec l'extension <code>.yaml</code> seront automatiquement charg\u00e9s.</p> <p>Si vous n'avez que des clusters manag\u00e9s par Rancher, c'est encore mieux ! l'URL Rancher, un token, quelques lignes de configuration, et hop, tous vos clusters sont automagiquement d\u00e9couverts. D'autres fournisseurs sont \u00e9galement disponibles</p> <p>Pour split, n'oubliez pas konfig. Par exemplep pour notre context tools</p> <pre><code>konfig split tools &gt; tools.yaml\n</code></pre>"},{"location":"kubernetes/cli/tools/","title":"Outils pour mieux g\u00e9rer K8S","text":"<p>Kubernetes c'est bien, mais c'est tr\u00e8s vite la gal\u00e8re \u00e0 tout g\u00e9rer. Voici donc quelques outils pour mieux g\u00e9rer tout \u00e7a :</p> <ul> <li><code>kubectx</code> permet de switch rapidement entre plusieurs contextes     K8S : a voir ici.</li> <li><code>kubeswitch</code> permet tout comme kubectx de switch de contextes rapidement. Avantage de kubeswitch, le switch n'est pas g\u00e9n\u00e9ral mais est li\u00e9 \u00e0 la session, on peut donc utiliser sur un m\u00eame terminal diff\u00e9rents clusters : a voir ici</li> <li><code>kubens</code> permet de switch rapidement entre plusieurs namespaces K8S : a voir ici.</li> <li><code>stern</code> permet de tail plusieurs pods rapidement : a voir ici</li> <li><code>kail</code> permet de tail plusieurs pods rapidement : a voir ici.</li> <li><code>kubepug</code> permet de v\u00e9rifier la compatibilit\u00e9 des diff\u00e9rentes APIVersion : a voir ici.</li> <li><code>pluto</code> est un concurrent \u00e0 kubepug, peut \u00eatre plus facile : a voir ici</li> <li><code>ketall</code> permet de (r\u00e9ellement) lister toutes les ressources de son cluster : a voir ici</li> <li><code>konfig</code> est un outil permettant de g\u00e9rer sur <code>~/.kube/config</code> facilement, en faisant des merge, split... : a voir ici</li> <li><code>kubecolor</code> est un outil qui nous permet d'avoir une magnifique coloration syntaxique sur kubectl : a voir ici</li> <li><code>kdash</code> est un dashboard Kubernetes en CLI, tel que k9s : a voir ici</li> </ul> <p>Evidemment, nous avons l'autocompl\u00e9tion \u00e0 activer :</p> <pre><code>echo alias k=kubectl &gt;&gt; ~/.bashrc\necho complete -F __start_kubectl k &gt;&gt; ~/.bashrc/\n</code></pre> <p>Ou bien en zsh :</p> <pre><code>    echo alias k=kubectl &gt;&gt; ~/.zshrc\n    echo compdef __start_kubectl k &gt;&gt; ~/.zshrc\n</code></pre> <p>En GUI, nous avons Lens qui nous permet d'avoir un bon overview de notre cluster rapidement</p>"},{"location":"kubernetes/cli/useful_commands/","title":"Commandes utiles pour K8S","text":"<p>Pour K8S, les commandes sont assez difficiles de base. De plus, il existe certaines commandes assez tricky que je vais essayer de r\u00e9pertorier ici</p> Delete all pods not running <pre><code>kubectl delete pods --field-selector=status.phase!=Running -A\n</code></pre> <p>Permet de supprimer les pods de la liste\u00a0qui ne sont pas running (Dont les evicted). Si vous en avez beaucoup, on passe par xargs comme des barbares</p> Delete massive pods <pre><code>kubectl get pods |grep -v Running |awk '{print $1}' |xargs -P20 -I{} kubectl delete pod {}\n</code></pre> <p>Liste toutes les ressources K8S qui sont link \u00e0 la g\u00e9n\u00e9ration d'un certificat</p> Resources linked to a certificate <pre><code>$ kubectl get Issuers,ClusterIssuers,Certificates,CertificateRequests,Orders,Challenges -A\nNAMESPACE   NAME                                            READY   AGE\nteleport    issuer.cert-manager.io/letsencrypt-production   True    392d\n\nNAMESPACE   NAME                                   READY   SECRET         AGE\nteleport    certificate.cert-manager.io/teleport   True    teleport-tls   392d\n\nNAMESPACE   NAME                                                APPROVED   DENIED   READY   ISSUER                   REQUESTOR                                         AGE\nteleport    certificaterequest.cert-manager.io/teleport-467wl   True                True    letsencrypt-production   system:serviceaccount:cert-manager:cert-manager   213d\nteleport    certificaterequest.cert-manager.io/teleport-7xs8t   True                True    letsencrypt-production   system:serviceaccount:cert-manager:cert-manager   33d\nteleport    certificaterequest.cert-manager.io/teleport-bbw7j   True                True    letsencrypt-production   system:serviceaccount:cert-manager:cert-manager   272d\nteleport    certificaterequest.cert-manager.io/teleport-jb2mk   True                True    letsencrypt-production   system:serviceaccount:cert-manager:cert-manager   153d\nteleport    certificaterequest.cert-manager.io/teleport-kgxhx   True                True    letsencrypt-production   system:serviceaccount:cert-manager:cert-manager   332d\nteleport    certificaterequest.cert-manager.io/teleport-splkd   True                True    letsencrypt-production   system:serviceaccount:cert-manager:cert-manager   93d\n\nNAMESPACE   NAME                                                   STATE   AGE\nteleport    order.acme.cert-manager.io/teleport-467wl-1964815354   valid   213d\nteleport    order.acme.cert-manager.io/teleport-7xs8t-1964815354   valid   33d\nteleport    order.acme.cert-manager.io/teleport-bbw7j-1964815354   valid   272d\nteleport    order.acme.cert-manager.io/teleport-jb2mk-1964815354   valid   153d\nteleport    order.acme.cert-manager.io/teleport-kgxhx-1964815354   valid   332d\nteleport    order.acme.cert-manager.io/teleport-splkd-1964815354   valid   93d\n</code></pre> <p>Permet d'ex\u00e9cuter la m\u00eame commande sur de multiples pods</p> Same commands on multiples pods <pre><code>kubectl get pods -o name | xargs -I{} kubectl exec {} -- &lt;command goes here&gt;\n</code></pre> <p>Permet de lister les PVC qui sont actuellement asssoci\u00e9s \u00e0 un pod</p> List all PVC bound to a pod <pre><code>$ kubectl get pods --all-namespaces -o=json | jq -c '.items[] | {name: .metadata.name, namespace: .metadata.namespace, claimName: .spec |  select( has (\"volumes\") ).volumes[] | select( has (\"persistentVolumeClaim\") ).persistentVolumeClaim.claimName }'\n{\"name\":\"loki-backend-0\",\"namespace\":\"dyn-tools\",\"claimName\":\"data-loki-backend-0\"}\n{\"name\":\"loki-write-0\",\"namespace\":\"dyn-tools\",\"claimName\":\"data-loki-write-0\"}\n{\"name\":\"loki-write-1\",\"namespace\":\"dyn-tools\",\"claimName\":\"data-loki-write-1\"}\n{\"name\":\"prometheus-alertmanager-0\",\"namespace\":\"dyn-tools\",\"claimName\":\"storage-prometheus-alertmanager-0\"}\n{\"name\":\"prometheus-server-7774557469-6jrhk\",\"namespace\":\"dyn-tools\",\"claimName\":\"prometheus-server\"}\n</code></pre> <p>Permet de lister tous les secrets et de les decoder</p> Decode all secrets from a secret <pre><code>kubectl get secret postgresql-secrets -o go-template='{{ range $key, $value := .data }}{{ $key }}{{ \": \" }}{{ $value | base64decode }}{{ \"\\n\" }}{{ end }}'\n</code></pre> <p>Permet d'attacher un container a un pod existant, ici, nous utilisons l'image busybox dans sa version 1.28, nous attachons notre container au pod <code>thanos-bidder-euw1-prod-sidecar-query-57bfd8f848-pmdp9</code> en partageant le process namespace du container query</p> Debug pod <pre><code>kubectl debug -it thanos-bidder-euw1-prod-sidecar-query-57bfd8f848-pmdp9 --image=busybox:1.28 --target=query\n</code></pre> <p>Permet de lister les PVC de tous les NS mais \u00e9galement de lister le pod et le noeud associ\u00e9</p> List PVC bound to a pod and node <pre><code>(echo -e \"NAMESPACE\\tPOD\\tNODE\\tPVC\" &amp;&amp; \\\nkubectl get pods -A -o json | jq -r '\n  .items[]\n  | select(.spec.volumes[]? | has(\"persistentVolumeClaim\"))\n  | . as $pod\n  | $pod.spec.volumes[]\n  | select(.persistentVolumeClaim)\n  | \"\\($pod.metadata.namespace)\\t\\($pod.metadata.name)\\t\\($pod.spec.nodeName)\\t\\(.persistentVolumeClaim.claimName)\"') \\\n| column -t -s $'\\t'\n</code></pre> <p>Permet de forcer le refresh de tous les ExternalSecrets qui sont en erreur</p> Force refresh of ExternalSecrets <pre><code>while read -r ES\ndo\n    NS=$(echo $ES | cut -d ' ' -f1)\n    ES_NAME=$(echo $ES | cut -d ' ' -f2)\n    kubectl annotate es -n $NS $ES_NAME force-sync=$(date +%s) --overwrite\ndone &lt; &lt;(kubectl get es -A|grep -i SecretSyncedError|awk {'print $1 \" \" $2'})\n</code></pre>"},{"location":"kubernetes/deployment/golang_kubernetes_limit/","title":"Golang : D\u00e9finir automatiquement son GOMEMLIMIT/GOMAXPROCS","text":"<p>Golang est un puissant language de programmation dont il est important de connaitre les subtilit\u00e9s, parmis celles-ci <code>GOMEMLIMIT</code> et <code>GOMAXPROCS</code></p> <ul> <li><code>GOMEMLIMIT</code> va d\u00e9finir le comportement du Garbage Collector (GC). Plus la limite tend vers GOMEMLIMT, plus le GC va devenir agressif</li> <li><code>GOMAXPROCS</code> va limiter le nombre de CPU maximum sur lequel va s'ex\u00e9cuter notre programme Go</li> </ul> <p>Imaginons le d\u00e9ploiement K8S suivant :</p> <pre><code>kind: Namespace\napiVersion: v1\nmetadata:\n  name: demo\n---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: go-limits\n  namespace: demo\nspec:\n  containers:\n    - name: test-container\n      image: docker pull debian:trixie-slim\n      resources:\n        limits:\n          memory: 128Mi\n          cpu: \"2\"\n      command:\n        - sh\n        - '-c'\n      args:\n        - &gt;-\n          while true; do echo -en '\\n'; printenv GOMEMLIMIT; printenv GOMAXPROCS\n          sleep 10; done;\n</code></pre> <p>Par d\u00e9faut, nos variables ne sont pas d\u00e9finies automagiquement. Cependant, comme nous avons d\u00e9finit des limites, le container est donc conscient des limites qui lui sont attribu\u00e9es, le programme Go sera inform\u00e9 de ces derni\u00e8res.</p> <p>Il est cependant utile de bien comprendre ces variables, nous allons donc les attribuer automatiquement en ajoutant des variables d'environnement</p> <pre><code>    env:\n    - name: GOMEMLIMIT\n      valueFrom:\n        resourceFieldRef:\n          resource: limits.memory\n    - name: GOMAXPROCS\n      valueFrom:\n        resourceFieldRef:\n          resource: limits.cpu\n</code></pre> <p>Avec ces simples lignes, les variables seront automatiquement remplies. Magique non ? :)</p> <p>Ces deux variables sont bien entendu ind\u00e9pendantes du d\u00e9ploiement via Kubernetes</p>"},{"location":"kubernetes/operator/strimzi/rollout_strimzi/","title":"Comment rollout restart un composant Strimzi","text":"<p>Restart un d\u00e9ploiement est une chose facile sur K8S.</p> <p>Cependant, comme Strimzi a sa propre CRD (strimzipodset), c'est un peu plus ennuyeux.</p> <p>Pour restart un composant strimzi, il faut ajouter une annotation.</p> <p>La premi\u00e8re \u00e9tape consiste \u00e0 v\u00e9rifier quels sont les clusters dont nous disposons :</p> <pre><code>\u279c  strimzi git:(master) k get strimzipodsets.core.strimzi.io -A\nNAMESPACE               NAME                                   PODS   READY PODS   CURRENT PODS   AGE\nnamespace-a             kafka-random-cluster-dev-kafka         3      3            3              2d23h\nnamespace-a             kafka-random-cluster-dev-zookeeper     3      3            3              2d23h\n</code></pre> <p>Annotons le cluster Kafka</p> <pre><code>kubectl annotate -n namespace-a strimzipodset kafka-random-cluster-dev-kafka strimzi.io/manual-rolling-update=\"true\"\n</code></pre> <p>L'op\u00e9rateur traitera l'annotation et d\u00e9clenchera le red\u00e9marrage des pods</p> <p>Vous pouvez ajouter la m\u00eame annotation \u00e0 un pod sp\u00e9cifique si vous souhaitez red\u00e9marrer un seul pod :</p> <pre><code>kubectl annotate -n namespace-a pod kafka-random-cluster-dev-kafka-0 strimzi.io/manual-rolling-update=\"true\"\n</code></pre> <p>Rien n'a \u00e9t\u00e9 invent\u00e9 ici, tout est \u00e9crit dans la documentation</p>"},{"location":"kubernetes/rancher/reset_password/","title":"Reset son password Rancher","text":"<p>Une seule commande suffit :</p> <pre><code>kubectl -n cattle-system exec $(kubectl -n cattle-system get pods -l app=rancher | grep 1/1 | head -1 | awk { print $1 }) -- reset-password\n</code></pre>"},{"location":"kubernetes/rke/bootstrap_cluster/","title":"Bootstrap rapidement son cluster","text":"<p>Pour bootstrap rapidement un cluster, on peut utiliser RKE, un outil Rancher. A noter que nous allons utiliser RKE et non RKEv2 car ce dernier se base sur K3S et non K8S, qui nous apporte beaucoup moins de fonctionnalit\u00e9s.</p> <p>Pour faire simple, RKE c'est un binary et un fichier cluster.yaml. RKE est initialement un simple binaire pouvant \u00eatre ex\u00e9cut\u00e9 depuis le serveur lui m\u00eame, ou bien en remote. Vous trouverez la derni\u00e8re version ici.</p> <p>Voici un exemple de fichier cluster.yml</p> <pre><code>####################################\n## CLUBIC Rancher master cluster ##\n####################################\n\ncluster_name: K8S-CC-Preprod\n\n# Nodes definition\n# ---\nnodes:\n  - address: master01.rancher.k8s.local\n    role: [controlplane, etcd, worker]\n    internal_address: 192.168.1.220\n    hostname_override: master01.rancher.k8s\n    user: mgmt-rancher\n    port: \"1998\"\n    ssh_key_path: ~/.ssh/id_ed25519\n\n  - address: master02.rancher.k8s.local\n    role: [controlplane, etcd, worker]\n    internal_address: 192.168.1.221\n    hostname_override: master02.rancher.k8s\n    user: mgmt-rancher\n    port: \"1998\"\n    ssh_key_path: ~/.ssh/id_ed25519\n\n  - address: master03.rancher.k8s.local\n    role: [controlplane, etcd, worker]\n    internal_address: 192.168.1.222\n    hostname_override: master03.rancher.k8s\n    user: mgmt-rancher\n    port: \"1998\"\n    ssh_key_path: ~/.ssh/id_ed25519\n\n  - address: node01.rancher.k8s.local\n    role: [worker]\n    internal_address: 192.168.1.210\n    hostname_override: node01.rancher.k8s\n    user: mgmt-rancher\n    port: \"1998\"\n    ssh_key_path: ~/.ssh/id_ed25519\n\n  - address: node02.rancher.k8s.local\n    role: [worker]\n    internal_address: 192.168.1.211\n    hostname_override: node02.rancher.k8s\n    user: mgmt-rancher\n    port: \"1998\"\n    ssh_key_path: ~/.ssh/id_ed25519\n\n  - address: node03.rancher.k8s.local\n    role: [worker]\n    internal_address: 192.168.1.212\n    hostname_override: node03.rancher.k8s\n    user: mgmt-rancher\n    port: \"1998\"\n    ssh_key_path: ~/.ssh/id_ed25519\n\n\n# Service settings\n# ---\nservices:\n  kube-api:\n    extra-args:\n      external-hostname: rancher.k8s.domain.tld\n  etcd:\n    snapshot: true\n    creation: 6h\n    retention: 24h\n\n\n# Authentication settings\n# ---\nauthentication:\n  strategy: x509\n  sans:\n    - rancher.k8s.domain.tld\n\n\n# NGINX ingress controller settings\n# ---\ningress:\n  provider: nginx\n  network_mode: hostNetwork\n  options:\n    use-forwarded-headers: \"true\"\n</code></pre> <p>Une fois toute l'infrastructure d\u00e9crite, une simple commande suffit : rke up</p> <p>Ce cluster.yaml est compatible avec Kubernetes 1.22.</p> <p>Comme vous pouvez le voir, nous sp\u00e9cifions \u00e0 rancher que nous souhaitons utiliser l'user mgmt-rancher pour d\u00e9ployer Rancher. Nous discernons ici les noeuds master de worker.</p> <p>L'adresse sp\u00e9cifi\u00e9e doit id\u00e9alement \u00eatre sur un r\u00e9seau priv\u00e9 et \u00eatre r\u00e9solvable.</p> <p>Voici un fichier hosts id\u00e9al pour faire fonctionner notre cluster K8S</p> <pre><code>    # K8S\n    192.168.1.220   master01.vlan master01.rancher.k8s    master01.rancher.k8s.local\n    192.168.1.221   master02.vlan master02.rancher.k8s    master02.rancher.k8s.local\n    192.168.1.222   master03.vlan master03.rancher.k8s    master03.rancher.k8s.local\n\n    192.168.1.210   node01.vlan node01.rancher.k8s    node01.rancher.k8s.local\n    192.168.1.211   node02.vlan node02.rancher.k8s    node02.rancher.k8s.local\n    192.168.1.212   node03.vlan node03.rancher.k8s    node03.rancher.k8s.local\n</code></pre> <p>Nous activons \u00e9galement quelques options suppl\u00e9mentaires tel que le snapshot automatique de l'etcd toutes les 6h. Des examples sont dispoibles sur le site officiel de Rancher. Il est possible par exemple d'envoyer les snapshot automatiquement dans un S3</p>"},{"location":"kubernetes/rke/recover_rkestate/","title":"Recuperer son fichier rkestate","text":"<p>Le fichier rkestate est un fichier qui contient la description du cluster Kubernetes, il est indispensable si vous souhaitez ajouter ou supprimer un node.</p> <p>Pour de quelconques raisons, il est possible que vous ne l'ayez plus. Pas de panique, il est possible de le r\u00e9cuperer via de multiples mani\u00e8res :</p>"},{"location":"kubernetes/rke/recover_rkestate/#depuis-le-master","title":"Depuis le master","text":"<p>Depuis un master, plusieurs mani\u00e8res de le r\u00e9cuperer</p>"},{"location":"kubernetes/rke/recover_rkestate/#master-k8s-119-et","title":"Master - K8S (1.19 et +)","text":"<p>A lancer depuis un noeud controlplane, utilise n'importe quel image hyperkube</p> <pre><code>docker run --rm --net=host -v $(docker inspect kubelet --format '{{ range .Mounts }}{{ if eq .Destination \"/etc/kubernetes\" }}{{ .Source }}{{ end }}{{ end }}')/ssl:/etc/kubernetes/ssl:ro --entrypoint bash $(docker inspect $(docker images -q --filter=label=org.label-schema.vcs-url=https://github.com/rancher/hyperkube-base.git) --format='{{index .RepoTags 0}}' | tail -1) -c 'kubectl --kubeconfig /etc/kubernetes/ssl/kubecfg-kube-node.yaml -n kube-system get configmap full-cluster-state -o json | jq -r .data.\\\"full-cluster-state\\\" | jq -r .' &gt; cluster.rkestate\n</code></pre>"},{"location":"kubernetes/rke/recover_rkestate/#master-k8s-118-et-","title":"Master - K8S (1.18 et -)","text":"<pre><code>docker run --rm --net=host -v $(docker inspect kubelet --format '{{ range .Mounts }}{{ if eq .Destination \"/etc/kubernetes\" }}{{ .Source }}{{ end }}{{ end }}')/ssl:/etc/kubernetes/ssl:ro --entrypoint bash $(docker inspect $(docker images -q --filter=label=org.label-schema.vcs-url=https://github.com/rancher/hyperkube.git) --format='{{index .RepoTags 0}}' | tail -1) -c 'kubectl --kubeconfig /etc/kubernetes/ssl/kubecfg-kube-node.yaml -n kube-system get configmap full-cluster-state -o json | jq -r .data.\\\"full-cluster-state\\\" | jq -r .' &gt; cluster.rkestate\n</code></pre>"},{"location":"kubernetes/rke/recover_rkestate/#master-rancher-v22x","title":"Master - Rancher v2.2.x","text":"<pre><code>docker run --rm --net=host -v $(docker inspect kubelet --format '{{ range .Mounts }}{{ if eq .Destination \"/etc/kubernetes\" }}{{ .Source }}{{ end }}{{ end }}')/ssl:/etc/kubernetes/ssl:ro --entrypoint bash $(docker inspect $(docker images -q --filter=label=io.cattle.agent=true) --format='{{index .RepoTags 0}}' | tail -1) -c 'kubectl --kubeconfig /etc/kubernetes/ssl/kubecfg-kube-node.yaml get configmap -n kube-system full-cluster-state -o json | jq -r .data.\\\"full-cluster-state\\\" | jq -r .' &gt; cluster.rkestate\n</code></pre>"},{"location":"kubernetes/rke/recover_rkestate/#depuis-une-machine-cliente-utilisant-kubectl","title":"Depuis une machine cliente, utilisant kubectl","text":"<pre><code># get kubeconfig file (this one has only *one* context inside)\nkubectl config view --flatten &gt; kube_config_cluster.yml\n# get cluster.yml (this one references *master nodes only*)\nkubectl get configmap -n kube-system full-cluster-state -o \"jsonpath={.data.full-cluster-state}\" | python3 -c 'import json, yaml, sys; yaml.safe_dump(json.load(sys.stdin).get(\"currentState\", []).get(\"rkeConfig\",[]), sys.stdout)' &gt; cluster.yml\n# get rkestate\nrke util get-state-file\n</code></pre> <p>Pour information, je n'ai absolument rien invent\u00e9 sur cet article. Il s'agit simplement d'un m\u00e9mo pour regrouper l'information. La source originelle est ce gist</p>"},{"location":"kubernetes/troubleshooting/resize_pvc_statefulset/","title":"Resize les PVC de son Statefulset","text":"<p>Les Statefulset, c'est archa\u00efque.</p> <p>By-design, la spec ne permet pas de resize les PVC alors qu'on peut totalement resize les PVC des pods associ\u00e9s.</p> <p>Heureusement, tout est possible eheh</p> <ul> <li>On commence par modifier la taille de ses PVC sur les pods : <code>kubectl edit pvc</code></li> <li>On delete le statefulset sans toucher les pods associ\u00e9s : <code>kubectl delete sts my-statefulset --cascade=orphan</code></li> <li>On modifie le template PVC dans le statefulset : <code>kubectl edit sts my-statefulset</code></li> </ul> <p>Hopl\u00e0, on aura notre templace PVC modifi\u00e9 pour nos STS</p>"},{"location":"kubernetes/troubleshooting/troubleshooting_sa/","title":"Debug son ServiceAccount Kubernetes","text":"<p>Un ServiceAccount ? Kezako, encore une notion bizarre de Kube, mais super utile pour donner des droits sp\u00e9cifique \u00e0 un Pod</p> <p>Un ServiceAccount sur Kubernetes est une resource d'API qui repr\u00e9sente une identit\u00e9 pour les applications s'ex\u00e9cutant dans un cluster Kubernetes. Il est utilis\u00e9 pour permettre aux pods ou aux autres ressources d'acc\u00e9der aux ressources du cluster Kubernetes de mani\u00e8re s\u00e9curis\u00e9e. Un ServiceAccount est associ\u00e9 \u00e0 un ensemble de permissions d\u00e9finies par des r\u00f4les ou des r\u00f4les li\u00e9s, ce qui d\u00e9termine les actions que l'entit\u00e9 peut effectuer dans le cluster. Cela permet de contr\u00f4ler et de limiter les privil\u00e8ges des applications, am\u00e9liorant ainsi la s\u00e9curit\u00e9 du syst\u00e8me.</p> <p>Tout cela est bien beau, mais quand notre Pod ne fonctionne pas et qu'on soupconne le ServiceAcccount, comment qu'on fait ? :)</p> <p>C'est simple, en lancant un pod qui utilise ce ServiceAccount et qui ex\u00e9cute une action sur la ressource associ\u00e9e.</p> <p>Exemple simple, j'ai un ServiceAccount qui a pour but de donner l'acc\u00e8s \u00e0 un bucket S3. Voici \u00e0 quoi ressemble mon ServiceAccount :</p> <pre><code>\u279c  ~  k get serviceaccounts loki -o yaml\napiVersion: v1\nautomountServiceAccountToken: true\nkind: ServiceAccount\nmetadata:\n  annotations:\n    eks.amazonaws.com/role-arn: arn:aws:iam:::role/AccessToS3Loki\n    meta.helm.sh/release-name: loki\n    meta.helm.sh/release-namespace: namespace\n  creationTimestamp: \"2023-05-15T14:15:20Z\"\n  labels:\n    app.kubernetes.io/instance: loki\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: loki\n    app.kubernetes.io/version: 2.8.2\n    helm.sh/chart: loki-5.5.0\n  name: loki\n  namespace: namespace\n  resourceVersion: \"103524415\"\n  uid: dd3baab0-7d90-4cf7-aead-76abbe9f77f0\nsecrets:\n- name: loki-x\n</code></pre> <p>On observe que notre bucket S3 reste vide alors que nos pod tournent, on peut donc (l\u00e9gitimiement) soupconner le role d'\u00eatre mauvais, ou que le ServiceAccount soit d\u00e9faillant d'une mani\u00e8re ou d'une autre.</p> <p>On va donc lancer la CLI aws dans un Pod en utilisant ce ServiceAccount</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    run: my-pod\n  name: my-pod\n  namespace:  default\nspec:\n  serviceAccountName: default\n  initContainers:\n  - image: amazon/aws-cli\n    name: my-aws-cli\n    command: ['aws', 's3', 'ls', 's3://loki/']\n  containers:\n  - image: nginx\n    name: my-pod\n    ports:\n    - containerPort: 80\n  dnsPolicy: ClusterFirst\n  restartPolicy: Always\nstatus: {}\n</code></pre> <p>Et on observe les logs de notre Pod</p> <pre><code>\u279c  ~ stern my-pod\n+ my-pod \u203a my-aws-cli\nmy-pod my-aws-cli\nmy-pod my-aws-cli An error occurred (AccessDenied) when calling the ListObjectsV2 operation: Access Denied\n</code></pre> <p>Bingo, notre pod a un probl\u00e8me pour acc\u00e9der au Bucket, probablement la politique \u00e0 modifier :)</p> <p>Par ailleurs, la bonne pratique est de ne pas utiliser le ServiceAccount par d\u00e9faut, voici une petite commande pour \u00eatre sur qu'aucun Pod ne tourne avec :</p> <pre><code>kubectl get pods --all-namespaces -o jsonpath='{range .items[?(@.spec.serviceAccountName == \"default\")]}{.metadata.namespace} {.metadata.name}{\"\\n\"}{end}' 2&gt;/dev/null\n</code></pre>"},{"location":"linux/advanced/lock_ddos/","title":"Luter contre un DDOS","text":"<p>Tr\u00e8s int\u00e9ressant de luter contre un DDOS L7. Voici des pistes \u00e0 check :</p> <ul> <li>Page fixe ? (/login par exemple) -&gt; Pool FPM d\u00e9di\u00e9 du coup</li> <li>User-agent fixe ? -&gt; Drop de l'user agent</li> <li>Pays SRC -&gt; Drop ipset des pays</li> <li>Protocole HTTP1.1/HTTP2.0 -&gt; Si pas 2.0, drop du HTTP 1.1</li> <li>TLS v1.3 / Ciphers ? -&gt; On drop les anciens</li> <li>Jouer sur les timeout pour voir ce qui sature et bien param\u00e9trer les maxconn de toute la stack (HAproxy -&gt; NGINX -&gt; PHP-FPM)</li> </ul>"},{"location":"linux/advanced/move_process_to_tmux/","title":"Deplacer un processus dans un tmux","text":"<p>Il peut \u00eatre utile de d\u00e9placer un processus dans un tmux pour une op\u00e9ration qui peut \u00eatre plus longue que pr\u00e9vue. Techniquement, c'est plut\u00f4t simple. nelhage a \u00e9crit un super outil permettant de rattacher un processus a un nouveau TTY, reptyr</p> <p>Premi\u00e8rement, il faut passer un processus en background. Une fois que c'est effectu\u00e9, il faut dissocier le processus du TTY.</p> <pre><code>\u2514\u2500$ jobs -l\n[1]+ 25644 Signal darr\u00eat         php\n\u2514\u2500$ disown 25644\n-bash: avertissement :suppression de la t\u00e2che stopp\u00e9e 1 avec le groupe de processus 25644\n\u2514\u2500$ jobs -l\n</code></pre> <p>Une fois que c'est OK, on ouvre un tmux, et on attach le processus au nouveau TTY avec reptyr</p> <pre><code>\u2514\u2500$ reptyr 25644\n</code></pre> <p>Et voil\u00e0, on a d\u00e9sormais le processus dans un tmux !</p>"},{"location":"linux/advanced/strace/","title":"Utilisation de strace","text":"<p>Quelques usages assez sympa de strace :</p> <pre><code>strace echo \"Coucou\"\n</code></pre> <p>Nous permet de strace la commande qui est indiqu\u00e9e en param\u00e8tre.</p> <pre><code>sudo strace --summary -f $(pgrep php-fpm | paste -s | sed -e s/'([0-9]'+')/-p '1/g -e s/'t/ /g)\n</code></pre> <p>Permet d'avoir une vue r\u00e9sum\u00e9 de l'ensemble des calls fait par les processus PHP-FPM. (-f permet un follow des child si le process fork)</p> <p>On peut \u00e9galement filtrer par type de call avec -e</p> <pre><code>sudo strace -e stat -f $(pgrep php-fpm | paste -s | sed -e s/'([0-9]'+')/-p '1/g -e s/'t/ /g)\n</code></pre> <p>Ici, on va filtrer uniquement les calls de type stat</p>"},{"location":"linux/advanced/troubleshooting_grub/","title":"Troubleshooting Grub","text":"<p>GRUB c'est chiant. Voici quelques pistes \u00e0 v\u00e9rifier pour son GRUB.</p> <ul> <li>Est-il installer ? grub-install</li> <li>Est-il configurer ? update-grub</li> </ul> <p>Si l'update grub ne fonctionne pas, il faut enlever les 2'&gt;/dev/null du script <code>grub-mkconfig</code> (foutu dev). Si vous avez LVM, il faut \u00e9galement monter le /run dans votre chroot.</p>"},{"location":"linux/advanced/understand_sysfs_procfs/","title":"Exploration pouss\u00e9e des syst\u00e8mes de fichiers sysfs &amp; procfs","text":""},{"location":"linux/advanced/understand_sysfs_procfs/#introduction","title":"Introduction","text":"<p>Beaucoup de r\u00e9pertoires sous Linux sont connus par la majorit\u00e9 des administrateurs syst\u00e8mes (/usr,/etc,/bin)...</p> <p>Cependant, 2 filesystem restent assez m\u00e9connus pour bon nombre d'entre nous, <code>/sys</code> et <code>/proc</code>. Cet article aura pour but d'en expliquer les principaux fichiers.</p>"},{"location":"linux/advanced/understand_sysfs_procfs/#systeme-de-fichier-proc","title":"Syst\u00e8me de fichier /proc","text":"<p><code>/proc</code> dispose de son propre \u00e0 celui-ci, procfs. Il est possible de renforcer la s\u00e9curit\u00e9 de ce dernier qui est simplement inexistante de base. Nous allons voir ult\u00e9rieuemenr les diff\u00e9rentes options de hardening</p>"},{"location":"linux/advanced/understand_sysfs_procfs/#structure-de-base-de-proc","title":"Structure de base de /proc","text":"<p>Il s'agit d'un point de montage mont\u00e9 dans toute les distributions UNIX. Toutes les commandes tels que ps,top,vmstat et free parsent diff\u00e9rents fichiers de /proc afin d'obtenir leur r\u00e9sultats. Voici par exemple le r\u00e9sultat de free et son \u00e9quivalent dans /proc</p> <pre><code>\u03bb jeremy /proc \u2192 free\n              total        used        free      shared  buff/cache   available\nMem:       16379504     1948272     3373296        6112    11057936    14094688\nSwap:       4189180     2077184     2111996\n\n\u03bb jeremy / \u2192 cat /proc/meminfo\nMemTotal:       16379504 kB\nMemFree:         2793060 kB\nMemAvailable:   14082656 kB\nBuffers:          346800 kB\nCached:         10535828 kB\n</code></pre> <p>Nous pouvons voir que la commande free est juste un \"parsage\" du contenu de <code>/proc/meminfo</code>. (Techniquement, le syscall g\u00e9n\u00e9rant le fichier ou utilisant la commande est le m\u00eame, ce n'est pas un \"simple\" parsage)</p> <p>Une vue globale de /proc est disponible ici</p> <p>Tout d'abord, nous pouvons voir les dossiers <code>/proc/[pid]</code>. Chaque r\u00e9pertoire contient diff\u00e9rentes informations pour chaque PID, nous reviendrons sur ces r\u00e9pertoires par la suite. Par d\u00e9faut, chaque utilisateur peut voir tous les PID de tout le monde. Cependant, il est possible de rendre invisible les PID ne nous appartenant pas afin de rendre plus s\u00e9curis\u00e9 notre syst\u00e8me. N'importe quel utilisateur non-privil\u00e9gi\u00e9 peut acc\u00e9der a beaucoup d'informations. Ce n'est pas forc\u00e9ment critique, mais moins l'utilisateur en sait, mieux c'est non ? :-)</p> <p>De m\u00eame que pour les pids, nous avoir un r\u00e9pertoire virtuel</p> <ul> <li> <p><code>/proc/net</code> contient de multiples informations sur les composants r\u00e9seaux de votre syst\u00e8me.</p> </li> <li> <p><code>/proc/sys</code> est un r\u00e9pertoire o\u00f9 nous pouvons d\u00e9finir ou visualiser beaucoup de comportements du syst\u00e8me tel que le nombre maximum de PID du syst\u00e8me, le comportement \u00e0 adopter apr\u00e8s un kernel-panic...</p> </li> <li> <p><code>/proc/irq</code> est un r\u00e9pertoire un peu '\"particulier'\" o\u00f9 nous pouvons d\u00e9finir manuellement les interruptions \u00e0 un certain core du CPU.</p> </li> </ul> <p>Outre ces r\u00e9pertoires, de nombreux fichiers peuvent nous importer de nombreuses informations.</p>"},{"location":"linux/advanced/understand_sysfs_procfs/#fichiers-utiles","title":"Fichiers utiles","text":"<p>Tous les fichiers ne seront pas trait\u00e9s dans cette partie, seuls les fichiers que j'ai jug\u00e9 utiles le seront. Certains autres fichiers peuvent \u00e9galement \u00eatre utiles mais difficilement exploitable par l'Homme.</p> <ul> <li><code>/proc/cpuinfo</code> nous apportera des pr\u00e9cisions sur quel processeur nous utilisons, son mod\u00e8le, les bugs auxquels il est vuln\u00e9rable...</li> </ul> /proc/cpuinfo <pre><code>processor   : 0\nvendor_id   : GenuineIntel\ncpu family  : 6\nmodel       : 42\nmodel name  : Intel(R) Xeon(R) CPU E31230 @ 3.20GHz\nstepping    : 7\nmicrocode   : 0x2f\ncpu MHz     : 3559.874\ncache size  : 8192 KB\nphysical id : 0\nsiblings    : 8\ncore id     : 0\ncpu cores   : 4\napicid      : 0\ninitial apicid  : 0\nfpu     : yes\nfpu_exception   : yes\ncpuid level : 13\nwp      : yes\nflags       : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer aes xsave avx lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid xsaveopt dtherm ida arat pln pts md_clear flush_l1d\nbugs        : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit\nbogomips    : 6385.39\nclflush size    : 64\ncache_alignment : 64\naddress sizes   : 36 bits physical, 48 bits virtual\npower management:\n</code></pre> <p>Un petit extrait de notre fichier /proc/cpuinfo. Nous pouvons rapidement voir qu'il s'agit d'un mod\u00e8le E3-1230 propuls\u00e9 \u00e0 3.20GHz de base. Nous pouvons voir la version du microcode embarqu\u00e9, les instructions embarqu\u00e9es ainsi que les bugs auquel il est touch\u00e9.</p> <p>Pour rappel, si vous souhaitez retrouver des performances sur votre processeur Intel et d\u00e9sactiver les patchs de s\u00e9curit\u00e9, je vous rappelle qu'un tutoriel est disponible ici</p> <ul> <li><code>/proc/meminfo</code> nous permet d'obtenir toutes les informations     n\u00e9cessaires \u00e0 notre RAM (RAM Totale, disponible, free...)</li> </ul> Sample of /proc/meminfo <pre><code>MemTotal:       16379496 kB\nMemFree:         1008852 kB\nMemAvailable:   14001640 kB\nBuffers:           87848 kB\nCached:         12093768 kB\n</code></pre> <ul> <li><code>/proc/cgroup</code> est un m\u00e9canisme de linux (Control Group) est un     ensemble de processus li\u00e9s \u00e0 un ensemble de limites ou param\u00e8tres     d\u00e9finis via un filesystem cgroup. Ce m\u00e9canisme est par exemple     utilis\u00e9 par Docker afin de limiter les ressources si vous le     souhaitez. Nous explorerons certainement les cgroups dans un prochain     articl.</li> <li><code>/proc/cmdline</code> est \u00e9galement un fichier tr\u00e8s int\u00e9ressant. il nous     indique avec quels param\u00e8tres est lanc\u00e9 notre kernel Linux mais     \u00e9galement dans quelle version</li> </ul> <pre><code>\u03bb jeremy /proc \u2192 cat cmdline\nBOOT_IMAGE=/vmlinuz-4.19.0-8-amd64 root=UUID=ccedef42-f296-4e01-ad9e-4327f847b728 ro debian-installer=en_US.UTF-8 quiet noibrs noibpb nopti nospectre_v2 nospectre_v1 l1tf=off nospec_store_bypass_disable no_stf_barrier mds=off mitigations=off\n</code></pre> <p>Je d\u00e9marre ici sur le kernel 4.19.0-8 sur la partition ayant l'UUID ccedef42-f296-4e01-ad9e-4327f847b728 en d\u00e9sactivant tous les patchs de s\u00e9curit\u00e9 du CPU</p> <ul> <li><code>/proc/filesystems</code> pour lister tous les FS g\u00e9rer par le kernel     nativement.</li> <li><code>/proc/interrupts</code> nous permet de voir comment sont g\u00e9rees les     interruptions et celles qui sont utilis\u00e9es. Pour expliquer un petit     peu le fichier :</li> </ul> Sample of /proc/interrupts <pre><code>               CPU0       CPU1       CPU2       CPU3\n      0:          6          0          0          0  IR-IO-APIC   2-edge      timer\n      1:          0          0          0          9  IR-IO-APIC   1-edge      i8042\n      8:          0          1          0          0  IR-IO-APIC   8-edge      rtc0\n      9:          0          0          0          0  IR-IO-APIC   9-fasteoi   acpi\n     12:          0          0          5          0  IR-IO-APIC  12-edge      i8042\n     16:          0          0          0        453  IR-IO-APIC  16-fasteoi   uhci_hcd:usb2, hpilo\n     20:         29          0          0          0  IR-IO-APIC  20-fasteoi   ehci_hcd:usb3\n     21:          0          0         30          0  IR-IO-APIC  21-fasteoi   ehci_hcd:usb1\n     24:          0          0          0          0  DMAR-MSI   0-edge      dmar0\n     25:  158604567  960976068  268830823  527035126  IR-PCI-MSI 1048576-edge      eno0-rx-0\n     26:  475449447  461628402  354301051  453787807  IR-PCI-MSI 1048577-edge      eno0-tx-0\n     27:      66007      20504      41564      25490  IR-PCI-MSI 1048578-edge      eno0\n     28:   76098051          0          0          0  IR-PCI-MSI 2097152-edge      hpsa0-msix0\n     29:          0   79605111          0          0  IR-PCI-MSI 2097153-edge      hpsa0-msix1\n</code></pre> <p>La premi\u00e8re colonne correspond \u00e0 l'IRQ, les CPUs aux diff\u00e9rents cores de notre machine, et la derni\u00e8re au nom de l'interruption. Il s'agit ici d'un extrait, le syst\u00e8me dispose de bien plus d'IRQ que celles-ci et sont variables selon vos composant syst\u00e8mes.</p> <p>Ici, dans cet exemple, nous pouvons voir que les IRQ 25/26 correspondeant au nombre interruptions depuis le lanchement de notre machine de notre NIC eno0 en RX/TX sont g\u00e9r\u00e9es par les 4 threads de notre processeur de mani\u00e8re non \u00e9quitable. Voici un exemple d'un autre serveur :</p> <pre><code>               CPU0       CPU1       CPU2       CPU3       CPU4       CPU5       CPU6       CPU7\n     25:          0          0        107          0          0          0  350619649          0  IR-PCI-MSI 1048576-edge      eno0-rx-0\n     26:          0          0          0         59          0  415375689          0          0  IR-PCI-MSI 1048577-edge      eno0-tx-0\n</code></pre> <p>Ici, nous pouvons voir que le RX est uniquement g\u00e9r\u00e9 par le CPU6 et le TX par CPU7. Sur des petits d\u00e9bits, ce n'est pas forc\u00e9ment grave, sur de gros d\u00e9bits, cela peut causer un bottleneck. Il est possible d'obtenir un r\u00e9sultat un peu plus digeste via la commande dstat. <code>dstat -tif --int24 60</code> nous permet de lister toutes les interruptions syst\u00e8me pour une dur\u00e9e donn\u00e9e (Ici 60 secondes)</p> <pre><code>\u03bb jeremy ~ \u2192 dstat -tif --int24 60\n----system---- -------------------interrupts------------------ -------------interrupts------------\n     time     |  20    21    25    26    27    28    29    30 | LOC   PMI   RES   CAL   TLB   MCP\n14-04 22:18:05|   0     0   237   129     0     8     0     0 | 468     0    16   119   108     0\n14-04 22:19:05|   0     0   116     6     0     2     0     0 | 414     0     8    11     0     0\n14-04 22:20:05|   0     0   119    15     0     1     0     0 | 412     0     9    10     0     0\n</code></pre> <p>Plus d'informations dans le man de la commande.</p> <ul> <li>loadavg qui nous fournit le load-average que nous connaissons     tous</li> </ul> <pre><code>\u03bb jeremy /proc \u2192 cat loadavg\n0.24 0.10 0.09 1/546 5181\n</code></pre> <p>Les 3 premi\u00e8res valeurs nous fournissent la charge moyenne du syst\u00e8me pour 1/5/15 minutes derni\u00e8res minutes. Le 4\u00e8me champ contient 2 valeurs distinctes s\u00e9par\u00e9es par un /, la premi\u00e8re corresond au nombre de processus s'ex\u00e9cutant en ce moment et le nombre total de processus. Enfin la derni\u00e8re valeur correspond au PID le plus r\u00e9cent du syst\u00e8me.</p> <p>Il est possible d'avoir un load d\u00e9taill\u00e9, pour cela, on s'int\u00e9resse au dossier <code>/proc/pressure</code></p> <pre><code>\u03bb jeremy ~ \u2192 ls /proc/pressure\ncpu  io  memory\n</code></pre> <p>Ici, le format est l\u00e9g\u00e8rement diff\u00e9rent du fichier <code>/proc/loadavg</code></p> <pre><code>\u03bb jeremy ~ \u2192 cat /proc/pressure/cpu\nsome avg10=3.58 avg60=4.12 avg300=3.72 total=603533453516\n</code></pre> <p>Dans notre exemple, il s'agit du % de process attendant le CPU pendant les 10, 60 et 300 derni\u00e8res secondes. Il s'agit donc d'une valeur plus int\u00e9ressante en cas d'un troubleshooting fin qu'un simple load-average</p>"},{"location":"linux/advanced/understand_sysfs_procfs/#hardening-de-proc","title":"Hardening de /proc","text":"<p>2 options sont particuli\u00e8rement int\u00e9ressantes dans le montage de <code>/proc</code>pour renforcer de la s\u00e9curit\u00e9 sous Linux : <code>hidepid</code> et <code>gid</code></p> <p>La premi\u00e8re permet de cacher les informations des diff\u00e9rents PID par certains utilisateurs. Cette option prend 3 valeurs :</p> <ul> <li>hidepid=0 : Tout le monde peut acc\u00e9der au diff\u00e9rents PID. Si aucune valeur n'est explicitement sp\u00e9cifi\u00e9e, il s'agit de la valeur par d\u00e9faut</li> <li>hidepid=1 : Tout le monde peut voir l'arborescence de tous les PID, mais certains fichiers ne seront pas accessible par les autres utilisateurs</li> <li>hidepid=2 : Personne ne voit les dossier des PID (/proc/[pid]) hormis root. Il s'agit donc de l'option la plus sure.</li> </ul> <p>En combinaison avec <code>hidepid</code>, nous avons l'option <code>gid</code>. Comme son nom l'indique tr\u00e8s simplement, cela permettra aux users qui disposent du GID indiqu\u00e9 de voir tous les PID, malgr\u00e9 un <code>hidpid=2</code> sp\u00e9cifi\u00e9.</p> <p>Un cas typique est l'utilisation d'un monitoring. Celui-ci aura besoin de voir l'int\u00e9gralit\u00e9 du syst\u00e8me, mais ne doit pas tourner en tant que root.</p> <p>Imaginons que notre utilisateur <code>monitoring</code> appartient au GID 1500 et que notre utilisateur <code>pierre</code> dispose d'un GID de 1200.</p> <pre><code>\u03bb jeremy /proc \u2192 cat /etc/fstab\nproc    /proc        proc        defaults,hidepid=2,gid=1500    0 0\n</code></pre> <p>Dans ce notre exemple ci-dessus :</p> <ul> <li>Comme toujours, notre utilisateur <code>root</code> verra tous les PID.</li> <li>Notre utilisateur <code>monitoring</code> verra tous les PID, grace \u00e0 son appartenance au groupe 1500</li> <li>Notre user g\u00e9n\u00e9rique <code>pierre</code> ne verra quant \u00e0 lui que les PID dont il est propri\u00e9taire, n'appartenant pas au GID 1500</li> </ul>"},{"location":"linux/advanced/understand_sysfs_procfs/#sys","title":"/sys","text":""},{"location":"linux/advanced/cli/extend_partition/","title":"Etendre \u00e0 chaud sa partition root","text":"<p>Etendre une partition root \u00e0 chaud sur son serveur requiert g\u00e9n\u00e9ralement un red\u00e9marrage de ce dernier sur un syst\u00e8me rescue (hors syst\u00e8me scalable comme LVM,XFS ou autre). Hors, via un simple logiciel, il est possible d'\u00e9viter ce red\u00e9marrage en rescue : growpart.</p> <p>Ceci peut \u00eatre extr\u00eamemnt utile dans le cas d'un agrandissement \u00e0 chaud d'un disque dur d'un VPS par exemple.</p> <p>Tout d'abord, nous devons v\u00e9rifier que le disque dur a bien \u00e9t\u00e9 \u00e9tendu sur le syst\u00e8me :</p> <pre><code>[vps ~]$ lsblk\nNAME          MAJ:MIN RM SIZE RO TYPE MOUNTPOINT\nnvme1n1       259:0    0  30G  0 disk /data\nnvme0n1       259:1    0  16G  0 disk\n\u2514\u2500nvme0n1p1   259:2    0   8G  0 part /\n\u2514\u2500nvme0n1p128 259:3    0   1M  0 part\n</code></pre> <p>Ici, nous voyons que nous avons 2 disques dur NVMe. Sur nvme0n1, nous pouvons voir 2 partitions, une de 8GB et une de 1M. Nous souhaitons donc \u00e9tendre la partition root \u00e0 16G.</p> <pre><code>[vps ~]$ growpart /dev/nvme0n1 1\n</code></pre> <p>La syntaxe du logiciel est tr\u00e8s simple \u00e0 comprendre. Nous prenons le disque dur nvme0n1 et choisissons la premi\u00e8re partition. Nous refaisons un coup de lsblk afin de s'assurer que la partition a \u00e9t\u00e9 \u00e9tendue :</p> <pre><code>[vps ~]$ lsblk\nNAME          MAJ:MIN RM SIZE RO TYPE MOUNTPOINT\nnvme1n1       259:0    0  30G  0 disk /data\nnvme0n1       259:1    0  16G  0 disk\n\u2514\u2500nvme0n1p1   259:2    0  16G  0 part /\n\u2514\u2500nvme0n1p128 259:3    0   1M  0 part\n</code></pre> <p>Nous pouvons voir d\u00e9sormais que la partition fait 16G et non 8G. Il ne nous reste plus qu'\u00e0 notifier ce changement</p> <pre><code>[vps ~]$ resize2fs /dev/nvme0n1p1\n</code></pre> <p>Nous avons d\u00e9sormais notre partition / \u00e9tendue sans aucune interruption de service</p>"},{"location":"linux/advanced/shell/debug_slowness_ohmyzsh/","title":"Debug ses lenteurs de ohmyzsh","text":"<p>Quelques informations chop\u00e9es \u00e0 gauche \u00e0 droite bien utile</p> <p>On peut profiler basiquement quel plugin cause les lenteurs, dans le fichier source de ohmyzsh remplacer cette partie de code par le code suivant :</p> <pre><code># Load all of the plugins that were defined in ~/.zshrc\nfor plugin ($plugins); do\n  timer=$(($(/opt/homebrew/bin/gdate +%s%N)/1000000))\n  if [ -f $ZSH_CUSTOM/plugins/$plugin/$plugin.plugin.zsh ]; then\n    source $ZSH_CUSTOM/plugins/$plugin/$plugin.plugin.zsh\n  elif [ -f $ZSH/plugins/$plugin/$plugin.plugin.zsh ]; then\n    source $ZSH/plugins/$plugin/$plugin.plugin.zsh\n  fi\n  now=$(($(/opt/homebrew/bin/gdate +%s%N)/1000000))\n  elapsed=$(($now-$timer))\n  echo $elapsed\":\" $plugin\ndone\n</code></pre> <p>Ce code induit que vous \u00eates sur mac avec gdate d'install\u00e9, sinon, utilisez simplement date. Vous aurez l'output suivant :</p> <pre><code>27: ssh-agent\n3: terraform\n14: zsh-syntax-highlighting\n3: timer\n4: kubectl\n3: kube-ps1\n4: helm\n3: battery\n37: brew\n5: aws\n</code></pre> <p>On peut d\u00e9j\u00e0 voir que les 2 plugins les plus lents sont ssh-agent et zsh-syntax-highlighting, mais sans \u00eatre alarmant.</p> <p>N'h\u00e9sitez pas \u00e0 cleanup r\u00e9guli\u00e8rement vos plugins</p> <p>On peut \u00e9galement faire un profiling beaucoup plus pouss\u00e9 avec du zsh natif</p> <pre><code>\u279c  ~ cat .zshrc\nzmodload zsh/zprof\n...\nvotre zshrc classique\n...\nzprof\n</code></pre> <p>Via cette m\u00e9thode, nous aurons r\u00e9ellement un profiling de votre ZSH d\u00e9taill\u00e9</p> <pre><code>num  calls                time                       self            name\n-----------------------------------------------------------------------------------\n 1)    1         642.37   642.37   85.74%    369.76   369.76   49.36%  compinit\n 2)  816         138.14     0.17   18.44%    138.14     0.17   18.44%  compdef\n 3)    1         107.30   107.30   14.32%    107.30   107.30   14.32%  compdump\n 4)    1          29.49    29.49    3.94%     29.49    29.49    3.94%  _add_identities\n 5)    2          28.07    14.04    3.75%     28.07    14.04    3.75%  compaudit\n 6)   21          34.68     1.65    4.63%     25.59     1.22    3.42%  _omz_source\n 7)    1          16.80    16.80    2.24%     16.80    16.80    2.24%  zrecompile\n 8)    1           8.76     8.76    1.17%      8.69     8.69    1.16%  _zsh_highlight_load_highlighters\n 9)    1           5.59     5.59    0.75%      5.59     5.59    0.75%  (anon) [/Users/jeremy/.oh-my-zsh/tools/check_for_upgrade.sh:157]\n10)    1           4.32     4.32    0.58%      4.32     4.32    0.58%  test-ls-args\n11)    1           9.85     9.85    1.31%      4.26     4.26    0.57%  handle_update\n12)    4           2.37     0.59    0.32%      2.37     0.59    0.32%  is-at-least\n13)    1           1.79     1.79    0.24%      1.78     1.78    0.24%  _zsh_highlight__function_callable_p\n14)    1           1.50     1.50    0.20%      1.50     1.50    0.20%  _start_agent\n15)    3           1.27     0.42    0.17%      1.23     0.41    0.16%  add-zle-hook-widget\n16)    1           1.06     1.06    0.14%      1.06     1.06    0.14%  regexp-replace\n17)    1           0.89     0.89    0.12%      0.89     0.89    0.12%  colors\n18)    9           0.85     0.09    0.11%      0.85     0.09    0.11%  add-zsh-hook\n19)    3           0.58     0.19    0.08%      0.58     0.19    0.08%  bashcompinit\n20)    1           0.34     0.34    0.05%      0.28     0.28    0.04%  _kube_ps1_init\n21)    5           0.43     0.09    0.06%      0.19     0.04    0.03%  complete\n22)   19           0.19     0.01    0.03%      0.19     0.01    0.03%  is_plugin\n23)    3           0.24     0.08    0.03%      0.09     0.03    0.01%  _build_kubectl_out_alias\n24)    3           0.05     0.02    0.01%      0.05     0.02    0.01%  is_theme\n25)    1           0.04     0.04    0.01%      0.04     0.04    0.01%  (anon) [/usr/share/zsh/5.9/functions/add-zle-hook-widget:28]\n26)    2           0.02     0.01    0.00%      0.02     0.01    0.00%  env_default\n27)    1           0.01     0.01    0.00%      0.01     0.01    0.00%  _zsh_highlight__is_function_p\n28)    1           0.00     0.00    0.00%      0.00     0.00    0.00%  _zsh_highlight_bind_widgets\n\n-----------------------------------------------------------------------------------\n</code></pre> <ul> <li>Les colonnes les plus importantes sont le temps pass\u00e9 dans le self, en pourcentage et en temps r\u00e9el</li> <li>Cette stacktrace nous apprend qu'une grande partie du temps est pass\u00e9 dans les calls de compinit, compinit et compdump</li> </ul> <p>Par la suite, nous avons le d\u00e9tail de chaque num\u00e9ro, par exemple</p> <pre><code> 1)    1         642.37   642.37   85.74%    369.76   369.76   49.36%  compinit\n       1/2        28.07    28.07    3.75%      0.17     0.17             compaudit [5]\n       1/1       107.30   107.30   14.32%    107.30   107.30             compdump [3]\n     800/816     137.23     0.17   18.32%    137.23     0.17             compdef [2]\n</code></pre> <ul> <li>Dans les 369ms de compinit qui prend 49% de zsh, une grande partie est du \u00e0 compdump</li> </ul> <p>Plus qu'\u00e0 faire de la speleologie dans vos plugins :)</p>"},{"location":"linux/advanced/shell/template_bash_script/","title":"Un template pour un script bash","text":"<p>Ecrire un script bash, tout le monde peut le faire. Ecrire un bon script bash, c'est d\u00e9j\u00e0 plus compliqu\u00e9.</p> <pre><code>#!/usr/bin/env bash\n\nset -Eeuo pipefail\ntrap cleanup SIGINT SIGTERM ERR EXIT\n\nscript_dir=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" &amp;&gt;/dev/null &amp;&amp; pwd -P)\n\nusage() {\n  cat &lt;&lt; EOF # remove the space between &lt;&lt; and EOF, this is due to web plugin issue\nUsage: $(basename \"${BASH_SOURCE[0]}\") [-h] [-v] [-f] -p param_value arg1 [arg2...]\n\nScript description here.\n\nAvailable options:\n\n-h, --help      Print this help and exit\n-v, --verbose   Print script debug info\n-f, --flag      Some flag description\n-p, --param     Some param description\nEOF\n  exit\n}\n\ncleanup() {\n  trap - SIGINT SIGTERM ERR EXIT\n  # script cleanup here\n}\n\nsetup_colors() {\n  if [[ -t 2 ]] &amp;&amp; [[ -z \"${NO_COLOR-}\" ]] &amp;&amp; [[ \"${TERM-}\" != \"dumb\" ]]; then\n    NOFORMAT='\\033[0m' RED='\\033[0;31m' GREEN='\\033[0;32m' ORANGE='\\033[0;33m' BLUE='\\033[0;34m' PURPLE='\\033[0;35m' CYAN='\\033[0;36m' YELLOW='\\033[1;33m'\n  else\n    NOFORMAT='' RED='' GREEN='' ORANGE='' BLUE='' PURPLE='' CYAN='' YELLOW=''\n  fi\n}\n\nmsg() {\n  echo &gt;&amp;2 -e \"${1-}\"\n}\n\ndie() {\n  local msg=$1\n  local code=${2-1} # default exit status 1\n  msg \"$msg\"\n  exit \"$code\"\n}\n\nparse_params() {\n  # default values of variables set from params\n  flag=0\n  param=''\n\n  while :; do\n    case \"${1-}\" in\n    -h | --help) usage ;;\n    -v | --verbose) set -x ;;\n    --no-color) NO_COLOR=1 ;;\n    -f | --flag) flag=1 ;; # example flag\n    -p | --param) # example named parameter\n      param=\"${2-}\"\n      shift\n      ;;\n    -?*) die \"Unknown option: $1\" ;;\n    *) break ;;\n    esac\n    shift\n  done\n\n  args=(\"$@\")\n\n  # check required params and arguments\n  [[ -z \"${param-}\" ]] &amp;&amp; die \"Missing required parameter: param\"\n  [[ ${#args[@]} -eq 0 ]] &amp;&amp; die \"Missing script arguments\"\n\n  return 0\n}\n\nparse_params \"$@\"\nsetup_colors\n\n# script logic here\n\nmsg \"${RED}Read parameters:${NOFORMAT}\"\nmsg \"- flag: ${flag}\"\nmsg \"- param: ${param}\"\nmsg \"- arguments: ${args[*]-}\"\n</code></pre> <p>Quelques explications de ce template (qui n'est pas de moi, mais qui est excellent)</p> <ul> <li>Utilisation de env \u00e0 la place de bash directement pour garantir une compatibilit\u00e9 sur tous les OS</li> <li>Utilisation de trap pour effectuer une fonction de cleanup</li> <li>Affichage d'une aide</li> <li>Parsage des param\u00e8tres fournit au script</li> </ul>"},{"location":"linux/advanced/shell/tips_bash/","title":"Astuces bash","text":""},{"location":"linux/advanced/shell/tips_bash/#historique-bash","title":"Historique bash","text":"<pre><code>HISTSIZE=1000\n</code></pre> <p>Nous permet de d\u00e9finir un historique de 1000 commandes (au lieu de 500 par d\u00e9faut)</p> <pre><code>HISTFILE = ~/.bash_history\n</code></pre> <p>Permet de d\u00e9finir un fichier o\u00f9 seront stock\u00e9es l'historique</p> <pre><code>HISTIGNORE=\"ls *:man *:history:clear:GCP_KEY*\"\n</code></pre> <p>Nous permet de ne pas logger toutes les commandes, ici, nous ignorons clear, tous les ls, tous les man, et notre cl\u00e9 GCP.</p>"},{"location":"linux/advanced/shell/tips_bash/#divers","title":"Divers","text":"<pre><code>fc\n</code></pre> <p>Nous permet d'ouvrir la derni\u00e8re commande dans notre \u00e9diteur par d\u00e9faut et de l'\u00e9diter plus facilement, puis de la r\u00e9ex\u00e9cuter dans la foul\u00e9e</p> <pre><code>sleep $[ ( $RANDOM % 10 )  + 1 ]s\n</code></pre> <p>Introduit un random entre 1 et 10s</p> <pre><code># Disconnect the session after 30 minutes of idle\nif [ -z \"$TMOUT\" ] ; then\n    TMOUT=1800\n    [ -z \"$TMUX\" ] || TMOUT=345600\nfi\n</code></pre> <p>Comme dis dans le commentaire, permet de deconnecteur automatiquement un user apr\u00e8s X secondes, \u00e0 mettre dans le .bashrc ou autre prompt</p>"},{"location":"linux/advanced/shell/tips_zsh/","title":"Astuces zsh","text":"<p>Tout comme les astuces bash, mais des astuces sp\u00e9cifiques \u00e0 zsh.</p>"},{"location":"linux/advanced/shell/tips_zsh/#fichiers","title":"Fichiers","text":"<p>A ins\u00e9rer dans son .zshrc de pr\u00e9f\u00e9rence</p> <pre><code>alias -s yml=vim\n</code></pre> <p>Grace \u00e0 cette option, si nous tapons le nom du fichier dans notre shell zsh, celui-ci sera ouvert via vim. Il est \u00e9galement possible de faire une association en masse</p> <pre><code>alias -s {yml,yaml}=vim\n</code></pre>"},{"location":"linux/advanced/shell/useful_commands/","title":"Liste de commandes utiles assez avanc\u00e9es","text":"<ul> <li>Permet de tcpdump uniquement les IPv6 RA</li> </ul> <pre><code>tcpdump -vvvv -tttt -i ethX icmp6 and ip6[40] = 134\n</code></pre> <ul> <li>Pour pinguer une adresse du link-local, ne pas oublier le %ethX</li> </ul> <pre><code>ping6 fe80::2%eth0\n</code></pre> <ul> <li>Permet de faire un SMART sur un HDD en RAID (DELL)</li> </ul> <pre><code>smartctl -T permissive -a /dev/sgX\n</code></pre> <ul> <li>Permet d'enregistrer les trames en format pcap puis de les d\u00e9coder</li> </ul> <pre><code>tshark -w data.pcap\ntshark -nr data.pcap -V\n</code></pre> <ul> <li>Si un volume ne peut pas s'unmount (Comme un NFS par exemple)</li> </ul> <pre><code>umount -f -l /mnt/\n</code></pre> <ul> <li>Permet de supprimer un LV quand on a un probl\u00e8me</li> </ul> <pre><code>lvchange -an -v /dev/mapper/grp-jojo\nlvremove -vf /dev/mapper/grp-jojo\n</code></pre> <ul> <li>Rename lvold en lvnew dans le VG vg02</li> </ul> <pre><code>lvrename vg02 lvold lvnew\n</code></pre> <ul> <li>Lancer une t\u00e2che de fond avec la priorit\u00e9 CPU et disque minimale     (afin qu'elle ralentisse le moins possible les autres programmes)</li> </ul> <pre><code>alias ni=nice -n 19 ionice -c3 &gt;&gt; ~/.zshrc\nni tar cvfz monarchive.tgz monrepertoire/\n</code></pre> <ul> <li>Copie les fichiers localement en ignorant les symlink et en     pr\u00e9cisant un port (A faire sur le serveur o\u00f9 les donn\u00e9es sont     situ\u00e9es de base)</li> </ul> <pre><code>rsync --progress -avhe ssh -p 1998 . jeremy@$IP:$PATH\n</code></pre> <ul> <li>Installe tous les packages 7.2 existants par les 7.3</li> </ul> <pre><code>dpkg -l|grep php7.2|awk {print $2}|sed s/7.2/7.3/g|xargs apt install -y\n</code></pre> <ul> <li>N'utilise pas l'alias de ls</li> </ul> <pre><code>\\ls\n</code></pre> <ul> <li>G\u00e9n\u00e8re un fichier de 10G rapidement</li> </ul> <pre><code>fallocate -l 10G test.img\n</code></pre> <ul> <li>R\u00e9cuperer le mod\u00e8le de serveur</li> </ul> <pre><code>dmidecode | grep -A3 ^System Information\n</code></pre> <ul> <li>Test le nouveau nom de l'interface</li> </ul> <pre><code>udevadm test-builtin net_id /sys/class/net/eth0\n</code></pre> <ul> <li>Cr\u00e9er un RAID5 en assumant que le RAID est fonctionnel. (Utile si le     RAID n'est pas du tout d\u00e9tect\u00e9)</li> </ul> <pre><code>mdadm --create /dev/md0 --level=5 --raid-devices=3 /dev/mapper/sdb1 /dev/mapper/sdc1 /dev/mapper/sdd1 --assume-clean\n</code></pre> <p>Warning</p> <p>La reconstruction du raid est \"brid\u00e9\" par des param\u00e8tres sysctl, <code>dev.raid.speed_limit_min</code> et <code>dev.raid.speed_limit_max</code></p> <ul> <li>Se reendre dans le BIOS directement au reboot</li> </ul> <pre><code>systemctl reboot --firmware-setup\n</code></pre> <ul> <li>Lister les crontabs des utilisateurs</li> </ul> <pre><code>cat /var/spool/cron/crontabs/\n</code></pre> <ul> <li>Backup &amp; Restore des ACL (Fortement utile pour une modification de     masse)</li> </ul> <pre><code>getfacl -R . &gt;permissions.facl\nsetfacl --restore=permissions.facl\n</code></pre> <ul> <li>Extract la pubkey SSH de la privkey</li> </ul> <pre><code>ssh-keygen -y -f privatekey &gt; pubkey\n</code></pre> <ul> <li>Check IO d\u00e9taill\u00e9</li> </ul> <pre><code>iostat -N 10 -kx -h\n</code></pre> <ul> <li>Top 10 des commandes qu'on utilise le plus</li> </ul> <pre><code>history | awk {CMD[$2]++;count++;}END { for (a in CMD)print CMD[a] \" \" CMD[a]/count*100 \"% \" a;} | grep -v \"./\" | column -c3 -s \" \" -t | sort -nr | nl |  head -n10\n</code></pre> <ul> <li>Test compression des fichiers selon diff\u00e9rents algos</li> </ul> <pre><code>for NB in 4 16 64 256 1024 4096 ; do echo \"::: $NB\" ; head -n $NB mysql-slow.log &gt; foo.$NB ; cat foo.$NB | zstd -c &gt; foo.$NB.zstd ; done\nfor NB in 4 16 64 256 1024 4096 ; do head -n $NB mysql-slow.log &gt; foo.$NB ; cat foo.$NB | lzop -c &gt; foo.$NB.lzo ; done\n</code></pre> <ul> <li>Avoir les droits effectifs pour chaque folder d'un path</li> </ul> <pre><code>root@prod g262:/home/pierre/home/http/www/shop/modules/appagebuilder/translations$ namei -o -m  /home/pierre/home/http/www/shop/modules/appagebuilder/translations/fr.php\nf: /home/pierre/home/http/www/shop/modules/appagebuilder/translations/fr.php\n drwxr-xr-x root      root          /\n drwxr-x--x root      adm           home\n drwxr-xr-x root      root          pierre\n drwxr-x--x pierre pierre     home\n drwxr-x--- pierre www-pierre http\n drwxr-xr-x pierre pierre     www\n drwxrwxr-x pierre pierre     shop\n drwxrwxr-x pierre pierre     modules\n drwxrwxr-x pierre pierre     appagebuilder\n drwxrwxr-x pierre pierre     translations\n -rwxrwxr-x pierre pierre     fr.php\n</code></pre> <ul> <li>Lister les ciphers propos\u00e9s par un site web</li> </ul> <pre><code>nmap --script ssl-enum-ciphers -p 443 clubic.com\n</code></pre> <ul> <li>Remove PCS node</li> </ul> <pre><code>crm_node --force -R $node\n</code></pre> <ul> <li>varnishlog des requ\u00eates non cach\u00e9es</li> </ul> <pre><code>varnishlog -i Begin,ReqUrl,Link,BereqURL\n</code></pre> <ul> <li>Remove un LV inexistant (PV ou VG mort)</li> </ul> <pre><code>dmsetup remove vgname-lvname\n</code></pre> <ul> <li>Trouver depuis quel paquet provient un binaire</li> </ul> <pre><code>[17:41] \u2714 X@hostname.tld:~\n\u2514\u2500$ dpkg-query -S \"*/dig\"\ndnsutils: /usr/bin/dig\n</code></pre> <ul> <li>Analyser le fichier mysql-slow</li> </ul> <pre><code>mysqldumpslow -s c -r\n</code></pre> <ul> <li>Timestamp compr\u00e9hensible dans dmesg</li> </ul> <pre><code>dmesg -T\n</code></pre> <ul> <li>Clean la queue exim</li> </ul> <pre><code>exim -bp | exiqgrep -i | xargs exim -Mrm\n</code></pre> <ul> <li>Check le 0-RTT</li> </ul> <pre><code>sslyze --early_data cloudflare.com\n</code></pre> <ul> <li>Upgrade Debian full non-interactive</li> </ul> <pre><code>export DEBIAN_FRONTEND=noninteractive\nexport DEBIAN_PRIORITY=critical\nsudo -E apt-get -qy update\nsudo -E apt-get -qy -o \"Dpkg::Options::=--force-confold\" -o \"Dpkg::Options::=--force-confdef\"  upgrade\n</code></pre> <ul> <li>Check l'historique des resize &amp; co LVM</li> </ul> <pre><code>[20:27] \u2714 x-y@hostname.fdn:~\n\u2514\u2500$ sudo bash -c \"cat /etc/lvm/archive/*\" | '\n   awk -F= $0 ~ /^creation_time =|^description =/ { print $2 } | '\n   awk NR%2==1 {sub(/Created '*before'* /,\"\",$0);line1=$0;state=1}\n        NR%2==0 {line2=$0;state=0}\n        {if(state==0) {print line2 \" -\" line1}} | '\n   sort -n -k 1 | '\n   grep -v \"lvs'|vgs'|vgdisplay'|vgscan\"\n 1633118488 # Fri Oct  1 20:01:28 2021 - \"executing lvcreate -L 2G -n home vg --wipesignatures\n 1633118488 # Fri Oct  1 20:01:28 2021 - \"executing lvcreate -L 2G -n var vg --wipesignatures\n 1633118501 # Fri Oct  1 20:01:41 2021 - \"executing lvcreate -L 2G -n mysql vg --wipesignatures\n 1633118502 # Fri Oct  1 20:01:42 2021 - \"executing lvcreate -L 2G -n mysqlinnodb vg --wipesignatures\n 1633161982 # Sat Oct  2 10:06:22 2021 - \"executing vgcreate vg-x /dev/sdc\"\n 1633161987 # Sat Oct  2 10:06:27 2021 - \"executing lvcreate -L 2G -n mysql vg-x --wipesignatures\n</code></pre> <ul> <li>Lire les infos TLS rapidement sur un serveur HTTPS, 2 m\u00e9thodes pour \u00e7a</li> </ul> <pre><code>\u279c  ~ gnutls-cli -p 443 google.com\nProcessed 147 CA certificate(s).\nResolving 'google.com:443'...\nConnecting to '2a00:1450:4007:818::200e:443'...\n- Certificate type: X.509\n- Got a certificate list of 3 certificates.\n- Certificate[0] info:\n - subject `CN=*.google.com', issuer `CN=WR2,O=Google Trust Services,C=US', serial 0x463e05b5a27190c90aeb46472b6cdeca, EC/ECDSA key 256 bits, signed using RSA-SHA256, activated `2024-08-12 06:33:49 UTC', expires `2024-11-04 06:33:48 UTC', pin-sha256=\"9gRz00N3xKCUAn/eI9TvsZ3roKNhAdbD7Xo+MU3MoUI=\"\n        Public Key ID:\n                sha1:cf70ac9e7993aaaf88a36e35383de1fb0170e4e4\n                sha256:f60473d34377c4a094027fde23d4efb19deba0a36101d6c3ed7a3e314dcca142\n        Public Key PIN:\n                pin-sha256:9gRz00N3xKCUAn/eI9TvsZ3roKNhAdbD7Xo+MU3MoUI=\n\n- Certificate[1] info:\n - subject `CN=WR2,O=Google Trust Services,C=US', issuer `CN=GTS Root R1,O=Google Trust Services LLC,C=US', serial 0x7ff005a07c4cded100ad9d66a5107b98, RSA key 2048 bits, signed using RSA-SHA256, activated `2023-12-13 09:00:00 UTC', expires `2029-02-20 14:00:00 UTC', pin-sha256=\"YPtHaftLw6/0vnc2BnNKGF54xiCA28WFcccjkA4ypCM=\"\n- Certificate[2] info:\n - subject `CN=GTS Root R1,O=Google Trust Services LLC,C=US', issuer `CN=GlobalSign Root CA,OU=Root CA,O=GlobalSign nv-sa,C=BE', serial 0x77bd0d6cdb36f91aea210fc4f058d30d, RSA key 4096 bits, signed using RSA-SHA256, activated `2020-06-19 00:00:42 UTC', expires `2028-01-28 00:00:42 UTC', pin-sha256=\"hxqRlPTu1bMS/0DITB1SSu0vd4u/8l8TjPgfaAp63Gc=\"\n- Status: The certificate is trusted.\n- Description: (TLS1.3-X.509)-(ECDHE-X25519)-(ECDSA-SECP256R1-SHA256)-(AES-256-GCM)\n- Session ID: A2:5D:01:EC:9D:5D:2D:80:24:F9:3A:35:5C:E5:4F:65:72:39:04:62:08:59:43:36:12:DB:D7:C2:63:CC:6D:2A\n- Options:\n- Handshake was completed\n\n- Simple Client Mode:\n\n\u279c  linux git:(master) \u2717 openssl s_client -connect google.com:443\nConnecting to 2a00:1450:4007:818::200e\nCONNECTED(00000006)\ndepth=2 C=US, O=Google Trust Services LLC, CN=GTS Root R1\nverify return:1\ndepth=1 C=US, O=Google Trust Services, CN=WR2\nverify return:1\ndepth=0 CN=*.google.com\nverify return:1\n---\nCertificate chain\n 0 s:CN=*.google.com\n   i:C=US, O=Google Trust Services, CN=WR2\n   a:PKEY: id-ecPublicKey, 256 (bit); sigalg: RSA-SHA256\n   v:NotBefore: Aug 12 06:33:49 2024 GMT; NotAfter: Nov  4 06:33:48 2024 GMT\n 1 s:C=US, O=Google Trust Services, CN=WR2\n   i:C=US, O=Google Trust Services LLC, CN=GTS Root R1\n   a:PKEY: rsaEncryption, 2048 (bit); sigalg: RSA-SHA256\n   v:NotBefore: Dec 13 09:00:00 2023 GMT; NotAfter: Feb 20 14:00:00 2029 GMT\n 2 s:C=US, O=Google Trust Services LLC, CN=GTS Root R1\n   i:C=BE, O=GlobalSign nv-sa, OU=Root CA, CN=GlobalSign Root CA\n   a:PKEY: rsaEncryption, 4096 (bit); sigalg: RSA-SHA256\n   v:NotBefore: Jun 19 00:00:42 2020 GMT; NotAfter: Jan 28 00:00:42 2028 GMT\n---\nServer certificate\n-----BEGIN CERTIFICATE-----\n-----END CERTIFICATE-----\nsubject=CN=*.google.com\nissuer=C=US, O=Google Trust Services, CN=WR2\n---\nNo client certificate CA names sent\nPeer signing digest: SHA256\nPeer signature type: ECDSA\nServer Temp Key: X25519, 253 bits\n---\nSSL handshake has read 6589 bytes and written 398 bytes\nVerification: OK\n---\nNew, TLSv1.3, Cipher is TLS_AES_256_GCM_SHA384\nServer public key is 256 bit\nThis TLS version forbids renegotiation.\nCompression: NONE\nExpansion: NONE\nNo ALPN negotiated\nEarly data was not sent\nVerify return code: 0 (ok)\n---\n</code></pre>"},{"location":"linux/advanced/shell/write_bash_scripts/","title":"Ecrire son script bash","text":""},{"location":"linux/advanced/shell/write_bash_scripts/#introduction","title":"Introduction","text":"<p>Dans une vie de sysadmin respectable, nous devrons un jour ou l'autre faire face \u00e0 un script bash. Il est donc indispensable d'avoir cette base que je vais essayer de vous expliquer dans cet article. Nous allons voir comment cr\u00e9er son script de la mani\u00e8re la plus optimale et propre possible.</p>"},{"location":"linux/advanced/shell/write_bash_scripts/#creer-son-premier-script-bash","title":"Cr\u00e9er son premier script bash","text":"<p>Un script bash n'est ni plus ni moins qu'un simple fichier texte avec certaines commandes et une syntaxe pr\u00e9cise, voici notre premier script bash :</p> <pre><code>#!/usr/bin/env bash\necho \"Mon premier script bash\" # Ma commande\n</code></pre> <p>Tout d'abord, nous observons une ligne commen\u00e7ant par #!, il s'agit du shebang. Cette ligne est tr\u00e8s utile dans le cas o\u00f9 nous lan\u00e7ons le script via ./mon_script.sh, nous savons ici que ce script devra \u00eatre ex\u00e9cut\u00e9 avec l'interpreteur bash.</p> <p>Nous avons ici notre premi\u00e8re bonne pratique, nous n'utilisons pas directement /bin/bash en shebang mais /usr/bin/env bash. M\u00eame si le chemin du fichier binaire probablement le plus connu de Linux est dans une vaste majorit\u00e9 des cas /bin/bash, il se peut que celui-ci diff\u00e8re (par exemple dans une distribution BSD). Ce shebang peut \u00e9galement \u00eatre adapt\u00e9 \u00e0 python ou d'autres langages de scripting.</p> <p>La commande echo affiche tout simplement le texte qui lui est pass\u00e9 en argument. echo est une commande dites '\"built-in'\", c'est \u00e0 dire qu'elle sera inclue dans toutes les versions de bash quelque soit la distribution. Pour voir toutes les commandes built-in, nous utilisons la commande compgen -b.</p> <p>Le texte '\"Ma commande'\" a \u00e9t\u00e9 \u00e9crit apr\u00e8s un '# ce qui signifie que le texte apr\u00e8s ce caract\u00e8re ne sera pas interpr\u00e9t\u00e9, nous pouvons donc y mettre ce que nous voulons, g\u00e9n\u00e9ralement, ce sera du texte pour nous aider \u00e0 comprendre la ligne pr\u00e9c\u00e9d\u00e9e.</p>"},{"location":"linux/advanced/shell/write_bash_scripts/#operations-de-base","title":"Op\u00e9rations de base","text":""},{"location":"linux/advanced/shell/write_bash_scripts/#les-variables","title":"Les Variables","text":""},{"location":"linux/advanced/shell/write_bash_scripts/#variables-built-in","title":"Variables built-in","text":"<p>De nombreuses variables sont incluses dans un script bash, il est utile d'en connaitres quelques unes.</p> <ul> <li><code>$1</code> contient la valeur du premier argument de votre script bash ou     de votre fonction. ('$0 repr\u00e9sente le script lui m\u00eame)</li> <li><code>$#</code> contient le nombre d'arguments pass\u00e9s \u00e0 votre script</li> <li><code>$?</code> contient le code retour de votre programme script...</li> <li><code>$PWD</code> contient le chemin du r\u00e9pertoire courant</li> </ul>"},{"location":"linux/advanced/shell/write_bash_scripts/#assignation-de-variables","title":"Assignation de variables","text":"<p>Pour assigner une valeur \u00e0 une variable en bash, qu'une seule fa\u00e7on est possible :</p> <pre><code>#!/bin/bash\nVAL=\"mavaleur\"\n</code></pre> <p>Il est \u00e9galement possible d'assigner dynamiquement une valeur \u00e0 une variable. Notre premi\u00e8re bonne pratique ici est d'\u00e9crire le nom de la variable en majuscule.</p> <pre><code>#!/bin/bash\nHOST=$(hostname)\n</code></pre> <p>La variable HOST contiendra le retour de la commande hostname. Enfin, il est possible d'attribuer des valeurs par d\u00e9fauts \u00e0 des variables si l'utilisateur ne la r\u00e9\u00e9crit pas (par exemple, via un argument du script).</p> <pre><code>#!/bin/bash\nFOO=${1:-BAR}\n</code></pre> <p>Si notre variable '$1 ne contient rien, notre varible FOO prendra alors la valeur BAR, sinon, la valeur de '$1.</p>"},{"location":"linux/advanced/shell/write_bash_scripts/#manipulation-de-variables","title":"Manipulation de variables","text":"<p>Sous bash, il est possible simplement de modifier ses variables simplement. Dans les exemples suivant, nous supposons que notre variable FOO contienne monfichier.txt et que nous souhaitons garder que monfichier dans une variable nomm\u00e9e BASE.</p> <pre><code>#!/bin/bash\nBASE=${FOO%%.txt}\n</code></pre> <p>Comme vous pouvez le voir, via %%.txt, nous supprimons .txt de notre variable</p> <p>Il est \u00e9galement possible de subtituer .txt par .pdf par exemple.</p> <pre><code>#!/bin/bash\nBASE=${FOO/txt/pdf}\n</code></pre> <p>Nous pouvons \u00e9galement effectuer une sous chaine \u00e0 partir de la chaine de base</p> <pre><code>#!/bin/bash\n# echo ${FOO:position:taille}\n${FOO:2:2}\n</code></pre> <p>Par exemple, ici, nous allons afficher la variable \u00e0 partir de la position 2 pour 2 caract\u00e8res.</p> <p>Dans le code suivant, toujours en se basant sur la variable FOO, nous prenons les 3 derniers caract\u00e8res (le signe - signifie que nous partons de la fin de la variable), ce qui nous permet par exemple de prendre juste l'extension du fichier</p> <pre><code>#!/bin/bash\nEXT=${FOO:(-3)}\n</code></pre>"},{"location":"linux/advanced/shell/write_bash_scripts/#tests-conditionnels","title":"Tests conditionnels","text":""},{"location":"linux/advanced/shell/write_bash_scripts/#boucles","title":"Boucles","text":"<pre><code>#!/bin/bash\nfor i in {1..5}\ndo\n   echo \"Welcome $i times\"\ndone\n</code></pre> <pre><code>#!/bin/bash\nfor i in {0..10..2}\ndo\n    echo \"Welcome $i times\"\ndone\n</code></pre> <pre><code>#!/bin/bash\nfor (( c=1; c&lt;=5; c++ ))\ndo\n   echo \"Welcome $c times\"\ndone\n</code></pre> <pre><code>#!/bin/bash\nfor I in 1 2 3 4 5\ndo\n  statements1      #Executed for all values of I, up to a disaster-condition if any.\n  statements2\n  if (disaster-condition)\n  then\n    break              #Abandon the loop.\n  fi\n  statements3          #While good and, no disaster-condition.\ndone\n</code></pre> <pre><code>#!/bin/bash\nfor s in server0{1..8}\ndo\n    echo \"*** Patching and updating ${s} ***\"\n    ssh root@${s} -- \"yum -y update\"\ndone\n</code></pre>"},{"location":"linux/advanced/shell/write_bash_scripts/#astuces-de-script","title":"Astuces de script","text":""},{"location":"linux/advanced/shell/write_bash_scripts/#optimiser-le-debug","title":"Optimiser le debug","text":"<p>Par d\u00e9faut, bash est laxiste. Il n'int\u00e8gre aucun controle d'erreur ou autre. En d\u00e9finissant un simple shebang, nous n'avons aucun controle. C'est pour \u00e7a que je conseille d'utiliser les options bash suivantes :</p> <pre><code>#!/bin/bash\nset -euo pipefail\n</code></pre> <p>Petite explication de ces options :</p> <ul> <li>-e : Interrompt le script \u00e0 la moindre commande ne retournant     pas 0. Implique une mani\u00e8re d'\u00e9crire ses scripts afin qu'aucune     commande ne retourne d'erreur par d\u00e9faut</li> <li>-u : Indique qu'une variable n'a pas \u00e9t\u00e9 d\u00e9finit. Par d\u00e9faut,     bash va bug ou ne rien afficher dans le cas d'un echo. Prenons un     exemple o\u00f9 nous avons un probl\u00e8me de casse :</li> </ul> <pre><code>jeremy@macbook-pro-de-delgado:~ $ cat l\n#!/bin/bash\nset -euo pipefail\nfirstName=\"Aaron\"\nfullName=\"$firstname Maxwell\"\necho \"$fullName\"\njeremy@macbook-pro-de-delgado:~ $ bash l\nl: ligne 4: firstname : variable sans liaison\n</code></pre> <ul> <li><code>-o pipefail</code> : Sans cette option, une erreur dans un pipe sera     masqu\u00e9e, et ne sera pas intercept\u00e9e par le param\u00e8tre -e</li> </ul>"},{"location":"linux/advanced/shell/write_bash_scripts/#template-de-script","title":"Template de script","text":"<p>Il est possible d'\u00e9crire de bons scripts Shell, mais il est encore plus facile d'en \u00e9crire des mauvais. Voici donc un excellent template :</p> <pre><code>#!/usr/bin/env bash\n\nset -o errexit\nset -o nounset\nset -o pipefail\nif [[ \"${TRACE-0}\" == \"1\" ]]; then\n    set -o xtrace\nfi\n\nif [[ \"${1-}\" =~ ^-*h(elp)?$ ]]; then\n    echo 'Usage: ./script.sh arg-one arg-two\n\nThis is an awesome bash script to make your life better.\n\n'\n    exit\nfi\n\ncd \"$(dirname \"$0\")\"\n\nmain() {\n    echo do awesome stuff\n}\n\nmain \"$@\"\n</code></pre> <p>Ce template ne vient pas de moi mais de cet excllent site.</p>"},{"location":"linux/advanced/shell/write_bash_scripts/#misc","title":"Misc","text":"<p>Quelques astuces de scripts bash trouv\u00e9es \u00e0 gauche ou \u00e0 droite</p> <pre><code>#!/bin/bash\necho avant &amp;&amp; : moi  &amp;&amp; echo apr\u00e8s\n</code></pre> <p>Ici, le : moi est en faite un commentaire inline, plut\u00f4t ing\u00e9nieux !</p> <pre><code>#!/bin/bash\nif doesnotexist |&amp; grep command not found &gt;/dev/null\nthen\n  echo oops\nfi\n</code></pre> <p>Nous connaissons tous les fameux 2&amp;'&gt;1 pour rediriger STDERR dans STDOUT. Ici, nous redirigons les 2 sorties vers la prochaine instruction du pipeline, tr\u00e8s utile.</p> <pre><code>#!/bin/bash\nexec 8&lt;&gt;/dev/tcp/wiki.jdelgado.fr/80\necho -e \"GET / HTTP/1.1\\r\\nHost: wiki.jdelgado.fr\\r\\n\\r\\n\" &gt;&amp;8\ncat &lt;&amp;8\n</code></pre> <p>Petit snippet utile afin de s'affranchir de toute commande. Dans un premier temps, nous ouvrons le file descriptor 8. Via cette premi\u00e8re commande, nous ouvrons ainsi un socket TCP sur notre wiki. Secondement, nous envoyons un header HTTP classique, enfin, nous lisons le contenu du file descriptor 8</p> <p>shellcheck est un petit outil regroupant \u00e9norm\u00e9ment de bonnes pratiques. Il est possible d'appliquer automatiquement les fix avec la commande suivante :</p> <pre><code>shellcheck -f diff &lt;files&gt; | git apply\n</code></pre>"},{"location":"linux/advanced/systemd/create_unit/","title":"Cr\u00e9er son service systemd","text":""},{"location":"linux/advanced/systemd/create_unit/#quelques-explications","title":"Quelques explications","text":"<p>Depuis quelques ann\u00e9es, systemd s'est impos\u00e9 comme \u00e9tant l'init de beaucoup de distributions, g\u00e9rant ainsi les d\u00e9marrages systemd est vou\u00e9 \u00e0 remplacer de nombreux composants syst\u00e8mes historiques tels que cron, network...</p> <p>systemd a \u00e9t\u00e9 impl\u00e9ment\u00e9 de diff\u00e9rentes mani\u00e8res selon les OS (et rarement de la bonne mani\u00e8re) et les mainteneurs de paquets n'ont toujours les bonnes pratiques. Officiellement, voici les bonnes pratiques \u00e0 faire quand on parle d'unit systemd. Une unit est un service en jargon systemd.</p> <ul> <li><code>/usr/lib/systemd/system/</code> : Units install\u00e9es par les paquets</li> <li><code>/etc/systemd/system/</code> : Units cr\u00e9\u00e9s par l'administrateur     syst\u00e8me.</li> </ul> <p>Malheureusement, quelques units de packages se trouvent encore dans <code>/etc/systemd/system</code>. Historiquement, les scripts de d\u00e9marrages se trouvaient dans <code>/etc/init.d</code>.</p>"},{"location":"linux/advanced/systemd/create_unit/#cas-pratique","title":"Cas pratique","text":"<p>Concr\u00e8tement, voici un exemple type d'unit :</p> Simple unit file : /etc/systemd/system/prometheus.service <pre><code>[Unit]\nDescription=Prometheus\nDocumentation=https://prometheus.io/docs/guides/\nAfter=network-online.target\n\n[Service]\nType=simple\nUser=prometheus\nWorkingDirectory=/etc/prometheus\nEnvironmentFile=/etc/default/prometheus\nExecStart=/usr/bin/prometheus --storage.tsdb.path=/var/lib/prometheus\nRestart=always\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <p>Il s'agit d'une unit extr\u00eamement simple.</p> <p>Nous pouvons constater 3 blocs principaux : Unit, Service et Install. Il s'agit simplement de mots clefs afin de rendre plus lisible un unit.</p> <p>Tout d'abord, dans la partie Unit nous pouvons voir la directive Description. Comme son nom l'indique, il s'agit simplement d'une description lorsque nous souhaitons obtenir le status d'un service. La directive Documentation nous sert juste \u00e0 apporter une documentation (comme son nom l'indique). After est une directive importante, celle-ci indique que nous devrons lancer notre unit apr\u00e8s celle indiqu\u00e9e, ici, network-online (logique \u00e9tant donner que notre logiciel \u00e9coutera sur un port).</p> <p>Par la suite, nous avons la partie qui nous concerne r\u00e9ellement, Service.</p> <p>Dans cette partie, nous commencons par la directive Type=Simple. Il existe de nombreux types, celui-ci nous indique simplement que notre processus va d\u00e9marrer imm\u00e9diatement :</p> <ul> <li><code>Simple</code> : Il s'agit du type par d\u00e9faut. C'est un service     d\u00e9marrant imm\u00e9diatement qui ne doit pas fork. Il ne faut pas     utiliser ce type de service s'il d\u00e9pend d'autres services</li> <li><code>idle</code> : Le service est identique au type Simple. Cependant, il     n'est pas prioritaire et sera lanc\u00e9 apr\u00e8s tous les autres au     d\u00e9marrage du syst\u00e8me.</li> <li><code>Forking</code> : Consid\u00e8re le service comme lanc\u00e9 une fois que le     processus p\u00e8re \u00e0 exit apr\u00e8s d\u00e9marrage complet de son fork. Il est     utile d'y combiner l'option PIDFile afin que systemd garde une     trace du processus p\u00e8re</li> <li><code>Oneshot</code> : Encore une fois, il s'agit du m\u00eame comportement que     le service simple. Il est par exemple tr\u00e8s utile dans l'ex\u00e9cution     d'un script qui font un seul job et se terminent.</li> </ul> <p>D'autres services sont \u00e9galement disponibles mais sont tr\u00e8s peu utilis\u00e9s. Je vous renvoie vers la section Type de la page man de systemd afin d'obtenir toutes les explications.</p> <p>L'User avec lequel sera ex\u00e9cut\u00e9 sera prometheus. (La directive Group est \u00e9galement disponible).</p> <p>La directive WorkingDirectory est assez importante. Toutes les directives des fichiers de configuration faisant r\u00e9f\u00e9rence \u00e0 des chemins relatifs seront donc bas\u00e9s par rapport \u00e0 celui-ci. Exemple, si dans mon fichier de configuration je pr\u00e9cise un chemin relatif vers fichier.json par exemple, alors le fichier comprit par le logiciel sera <code>/etc/prometheus/fichier.json</code>.</p> <p><code>EnvironmentFile</code> est un autre fichier \u00e9galement important. Il sera utilis\u00e9 pour charger des variables d'environnement au fichier. Il existe une autre alternative qui consiste \u00e0 utiliser la directive Environment afin de charger directement la variable d'environnement. Par exemple <code>Environment=FOO=bar</code> va charger la variable FOO contenant la valeur bar.</p> <p>Enfin, la directive la plus importante est l'ExecStart qui indique tout simplement la commande \u00e0 charger. Dans notre exemple, nous lan\u00e7ons juste prometheus en lui indiquant o\u00f9 stocker ses donn\u00e9es. Enfin, nous lui indiquons de toujours relancer le service. La m\u00eame directive existe pour ExecStop. Si aucun ExecStop n'est sp\u00e9cifi\u00e9, le comportement par d\u00e9faut de systemd est d'envoyer un SIGTERM (15) sur tous les processus lanc\u00e9s par ce service, apr\u00e8s un timeout, un SIGKILL (9) est envoy\u00e9.</p> <p>De plus, il est posssible de pr\u00e9ciser des commandes pre-start ou post-start (ainsi que pour stop) gr\u00e2ces aux directives ExecStartPre et ExecStartPost</p> <p>Dernier block de notre unit systemd et pas le moins important, <code>Install</code>. La directive <code>WantedBy=multi-user.target</code> permet de sp\u00e9cifier dans quelle target doit \u00eatre actif 2,3,4 et 5. Concr\u00eatement, nous allons toujours utiliser cette target.</p>"},{"location":"linux/advanced/systemd/create_unit/#service-modele","title":"Service Mod\u00e8le","text":"<p>Un service template est appel\u00e9 ainsi car il s'agit d'un service pouvant \u00eatre utilis\u00e9 :</p> Simple unit file : /etc/systemd/system/openvpn@.service <pre><code>[Unit]\nDescription=OpenVPN service for %I\nAfter=syslog.target network-online.target\nWants=network-online.target\nDocumentation=man:openvpn(8)\nDocumentation=https://community.openvpn.net/openvpn/wiki/Openvpn24ManPage\nDocumentation=https://community.openvpn.net/openvpn/wiki/HOWTO\n\n[Service]\nType=notify\nPrivateTmp=true\nWorkingDirectory=/etc/openvpn/client/%i/\nExecStart=/usr/sbin/openvpn --status %t/openvpn-server/status-%i.log --status-version 2 --suppress-timestamps --cipher AES-256-GCM --ncp-ciphers AES-256-GCM:AES-128-GCM:AES-256-CBC:AES-128-CBC:BF-CBC --config /etc/openvpn/client/%i/%i.conf\n    =CAP_IPC_LOCK CAP_NET_ADMIN CAP_NET_BIND_SERVICE CAP_NET_RAW CAP_SETGID CAP_SETUID CAP_SYS_CHROOT CAP_DAC_OVERRIDE\nLimitNPROC=10\nDeviceAllow=/dev/null rw\nDeviceAllow=/dev/net/tun rw\nProtectSystem=true\nProtectHome=true\nKillMode=process\nRestartSec=5s\nRestart=on-failure\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <p>Comme nous pouvons d\u00e9j\u00e0 l'observer dans le nom de l'unit, celle-ci contient un @. Celui-ci signifie qu'il s'agit d'un template.</p> <p>L'exemple est un peu plus compliqu\u00e9 que le pr\u00e9c\u00e9dent.</p> <ul> <li> <p><code>PrivateTmp</code> nous permet de nous assurer qu'aucun fichier ne soit \u00e9crit dans le /tmp (accessible par tout le monde).</p> </li> <li> <p><code>WorkingDirectory</code> contient ici un %i indiquant une variable systemd. Ici, le %i signifie que nous prenons tous les caract\u00e8res tap\u00e9s apr\u00e8s l'@ lors du start du service.</p> <p> * Par exemple systemctl start openvpn@toto.service, notre variable <code>%i</code> contiendra toto.</p> </li> </ul> <ul> <li> <p><code>%t</code> contenu dans la directive ExecStart est le r\u00e9pertoire d'ex\u00e9cution. Il existe une tonne de variables de ce genre, une liste compl\u00e8te est disponible sur la documentation du projet.</p> </li> <li> <p><code>CapabilityBoundingSet</code> nous permet de d\u00e9finir \u00e0 quelles capabilities aura acc\u00e8s le binaire, seules les capabilities list\u00e9es dans la liste seront autoris\u00e9es et aucune autre.</p> </li> <li> <p><code>LimitNPROC</code> nous d\u00e9finit le nombre de processus pouvant \u00eatre lanc\u00e9s par le service.</p> </li> <li> <p><code>DeviceAllow</code> nous permet d'acc\u00e9der \u00e0 un device sp\u00e9cifique en lecture et \u00e9criture.</p> </li> <li> <p><code>ProtectSystem</code> est une directive tr\u00e8s utile. Ici, mise \u00e0 true, les r\u00e9pertoires /usr et /boot seront accessible en lecture uniquement pour le processus invoqu\u00e9e par notre unit. Si cette directive est d\u00e9finie \u00e0 full, le r\u00e9pertoire /etc sera \u00e9galement en read-only. Enfin, d\u00e9finie \u00e0 strict, tout le syst\u00e8me est en read-only sauf /dev, /proc et /sys.</p> </li> <li> <p><code>ProtectHome</code>, d\u00e9finie \u00e0 true, nous permettra de rendre les r\u00e9pertoires /home, /root et /run/user <code>vides</code> pour le processus.</p> </li> </ul>"},{"location":"linux/advanced/varnish/config/","title":"Config varnish","text":"<p>Bonne config trouv\u00e9e de Git que je reposte ici si jamais : Gist</p> Example : /etc/varnish/default.vcl <pre><code>#########################################################################\n# This is an example VCL file for Varnish 4.0.              #\n# From: &lt;https://gist.github.com/davidthingsaker/6b0997b641fdd370a395&gt;    #\n# LICENSE: If this could help you in any way, you are obliged to use it #\n# for free with no limitations.                     #\n#########################################################################\n\n# Marker to tell the VCL compiler that this VCL has been adapted to the\n# new 4.0 format.\nvcl 4.0;\n\nimport std;\n\n# Default backend definition. Set this to point to your content server.\nbackend default {\n    .host = \"127.0.0.1\";\n    .port = \"8080\";\n}\n\nsub vcl_recv {\n    # Happens before we check if we have this in cache already.\n    #\n    # Typically you clean up the request here, removing cookies you dont need,\n    # rewriting the request, etc.\n\n    # Properly handle different encoding types\n    if (req.http.Accept-Encoding) {\n        if (req.url ~ \"'.(jpg|jpeg|png|gif|gz|tgz|bz2|tbz|mp3|ogg|swf|woff)$\") {\n                # No point in compressing these\n                unset req.http.Accept-Encoding;\n        } elsif (req.http.Accept-Encoding ~ \"gzip\") {\n                set req.http.Accept-Encoding = \"gzip\";\n        } elsif (req.http.Accept-Encoding ~ \"deflate\") {\n                set req.http.Accept-Encoding = \"deflate\";\n        } else {\n                # unknown algorithm (aka crappy browser)\n            unset req.http.Accept-Encoding;\n        }\n    }\n\n    # Cache files with these extensions\n    if (req.url ~ \"'.(js|css|jpg|jpeg|png|gif|gz|tgz|bz2|tbz|mp3|ogg|swf|woff)$\") {\n        unset req.http.cookie;\n        return (hash);\n    }\n\n    # Dont cache anything thats on the blog page or thats a POST request\n    if (req.url ~ \"^/blog\" || req.method == \"POST\") {\n            return (pass);\n    }\n\n    # This is Laravel specific, we have session-monster which sets a no-session header if we dont really need the set session cookie.\n    # Check for this and unset the cookies if not required\n    # Except if its a POST request\n    if (req.http.X-No-Session ~ \"yeah\" &amp;&amp; req.method != \"POST\") {\n            unset req.http.cookie;\n    }\n\n    return (hash);\n}\n\nsub vcl_backend_response {\n    # Happens after we have read the response headers from the backend.\n    #\n    # Here you clean the response headers, removing silly Set-Cookie headers\n    # and other mistakes your backend does.\n\n    # This is how long Varnish will cache content. Set at top for visibility.\n    set beresp.ttl = 1d;\n\n    if ((bereq.method == \"GET\" &amp;&amp; bereq.url ~ \"'.(css|js|xml|gif|jpg|jpeg|swf|png|zip|ico|img|wmf|txt)$\") ||\n                bereq.url ~ \"'.(minify).*'.(css|js).*\" ||\n                bereq.url ~ \"'.(css|js|xml|gif|jpg|jpeg|swf|png|zip|ico|img|wmf|txt)'?ver\") {\n                unset beresp.http.Set-Cookie;\n                set beresp.ttl = 5d;\n        }\n\n    # Unset all cache control headers bar Age.\n    unset beresp.http.etag;\n    unset beresp.http.Cache-Control;\n        unset beresp.http.Pragma;\n\n    # Unset headers we never want someone to see on the front end\n    unset beresp.http.Server;\n        unset beresp.http.X-Powered-By;\n\n        # Set how long the client should keep the item by default\n        set beresp.http.cache-control = \"max-age = 300\";\n\n        # Set how long the client should keep the item by default\n        set beresp.http.cache-control = \"max-age = 300\";\n\n        # Override browsers to keep styling and dynamics for longer\n        if (bereq.url ~ \".minify.*'.(css|js).*\") { set beresp.http.cache-control = \"max-age = 604800\"; }\n        if (bereq.url ~ \"'.(css|js).*\") { set beresp.http.cache-control = \"max-age = 604800\"; }\n\n        # Override the browsers to cache longer for images than for main content\n        if (bereq.url ~ \".(xml|gif|jpg|jpeg|swf|css|js|png|zip|ico|img|wmf|txt)$\") {\n                set beresp.http.cache-control = \"max-age = 604800\";\n        }\n\n    # Were done here, send the data to the browser\n    return (deliver);\n}\n\n\nsub vcl_deliver {\n    # Happens when we have all the pieces we need, and are about to send the\n    # response to the client.\n    #\n    # You can do accounting or modifying the final object here.\n\n    # Lets not tell the world we are using Varnish in the same principle we set server_tokens off in Nginx\n    unset resp.http.Via;\n    unset resp.http.X-Varnish;\n}\n</code></pre> <p>Cette autre config orient\u00e9e pour WordPress est \u00e9galement bien Gist :</p> Example 2 : /etc/varnish/default.vcl <pre><code># Set the default backend (Nginx server for me)\nbackend default {\n  # My Nginx server listen on IP address 127.0.0.1 and TCP port 8080\n  .host = \"localhost\";\n  .port = \"80\";\n  .first_byte_timeout = 300s;\n}\n\n# Purge ACL\nacl purge {\n        \"127.0.0.1\";\n}\n\n# This function is used when a request is send by a HTTP client (Browser)\n# !!! Replace: blog.nicolargo.com by your own URL !!!\nsub vcl_recv {\n\n  call detect_device;\n\n  #nginx&amp;php-fpm fix\n  set req.http.X-Forwarded-For = client.ip;\n  set req.http.Host = regsub(req.http.Host, \":[0-9]+\", \"\");\n\n  # Allow purging from ACL\n  if (req.request == \"PURGE\") {\n    # If not allowed then a error 405 is returned\n    if (!client.ip ~ purge) {\n      error 405 \"This IP is not allowed to send PURGE requests.\";\n    }\n    # If allowed, do a cache_lookup -&gt; vlc_hit() or vlc_miss()\n    return (lookup);\n  }\n\n  # Post requests will not be cached\n  if (req.request == \"POST\") {\n    return (pass);\n  }\n\n  # --- Wordpress specific configuration\n\n  # Did not cache the RSS feed\n  if (req.url ~ \"/feed\") {\n      return (pass);\n  }\n\n  # Did not cache the admin and login pages\n  if (req.url ~ \"/wp-(login|admin)\") {\n    return (pass);\n  }\n\n  // server1 must handle file uploads\n  if (req.url ~ \"media-upload.php\" || req.url ~ \"file.php\" || req.url ~ \"async-upload.php\") {\n    return(pass);\n  }\n\n  // do not cache xmlrpc.php\n  if (req.url ~ \"xmlrpc.php\") {\n    return(pass);\n  }\n\n  // strip cookies from xmlrpc\n  if (req.request == \"GET\" &amp;&amp; req.url ~ \"xmlrpc.php\"){\n      remove req.http.cookie;return(pass);\n  }\n\n  # Remove the \"has_js\" cookie\n  set req.http.Cookie = regsuball(req.http.Cookie, \"has_js=[^;]+(; )?\", \"\");\n\n  # Remove any Google Analytics based cookies\n  set req.http.Cookie = regsuball(req.http.Cookie, \"__utm.=[^;]+(; )?\", \"\");\n\n  # Remove the Quant Capital cookies (added by some plugin, all __qca)\n  set req.http.Cookie = regsuball(req.http.Cookie, \"__qc.=[^;]+(; )?\", \"\");\n\n  # Remove the wp-settings-1 cookie\n  set req.http.Cookie = regsuball(req.http.Cookie, \"wp-settings-1=[^;]+(; )?\", \"\");\n\n  # Remove the wp-settings-time-1 cookie\n  set req.http.Cookie = regsuball(req.http.Cookie, \"wp-settings-time-1=[^;]+(; )?\", \"\");\n\n  # Remove the wp test cookie\n  set req.http.Cookie = regsuball(req.http.Cookie, \"wordpress_test_cookie=[^;]+(; )?\", \"\");\n\n  # Are there cookies left with only spaces or that are empty?\n  if (req.http.cookie ~ \"^ *$\") {\n        unset req.http.cookie;\n  }\n\n  if (req.http.Accept-Encoding) {\n    # Do no compress compressed files...\n    if (req.url ~ \"'.(jpg|png|gif|gz|tgz|bz2|tbz|mp3|ogg)$\") {\n          remove req.http.Accept-Encoding;\n    } elsif (req.http.Accept-Encoding ~ \"gzip\") {\n          set req.http.Accept-Encoding = \"gzip\";\n    } elsif (req.http.Accept-Encoding ~ \"deflate\") {\n          set req.http.Accept-Encoding = \"deflate\";\n    } else {\n      remove req.http.Accept-Encoding;\n    }\n  }\n\n  # Cache the following files extensions\n  if (req.url ~ \"'.(css|js|png|gif|jp(e)?g)\") {\n    unset req.http.cookie;\n  }\n\n  # Check the cookies for wordpress-specific items\n  if (req.http.Cookie ~ \"wordpress_\" || req.http.Cookie ~ \"comment_\") {\n    return (pass);\n  }\n  if (!req.http.cookie) {\n    unset req.http.cookie;\n  }\n\n  # --- End of Wordpress specific configuration\n\n  # Did not cache HTTP authentication and HTTP Cookie\n  if (req.http.Authorization || req.http.Cookie) {\n    # Not cacheable by default\n    return (pass);\n  }\n\n  # Cache all others requests\n  return (lookup);\n}\n\nsub vcl_pipe {\n  return (pipe);\n}\n\nsub vcl_pass {\n  return (pass);\n}\n\n# The data on which the hashing will take place\nsub vcl_hash {\n  hash_data(req.url);\n  if (req.http.host) {\n      hash_data(req.http.host);\n  } else {\n      hash_data(server.ip);\n  }\n\n  # ensure separate cache for mobile clients (WPTouch workaround)\n  if (req.http.X-Device ~ \"smart\" || req.http.X-Device ~ \"other\") {\n    hash_data(req.http.X-Device);\n  }\n\n  # If the client supports compression, keep that in a different cache\n  if (req.http.Accept-Encoding) {\n    hash_data(req.http.Accept-Encoding);\n  }\n  return (hash);\n}\n\nsub detect_device {\n  # Define the desktop device and ipad\n  set req.http.X-Device = \"desktop\";\n\n  if (req.http.User-Agent ~ \"iP(hone|od)\" || req.http.User-Agent ~ \"Android\" ) {\n    # Define smartphones and tablets\n    set req.http.X-Device = \"smart\";\n  }\n\n  elseif (req.http.User-Agent ~ \"SymbianOS\" || req.http.User-Agent ~ \"^BlackBerry\" || req.http.User-Agent ~ \"^SonyEricsson\" || req.http.User-Agent ~ \"^Nokia\" || req.http.User-Agent ~ \"^SAMSUNG\" || req.http.User-Agent ~ \"^LG\") {\n    # Define every other mobile device\n    set req.http.X-Device = \"other\";\n  }\n}\n\nsub vcl_hit {\n  # Allow purges\n  if (req.request == \"PURGE\") {\n    purge;\n    error 200 \"Purged.\";\n  }\n\n  return (deliver);\n}\n\nsub vcl_miss {\n  # Allow purges\n  if (req.request == \"PURGE\") {\n    purge;\n    error 200 \"Purged.\";\n  }\n\n  return (fetch);\n}\n\n# This function is used when a request is sent by our backend (Nginx server)\nsub vcl_fetch {\n  # For static content related to the theme, strip all backend cookies\n  if (req.url ~ \"'.(css|js|png|gif|jp(e?)g)\") {\n    unset beresp.http.cookie;\n  }\n\n  # A TTL of 30 minutes\n  set beresp.ttl = 1800s;\n\n  return (deliver);\n}\n\n# The routine when we deliver the HTTP request to the user\n# Last chance to modify headers that are sent to the client\nsub vcl_deliver {\n\n  set resp.http.X-Served-By = server.hostname;\n  if (obj.hits &gt; 0) {\n    set resp.http.X-Cache = \"HIT\";\n    set resp.http.X-Cache-Hits = obj.hits;\n  } else {\n    set resp.http.X-Cache = \"MISS\";\n  }\n  unset resp.http.Via;\n  unset resp.http.X-Varnish;\n\n  # Remove some headers: PHP version\n  unset resp.http.X-Powered-By;\n\n  return (deliver);\n}\n\nsub vcl_init {\n  return (ok);\n}\n\nsub vcl_fini {\n  return (ok);\n}\n</code></pre>"},{"location":"linux/automatisation/ansible/ansible/","title":"Automatisation des taches avec ansible","text":""},{"location":"linux/automatisation/ansible/ansible/#ansible-kezako","title":"Ansible ? Kezako","text":"<p>ansible est un outil d'automatisation des t\u00e2ches d'un serveur d\u00e9velopp\u00e9 en python agent-less (c\u00e0d sans agent \u00e0 installer sur le serveur) via des '\"recettes'\" appel\u00e9es playbooks en jargon ansible ou alors pour des actions simples des lignes de commandes. Il ne s'agit ni plus ni moins que de scripts \u00e0 la sauce ansible permettant de configurer vos serveurs.</p>"},{"location":"linux/automatisation/ansible/ansible/#le-fichier-hosts","title":"Le fichier hosts","text":"<p>Le fichier hosts est le fichier o\u00f9 nous allons d\u00e9finir tous les serveurs d\u00e9stin\u00e9s \u00e0 recevoir les commandes d'ansible. Sa syntaxe est simplissime</p> <pre><code>    myserver.com:1881\n</code></pre> <p>Via ce simple code, nous allons indiquer \u00e0 ansible de se connecter \u00e0 myserver.com sur le port SSH 1881. Par d\u00e9faut, le port 22 est \u00e9videmment utilis\u00e9.</p> <p>Il est possible de d\u00e9finir des groupes de serveurs afin d'appliquer les actions sur un type de serveur donn\u00e9, par exemple</p> <pre><code>    myserver.com:1881\n\n    [webservers]\n    foo.myserver.com\n    bar.myserver.com\n</code></pre> <p>Dans cet exemple, nous avons le groupe <code>webservers</code>. L'argument <code>ansible</code> pour sp\u00e9cifier un groupe est <code>-l webservers</code>. Il est \u00e9galement possible de ne cibler qu'un serveur via cet argument.</p> <p>De plus, il est possible de d\u00e9finir des variables de groupes ou globales. Par exemple, si tous vos serveurs de BDD ont leur port SSH en 8237, nous n'allons pas d\u00e9finir le port pour chaque h\u00f4te.</p> <pre><code>    [database]\n    db1.sql.com\n    db2.sql.com\n\n    [database:vars]\n    ansible_port=8237\n</code></pre> <p>Dans le cas d'une soci\u00e9t\u00e9, nous avons un dossier customers dans le dossier <code>/etc/ansible</code>. Chaque fichier contenu dans ce dossier contiendra un client...</p>"},{"location":"linux/automatisation/ansible/ansible/#ligne-de-commande","title":"Ligne de commande","text":"<p>Comme dis pr\u00e9c\u00e9demment, l'une des 2 mani\u00e8res de lancer ansible est via la ligne de commande. Par exemple, si vous souhaitez faire un ls d'un r\u00e9pertoire pr\u00e9cis dans tous vos linux, voici la commande \u00e0 taper :</p> <pre><code>ansible -i /etc/ansible/customers/absix.hosts linux -a \"ls /var/www\"\n</code></pre> <p>Via cette commande, nous utilisons comme fichier hosts <code>/etc/ansible/customers/lol.absix</code> sur le groupe 'linux' et nous lan\u00e7ons la commande <code>ls /var/www</code></p> <p>Si vous souhaitez boucler sur tous les clients, il suffira de faire une boucle for</p> <pre><code>for HOST in /etc/ansible/customers/*\ndo\n    ansible -i $HOST linux -a \"ls /var/www\"\ndone\n</code></pre> <p>Plus d'informations sur les commandes ad-hoc sont disponibles sur le site officiel</p> <p>'## Playbooks</p> <p>Un playbook est un fichier de '\"description'\" des actions \u00e0 r\u00e9aliser \u00e9crit en YAML.</p> <p>Voici un exemple de playbook simple :</p> <pre><code>---\n- hosts: linux\n  user: root\n  connection: ssh\n\n  tasks:\n  - name: Copy mk_mysql script\n    copy:\n      src: /root/mk_mysql/files_script/mk_mysql\n      dest: /usr/lib/check_mk_agent/plugins/mk_mysql\n      owner: root\n      group: root\n      mode: 0755\n    when: ansible_distribution == Debian\n\n  - name: Add configuration file\n    command: cp /etc/mysql/debian.cnf /etc/check_mk\n\n  - name: Rename with correct name\n    command: mv /etc/check_mk/debian.cnf /etc/check_mk/mysql.cfg\n\n  - name: Remove white space\n    command: sed -i s/ //g /etc/check_mk/mysql.cfg\n</code></pre> <p>Ce playbook est tout simple. Tout d'abord, il sera appliqu\u00e9 qu'aux hotes dans le groupe ansible linux en utilisant une connexion SSH via l'utilisateur root.</p> <p>4 taches seront ex\u00e9cut\u00e9es via ce script :</p> <ul> <li>Tout d'abord, il via copier le fichier contenu dans la machine     ansible <code>/root/mk_mysql/files_script/mk_mysql</code> vers     <code>/usr/lib/check_mk_agent/plugins/mk_mysql</code> dans la machine distante</li> <li>Secondement, le fichier de la machine distante     <code>/etc/mysql/debian.cnf</code> sera copi\u00e9 dans le r\u00e9pertoire     <code>/etc/check_mk</code></li> <li>Par la suite, il renomme le fichier contenu dans <code>/etc/check_mk</code> de     <code>debian.cnf</code> \u00e0 <code>mysql.cfg</code></li> <li>Et enfin, il supprime tous les whitespace du fichier</li> </ul> <p>Dans ce playbook, seul le module copy est utilis\u00e9, mais une liste exhaustive des modules existants est disponible sur le site officiel</p> <p>Pour lancer ce playbook sur tous les clients d'un seul coup, la m\u00eame boucle for que toute \u00e0 l'heure est n\u00e9cessaire, mais avec une commande diff\u00e9rente.</p> <pre><code>for HOST in /etc/ansible/customers/*.hosts\ndo\n    ansible-playbook -i ${HOST} deploy_mkmysql.yml\ndone\n</code></pre> <p>Pour une documentation plus pouss\u00e9e, je vous recommande d'aller sur l'article de Buzut qui d\u00e9crit simplement l'utilisation de ansible, ou encore l'article de memo-linux.</p> <p>L'excellent xavki a \u00e9galement sorti une formation pouss\u00e9e sur le sujet</p>"},{"location":"linux/automatisation/ansible/ansible/#utilisation-des-variables","title":"Utilisation des variables","text":"<p>ansible est nativement pr\u00e9vu pour \u00eatre compatible avec les variables, afin de factoriser le code. Il est possible d'en d\u00e9finir dans des fichiers yaml. Celles-ci peuvent \u00eatre de plusieurs niveaux (dit dictionnaires):</p> <pre><code>$ cat vars/users.yml\n# Users variable\nusers:\n  ## tecteam users\n  jdelgado:\n    my_key: my_value\n</code></pre> <p>Dans ce fichiers vars/users.yml, nous avons une variable nomm\u00e9e users contenant 1 entr\u00e9e, jdelgado, qui contient elle m\u00eame une entr\u00e9e exemple.</p> <p>Pour utiliser ce fichier dans un role, il faut dans un premier temps inclure le fichier dans notre task:</p> <pre><code>$ cat tasks/main.yml\n- name: \"Include users vars\"\n  ansible.builtin.include_vars:\n    file: ../../inventory/vars/users.yml\n</code></pre> <p>Puis nous pouvons utiliser comme ceci la variable :</p> <pre><code>- name: Update .bashrc for {{ item.key }}\n  ansible.builtin.copy:\n    src: files/.bashrc\n    dest: \"/home/{{ item.key }}/.bashrc\"\n    mode: 0644\n  loop: \"{{ users | dict2items }}\"\n  loop_control:\n    label: \"{{ item.key }}\"\n  when: item.value['group_name']  == 'sysadmin'\n</code></pre> <p>Dans cet exemple, nous transformons notre variable en item afin d'utiliser plus facilement la cl\u00e9.</p> <p>Nous souhaitons boucler  autour du nom d'utilisateur, qui sera dans notre cas la cl\u00e9.</p>"},{"location":"linux/automatisation/ansible/ansible_reuse_variable/","title":"R\u00e9utilisation de variables ansible entre diff\u00e9rentes t\u00e2ches","text":"<p>L'utilisation des variables dans ansible est parfois une plaie.</p> <p>Imaginons un cas simple, nous souhaitons faire un check sur un serveur pr\u00e9cis, puis d\u00e9ploy\u00e9 sur une flotte de serveur identiques. Dans ce cas simple, il semblerait trivial d'executer la tache A sur le serveur A, puis d'appliquer aux serveurs B, C et D, ce qui nous donnerait ce playbook :</p> File : wrong_playbook.yml <pre><code>- name: Task A\n  hosts: host_a\n  tasks:\n    - name: Check Task Version\n      ansible.builtin.shell: php check\n      register: neededupdate\n\n- name: Update youtube-dl on servers\n  vars:\n    update: \"{{ neededupdate.stdout }}\"\n  hosts:\n    - host_a\n    - host_b\n    - host_c\n    - host_d\n  tasks:\n    - name: Upgrade &amp; install youtube-dl via PIP3\n      ansible.builtin.pip:\n        name: youtube-dl\n      when: \"'new_version_available' in neededupdate\"\n</code></pre> <p>Malheureusement, cet exemple ne peut pas marcher. Pour rappel, les variables ansible ont comme port\u00e9e leur host d'ex\u00e9cution, plut\u00f4t ballot. Il faudrait donc qu'on puisse indiquer \u00e0 ansible d'utiliser une variable d'un host sp\u00e9cifique sur un ensemble d'host.</p> <p>Heureusement, ansible a tout pr\u00e9vu avec le keyword <code>hostvars</code> qui permet d'acc\u00e9der a une variable d'un host sp\u00e9cifique</p> File : correct_playbook.yml <pre><code>- name: Task A\n  hosts: host_a\n  tasks:\n    - name: Check Task Version\n      ansible.builtin.shell: php check\n      register: neededupdate\n\n- name: Update youtube-dl on servers\n  vars:\n    update: \"{{ neededupdate.stdout }}\"\n  hosts:\n    - host_a\n    - host_b\n    - host_c\n    - host_d\n  tasks:\n    - name: Upgrade &amp; install youtube-dl via PIP3\n      ansible.builtin.pip:\n        name: youtube-dl\n      when: \"'new_version_available' in hostvars['host_a']['neededupdate']['stdout']\"\n</code></pre>"},{"location":"linux/automatisation/ansible/ansible_tips/","title":"Ansible : Tips","text":"<p>Quelques tips o\u00f9 j'ai perdu beaucoup de temps dessus</p> <pre><code>{% for SERVER in  groups[group_names[0]] -%}\n{{ hostvars[SERVER].ansible_host }},\n{%- endfor %}\n</code></pre> <p>Plusieurs cas concr\u00eats ici :</p> <ul> <li>Nous l'avons l'utilisation d'une variable sp\u00e9ciale d'ansible.</li> <li><code>group_names</code> nous indique l'ensemble des groupes o\u00f9 appartient notre serveur</li> <li><code>groups</code> liste ici l'ensemble des groupes dont l'inventaire est constitu\u00e9, et chaque groupe contient les hosts qu'il poss\u00e8de.</li> </ul> <p>Multi group</p> <p>Dans le cas d'un multi-group, il faut utiliser l'id -1 qui correpsond au groupe dont notre serveur d\u00e9pend directement</p> <p>Cette boucle parcourt l'int\u00e9gralit\u00e9 des serveurs dont est constitu\u00e9 le premier groupe parent (index 0 de notre tableau) de notre serveur</p> <p><code>hostvars</code> est \u00e9galement une variable sp\u00e9ciale. Celle-ci contient l'ensemble des serveurs de notre inventaire ainsi que chaque variable qui lui est associ\u00e9. Concr\u00eatement, ici, nous listons toutes les adresses IPs de tous les serveurs qui constituent le premier groupe parent de notre serveur.</p> <p>MAIS C'EST PAS FINIT: vous voyez le petit <code>-%}</code> dans le for et le <code>{%-</code>. Le - n'est pas l\u00e0 par hasard, celui-ci supprime le retour \u00e0 la ligne apr\u00e8s chaque item de notre for, plut\u00f4t pratique pour faire une liste d'adresse IP ou autre. Plus d'infos sont dispoibles ici</p>"},{"location":"linux/automatisation/misc/Makefile/","title":"Makefile : \u00e0 quoi \u00e7a sert ?","text":""},{"location":"linux/automatisation/misc/Makefile/#bonus","title":"Bonus","text":""},{"location":"linux/automatisation/misc/Makefile/#generer-une-documentation-automatique-pour-son-makefile","title":"G\u00e9n\u00e9rer une documentation automatique pour son Makefile","text":"<p>Avec un peu de malice, rien de plus simple :</p> <pre><code>.DEFAULT_GOAL := help\n\nhelp:\n    @grep -E '^[a-zA-Z_-]+:.*?## .*$$' $(MAKEFILE_LIST) | sort | awk 'BEGIN {FS = \":.*?## \"}; {printf \"\\033[36m%-30s\\033[0m %s\\n\", $$1, $$2}'\n</code></pre> <p>Pour vous d\u00e9cripter ce que fait cette ligne automagique, tout d'abord, nous allons appliquer un grep sur les lignes commencant par une (ou plusieurs) lettre(s) suivi d'un <code>:</code>. Nous allons prendre tout le contenu qui suit les signes <code>##</code>. Une fois cela fait, nous allons le strier, puis appliquer un filtre pour les afficher de mani\u00e8re \u00e9l\u00e9gante.</p> <p>Tout ceci pour nous donner le r\u00e9sultat suivant :</p> <p></p>"},{"location":"linux/automatisation/terraform/cheatsheet/","title":"Cheatsheet terraform","text":"<p>Quelques commandes importantes/utiles pour Terraform. Je n'ai rien invent\u00e9, les commandes viennent d'une cheatsheet des internet mondiaux. J'ai simplement repris les commandes qui me sont utiles de ce magnifique PDF</p> <ul> <li><code>terraform version</code> : Obtenir la version de terraform</li> <li><code>terraform get -update=true</code> : Update les modules d'un projet</li> <li><code>terraform validate</code> : Valide la syntaxe d'un Terraform</li> <li><code>terraform fmt</code> : Formate notre terraform (tr\u00e8s pratique pour avoir une uniformit\u00e9 entre collaborateurs)</li> <li><code>terraform plan</code> : Montre les modifications</li> <li><code>terraform apply</code> : Applique les modifications</li> <li><code>-auto-approve</code> applique automatiquement les modifs</li> </ul>"},{"location":"linux/automatisation/terraform/speedup/","title":"Acc\u00e9lerer Terraform","text":"<p>Pour acc\u00e9lerer Terraform, quelques bonnes pratiques</p>"},{"location":"linux/automatisation/terraform/speedup/#parallelisme","title":"Parall\u00e9lisme","text":"<p>Par d\u00e9faut, si vous dispoez d'un large nombre de ressource, le parall\u00e9lisme de Terraform est seulement de 10. C'est \u00e0 dire que Terraform ne va pas effectuer plus de 10 op\u00e9rations en parall\u00e8le.</p> <p>Pour cela, augmenter le <code>-parallelism</code> \u00e0 une valeur sup\u00e9rieur.</p> <p>Danger</p> <p>Attention \u00e0 ne pas spam les API provider et provoquer d'autres bugs</p>"},{"location":"linux/automatisation/terraform/speedup/#reutilisation-des-providers","title":"R\u00e9utilisation des providers","text":"<p>Un comportement pas vraiment intelligent de Terraform est le pull syst\u00e9matique des providers.</p> <p>Imaginons que nous avons 10 repos utilisant les m\u00eames 4 providers, Terraform va les pull 10 fois alors qu'il s'agit des m\u00eames. Cela peut \u00e9galement couteux en terme d'espace disque</p> <p>Pour cela, la bonne pratique est de d\u00e9finir la variable <code>TF_PLUGIN_CACHE_DIR</code>. Cette variable va indiquer \u00e0 Terraform de e r\u00e9f\u00e9rer \u00e0 un dossier pour les providers plut\u00f4t que de les re-t\u00e9l\u00e9charger \u00e0 chaque fois</p> <p>En pratique, il existe 2 mani\u00e8res d'effectuer cette op\u00e9ration :</p> <p>Dans votre configuration de la CLI Terraform, vous pouvez ajouter cette ligne</p> <pre><code>plugin_cache_dir = \"${HOME}/.terraform.d/plugin-cache\"\n</code></pre> <p>La seconde mani\u00e8re que je conseille est d'ajouter directement une variable d'environnement</p> <pre><code>export TF_PLUGIN_CACHE_DIR=\"${HOME}/.terraform.d/plugin-cache\"\n</code></pre>"},{"location":"linux/automatisation/terraform/speedup/#bonus-gitlab-ci","title":"Bonus : Gitlab-CI","text":"<p>Il est \u00e9galement possible de setup du cache sur une pipeline Gitlab</p> <p>Comme pour Terraform sur notre poste, il est n\u00e9cessaire de d\u00e9finir la m\u00eame variable puis nous allons utiliser le keyword cache de Terrraform pour activer ce dernier</p> <pre><code>.terraform:\n  image:\n    name: terraform:latest\n  variables:\n    TF_INPUT: \"false\"\n    TF_IN_AUTOMATION: \"true\"\n    TF_PLUGIN_CACHE_DIR_RELPATH: .terraform.d/plugin-cache\n    TF_PLUGIN_CACHE_DIR: ${CI_PROJECT_DIR}/${TF_PLUGIN_CACHE_DIR_RELPATH}\n  artifacts:\n    expire_in: 3 hours\n  before_script:\n    - mkdir -p \"${TF_PLUGIN_CACHE_DIR}\"\n  cache:\n    key: terraform-plugins-cache\n    paths:\n      - ${TF_PLUGIN_CACHE_DIR_RELPATH}\n    when: always\n</code></pre> <p>Puis sur les \u00e9tapes suivantes, nous allons \u00e9tendre ce template</p> <pre><code>terraform-init:\n  extends: .terraform\n</code></pre> <p>Nous disposons maintenant d'un cache commun aux diff\u00e9rentes stages</p> <p>Pour confirmer que l'init est correctement load depuis le cache, nous devons avoir l'output suivant :</p> <pre><code>time terraform init\n\nInitializing the backend...\n\nInitializing provider plugins...\n- Finding hashicorp/aws versions matching \"~&gt; 4.45.0\"...\n- Finding hashicorp/random versions matching \"~&gt; 3.4.3\"...\n- Finding hashicorp/googleworkspace versions matching \"~&gt; 0.6.0\"...\n- Finding hashicorp/time versions matching \"~&gt; 0.7.2\"...\n- Finding hashicorp/google versions matching \"~&gt; 4.20.0\"...\n- Finding hashicorp/local versions matching \"~&gt; 2.2.2\"...\n- Finding hashicorp/archive versions matching \"~&gt; 2.2.0\"...\n- Finding hashicorp/external versions matching \"~&gt; 2.2.2\"...\n- Finding hashicorp/tls versions matching \"~&gt; 3.3.0\"...\n- Finding hashicorp/null versions matching \"~&gt; 3.1.1\"...\n- Using hashicorp/aws v4.45.0 from the shared cache directory\n- Using hashicorp/external v2.2.3 from the shared cache directory\n- Using hashicorp/local v2.2.3 from the shared cache directory\n- Using hashicorp/archive v2.2.0 from the shared cache directory\n- Using hashicorp/tls v3.3.0 from the shared cache directory\n- Using hashicorp/null v3.1.1 from the shared cache directory\n- Using hashicorp/random v3.4.3 from the shared cache directory\n- Using hashicorp/googleworkspace v0.6.0 from the shared cache directory\n- Using hashicorp/time v0.7.2 from the shared cache directory\n- Using hashicorp/google v4.20.0 from the shared cache directory\n\nterraform init  0.35s user 0.12s system 15% cpu 3.078 total\n</code></pre>"},{"location":"linux/automatisation/terraform/tools/","title":"Tools Terraform indispensables","text":"<p>Terraform est un outil fabuleux permettant de faire du IaaS (Infrastructure As A Service).</p> <p>Cependant, nous pouvons encore am\u00e9liorer son exp\u00e9rience avec quelques outils :</p> <ul> <li><code>tfswitch</code> nous permettra de s\u00e9lectionner automatiquement la bonne     version de Terraform :     tfswitch</li> <li><code>terraform-docs</code> nous permettra de simplement g\u00e9n\u00e9rer une     documentation pour votre projet Terraform, \u00e0 agr\u00e9menter \u00e9videmment :     terraform-docs</li> <li><code>tfsec</code> nous permettra de v\u00e9rifier les bonnes pratiques en terme     de s\u00e9curit\u00e9, il est \u00e9galement possible de cr\u00e9er ses r\u00e8gles     custom... : tfsec</li> <li><code>checkov</code> est un \u00e9quivalent \u00e0 tfsec mais est g\u00e9n\u00e9rique, il peut     \u00e9galement scanner les YAML K8S...     checkov</li> </ul>"},{"location":"linux/bsd/wheel_group/","title":"Ajouter un utilisateur au groupe wheel","text":"<p>Sous BSD, notre utilisateur cr\u00e9\u00e9 lors de l'installation ne peut pas faire la commande '\"su'\" par d\u00e9faut. Nous devons l'ajouter au groupe wheel. Il s'agit d'une diff\u00e9rence minuscule mais qui a une grande importance.</p> <pre><code>pw groupmod wheel -m username\n</code></pre> <p>Avec cette commande, vous pourriez effectuer la commande '\"su'\" comme de base sous GNU/Linux</p>"},{"location":"linux/centos/add_epel_repositories/","title":"Ajouter les repositories EPEL","text":"<p>Les repositories EPEL (Extra Packages for Enterprise Linux) sont extr\u00eamements importants pour les utilisateurs de CentOS. Sous forme de package, celui-ci ajoute simplement une liste de repository. Initialement, l'EPEL est un groupe au sein du Projet Fedora. Les repositories EPEL peuvent \u00eatre utilis\u00e9s dans les projets suivants :</p> <ul> <li>Red Hat Enterprise Linux</li> <li>CentOS</li> <li>Scientific Linux</li> <li>Oracle Linux</li> </ul>"},{"location":"linux/centos/add_epel_repositories/#installation","title":"Installation","text":"<p>Pour installer le package, rien de plus simple :</p> <pre><code>yum install epel-release\n</code></pre> <p>La liste des packages disponible dans EPEL est disponible ici. Nous voyons par exemple que les paquets htop ou encore tmux sont fournis par ces repositories.</p>"},{"location":"linux/cli/confrc/","title":"Mes fichiers de configuration","text":"<p>Mes diff\u00e9rents fichiers de configuration sont disponibles sur mon repository GitHub \u00e0 l'adresse suivante : https://github.com/PixiBixi/dotfiles. En vrac, ce qu'ils contiennent :</p> <ul> <li>Configuration zshrc + utilisation des plugins oh-my-zsh</li> <li>SSH basic configuration</li> <li>.gitconfig configuration tous mes alias ainsi que d'autres trucs et astuces</li> <li>Le Brewfile, permettant d'installer toutes mes applications rapidement</li> <li>Ma config Neovim, ainsi que la vim</li> </ul>"},{"location":"linux/cli/define_hostname/","title":"Configurer correctement son hostname","text":"<p>Dans cet article, nous allons voir comment configurer correctement notre nom de domaine</p>"},{"location":"linux/cli/define_hostname/#vocabulaire","title":"Vocabulaire","text":"<p>Tout d'abord, pour bien installer son nom de domaine, voici un peu de vocabulaire sp\u00e9cifique dont nous aurons besoin par la suite :</p> <ul> <li>Nom de domaine principal : domain.tld</li> </ul> <p>Il s'agit du nom de domaine que l'ont vient d'acheter (Par exemple : toto.fr)</p> <ul> <li>Nom dh\u00f4te : hostname</li> </ul> <p>Il s'agit ce coup-ci du nom que portera notre machine (Par exemple : warrior)</p> <ul> <li>FQDN : hostname.domain.tld</li> </ul> <p>D\u00e9sormais, il s'agit du '\"m\u00e9lange'\" des deux \u00e9l\u00e9ments pr\u00e9c\u00e9dents (Donc dans notre cas : warrior.toto.fr)</p> <ul> <li>Reverse : hostname.domain.tld</li> </ul> <p>Attention, il se peut qu'il y ai parfois un . \u00e0 la fin de celui-ci (Dans notre cas : warrior.toto.fr.)</p>"},{"location":"linux/cli/define_hostname/#installer-correctement-le-nom-de-domaine-sur-son-serveur","title":"Installer correctement le nom de domaine sur son serveur","text":"<p>Tout d'abord, nous devons configurer l'hostname</p> <p>Tout au long du tutoriel, nous allons prendre en exemple nos valeurs d'exemple</p> <pre><code>echo \"warrior\" &gt; /etc/hostname\n</code></pre> <p>Ou alors, une autre possibilit\u00e9 :</p> <pre><code>hostname warrior\n</code></pre> <p>Puis on edit le fichier /etc/hosts</p> <pre><code>$ cat /etc/hosts\n127.0.0.1 warrior.toto.fr warrior\n127.0.0.1 localhost.localdomain localhost\nIPv4 warrior.toto.fr warrior\nIPv6 warrior.toto.fr warrior\n</code></pre> <p>Les lignes concernant 127.0.0.1 ne sont pas \u00e0 \u00e9diter</p>"},{"location":"linux/cli/define_hostname/#verifications","title":"V\u00e9rifications","text":"<p>Concernant les v\u00e9rifications, celles-ci devront se faire dans une autre session SSH en tant que root</p> <p>Tout va se passer avec la commande hostname et diff\u00e9rentes options</p> <p>Voici les diff\u00e9rentes commande \u00e0 effectuer :</p> <pre><code>hostname -d\n</code></pre> <p>Doit retourner le nom de domaine</p> <pre><code>hostname -f\n</code></pre> <p>Doit retourner le FQDN</p> <pre><code>hostname -a\n</code></pre> <p>Doit retourner l'hostname</p> <p>Si tout se passe correctement, alleluia, sinon, il faut r\u00e9peter les \u00e9tapes pr\u00e9c\u00e9dentes</p>"},{"location":"linux/cli/dfc/","title":"DFC, la commande DF en plus","text":""},{"location":"linux/cli/dfc/#presentation","title":"Pr\u00e9sentation","text":"<p>dfc est un petit utilitaire rendant la commande df d\u00e9pass\u00e9e. En effet, dfc est beaucoup plus clair que la commande df, et supporte \u00e9galement les couleurs.</p> <p>Comme des images sont plus repr\u00e9sentatives, voil\u00e0 les deux commandes :</p> <p>df :</p> <p></p> <p>dfc :</p> <p></p> <p>Comme vous pouvez, le voir, le r\u00e9sultat est quasiment identique, mais dfc est bien plus clair.</p>"},{"location":"linux/cli/dfc/#installation","title":"Installation","text":""},{"location":"linux/cli/dfc/#wheezy","title":"Wheezy","text":"<p>Sous Wheezy, il n'y a rien \u00e0 faire, vu que le paquet est dans les d\u00e9pots de base, donc on l'installe comme d'habitude :</p> <pre><code>apt-get -y install dfc\n</code></pre> <p>La version t\u00e9l\u00e9charg\u00e9 est la 2.5.0, \u00e0 l'heure actuelle, nous sommes \u00e0 la 3.0.5. Cependant, aucun ajout utile ne n\u00e9c\u00e9ssite une upgrade, vous pouvez donc soit compiler \u00e0 la main, soit installer depuis les d\u00e9pots. Le changelog est disponible ici</p> <p>Puis nous l'utilisons simplement via la commande dfc</p>"},{"location":"linux/cli/dfc/#jessie","title":"Jessie","text":"<p>Sous Jessie, cela se complique un peu, nous devons le compiler \u00e0 la main, \u00e9tant donn\u00e9 qu'aucun paquet n'est disponible dans les sources de base.</p> <p>On commence par installer les pr\u00e9-requis pour compiler dfc</p> <pre><code>apt-get -y install cmake gettext git-core\n</code></pre> <p>On t\u00e9l\u00e9charge les sources</p> <pre><code>git clone https://github.com/Rolinh/dfc\n</code></pre> <p>On se rend dans le dossier de t\u00e9l\u00e9chargement de dfc</p> <pre><code>cd dfc\n</code></pre> <p>On cr\u00e9\u00e9 un dossier n\u00e9c\u00e9ssaire \u00e0 la compilation</p> <pre><code>mkdir build &amp;&amp; cd build\n</code></pre> <p>Et enfin, on lance la compilation</p> <pre><code>cmake .. &amp;&amp; make &amp;&amp; make install\n</code></pre>"},{"location":"linux/cli/dfc/#stretch-et-superieur","title":"Stretch et Sup\u00e9rieur","text":"<p>A partir de Debian Stretch, dfc est rentr\u00e9 dans les repositories, il n'est donc plus n\u00e9cessaire de le compiler.</p> <pre><code>apt update &amp;&amp; apt install -y dfc\n</code></pre>"},{"location":"linux/cli/dfc/#bonus","title":"Bonus","text":"<p>Nous pouvons totalement se passer de df en le rempla\u00e7ant par dfc via un alias dans le .bashrc</p> <pre><code>echo \"alias df=dfc\" &gt;&gt; ~/.bashrc\n</code></pre>"},{"location":"linux/cli/find/","title":"La commande find","text":"<p>La commande find sous Linux est une commande extr\u00eamement puissante qui a une tonne d'options. Elle nous permet de rep\u00e9rer les fichiers les plus gros, les fichiers qui n'ont pas \u00e9t\u00e9 modifi\u00e9s depuis 30j...</p>"},{"location":"linux/cli/find/#exemples","title":"Exemples","text":""},{"location":"linux/cli/find/#filtre-sur-le-nom","title":"Filtre sur le nom","text":"<pre><code>find . -iname power.log\n</code></pre> <p>Cherche dans tous les dossiers contenus dans le r\u00e9pertoire courant un fichier se nommant (de mani\u00e8re insensitive) power.log</p> <pre><code>find . -name *.log\n</code></pre> <p>Cherche dans tous les dossiers n'importe quel type de document (fichiers/dossiers) finissant par .log</p> <pre><code>find -not -name *log\n</code></pre> <p>Cherche dans le r\u00e9pertoire courant (et uniquement le courant) n'importe quel type de document ne contenant pas (-not) log</p>"},{"location":"linux/cli/find/#filtre-sur-le-type","title":"Filtre sur le type","text":"<pre><code>find /home/guest1/proj -type f -name .*\n</code></pre> <p>Recherche uniquement les fichiers (-type f) commen\u00e7ant par . (Concr\u00eatement, les fichiers cach\u00e9s de Linux) dans le dossier /home/guest1/proj</p> <ul> <li>f : File</li> <li>d : Directory</li> <li>l : Symlink</li> </ul> <pre><code>find /opt /usr /var -name foo.scala -type f\n</code></pre> <p>Il est \u00e9galement possible de chercher un fichier dans plusieurs dossiers. (/opt /usr et /var). Ici, nous cherchons le fichier foo.scala</p> <pre><code>find . -type f '( -name \"*.c\" -o -name \"*.sh\" ')\n</code></pre> <p>De plus, nous pouvons chercher plusieurs fichiers \u00e0 la fois. Dans cet exemple, nous cherchons \u00e0 la fois les fichiers en .c et en .sh</p>"},{"location":"linux/cli/find/#filtrage-sur-les-proprietes-des-fichiers","title":"Filtrage sur les propri\u00e9t\u00e9s des fichiers","text":"<pre><code>find -mtime -2\n</code></pre> <p>Affiche tout ce qui a \u00e9t\u00e9 modifi\u00e9 il y a moins de 2 jours (Unit\u00e9 par d\u00e9faut)</p> <ul> <li> <ul> <li>= Moins de</li> </ul> </li> <li> <ul> <li>= Plus de</li> </ul> </li> <li>\u00d8 = Exactement</li> </ul> <p>L'argument <code>-size</code> fonctionne uniquement sur les fichiers</p> <pre><code>find -size +10k\n</code></pre> <p>Affiche tous les fichiers de plus de 10KB</p> <ul> <li><code>k</code> = Kilo-octets</li> <li><code>M</code> = Mega-octets</li> <li><code>G</code> = Giga-octets</li> <li><code>+</code> = Plus de</li> <li><code>-</code> = Moins de</li> <li><code>\u00d8</code> = Taille exacte</li> </ul>"},{"location":"linux/cli/find/#execution","title":"Ex\u00e9cution","text":"<p>Il est \u00e9galement possible de rediriger la sortie de find automatiquement vers les une commande en utilisant <code>-exec</code></p> <pre><code>find report -name *log* -exec rm {} ';\n</code></pre> <p>Recherche tous les fichiers comprenant la chaine log et les supprime (Le {} indique le fichier courant, et le ''; est indispensable (Le '' sert juste \u00e0 echaper le ; ))</p> <p>Il est \u00e9galement possible de faire cette m\u00eame commande avec <code>-delete</code></p> <pre><code>find report -name *log* -delete\n</code></pre> <pre><code>find -name *.txt -exec wc {} +\n</code></pre> <p>Ici, nous prenons tous les fichiers finissant par .txt et nous ex\u00e9cutons la commande sur tous ces fichiers. La diff\u00e9rence avec la premi\u00e8re est qu'ici nous cumulons les r\u00e9sultats (Avec le + (Qui n'a pas besoin d'\u00eatre echaper))</p>"},{"location":"linux/cli/ip/","title":"M\u00e9mo sur la commande IP","text":"<p>Comme vous le savez certainement, la commande ifconfig est maintenant depreciated depuis bon nombre de mois/ann\u00e9es, pourtant, nous avons toujours comme habitue d'utiliser cette commande.</p> <p>Pourtant, la commande ip propose bien plus d'options que son anc\u00eatre ifconfig, mais les habitudes sont durs \u00e0 changer.</p>"},{"location":"linux/cli/ip/#principe-de-base","title":"Principe de base","text":"<pre><code>ip OBJECT COMMAND\nip [options] OBJECT COMMAND\nip OBJECT help\n</code></pre>"},{"location":"linux/cli/ip/#activerdesactiver-une-interface","title":"Activer/d\u00e9sactiver une interface","text":"<p>Pour activer une interface :</p> <pre><code>ip link set wlan0 up\n</code></pre> <p>Pour d\u00e9sactiver une interface</p> <pre><code>ip link set wlan0 down\n</code></pre>"},{"location":"linux/cli/ip/#parametrer-une-adresse-ip","title":"Parametrer une adresse IP","text":"<pre><code>ip addr add 192.168.1.8/24 dev wlan0\n</code></pre> <p>Afin de v\u00e9rifier que l'adresse IP a bien \u00e9t\u00e9 prise en compte</p> <pre><code>ip addr show wlan0\n</code></pre> <p>Et voici l'output que nous devons obtenir :</p> <pre><code>    3: wlan0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000\n        link/ether 00:25:00:3d:e1:aa brd ff:ff:ff:ff:ff:ff\n        inet 192.168.1.8/24 brd 192.168.1.255 scope global wlan0\n        valid_lft forever preferred_lft forever\n</code></pre> <p>Si nous souhaitons supprimer une adresse IP, il suffit de remplacer add par del</p> <pre><code>ip addr del 192.168.1.8/24 dev wlan0\n</code></pre>"},{"location":"linux/cli/ip/#route","title":"Route","text":"<p>En plus des simples commandes d'IP, nous pouvons manipuler les routes via la commande ip</p>"},{"location":"linux/cli/ip/#montrer-les-routes","title":"Montrer les routes","text":"<pre><code>ip route show\n</code></pre>"},{"location":"linux/cli/ip/#ajoute-une-route","title":"Ajoute une route","text":"<pre><code>ip route add default via 192.168.1.1\n</code></pre>"},{"location":"linux/cli/ip/#supprime-une-route","title":"Supprime une route","text":"<pre><code>ip route del default via 192.168.1.1\n</code></pre>"},{"location":"linux/cli/ip/#statistiques","title":"Statistiques","text":"<p>Tout comme ifconfig, nous pouvons obtenir les statistiques des interfaces</p>"},{"location":"linux/cli/ip/#toutes-interfaces","title":"Toutes interfaces","text":"<pre><code>ip -statistics link\n</code></pre> <p>Output :</p> <pre><code>    1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 16436 qdisc noqueue state UNKNOWN mode DEFAULT\n        link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n        RX: bytes  packets  errors  dropped overrun mcast\n        439862908634 45470372 0       0       0       0\n        TX: bytes  packets  errors  dropped carrier collsns\n        439862908634 45470372 0       0       0       0\n    2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP mode DEFAULT qlen 1000\n        link/ether bc:30:5b:df:5a:36 brd ff:ff:ff:ff:ff:ff\n        RX: bytes  packets  errors  dropped overrun mcast\n        151855161674 446514789 0       0       0       47717941\n        TX: bytes  packets  errors  dropped carrier collsns\n        909110766609 783458587 0       0       0       0\n    3: eth1: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc mq state DOWN mode DEFAULT qlen 1000\n        link/ether bc:30:5b:df:5a:37 brd ff:ff:ff:ff:ff:ff\n        RX: bytes  packets  errors  dropped overrun mcast\n        0          0        0       0       0       0\n        TX: bytes  packets  errors  dropped carrier collsns\n        0          0        0       0       0       0\n    4: tun0: &lt;POINTOPOINT,MULTICAST,NOARP,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UNKNOWN mode DEFAULT qlen 100\n        link/none\n        RX: bytes  packets  errors  dropped overrun mcast\n        2316028442 35517985 0       0       0       0\n        TX: bytes  packets  errors  dropped carrier collsns\n        87027484021 64846840 0       567     0       0\n</code></pre>"},{"location":"linux/cli/ip/#interface-specifique","title":"Interface sp\u00e9cifique","text":"<pre><code>ip -statistics link show eth0\n2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP mode DEFAULT qlen 1000\n    link/ether bc:30:5b:df:5a:36 brd ff:ff:ff:ff:ff:ff\n    RX: bytes  packets  errors  dropped overrun mcast\n    151856389090 446526528 0       0       0       47722861\n    TX: bytes  packets  errors  dropped carrier collsns\n    909111458731 783462602 0       0       0       0\n</code></pre>"},{"location":"linux/cli/ip/#arp","title":"ARP","text":"<p>Nous pouvons \u00e9galement observer diff\u00e9rents \u00e9l\u00e9ments ARP avec la commande ip. Pour rappel, ARP fait la correspondance IP '&lt;-'&gt; MAC dans un r\u00e9seau local.</p>"},{"location":"linux/cli/ip/#ajout-statique","title":"Ajout Statique","text":"<pre><code>ip neigh add 192.168.0.1 lladdr 00:11:22:33:44:55 nud permanent dev eth0\n</code></pre>"},{"location":"linux/cli/ip/#desactiver-la-resolution-arp","title":"D\u00e9sactiver la r\u00e9solution ARP","text":"<pre><code>ip link set dev eth0 arp off\n</code></pre>"},{"location":"linux/cli/limit_bandwidth/","title":"Simuler des conditions r\u00e9seau sur Linux","text":"<p>Il peut \u00eatre int\u00e9ressant de limiter sa bande passante pour simuler certaines bande passante ou autre, ou tout simplement pour brider un processus.</p>"},{"location":"linux/cli/limit_bandwidth/#methode-barbare","title":"M\u00e9thode barbare","text":"<p>La m\u00e9thode barbare consiste \u00e0 tout simplement jouer avec les iproute directement avec la commande tc.</p> <p>tc va nous permettre d'ajouter de la latence artificielle, limiter le d\u00e9bit...</p> <p>D'autres options sont disponibles, mais ne sont que tr\u00e8s peu utile (packet re-ordering, duplication...)</p>"},{"location":"linux/cli/limit_bandwidth/#ajout-de-latence","title":"Ajout de latence","text":"<pre><code>tc qdisc add dev eth0 root netem delay 200ms\n</code></pre> <p>Via cette commande, nous ajoutons sur l'interface eth0 200ms de latence via le network emulator (netem). Une commande plus pr\u00e9cise existe afin de simuler un comportement plus r\u00e9el d'une connexion domestique basique</p> <pre><code>tc qdisc change dev eth0 root netem delay 100ms 10ms 25%\n</code></pre> <p>Les arguments suppl\u00e9mentaires de cette commande impliquent un delta de 10ms selon 25% du ping-1</p>"},{"location":"linux/cli/limit_bandwidth/#perte-de-paquet","title":"Perte de paquet","text":"<p>En 4G, il n'est pas rare d'avoir une connexion instable avec perte de paquets, voici donc comment le simuler :</p> <pre><code>tc qdisc change dev eth0 root netem loss 2%\n</code></pre> <p>2% de loss seront appliqu\u00e9s sur tous vos paquets, soit 2 paquets sur 100 (en flat)</p> <pre><code>tc qdisc change dev eth0 root netem loss 2% 33%\n</code></pre> <p>Toujours 2% de pertes, mais correl\u00e9s avec les 33% des derniers paquets.</p>"},{"location":"linux/cli/limit_bandwidth/#bande-passante","title":"Bande passante","text":"<p>M\u00e9thode simple. Il est possible de jouer plus finement avec de la QoS.</p> <pre><code>tc qdisc add dev eth0 root tbf rate 10mbit\n</code></pre>"},{"location":"linux/cli/limit_bandwidth/#methode-simple","title":"M\u00e9thode simple","text":"<p>Un wrapper a \u00e9t\u00e9 d\u00e9velopp\u00e9 permettant de manipuler (uniquement) la bande passante simplement :</p> <pre><code>apt-get install wondershaper\n</code></pre> <p>Et la syntaxe est simplement la suivante : wondershaper '[ interface '] '[ downlink '] '[ uplink ']</p> <p>Ce qui nous donne par exemple</p> <pre><code>wondershaper eth0 1024 1024\n</code></pre> <p>On bride ici le traffic de eth0 en DL/UL a 1mbps</p>"},{"location":"linux/cli/motd/","title":"Personnaliser ton motd","text":"<p>Voici un petit tutoriel qui permet de personnaliser le '\"Message Of The Day'\" sur Debian (adaptable \u00e0 toute distribution) Le '\"motd'\" c'est le message que vous avez au moment o\u00f9 vous vous connectez sur votre shell. Ce tutoriel vous permettra d'avoir un '\"motd'\" qui ressemblera \u00e0 \u00e7a:' </p> <pre><code>apt-get install update-notifier-common\n</code></pre> <p>Supprimer le contenu du motd actuel avec vim /etc/motd</p> <p>On cr\u00e9er ensuite le script qui affichera les informations choisies</p> /etc/profile.d/motd.sh <pre><code>let upSeconds=\"$(/usr/bin/cut -d. -f1 /proc/uptime)\"\nlet secs=$((${upSeconds}%60))\nlet mins=$((${upSeconds}/60%60))\nlet hours=$((${upSeconds}/3600%24))\nlet days=$((${upSeconds}/86400))\n\nUPTIME=`printf \"%d days, %02dh%02dm%02ds\" \"$days\" \"$hours\" \"$mins\" \"$secs\"`\nREMOTEIP=`echo $SSH_CLIENT | awk {print $1}`\n\nif [ -f /var/run/reboot-required ]; then\nREBOOT=\"'033[22;31m&gt;&gt;&gt;&gt;&gt;&gt; This server require a reboot &lt;&lt;&lt;&lt;&lt;&lt;'033[0m\"\nfi\n\nif [ -f /var/log/checkupdate.log ]; then PACKAGE=`cat /var/log/checkupdate.log | awk -F ; {print $1}` SECURITY=`cat /var/log/checkupdate.log | awk -F ; {print $2}`\nfi\n\nif [ \"$SECURITY\" -gt 0 ]; then SECURITY=\"'033[22;31m${SECURITY}'033[0m\"\nfi\n\n# get the load averages\nread one five fifteen rest &lt; /proc/loadavg\necho -e \"--------- '033[22;31mW'033[22;32melcome '033[0m--------------------------------------------- --- -- - -\nYou are entering into a secured area! All activities on this system\nare logged. Unauthorized access will be fully investigated and\nreported to the appropriate law enforcement agencies.\n------------------------------------------------------------ --- -- - -\nYou are connected from ${REMOTEIP} as `whoami`@`hostname`\nUptime.....: ${UPTIME}\nMemory.....: `free -m | grep Mem: | awk {print $3}`MB (Used) / `free -m | grep Mem: | awk {print $2}`MB (Total) / `free -m | grep Mem: | awk {print $4}`MB (Free)\nLoad Avg...: ${one}, ${five}, ${fifteen} (1, 5, 15 min)\nTop process: Memory: `ps axo %mem,comm | grep -v \"MEM\"| sort -nr | head -n 1 | awk {print $2}` `ps axo %mem,comm | grep -v \"MEM\" | sort -nr | head -n 1 | awk {print $1}`% Cpu: `ps axo pcpu,comm | grep -v \"CPU\" | sort -nr | head -n 1 | awk {print $2}` `ps axo pcpu,comm | grep -v \"CPU\" | sort -nr | head -n 1 | awk {print $1}`%\nUpdate.....: ${PACKAGE} package update / ${SECURITY} security update ${REBOOT}\n------------------------------------------------------------------ --- -- - - '033[0m\"\n</code></pre> <p>On cr\u00e9er ensuite le script qui v\u00e9rifiera toutes les heures si de nouvelles mises \u00e0 jour sont disponibles</p> /etc/cron.hourly/checkupdate <pre><code>#!/bin/bash\nif [ -f /var/log/checkupdate.log ]; then\nrm -f /var/log/checkupdate.log\nfi\n/usr/lib/update-notifier/apt-check &gt;&gt; /var/log/checkupdate.log 2&gt;&amp;1\n</code></pre> <p>On fini par le rendre executable :</p> <pre><code>chmod +x /etc/cron.hourly/checkupdate\n</code></pre> <p>Les plus impatients peuvent ex\u00e9cuter ce script (<code>/etc/cron.hourly/checkupdate</code>) manuellement et ouvrir un nouveau shell pour voir le r\u00e9sultat :)</p> <p>Ce script est loin d'\u00eatre parfait (Et n'a pas la pr\u00e9tention de l'\u00eatre), mais il fait ce qu'on lui demande.</p>"},{"location":"linux/cli/replace_base_commands/","title":"Remplacer les commandes de base Linux par des versions plus performantes","text":""},{"location":"linux/cli/replace_base_commands/#commandes-built-in","title":"Commandes Built-in","text":"<p>De nos jours, les commandes de bases linux sont d\u00e9su\u00e8tes. Il existe des commandes faisant le m\u00eame travail, mais plus rapidement, ou alors avec une syntaxe simplifi\u00e9e. Ces logiciels sont g\u00e9n\u00e9ralement \u00e9crit en language rust et Open Source.</p>"},{"location":"linux/cli/replace_base_commands/#remplacant-de-ls","title":"Remplacant de ls","text":"<p>Deux outils sont disponibles pour remplacer <code>ls</code>, libre \u00e0 vous de choisir celui que vous pr\u00e9f\u00e9rez</p> <p>En remplacement ls, nous avons l'excellent outil exa, disponible sur Linux et MacOS. exa est un excellent outil pour beaucoup de choses. Par exemple, celui-ci int\u00e8gre la fonctionnalit\u00e9 tree (Visualisation des fichiers sous forme d'arbre) via <code>--tree</code>. Celui-ci int\u00e8gre \u00e9galement un th\u00e8me visuel nous permettant d'observer au premier coup d'oeil certaines choses comme la pr\u00e9sence d'un lien symbolique rompus...</p> <p>Le second candidat est lsd.</p> <p>Tout comme exa, ce dernier poss\u00e8de les m\u00eames arguments... mais avec des petites icones</p> <p>Personnelement, c'est ce second que je pr\u00e9f\u00e8re car l'affichage est plus adapt\u00e9 pour moi</p>"},{"location":"linux/cli/replace_base_commands/#remplacant-de-du","title":"Remplacant de du","text":"<p>Si comme moi vous vous prenez toujours la t\u00eate avec du pour savoir quel fichier/dossier est le plus, gros, dust est fait pour vous. Disponible sur Linux et Mac, duty affiche simplement les plus gros \u00e9l\u00e9ments et affiche \u00e9galement un visuel, extr\u00eamement pratique</p>"},{"location":"linux/cli/replace_base_commands/#remplacant-de-df","title":"Remplacant de df","text":"<p>df est un outil vieillissant et peu visuel mais suffisant. Cependant, pour un usage domestique et plus visuel, deux outils sont disponibles.</p> <ul> <li>dfc, outil \u00e9crit en C, un tout petit peu plus visuel que df mais     quasiment aussi rapide</li> <li>duf, outil \u00e9crit en Go, plus lent que dfc mais bien plus visuel et     param\u00e9trable</li> </ul>"},{"location":"linux/cli/replace_base_commands/#remplacant-de-find","title":"Remplacant de find","text":"<p>find est un outil tr\u00e8s puissant que nous utilisons tous. Cependant, il existe encore un outil plus puissant se nommant fd. fd nous permet simplement de simples recherches. Par exemple, <code>fd -e md</code> nous permettra de rechercher tous les fichiers du r\u00e9pertoire (et sous-r\u00e9pertoire) courant. De nombreux exemples sont disponibles dans le Github</p>"},{"location":"linux/cli/replace_base_commands/#remplacant-de-cat","title":"Remplacant de cat","text":"<p>Arr\u00eatons d'afficher nos textes avec cat et utilisons son petit fr\u00e8re, bat. Il s'agit d'un logiciel puissant pouvant afficher les num\u00e9ros de lignes, int\u00e9grant une coloration syntaxique pour nos diff\u00e9rents scripts. De plus, si le texte est trop long ou large, pas besoin d'utiliser less, bat l'int\u00e8gre automatiquement. Enfin, d'un simple coup d'oeil, nous pouvons observer la diff\u00e9rence entre notre version et celle que nous avons clone depuis Git car bat se base sur l'index de git pour montrer les modifications.</p>"},{"location":"linux/cli/replace_base_commands/#remplacant-de-grep","title":"Remplacant de grep","text":"<p>ripgrep est un remplacant extr\u00eamement efficace \u00e0 grep. Il est en moyenne 2x plus rapide pour une recherche que grep. ripgrep ignore par d\u00e9faut les fichiers contenu dans le .gitignore. Un tutoriel d\u00e9taill\u00e9 est disponible sur le blog de Burntsushi</p>"},{"location":"linux/cli/replace_base_commands/#bonus","title":"Bonus","text":""},{"location":"linux/cli/replace_base_commands/#remplacant-de-dig","title":"Remplacant de dig","text":"<p>dig est d\u00e9j\u00e0 un excellent outil face \u00e0 nslookup. Cependant, un outil encore plus performant existe, dog. Malheureusement, il n'y a pas d'\u00e9quivalent de dig -x.</p>"},{"location":"linux/cli/replace_base_commands/#remplacant-de-gzip","title":"Remplacant de gzip","text":"<p>Aujourd'hui, j'ai d\u00e9couvert un outil qui s'appelle pigz. Il s'agit tout simplement d'un gzip mais multithread. Nous avons facilement un gain de performance de x3. Un benchmark est disponible</p>"},{"location":"linux/cli/replace_base_commands/#complement-de-mtrtraceroute","title":"Compl\u00e9ment de mtr/traceroute","text":"<p>Trippy est un excellent \u00e0 mtr avec une petite UI sympathique, pas forc\u00e9ment mieux mais tr\u00e8s sympa, \u00e0 voir ici</p>"},{"location":"linux/cli/replace_base_commands/#complement-de-git","title":"Compl\u00e9ment de git","text":"<p>Pour git, il existe un autre outil lightweight et tr\u00e8s sympa : tig permet une visualisation simple de son repository...</p>"},{"location":"linux/cli/replace_base_commands/#alternative-a-rm","title":"Alternative a rm","text":"<p>Si comme moi vous \u00eates du genre \u00e9tourdi et vous supprimez des fichiers que vous ne voulez pas, rip est l\u00e0.</p> <p>Basiquement, le fichier ne va pas \u00eatre supprim\u00e9 mais d\u00e9plac\u00e9 vers un r\u00e9pertoire temporaire. Pratique pour tous les \u00e9tourdis</p>"},{"location":"linux/cli/sed/","title":"Sed","text":"<p>Warning</p> <p>Sur mac, la version de sed par d\u00e9faut est la BSD. Je vous recommande vivement d'installer gnu-sed, disponible via brew</p> <p>sed est une commande aussi complete que puissante. Un article sur cette commande serait beaucoup trop long, je vous conseille d'aller consulter cette excellente documentation</p>"},{"location":"linux/cli/ss/","title":"La commande ss","text":"<p>La commande ss est aujourd'hui le nouveau netstat. netstat \u00e9tant d\u00e9pr\u00e9ci\u00e9 depuis des ann\u00e9es, voici comment l'utiliser :</p>"},{"location":"linux/cli/ss/#lister-toutes-les-connexions","title":"Lister toutes les connexions","text":"<p>Une utilit\u00e9 basique, une commande basique</p> <pre><code>ss | less\n</code></pre> <p>Nous voyons ici toutes les connexion, aussi bien celles bas\u00e9es sur UDP/TCP, que des connexions \u00e0 des sockets UNIX. Cette commande est compl\u00e8te, mais l'est donc trop (Par exemple, nous ne voulons g\u00e9n\u00e9ralement pas voir les connexions \u00e0 des sockets UNIX)</p>"},{"location":"linux/cli/ss/#filtrer-les-connexions-tcp-udp-ou-unix","title":"Filtrer les connexions TCP, UDP ou Unix","text":"<p>Rentrons un peu plus en profondeur dans la commande ss avec les filtres par type de connexion</p> <ul> <li><code>-t</code> ou <code>--tcp</code> : Socket TCP</li> <li><code>-u</code> ou <code>--udp</code> : Socket UDP</li> <li><code>-x</code> ou <code>--unix</code> : Sockets UNIX</li> </ul> <p>Les filtres sont assez explicites. Il existe \u00e9galement 2 autres types de filtres, mais ceux-ci ne sont jamais utilis\u00e9s dans un usage normal :</p> <ul> <li><code>-d</code> ou <code>--dccp</code> : Sockets DCCP</li> <li><code>-w</code> ou <code>--raw</code> : Sockets RAW</li> </ul> <p>Cette option est particuli\u00e8rement utilis\u00e9e avec <code>-a</code> ou <code>--all</code> qui permet de lister toutes les connexions d'un protocole</p> <p>Par exemple, pour lister toutes les connexions TCP :</p> <pre><code>ss -t -a | less\n</code></pre> <p>Par d\u00e9faut (sans l'option -a), seuls les connexions ESTABLISHED sont list\u00e9es (ou CONNECTED pour UDP). (Il s'agit de l'option <code>-l</code> ou <code>--listening</code>)</p>"},{"location":"linux/cli/ss/#afficher-les-numeros-de-port-ne-pas-resoudre-les-ips","title":"Afficher les num\u00e9ros de port / ne pas r\u00e9soudre les IPs","text":"<p>Par d\u00e9faut, il faut savoir que ss convertit les num\u00e9ros de port par le service associ\u00e9 (en se basant sur le fichier /etc/services) mais n'essaie de r\u00e9soudre l'IP par le rDNS associ\u00e9.</p> <p>Il est fort pr\u00e9f\u00e9rable que vous pr\u00e9feriez voir l'IP et le num\u00e9ro de port, plut\u00f4t que le rDNS et le service associ\u00e9 au port.</p> <p>Pour cela, voici l'option :</p> <ul> <li><code>-n</code> ou <code>--numeric</code> : Permet de ne pas r\u00e9soudre les IP et les ports associ\u00e9s aux services</li> </ul> <p>A noter qu'il n'est pas possible de ne pas r\u00e9soudre les adresses IPs ou les num\u00e9ros de ports uniquement, les deux sont li\u00e9s.</p> <p>Pour r\u00e9soudre les adresses IP :</p> <ul> <li><code>-r</code> ou <code>--resolve</code> : Permet de r\u00e9soudre les adresse IPs</li> </ul> <p>Petit exemple en cumulant les param\u00e8tres vu avant</p> <pre><code>ss -s -t -a\n</code></pre>"},{"location":"linux/cli/ss/#afficher-le-nom-du-processus-lie-et-son-pid","title":"Afficher le nom du processus li\u00e9 et son pid","text":"<p>Lister pr\u00e9cis\u00e9ment les connexions n'est pas tr\u00e8s utile si on ne connait pas le pid du programme associ\u00e9. Heureusement, la commande ss \u00e0 pens\u00e9 \u00e0 tout.</p> <ul> <li><code>-p</code> ou <code>--pid</code> : Permet de lister le processus li\u00e9 \u00e0 une connexion</li> </ul> <pre><code>ss -p\n</code></pre>"},{"location":"linux/cli/ss/#afficher-des-statistiques-avec-ss","title":"Afficher des statistiques avec SS","text":"<p>ss sait aussi faire des statistiques des connexions actives sur votre serveur</p> <ul> <li><code>-s</code> ou <code>--summary</code></li> </ul> <pre><code>ss -s\n</code></pre>"},{"location":"linux/cli/ss/#filtrer-les-connexions-par-types","title":"Filtrer les connexions par types","text":"<p>Si vous ne souhaitez voir que les connexions IPv4 ou IPv6 (voir socket), c'est possible avec ss :</p> <ul> <li><code>-f</code> ou <code>--family=...</code></li> </ul> <p>Et voici les types disponibles</p> <ul> <li><code>inet</code></li> <li><code>inet6</code></li> <li><code>link</code></li> <li><code>netlink</code></li> </ul> <p>Voici un exemple d'utilisation</p> <pre><code>ss -a -f inet6 -t -n\n</code></pre> <p>Dans cette example, j'affiche toutes les connexion IPv6 en TCP sans r\u00e9soudre le num\u00e9ro de port</p>"},{"location":"linux/cli/ss/#ss-et-les-filtres","title":"ss et les filtres","text":""},{"location":"linux/cli/ss/#filter-les-etats","title":"Filter les \u00e9tats","text":"<p>Dans ss, il est possible de filtrer leur connexion via leur statut (ESTABLISHED, CLOSED...) de mani\u00e8re extr\u00eamement simple :</p> <pre><code>ss state ESTABLISHED\n</code></pre> <p>Dans cet exemple, j'affiche toutes les connexions ayant ESTABLISHED en \u00e9tat.</p> <p>Voici tous les \u00e9tats support\u00e9s par ss</p> <ul> <li>established</li> <li>syn-sent</li> <li>syn-recv</li> <li>fin-wait-2</li> <li>fin-wait-1</li> <li>time-wait</li> <li>closed</li> <li>close-wait</li> <li>last-ack</li> <li>listen</li> <li>closing</li> </ul> <p>Certains de ces \u00e9tats sont \u00e9galement regroup\u00e9s en '\"cat\u00e9gories'\" :</p> <ul> <li><code>connected</code> = {established'|syn-sent'|syn-recv'|fin-wait-{1,2}'|time-wait'|close-wait'|last-ack'|closing}</li> <li><code>synchronized</code> = {established'|syn-recv'|fin-wait-{1,2}'|time-wait'|close-wait'|last-ack'|closing}</li> <li><code>bucket</code> = {syn-recv'|time-wait}</li> <li><code>big</code> = {established'|syn-sent'|fin-wait-{1,2}'|closed'|close-wait'|last-ack'|listen'|closing}</li> </ul>"},{"location":"linux/cli/ss/#filter-les-ports","title":"Filter les ports","text":"<p>Et enfin, ultime fonctionnalit\u00e9, le filtrage de port, qui permet de s\u00e9lectionner par port source ou destination, par exemple</p> <pre><code>ss -t -n sport eq 1998\n</code></pre> <p>Dans cet exemple, nous voulons voir toutes les connections TCP dont le port source est 1998</p> <p>Il est \u00e9galement possible de faire la m\u00eame commande avec le nom du service</p> <pre><code>ss -nt state ESTABLISHED dst :https\n</code></pre> <p>Ici, nous voulons toutes les connexions TCP ayant l'\u00e9tat ESTABLISHED dont le port destination est HTTPS.</p> <p>Et enfin, il est possible de r\u00e9unir plusieurs conditions avec un <code>AND</code> ou <code>OR</code></p> <pre><code>ss -nt ( dport = :443 or dport = :80 )\n</code></pre> <p>Enfin, nous voulons ici lister toutes les connexions de notre machine vers des sites internet (HTTP ou HTTPS)</p>"},{"location":"linux/cli/ss/#statistiques-avancees-tcp","title":"Statistiques avanc\u00e9es TCP","text":"<p>Une fonctionnalit\u00e9 qui peut \u00eatre \u00e9galement int\u00e9ressante est d'avoir des statistiques avanc\u00e9es concernant les connections TCP avec l'option -i (comme informations), \u00e0 cumuler souvent avec <code>-t</code> pour n'avoir que les sessions TCP.</p> <p>Voil\u00e0 comment une ligne se pr\u00e9sente :</p> <pre><code>root! misc-jd:/home/debian$ ss -4 -tin\nState                        Recv-Q                         Send-Q                                                  Local Address:Port                                                  Peer Address:Port                         Process\nESTAB                        0                              0                                                      95.179.123.231:1234                                                 51.91.123.231:57587\n         bbr wscale:6,10 rto:252 rtt:51.599/2.571 ato:40 mss:1228 pmtu:1500 rcvmss:1095 advmss:1448 cwnd:1484 bytes_sent:3413300 bytes_retrans:1584 bytes_acked:3411716 bytes_received:33889 segs_out:8219 segs_in:6474 data_segs_out:8133 data_segs_in:710 bbr:(bw:97300672bps,mrtt:42.084,pacing_gain:2.88672,cwnd_gain:2.88672) send 282540669bps lastsnd:92 pacing_rate 278070880bps delivery_rate 89216800bps delivered:8120 app_limited busy:42736ms retrans:0/7 dsack_dups:7 reordering:9 reord_seen:320 rcv_space:14600 rcv_ssthresh:42230 minrtt:41.31 rcv_ooopack:3 snd_wnd:3644416\n</code></pre> <p>Vous observez que nous avons ici beaucoup plus d'informations qu'en temps normal, je vais d\u00e9crire les principales :</p> <ul> <li><code>bbr</code> indique ici l'algorythme de congestion TCP que nous utilisons, tel que cubic...</li> <li><code>rto</code> indique (en ms) le timeout avant retransmission du paquet</li> <li><code>rtt:&lt;rtt&gt;/&lt;rttvar&gt;</code></li> <li><code>rtt</code> indique (en ms) la valeur moyenne du (round time trip)</li> <li><code>rttvar</code> est l'\u00e9cart type</li> <li><code>ptmu</code> est la valeur du MTU pour la connection TCP</li> <li><code>mss</code> est la taille maximum du payload d'un paquet (hors ent\u00eate)</li> </ul> <p>Si vous voulez plus d'informations sur ss, n'h\u00e9sitez pas \u00e0 consulter le wiki Archlinux ou directement dman7.org</p>"},{"location":"linux/cli/tmux/","title":"TMUX Multiplexeur de Shell","text":""},{"location":"linux/cli/tmux/#explication","title":"Explication","text":"<p>TMUX est un multiplexeur de shell permettant de lancer une multitude de fen\u00eatre dans une seule, de cr\u00e9er plusieurs instances...</p> <p>En terme de workflow, tmux permet un gain de productivit\u00e9 incroyable.</p> <p>Nous verrons en bonus tmux_xpanes qui permet d'automatiser encore plus les taches tmux</p>"},{"location":"linux/cli/tmux/#installation","title":"Installation","text":"<p>On update les d\u00e9pots &amp; on installe notre package</p> <pre><code>apt update &amp;&amp; apt install tmux\n</code></pre>"},{"location":"linux/cli/tmux/#shortcuts","title":"Shortcuts","text":"<p>De base, lorsque nous lan\u00e7ons tmux, nous avons une simple fen\u00eatre, avec une bar de statut en bas :</p> <p></p> <p>Puis nous pouvons faire une multitude de choses sur cette simple fen\u00eatre</p> <ul> <li>Split horizontal : <code>CTRL+B %</code></li> <li>Split horizontal : <code>CTRL+B \"</code></li> </ul> <p>Heureusement, nous avons des repository git qui ont une bonne configuration de base</p>"},{"location":"linux/cli/tmux/#bonus","title":"Bonus","text":"<p>Il existe un utilitaire qui permet de lancer un batch d'action, nomer tmux-xpanes</p> <p>Mon utilisation la plus courante de tmux-xpanes est pour ouvrir un batch de sessions SSH par rapport a un nom commun.Je l'utilise souvent coupl\u00e9 a un inventaire ansible</p> <p>J'utilise un alias csshx</p> <pre><code>csshx='tmux-xpanes --ssh'\n</code></pre> <p>Et enfin, voici le grep pour lancer le batch de sessions SSH :</p> <pre><code>csshx $(grep kafka- inventory|sed \"s/://g\")\n</code></pre> <p>Avec cet alias, je lance automatiquement une connexion ssh aux serveurs nomm\u00e9s kafka- de mon inventiare ansible.</p>"},{"location":"linux/cli/tmux/#vim","title":"Vim","text":"<pre><code>    set ttymouse=xterm2\n    set mouse=a\n</code></pre> <p>Morceau de code dans le .vimrc afin d'activer la souris dans vim</p>"},{"location":"linux/cli/git/git/","title":"Apprendre \u00e0 se servir de git","text":""},{"location":"linux/cli/git/git/#commandes-utiles","title":"Commandes utiles","text":"<pre><code>git push origin --delete branch_name\n</code></pre> <p>Delete la branche distante branch_name</p> <pre><code>git diff --name-only HEAD HEAD~1\n</code></pre> <p>Retrouver le nom des derniers fichiers commit</p> <pre><code>git remote set-url origin https://github.com/USERNAME/REPOSITORY.git\n</code></pre> <p>Change l'URL distante</p> <pre><code>git clean -d -fx .\n</code></pre> <p>Supprimer les fichiers non track\u00e9s inclus dans le gitignore</p> <pre><code>for BR in $(git branch --all --merged |grep -v $(git symbolic-ref refs/remotes/origin/HEAD | sed 's@^refs/remotes/origin/@@')) ; do\n    git push origin --delete \"${BR#remotes/origin/}\"\ndone\n</code></pre> <p>Supprimer sur le repo distant toutes les branches d\u00e9ja merged</p>"},{"location":"linux/cli/git/git/#gitconfig","title":".gitconfig","text":"<p>Afin d'\u00eatre ind\u00e9pendant de tout environnement (ohmyzsh ou autre), j'ai d\u00e9cid\u00e9 d'utiliser les alias du .gitconfig disponible sur github</p> <p>3 binaires sont n\u00e9cessaires :</p> <ul> <li><code>diff-so-fancy</code> afin d'avoir un meilleur diff</li> <li><code>giturl</code> qui est une Gem Ruby afin d'ouvrir dans le navigateur     l'URL du repository Git</li> <li><code>git-quick-stats</code> pour extraire les stats simplement d'un repository</li> </ul>"},{"location":"linux/cli/git/rework_files/","title":"R\u00e9duire la taille de son repository Git","text":"<p>J'\u00e9tais entrain de modifier un script bash puis m'est venu l'envie de voir la taille du repository</p> <pre><code>root~ du -sh myscripts\n242M    myscripts\n</code></pre> <p>Il s'agit d'un repository ne comprenant uniquement des scripts, je ne comprenais pas ce qui prenait tant de place...</p> <pre><code>root~ du -sh myscripts\n880K    dedicated\n 28K    img\n</code></pre> <p>Toujours rien, mais o\u00f9 sont donc cach\u00e9s ces 242MB...</p> <pre><code>root~ du -sh myscripts\n8.0K    .DS_Store\n241M    .git\n4.0K    .gitignore\n</code></pre> <p>242MB de .git pour un repository qui a moins de 5MB de scripts... J'ai donc compris qu'un fichier binaire devait trainer dans les commits et qui n'aurait peut \u00eatre pas du \u00eatre commit. C'est \u00e0 partir de maintenant que l'on s'amuse.</p> <p>La premi\u00e8re \u00e9tape est donc de lister les diff\u00e9rents fichiers dans les diff\u00e9rents commits. Plusieurs mani\u00e8res sont possibles, je pr\u00e9f\u00e8re la mani\u00e8re native \u00e0 git, sans surplus \u00e0 installer</p> <pre><code>root~ git rev-list --objects --all \\\n| git cat-file --batch-check='%(objecttype) %(objectname) %(objectsize) %(rest)' \\\n| awk '/^blob/ {print substr($0,6)}' \\\n| sort --numeric-sort --key=2 \\\n| cut --complement --characters=13-40 \\\n| numfmt --field=2 --to=iec-i --suffix=B --padding=7 --round=nearest \\\n| tac \\\n| head -5\nb4dfc33c1df6  149MiB my/path1/rescue.gz\n14a488d39e0c   51MiB my/path2/jessie.gz\nbf6f5aeda4b0   40MiB my/path3/wheezy.gz\nbd49a5cf67a5   19KiB live/generic/file.a\nc2959ad02037   11KiB ceph/profile\n</code></pre> <p>Il existe un plugin git qui va nous sortir concr\u00eatement le m\u00eame genre de r\u00e9sultat</p> <pre><code>root~ git filter-repo --analyze --report-dir=Analyze\nProcessed 44500 blob sizes\nProcessed 20392 commits\nWriting reports to Analyze...done.\n</code></pre> <p>On regarde le fichier <code>Analyze/blob-shas-and-paths.txt</code> pour voir ce qui nous prend toute la place</p> <p>Les 3 premiers fichiers occupent donc une grande majorit\u00e9 de notre repository, sans que ceux-ci ne nous soit utiles... Nous pouvons donc \u00e9conomiser pr\u00e8s de 99% d'espace.</p> <p>Pour les supprimer</p> <pre><code>~root git:(master) git filter-branch --force --index-filter \\\n  'git rm --cached --ignore-unmatch  my/path1/rescue.gz' \\\n  --prune-empty --tag-name-filter cat -- --all\nProceeding with filter-branch...\n\nRewrite 24aeb26df8b58d590dbf4c44c68ea651c85bbf8d (4/245) (0 seconds passed, remaining 0 predicted)    rm ' my/path1/rescue.gz'\nRewrite 31820d367600be9061a9f9924393bc1ab1ae2025 (5/245) (0 seconds passed, remaining 0 predicted)    rm ' my/path1/rescue.gz'\nRewrite 716fc2741bc354bc257ab9ae17b5165374e64408 (6/245) (0 seconds passed, remaining 0 predicted)    rm ' my/path1/rescue.gz'\nRewrite a31edc1ee2988ff567703886e3bca02482ace23a (235/245) (15 seconds passed, remaining 0 predicted)\nRef 'refs/heads/master' was rewritten\nRef 'refs/remotes/origin/master' was rewritten\nWARNING: Ref 'refs/remotes/origin/master' is unchanged\nRef 'refs/stash' was rewritten\n</code></pre> <p>Une fois que nous avons supprim\u00e9 les diff\u00e9rents fichiers, on va r\u00e9\u00e9crire les logs afin de supprimer toute occurence de ces fichiers qui ne sont plus dans aucun commit</p> <pre><code>root~ rm -rf .git/refs/original/\ngit reflog expire --expire=now --all\ngit gc --prune=now\ngit gc --aggressive --prune=now\n</code></pre> <p>Une fois cette derni\u00e8re \u00e9tape faites... tadam</p> <pre><code>root~ du -sh myscripts\n1.5M    myscripts\n</code></pre> <p>En supprimant ces gros fichiers binaires, nous sommes pass\u00e9s de 242MB \u00e0 1.5MB ! ;)</p>"},{"location":"linux/elasticsearch/log_slow_queries/","title":"Log des slow queries de ElasticSearch","text":"<p>Dans une optique d'optimisation des performances, il est int\u00e9ressant de log les slow queries afin de les optimiser si possible. Par d\u00e9faut, rien n'est log :(</p> <p>Les options sont propres \u00e0 chaque index.</p> <p>Il faut d'abord lister les index :</p> <pre><code>curl 127.0.0.1:9200/_cat/indices\ngreen open insee_and_postal_codes                      qA2bya4sRpu4WHlK3W5jgA 5 0   35856      0  21.9mb  21.9mb\ngreen open x_images_20210402185809                     oAY_xCe0QjqMhpKg6WTcCg 5 0  103208     97  52.3mb  52.3mb\ngreen open x_search_results_20210402185209             ouWAT_bBQKOPVNqXhumCGA 5 0 1584142 169124 972.3mb 972.3mb\n</code></pre> <p>Puis on applique les seuils que l'on veut :</p> <pre><code>curl -X PUT \"localhost:9200/x_search_results_20210402185209/_settings?pretty\" -H Content-Type: application/json -d\n{\n  \"index.search.slowlog.threshold.query.warn\": \"3s\",\n  \"index.search.slowlog.threshold.query.info\": \"1s\",\n  \"index.search.slowlog.threshold.query.debug\": \"2s\",\n  \"index.search.slowlog.threshold.query.trace\": \"500ms\",\n  \"index.search.slowlog.threshold.fetch.warn\": \"1s\",\n  \"index.search.slowlog.threshold.fetch.info\": \"800ms\",\n  \"index.search.slowlog.threshold.fetch.debug\": \"500ms\",\n  \"index.search.slowlog.threshold.fetch.trace\": \"200ms\"\n}\n</code></pre> <p>Les logs seront dans /var/log/elasticsearch/ et les options propres aux slowlog dans le fichier log4j2.properties</p>"},{"location":"linux/fundamentals/base_commands/","title":"Rappel des commandes de base","text":"<p>Linux est un syst\u00e8me incroyable, malheureusement complexe pour les n\u00e9ophytes. Dans cet article, nous allons voir les commandes de base que vous devez maitriser. Dans ce wiki, vous avez de nombreuses pages vous permettant de rentrer dans les entrailles de GNU/Linux</p>"},{"location":"linux/fundamentals/base_commands/#dossiers","title":"Dossiers","text":"<p><code>mkdir &lt;dir&gt;</code> : make directory</p> <p><code>rmdir &lt;dir&gt;</code> : remove directory</p> <p><code>pwd &lt;dir&gt;</code> : print working directory : Permet d'afficher le r\u00e9pertoire courant</p> <p><code>ls &lt;dir|file&gt;</code> : list sorted : Permet de lister les \u00e9l\u00e9ments d'un dossier</p> <ul> <li>-a : Affiche les dossiers cach\u00e9s</li> <li>-l : Affichages d\u00e9taill\u00e9</li> <li>-r : Affichage invers\u00e9</li> <li>-t : Du plus r\u00e9cent au plus ancien</li> <li>-S : Date d\u00e9croissante</li> </ul> <p><code>cd &lt;dir&gt;</code> : change directory : Permet de se d\u00e9placer dans les r\u00e9pertoires</p>"},{"location":"linux/fundamentals/base_commands/#fichiers","title":"Fichiers","text":"<p><code>ln &lt;src&gt; &lt;dst&gt;</code> : link : Permet de cr\u00e9er un lien entre deux fichiers</p> <ul> <li>-s : Lien symoblique (A la place d'un lien '\"dur'\" (hardlink))</li> </ul> <p><code>touch &lt;file&gt;</code> : Met \u00e0 jour l'heurodatage ou cr\u00e9\u00e9 le document si celui-ci n'existe pas</p> <p><code>type &lt;file&gt;</code> : Permet de trouver le chemin d'un binaire ainsi que son type</p> <p><code>diff &lt;file1&gt; &lt;file2&gt;</code>: Diff\u00e9rence entre 2 fichiers</p> <p><code>file &lt;file&gt;</code> : Permet de d\u00e9terminer le type d'un fichier</p> <ul> <li>-i : Permet de connaitre le type MIME d'un fichier</li> </ul> <p><code>cp &lt;src&gt; &lt;dst&gt;</code> : copy</p> <ul> <li>-v : Affiche les informations en mode verbose</li> <li>-r : Copie r\u00e9cursivement</li> <li>-L : Permet de suivre les liens symboliques</li> </ul> <p><code>mv &lt;src&gt; &lt;dst&gt;</code> : move</p> <ul> <li>-v : Affiche les informations en mode verbose</li> <li>-i : Mode interactif</li> <li>-n : Ne pas \u00e9craser si le fichier existe d\u00e9j\u00e0</li> </ul> <p><code>rm &lt;file'|dir&gt;</code> : remove</p> <ul> <li>-R : Remove recursivement (Pour des dossiers non vides)</li> <li>-v : Affiche les infos d\u00e9taill\u00e9es</li> </ul>"},{"location":"linux/fundamentals/base_commands/#droits","title":"Droits","text":"<p><code>chmod &lt;xyz&gt; &lt;file'|directory&gt;</code> : change file mode bits</p> <p></p> <ul> <li>x correspond aux droits pour le propri\u00e9taire</li> <li>y les droits du groupe</li> <li>et z les droits pour tous les autres</li> <li>-R pour changer les droits r\u00e9cursivement</li> </ul> <p><code>chown &lt;user:group&gt; &lt;file&gt;</code> : change owner</p> <ul> <li>-R pour changer les propri\u00e9taires r\u00e9cursivement</li> </ul> <p><code>umask &lt;xxx&gt;</code> : (user file creation mode mask) Droits sur les nouveaux fichiers</p> <ul> <li>Par d\u00e9faut, l'umask est de 022 (777-022 =&gt; Les fichiers seront     cr\u00e9\u00e9s en 755)</li> </ul>"},{"location":"linux/fundamentals/base_commands/#misc","title":"Misc","text":"<p><code>ssh &lt;ndd|ip&gt;</code> : secure shell</p> <ul> <li>-p : Permet de sp\u00e9cifier le port</li> </ul> <p><code>scp</code> : secure copy</p> <p><code>rsync</code> : remote sync</p> <p><code>sed</code> : stream editor</p> <p><code>grep</code> : Permet de rechercher un motif dans un document</p> <ul> <li>-v : Inverse les r\u00e9sultats</li> <li>-i : Ignore la casse</li> <li>-c : Compte le nombre d'occurence qui correspondent \u00e0 la regex</li> <li>-R : Recherche recursivement</li> <li>-n : Affiche le num\u00e9ro de lignes</li> </ul> <p><code>find</code> : Permet de rechercher un fichier (article complet)</p> <p><code>less/more</code> :</p> <p><code>wc</code> : word count</p> <ul> <li>-l : Line</li> <li>-w : Word</li> <li>-c : chars</li> </ul> <p><code>cut</code> :</p> <ul> <li>-d : Delimiteur</li> <li>-f : Champs</li> </ul> <p><code>head &lt;filename&gt;</code> : Affiche les premi\u00e8res lignes d'un fichier (Par d\u00e9faut, affiche les 10 premi\u00e8res lignes)</p> <ul> <li>-n : Permet de sp\u00e9cifier le nombre de lignes (Ex: -n5 pour les 5 premi\u00e8res lignes)</li> </ul> <p><code>tail/less</code> :</p>"},{"location":"linux/fundamentals/base_commands/#espace-disque","title":"Espace disque","text":"<p><code>df</code> : disk free : Affiche l'espace restant dans les partitions</p> <ul> <li>-h : Affiche de mani\u00e8re compr\u00e9hensible l'espace restant</li> </ul> <p><code>du</code> : disk usage : Affiche l'utilisation d'un dossier</p> <ul> <li>-sh : Affiche la taille du dossier</li> <li>-hc '--max-depth=1 : Affiche la taille des dossiers comme des     fichiers dans le r\u00e9pertoire courant</li> </ul>"},{"location":"linux/fundamentals/base_commands/#gestion-des-processus","title":"Gestion des processus","text":"<p><code>top</code> : Affiche les processus Linux</p> <ul> <li>k puis pid : Permet de kill un processus sp\u00e9cifique</li> <li>q : Quitter top</li> </ul> <p>free : Affiche les informations sur la RAM/Swap</p> <ul> <li>-m : Affiche la m\u00e9moire en MB</li> <li>-h : Lisible par un humain (Affichage plus compr\u00e9hensible)</li> <li>-t : Ajoute une ligne additionnant SWAP + RAM</li> <li>-s : Permet de pr\u00e9ciser un intervalle de refresh (en secondes)</li> </ul> <p><code>ps</code> : process status</p> <ul> <li>aux : Montrer tous les processus de tous les utilisateurs</li> <li>f : Formate l'affichage sous forme d'arbre</li> </ul> <p><code>pstree</code> : process status tree</p> <ul> <li>-p : Affiche les processus</li> </ul> <p><code>kill &lt;pid&gt;</code> : Tue un processus (via son PID)</p> <ul> <li>kill 9 permet de forcer le kill d'un processus (A utiliser en     dernier recours)</li> </ul> <p><code>killall &lt;processus_name&gt;</code> : Tue un processus (via son nom)</p>"},{"location":"linux/fundamentals/cron/","title":"Rappel sur le cron","text":"<p>Warning</p> <p>SystemD a introduit un nouveau type de cron d\u00e9nomm\u00e9s les \"timers\", ils permettent un meilleur suivi ainsi qu'une granularit\u00e9 plus fine. Il en va donc de bonne pratique de pr\u00e9ferer les timers aux crons</p> <p>La fonctionnalit\u00e9 cron a \u00e9t\u00e9 d\u00e9velopp\u00e9e afin de pouvoir automatiser certaines t\u00e2ches.</p> <p>Les t\u00e2ches planifi\u00e9es peuvent \u00eatre lanc\u00e9es en tant qu'utilisateur standard. Nous g\u00e9rons la plupart des t\u00e2che cron via la commande crontab. D'autres scripts peuvent \u00eatre directement d\u00e9ploy\u00e9s dans certains dossiers '\"sp\u00e9ciaux'\"</p>"},{"location":"linux/fundamentals/cron/#la-commande-crontab","title":"La commande crontab","text":"<pre><code>crontab -e\n</code></pre> <p>Nous permet d'\u00e9diter les t\u00e2ches cron pour l'user courant</p> <pre><code>crontab -l\n</code></pre> <p>Nous permet de lister les t\u00e2ches cron pour l'utilisateur courant</p> <pre><code>crontab -l -u www-data\n</code></pre> <p>Nous permet de lister les t\u00e2ches cron pour l'utilisateur www-data. Nous pouvons \u00e9galement appliquer le param\u00e8tre -u pour \u00e9diter la liste des cron.</p> <p>Tous les crons des utilisateurs sont stock\u00e9s dans /var/spool/cron/crontabs</p>"},{"location":"linux/fundamentals/cron/#dossiers-dedies-a-cron","title":"Dossiers d\u00e9di\u00e9s \u00e0 cron","text":"<p>Si vous souhaitez d\u00e9ployez un script une fois/jour sans importance d'heure, alors nous pouvons passer par certains dossiers d\u00e9di\u00e9s.</p> <pre><code>/etc/\n  |----- cron.d/\n  |----- cron.hourly/\n  |----- cron.daily/\n  |----- cron.monthly/\n  |----- cron.weekly/\n  |----- crontab\n</code></pre> <p>Par exemple, comme vous vous en doutez, si vous souhaitez avoir un script qui est ex\u00e9cut\u00e9e toutes les heures, alors vous pouvez le d\u00e9clarer dans ce dossier.</p>"},{"location":"linux/fundamentals/cron/#variable-cron","title":"Variable cron","text":"<p>Une fonctionnalit\u00e9 de cron tr\u00e8s pratique est l'envoie de mail du r\u00e9sultat du cron. Si vous d\u00e9finissez la variable MAILTO, alors le mail sera envoy\u00e9 \u00e0 cet utilisateur/son alias</p>"},{"location":"linux/fundamentals/cron/#divers","title":"Divers","text":"<p>Le site crontab.guru nous permet de voir visuellement \u00e0 quel moment une t\u00e2che va se d\u00e9clencher sans avoir \u00e0 r\u00e9fl\u00e9chir. Toutes les r\u00e8gles cron pour tous les utilisateurs sont accessibles dans le dossier /var/spool/cron</p>"},{"location":"linux/fundamentals/curl/","title":"cURL: La commande \u00e0 tout faire","text":"<ul> <li>cURL d\u00e9taill\u00e9</li> </ul> <pre><code>curl -I -v --trace-time https://www.google.com\n</code></pre>"},{"location":"linux/fundamentals/curl/#bonus","title":"BONUS","text":""},{"location":"linux/fundamentals/curl/#curl-detaille","title":"cURL d\u00e9taill\u00e9","text":"<p>Nous pouvons personnaliser l'output de cURL pour avoir des d\u00e9tails extr\u00eamements int\u00e9ressants tels que le temps de r\u00e9solution DNS, de n\u00e9gociation TLS...</p> <p>Nous utilisons pour cela un fichier qui sera un template :</p> <pre><code>Fichier:\n    time_namelookup:  %{time_namelookup}\\n\n       time_connect:  %{time_connect}\\n\n    time_appconnect:  %{time_appconnect}\\n\n   time_pretransfer:  %{time_pretransfer}\\n\n      time_redirect:  %{time_redirect}\\n\n time_starttransfer:  %{time_starttransfer}\\n\n                    ----------\\n\n         time_total:  %{time_total}\\n\n</code></pre> <p>Et enfin, nous l'appelons :</p> <pre><code>curl -w \"@curl-format.txt\" -o /dev/null -s \"https://wiki.jdelgado.fr\"\n    time_namelookup:  0,015000\n       time_connect:  0,057639\n    time_appconnect:  0,239148\n   time_pretransfer:  0,239948\n      time_redirect:  0,000000\n time_starttransfer:  0,281632\n                    ----------\n         time_total:  0,281707\n</code></pre> <p>Il est \u00e9galement possible d'avoir le retour de la commande cURL en JSON, tr\u00e8s facile \u00e0 parser</p> <pre><code>curl --write-out %{json} https://google.com -o saved\n</code></pre> <p>Toutes les options de '--write-out sont disponibles ici</p>"},{"location":"linux/fundamentals/curl/#details-crt","title":"D\u00e9tails CRT","text":"<p>On peut avoir quelques d\u00e9tails sur le CRT en utilisant cURL et un peu de magie :</p> <pre><code>\u03bb Jeremy ~ \u2192 curl -vvI https://wiki.jdelgado.fr 2&gt;&amp;1 | awk BEGIN { cert=0 } /^'* Server certificate:/ { cert=1 } /^'*/ { if (cert) print }\n* Server certificate:\n*  subject: CN=*.jdelgado.fr\n*  start date: Mar 21 03:47:50 2021 GMT\n*  expire date: Jun 19 03:47:50 2021 GMT\n*  subjectAltName: host \"wiki.jdelgado.fr\" matched certs \"*.jdelgado.fr\"\n*  issuer: C=US; O=Lets Encrypt; CN=R3\n*  SSL certificate verify ok.\n* Using HTTP2, server supports multi-use\n* Connection state changed (HTTP/2 confirmed)\n* Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0\n* Using Stream ID: 1 (easy handle 0x7f845200ca00)\n* Connection state changed (MAX_CONCURRENT_STREAMS == 250)!\n* Connection #0 to host wiki.jdelgado.fr left intact\n* Closing connection 0\n</code></pre>"},{"location":"linux/fundamentals/vim/","title":"VIM: L'editeur de texte de la mort","text":"<p>Dans cet article, nous allons voir tous les raccourcis, afin d'utiliser au mieux vim (En illustration, voici un screenshot de mon interface de vim)</p>"},{"location":"linux/fundamentals/vim/#raccourcis","title":"Raccourcis","text":""},{"location":"linux/fundamentals/vim/#fenetres","title":"Fen\u00eatres","text":"<ul> <li>Nouvelle fen\u00eatre :</li> <li><code>Ctrl W + V</code> : Verticale Fen\u00eatre</li> <li><code>Ctrl W + N</code> : Horizontale Fen\u00eatre</li> <li>Pour switch de fen\u00eatre : <code>W + Fl\u00e8che</code></li> <li><code>Ctrl F</code> : Descend d'un \u00e9cran</li> <li><code>Ctrl B</code> : Monte d'un \u00e9cran</li> </ul>"},{"location":"linux/fundamentals/vim/#texte","title":"Texte","text":"<ul> <li><code>c i</code> : Pour remove le contenu d'une parenth\u00e8se... (Change     Inside)</li> <li><code>d s (</code> : Remove des parenth\u00e8se... :</li> <li><code>%s/search/replace/g</code> : Pour sed un fichier</li> <li><code>F2, paste normal, puis F2</code> : Pour coller un texte <code>sans probl\u00e8me     de tab</code></li> <li><code>daw</code> : Supprime le mot courant (Delete a Word)</li> <li><code>das</code> : Supprime tout un bloc de texte tant qu'il n'y a aucun     saut de ligne</li> <li><code>R</code> : Pour remplacer du texte :</li> <li><code>J</code> : Pour joindre 2 lignes</li> <li><code>g U</code> : Pour passer du texter en uppercase</li> <li><code>g u</code> : Pour passer du texter en lowercase</li> </ul>"},{"location":"linux/fundamentals/vim/#copiedelete","title":"Copie/Delete","text":"<ul> <li><code>yy</code> ou <code>Y</code> : Copier une ligne</li> <li><code>v</code> : Permet de passer en mode visuel pour s\u00e9lectionner plusieurs     lignes</li> <li><code>dd</code> : Delete une ligne</li> <li><code>cw</code> : Delete un mot</li> <li><code>p</code> : Copier apr\u00e8s la ligne courante</li> <li><code>P</code> : Copier avant la ligne courante</li> </ul> <p>https://jordanelver.co.uk/blog/2014/03/12/sorting-columnds-of-text-in-vim-using-sort/ Faire des colonnes propres</p>"},{"location":"linux/fundamentals/vim/#misc","title":"Misc","text":"<ul> <li><code>'&lt;</code> : Diminiue la tab</li> <li><code>'&gt;</code> : Augmente la tab</li> <li><code>:r!ls :</code> Permet d'importer le r\u00e9sultat de la commande ls dans le     document actuel</li> <li><code>:!r&lt;filename&gt;</code> : Importe ' dans le document actuel <li><code>:!ls</code> : Permet de faire la commande ls depuis vim</li> <li><code>:!php -l %</code> : Permet d'ex\u00e9cuter un check syntax sur le document     actuel</li> <li> <p><code>:vs</code> : Editer le m\u00eame fichier sur 2 colonnes</p> </li> <li> <p><code>G</code> : Pour aller tout en bas d'un fichier</p> </li> <li> <p><code>Ctrl-P</code> : Liste des fichiers + Ouvrir</p> </li> <li> <p><code>gf</code> : Ouvre le lien du fichier</p> </li> <li><code>Ctrl-o</code> : Revenir au fichier original</li> <li><code>gx</code> : Ouvre le lien vers un browser</li> <li><code>gd</code> : D\u00e9claration locale d'une variable/fonction</li> <li> <p><code>gD</code> : D\u00e9claration globale d'une variable/fonction</p> </li> <li> <p><code>Ctrl a</code> : Incr\u00e9menter un chiffre</p> </li> <li><code>Ctrl x</code> : D\u00e9cr\u00e9menter un chiffre</li>"},{"location":"linux/fundamentals/vim/#plugins","title":"Plugins","text":"<ul> <li><code>tpope/vim-surround</code> : cs'\"' : Change les <code>'\"</code> en <code>'</code></li> </ul>"},{"location":"linux/fundamentals/vim/#configuration","title":"Configuration","text":"<p>Pour la configuration, tous mes fichiers sont disponibles sur mon GitHub (Repository)</p> <p>Pour installer ma configuration, rien de plus simple, il vous suffit d'avoir un environnement UNIX/BSD :</p> <pre><code>curl https://raw.githubusercontent.com/PixiBixi/dotfiles/master/init.sh | bash\n</code></pre> <p>Et voil\u00e0, vous avez avec ma configuration</p>"},{"location":"linux/hosting/dns/","title":"Installer son NS ainsi que son resolveur DNS via BIND9","text":""},{"location":"linux/hosting/dns/#introduction","title":"Introduction","text":"<p>Afin de se s\u00e9parer au maximum des services propos\u00e9s par diff\u00e9rents tiers, il est possible d'installer son propre resolveur DNS, ainsi que de param\u00e9trer son serveur DNS (Ici BIND9) afin d'avoir ses propre serveurs autoritaires.</p> <p>[Ne pas oublier DHCPD pour les DNS (CF Article Bortz)]{.underline}</p>"},{"location":"linux/hosting/dns/#comment-fonctionne-un-ns","title":"Comment fonctionne un NS","text":"<p>Un NS est un enregistrement DNS afin d'avoir son propre autoritaire : Prenons l'exemple avec ce nom de domaine : wiki.jdelgado.fr.</p> <ol> <li>Tout d'abord, nous allons int\u00e9rroger les root servers, par     exemple g.root-servers.net</li> <li>Ce serveur nous indique le serveur \u00e0 contacter, ici, les serveurs     autoritaires du TLD .eu : x.dns.eu</li> <li>Ces serveurs nous disent quel serveur autoritaires du nom de     domaine, dans notre cas, ns1.jdelgado.fr</li> <li>Et enfin, nous obtenons enfin l'IP du serveur.</li> </ol> <p>Le serveur que nous allons installer correspond \u00e0 l'\u00e9tape 3</p>"},{"location":"linux/hosting/dns/#comment-fonctionne-un-resolveur-dns","title":"Comment fonctionne un resolveur DNS","text":"<p>Un Resolveur DNS agit d'une mani\u00e8re extremement simple : Il va simplement r\u00e9soudre n'importe quel nom de domaine que vous cherchez, et retourner son adresse IP.</p> <p>Un des int\u00e9rets \u00e0 avoir son propre resolveur DNS est d'\u00e9vit\u00e9 le DNS Hijacking, c'est \u00e0 dire de modifier la r\u00e9solution DNS. Exemple flagrant avec le nom de domaine t411.io.</p> <p>Un autre int\u00e9ret \u00e0 avoir son propre resolveur DNS est d'\u00e9viter l'espionnage de notre FAI ou autre.</p> <p>Si vous voulez tout de m\u00eame \u00e9viter le flicage, mais que vous n'avez les comp\u00e9tences, ou tout simplement l'envie, il existe des projets tel que OpenNIC qui vous indique le resolveur DNS libre le plus proche de chez vous, pour ainsi minimiser le ping, et donc le temps de r\u00e9solution DNS. Il y a \u00e9galement le projet DNS Watch qui est un r\u00e9solveur libre IPV4/IPV6 sans log et qui supporte le DNSSEC.</p>"},{"location":"linux/hosting/dns/#installation","title":"Installation","text":""},{"location":"linux/hosting/dns/#resolveur-dns","title":"R\u00e9solveur DNS","text":"<p>De base, BIND9 est correctement configur\u00e9 afin de r\u00e9soudre les noms de domaine sur vos interfaces locales, soit <code>127.0.0.1, ::1</code> si vous disposez d'IPv6, et enfin, votre IP locale fournie par le DHCP de votre, soit <code>192.168.1.2</code> par exemple.</p> <p>Nous verrons par la suite comment le configurer.</p> <p>Afin qu'il r\u00e9solve les requ\u00eates DNS sur votre ordinateur locale, voici la ligne \u00e0 \u00e9crire :</p> <pre><code>apt-get -y install bind9\n</code></pre> <p>Pour \u00eatre certain que votre BIND9 soit bien install\u00e9, <code>dig +short google.fr</code> doit vous renvoyez une IP appartenant \u00e0 Google.</p> <p>Dans le dossier de configuration BIND9, vous y retrouverez 4 fichiers de configuration :</p> <ul> <li><code>named.conf</code> recense tous les fichiers de configuration. Au lieu     d'\u00e9crire la configuration dans un seul fichier, celle-ci est     partag\u00e9e en plusieurs fichiers.</li> <li><code>named.conf.default-zones</code> est un fichier contenant toutes les     zones par d\u00e9faut, comme son nom l'indique.</li> <li><code>named.conf.local</code> est vide par d\u00e9faut, et c'est normal, il     s'agit du fichier o\u00f9 l'on effectuera toutes nos modifications</li> <li><code>named.conf.options</code> est le configuration de base par d\u00e9faut, il     contient toutes les options n\u00e9c\u00e9ssaires pour bien param\u00e9trer notre     BIND9</li> </ul> <p>N'oubliez pas d'editer votre <code>resolv.conf</code> sous un syst\u00e8me UNIX afin d'utiliser votre resolveur, ou bien vos param\u00e8tres de votre carte r\u00e9seau sous Windows</p>"},{"location":"linux/hosting/dns/#serveur-autoritaire","title":"Serveur autoritaire","text":"<p>Un serveur autoritaire est un serveur faisant \"autorit\u00e9\" sur une zone donn\u00e9e. Celui-ci permet de toutes les redirections n\u00e9c\u00e9ssaires (MX, A, CNAME...)</p> <p>G\u00e9n\u00e9ralement, votre registrar fait \u00e9galement serveur DNS, mais il s'agit tr\u00e8s souvent d'une usine \u00e0 gaz, lorsqu'un simple BIND fait l'affaire, et est tr\u00e8s simple \u00e0 mettre en oeuvre</p> <p>Tout d'abord, il vous faudra mettre \u00e0 jour votre liste de NS sur votre registrar, par exemple, pour mon cas :</p> <p></p> <p>Ici, nous disons \u00e0 notre registrar que notre serveur autoritaire sera <code>ns1.jdelgado.fr</code> soit <code>195.154.226.173</code></p> <p>Repassons d\u00e9sormais \u00e0 notre BIND9, et regardons les fichiers \u00e0 \u00e9diter</p>"},{"location":"linux/hosting/dns/#namedconflocal","title":"named.conf.local","text":"<p>Dans ce fichier, nous allons ajouter la zone \u00e0 g\u00e9rer par BIND9. Voici un exemple de zone \u00e0 rajouter au fichier</p> <pre><code>zone \"jdelgado.fr\" IN {\n\n        # Zone de type ma\u00eetre\n        type master;\n\n        # Fichier de zone\n        file \"/etc/bind/jdelgado.fr/db.jdelgado.fr\";\n\n        # On autorise le transfert de la zone aux serveurs DNS secondaires (Slaves)\n        allow-transfer { 217.70.177.40; 213.186.33.199; 173.245.58.105; 173.245.59.150; 8.8.8.8; 8.8.4.4; };\n\n        # On autorise tout le monde \u00e0 envoyer des requ\u00eates vers cette zone\n        allow-query { any; };\n\n        # Pr\u00e9venir les serveurs DNS secondaires quun changement a \u00e9t\u00e9 effectu\u00e9 dans la zone ma\u00eetre\n        notify yes;\n\n};\n</code></pre> <p>Au final, ce fichier comporte assez peu d'instructions, je vous invite \u00e0 aller regarder les commentaires afin de savoir \u00e0 quoi correspondent chacunes d'entrent-elles</p> <p>Au final, ce fichier comporte assez peu d'instructions, je vous invite \u00e0 aller regarder les commentaires afin de savoir \u00e0 quoi correspondent chacunes d'entrent-elles</p>"},{"location":"linux/hosting/dns/#namedconf","title":"named.conf","text":"<p>Nous ajoutons un include dans ce fichier, afin de pouvoir faire des logs corrects, au lieu de tout log dans syslog par d\u00e9faut</p> <pre><code>include \"/etc/bind/named.conf.logging\";\n</code></pre>"},{"location":"linux/hosting/dns/#namedconflogging","title":"named.conf.logging","text":"<p>Et voici le fichier de logging : named.conf.logging</p> <pre><code>logging {\n    channel security_file {\n        file \"/var/log/bind/security.log\" versions 3 size 30m;\n        severity dynamic;\n    };\n\n    channel b_query {\n        file \"/var/log/bind/query.log\" versions 2 size 10m;\n        severity info;\n    };\n\n    channel general_file {\n        file \"/var/log/bind/general.log\" versions 3 size 5m;\n        severity dynamic;\n    };\n\n    category queries { b_query; };\n    category general { general_file; };\n    category security { security_file; };\n    category lame-servers { null; };\n};\n</code></pre>"},{"location":"linux/hosting/dns/#namedconfoptions","title":"named.conf.options","text":"<p>Le fichier de base \u00e9tant totalement inutile, en voici un plus utile</p> <pre><code>acl allowQueried {\n    188.166.95.206;\n};\n\nacl allowRecursion {\n    localhost;\n};\n</code></pre>"},{"location":"linux/hosting/ftp/","title":"Installer son serveur FTP","text":""},{"location":"linux/hosting/ftp/#introduction","title":"Introduction","text":"<p>Un serveur FTP (FTPES pour le SSL) est un serveur de transfert de fichier fonctionnant en TCP sur le port 21 par d\u00e9faut. Il existe une multitude de serveur FTP tel que PureFTPd, ProFTPd, DrFTPd ou bien GlFTPd, mais chacun \u00e0 ses avantages et ses inconv\u00e9nients.</p> <p>PureFTPd est un serveur FTP simple d'installation et de configuration, c'est pour cela que nous avons choisit de l'installer.</p>"},{"location":"linux/hosting/ftp/#installation","title":"Installation","text":"<p>Pour l'installer, rien de plus simple. Il suffit de l'installer via son gestionnaire de paquet.</p> <pre><code>apt install pure-ftpd\n</code></pre> <p>Ne pas oublier de v\u00e9rifier que nous disposons bien du paquet dans les sources</p> <pre><code>apt show pure-ftpd\n</code></pre>"},{"location":"linux/hosting/ftp/#configuration","title":"Configuration","text":"<p>Lorsque nous installons Pure-FTPd, son ex\u00e9cutable se place dans /usr/sbin, et divers fichiers dans /etc/pure-ftpd</p> <p>Par d\u00e9faut, voici ce que contient r\u00e9pertoire :</p> <ul> <li>auth : Dossier contenant les diff\u00e9rents moyens de se connecter \u00e0     notre serveur FTP (Unix, PAM, PureDB)</li> <li>conf est un dossier contenant les fichiers que nous pourrons     configurer. Nous pouvons \u00e9galement ajouter d'autres fichiers afin     de configurer des \u00e9l\u00e9ments suppl\u00e9mentaires</li> <li>db est un dossier vide qui va contenir la BDD des Virtual User     de PureFTPd</li> <li>pureftpd-dir-aliases est un fichier pouvant contenir des alias,     ceci \u00e9vitant les liens symboliques</li> <li>pureftpd.passwd est le fichier, tel que /etc/passwd qui va     contenir diverses informations tel que username, password,     chemin...</li> </ul> <p>Tout d'abord, nous devons ajouter un utilisateur et un groupe pour nos utilisateurs virtuels PureFTPd</p> <pre><code>groupadd ftpgroup\n</code></pre> <pre><code>useradd -g ftpgroup -d /dev/null -s /usr/sbin/nologin ftpuser\n</code></pre> <p>Maintenant, il faut donc cr\u00e9er un user afin de se connecter au FTP</p> <pre><code>pure-pw useradd test -u ftpuser -g ftpgroup -d /home/www/test\n</code></pre> <p>Puis on g\u00e9n\u00e8re la DB</p> <pre><code>pure-pw mkdb\n</code></pre> <p>Attention, \u00e0 chaque modification d'utilisateur, il ne faut pas oublier de r\u00e9g\u00e9n\u00e9rer la base de donn\u00e9e</p> <p>On active la reconnaissance des virtuals users par PureFTPd</p> <pre><code>ln -s /etc/pure-ftpd/conf/PureDB /etc/pure-ftpd/auth/50pure\n</code></pre> <p>Et enfin, pour activer la gestion des virtual users, il faut \u00e9diter le champ VIRTUALCHROOT et le passer \u00e0 true dans le fichier /etc/default/pure-ftpd-common</p> <p>Si vous \u00eates derri\u00e8re un NAT, il peut \u00eatre bon de forcer les PassivePorts afin de les NAT correctement</p> <pre><code>echo \"40110 40210\" &gt; /etc/pure-ftpd/conf/PassivePortRange\nservice pure-ftpd restart\n</code></pre>"},{"location":"linux/hosting/ftp/#bonus","title":"Bonus","text":""},{"location":"linux/hosting/ftp/#ssl","title":"SSL","text":"<p>Tout d'abord, nous devons configurer Pure-FTPd afin qu'il autorise les connexions via SSL. Pour cela, nous devons \u00e9diter le fichier TLS qui se trouve dans le dossier conf</p> <p>Voici les valeurs qu'il peut avoir:</p> <ul> <li>0 : N'autorise pas les connexions SSL</li> <li>1 : Autorise les connexions SSL et les connexions non-SSL</li> <li>2 : Autorise seulement les connexions SSL</li> </ul> <p>Qui dit TLS, dit \u00e9galement certificat. Nous devons donc cr\u00e9er les certificats</p> <pre><code>mkdir -p /etc/ssl/private/\n</code></pre> <p>Puis nous cr\u00e9ons notre certificat:</p> <pre><code>openssl req -x509 -nodes -days 7300 -newkey rsa:4096 -keyout /etc/ssl/private/pure-ftpd.pem -out /etc/ssl/private/pure-ftpd.pem\n</code></pre> <p>Et \u00e9videmment, on n'oublie pas de red\u00e9marrer son serveur FTP.</p>"},{"location":"linux/hosting/ftp/#ciphers","title":"Ciphers","text":"<p>Etant donn\u00e9 que les ciphers de Pure-FTPd sont totalement fucked-up, nous allons donc les modifier</p> <p>Pour avoir une bonne liste de ciphers, je vous recommande de prendre ceux Wiki Mozilla disponible ici</p> <p>Il suffit donc de copier la Ciphers Listdans un fichier que nous allons cr\u00e9er dans le dossier conf</p> <pre><code>touch /etc/pure-ftpd/conf/TLSCipherSuite\n</code></pre> <p>Puis l'on '\"ins\u00e8re'\" les ciphers</p> <pre><code>echo \"ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256\" &gt; /etc/pure-ftpd/conf/TLSCipherSuite\n</code></pre>"},{"location":"linux/hosting/ftp/#fxp","title":"FXP","text":"<p>Comme d'habitude, pour activer le FXP (File eXchange Protocole), tout cela se passe comme d'habitude dans le dossier conf</p> <p>Voici la commande \u00e0 taper afin d'activer le FXP</p> <pre><code>echo yes &gt; /etc/pure-ftpd/conf/AllowUserFXP\n</code></pre> <p>Rappel: Pour fonctionner, le FXP doit \u00eatre activer sur les 2 serveurs</p>"},{"location":"linux/hosting/ftp/#desactiver-les-users-systemes","title":"Desactiver les users syst\u00e8mes","text":"<p>Si vous ne souhaitez utilisez uniquement une auth' par users virtuelles, alors il faut d\u00e9sactiver l'authentification UNIX mais \u00e9galement l'authentification PAM</p> <pre><code>echo no &gt; /etc/pure-ftpd/conf/PAMAuthentication\necho no &gt; /etc/pure-ftpd/conf/UnixAuthentication\n</code></pre>"},{"location":"linux/hosting/ftp/#bridage","title":"Bridage","text":"<p>Il est possible de faire diff\u00e9rents types de bridage afin de mieux controler l'utilisateur</p>"},{"location":"linux/hosting/ftp/#lock-ip","title":"Lock IP","text":"<p>Afin de restreindre \u00e0 une IP/range un compte utilisateur :</p> <pre><code>pure-pw usermod &lt;username&gt; -R 192.168.2.0/24 -m\npure-pw usermod &lt;username&gt; -R 192.168.0.8 -m\n</code></pre> <p>Il est possible de s\u00e9parer plusieurs IP par une virgule.</p>"},{"location":"linux/hosting/ftp/#restrict-debit","title":"Restrict Debit","text":"<p>Vous pouvez affecter un d\u00e9bit maximum \u00e0 vos utiliateurs :</p> <pre><code>pure-pw usermod &lt;username&gt; -t 10 -T 10 -m\n</code></pre> <p>Il est possible d'utiliser -t et -T ind\u00e9pendament l'un de l'autre:</p> <ul> <li><code>-t</code> signifie downloads</li> <li><code>-T</code> signifie upload</li> </ul>"},{"location":"linux/hosting/ftp/#reset-bridage","title":"Reset Bridage","text":"<p>Tout simple !</p> <pre><code>pure-pw usermod &lt;username&gt; -N  -m\n</code></pre>"},{"location":"linux/hosting/mail/","title":"Postfix/Dovecot/DKIM/Postgrey et plus encore","text":"<p>Lorsque j'ai \u00e9cris ce titre, je voulais faire un tutoriel pour installer de A \u00e0 Z son serveur mail avec rspamd, du DKIM...</p> <p>Depuis ce temps, je suis pass\u00e9 \u00e0 Docker. Mon cher coll\u00e8ge Hardware a fait une magnifique image Docker qui nous permet d'obtenir un 10/10 \u00e0 mail-tester, alors pourquoi se priver ?</p> <pre><code>  mailserver:\n    image: hardware/mailserver:1.1-stable\n    container_name: mailserver\n    restart: unless-stopped\n    domainname: domain.tld  # Mail server A/MX/FQDN &amp; reverse PTR = mail.domain.tld.\n    hostname: mail\n    ports:\n      - \"25:25\"       # SMTP                - Required\n      - \"143:143\"     # IMAP       STARTTLS - Optional - For webmails/desktop clients\n      - \"587:587\"     # Submission STARTTLS - Optional - For webmails/desktop clients\n      - \"993:993\"     # IMAPS      SSL/TLS  - Optional - For webmails/desktop clients\n      - \"4190:4190\"   # SIEVE      STARTTLS - Optional - Recommended for mail filtering\n    environment:\n      - REDIS_HOST=redis_mailserver\n      - DBHOST=db_mailserver\n      - DBUSER=postfix\n      - DBPASS=$DB_PASS\n      - RSPAMD_PASSWORD=$RSPAMD_PASS\n      - VIRTUAL_HOST=spam.domain.tld\n      - VIRTUAL_PORT=11334\n      - LETSENCRYPT_HOST=spam.domain.tld\n      - LETSENCRYPT_EMAIL=admin@domain.tld\n    volumes:\n      - /home/USER/.apps/mailserver/mail:/var/mail\n    depends_on:\n      - db_mailserver\n      - redis_mailserver\n\n  # Configuration : https://github.com/hardware/mailserver/wiki/Postfixadmin-initial-configuration\n  postfixadmin:\n    image: hardware/postfixadmin\n    container_name: postfixadmin\n    restart: unless-stopped\n    domainname: domain.tld\n    hostname: mail\n    environment:\n      - DBHOST=db_mailserver\n      - DBPASS=$DB_PASS\n      - VIRTUAL_HOST=postfixadmin.domain.tld\n      - VIRTUAL_PORT=8888\n      - LETSENCRYPT_HOST=postfixadmin.domain.tld\n      - LETSENCRYPT_EMAIL=admin@domain.tld\n      - UID=100$UID\n      - GID=100$UID\n    depends_on:\n      - mailserver\n      - db_mailserver\n\n  rainloop:\n    image: hardware/rainloop\n    container_name: rainloop\n    restart: unless-stopped\n    environment:\n      - VIRTUAL_PORT=8888\n      - VIRTUAL_HOST=webmail.domain.tld\n      - LETSENCRYPT_HOST=webmail.domain.tld\n      - LETSENCRYPT_EMAIL=admin@domain.tld\n    volumes:\n      - /home/USER/.apps/mailserver/rainloop:/rainloop/data\n    depends_on:\n      - mailserver\n      - db_mailserver\n\n  # Database\n  db_mailserver:\n    image: webhippie/mariadb\n    container_name: db_mailserver\n    restart: unless-stopped\n    environment:\n      - MARIADB_ROOT_PASSWORD=$ROOT_PASS\n      - MARIADB_DATABASE=postfix\n      - MARIADB_USERNAME=postfix\n      - MARIADB_PASSWORD=$DB_PASS\n    volumes:\n      - /home/USER/.apps/mailserver/mysql/db:/var/lib/mysql\n\n  # Database\n  redis_mailserver:\n    image: redis:4.0-alpine\n    container_name: redis_mailserver\n    restart: unless-stopped\n    command: redis-server --appendonly yes\n    volumes:\n      - /home/USER/.apps/mailserver/redis/db:/data\n</code></pre>"},{"location":"linux/hosting/troubleshooting/","title":"MOZILLA_PKIX_ERROR_REQUIRED_TLS_FEATURE_MISSING","text":"<p>Une erreur courante avec Mozilla Firefox est l'erreur MOZILLA_PKIX_ERROR_REQUIRED_TLS_FEATURE_MISSING.</p> <p>Personnellement, j'ai souvent rencontr\u00e9 cette erreur avec des certificats Let's Encrypt ayant \u00e9t\u00e9 cr\u00e9\u00e9 avec l'argument '--must-staple. Ce bug se produit lorsque qu'aucun r\u00e9solveur n'est d\u00e9finit au niveau de nginx. Sans r\u00e9solveur, nginx n'est pas capable d'effectuer l'OCSP Stapling.</p> <p>Au niveau du nginx :</p> <pre><code>http {\n    ...\n    resolver 1.1.1.1;\n    ...\n}\n</code></pre> <p>Et au niveau de notre server-block (par ex: sites-enabled/coucou.fr) :</p> <pre><code>server {\n    server_name coucou.fr\n    ssl_certificate /etc/letsencrypt/live/coucou.fr-0002/fullchain.pem; # managed by Certbot\n    ssl_certificate_key /etc/letsencrypt/live/coucou.fr-0002/privkey.pem; # managed by Certbot\n    ssl_stapling on;\n}\n</code></pre> <p>Il faut v\u00e9rifier que vous ayez la variable ssl_stapling \u00e0 on. Le resolver \u00e9tant charg\u00e9 au d\u00e9marrage de nginx, un reload ne suffira pas, il faudra un restart.</p> <p>Dans le cadre de Let's Encrypt, \u00e9tant donner que nous donnons la chaine compl\u00e8te en tant que ssl_certificate \u00e0 nginx, nous n'avons aucunement besoin de sp\u00e9cifier ssl_trusted_certificate</p>"},{"location":"linux/hosting/lemp/custom_server_header/","title":"\u00catre encore plus safe en customisant son header Server NGINX","text":"<p>Editer son header Server n'est pas une chose inutile. En effet, selon celui-ci, nous pouvons d\u00e9terminer la version du serveur web (nginx, apache2) ainsi que celle de php. Grace \u00e0 cette information, si nous avons une ancienne version de ces logiciels, nous pouvons y retrouver des CVE et ainsi se faire pirater.</p> <p>Il existe donc 2 solutions afin d'\u00e9diter son header Server :</p>"},{"location":"linux/hosting/lemp/custom_server_header/#compilation-nginx","title":"Compilation nginx","text":"<pre><code># vi src/http/ngx_http_header_filter_module.c (lines 48 and 49)\nstatic char ngx_http_server_string[] = \"Server: MyDomain.com\" CRLF;\nstatic char ngx_http_server_full_string[] = \"Server: MyDomain.com\" CRLF;\n</code></pre>"},{"location":"linux/hosting/lemp/custom_server_header/#maniere-propre","title":"Mani\u00e8re '\"propre'\"","text":"<p>Il suffit d'installer nginx-extras qui nous apportera le module nginx more-headers</p> <pre><code>apt-get install nginx-extras\n</code></pre> <p>Puis on edit nginx.conf</p> <pre><code>server_tokens off; # removed pound sign\nmore_set_headers Server: MyServer;\n</code></pre>"},{"location":"linux/hosting/lemp/fetch_good_ips/","title":"Obtenir les bonnes IP sur apache derri\u00e8re un reverse proxy","text":"<p>Sans configuration particuli\u00e8re, on aura 127.0.0.1 dans les logs apache s'il est derri\u00e8re un reverse-proxy. Il est toujours bon d'avoir les vrais IPs</p> <p>Comme vous pouvez le voir, la conservation de l'IP d\u00e9pend du header <code>X-Forwarded-For</code>, soyez s\u00fbr que votre reverse-proxy transmet le header</p>"},{"location":"linux/hosting/lemp/fetch_good_ips/#nginx","title":"NGINX","text":"<p>Tout d'abord, on dit \u00e0 nginx de transmettre la bonne IP</p> <pre><code>$ cat /etc/nginx/proxy_params\nproxy_set_header Host $http_host;\nproxy_set_header X-Real-IP $remote_addr;\nproxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\nproxy_set_header X-Forwarded-Proto $scheme;\n</code></pre> <p>Et on inclue ce fichier dans le server block</p>"},{"location":"linux/hosting/lemp/fetch_good_ips/#apache","title":"Apache","text":"<p>C\u00f4t\u00e9 Apache, plusieurs \u00e9tapes \u00e0 faire. Personnelement, je cr\u00e9\u00e9 un logformat pr\u00e9cis et active le mode remoteip</p> <pre><code>$ cat /etc/apache2/conf-available/log-proxified.conf\nLogFormat \"%a %l %u %t '\"%r'\" %&gt;s %O '\"%{Referer}i'\" '\"%{User-Agent}i'\"\" proxified\n\n$ cat /etc/apache2/conf-available/remoteip.conf\nRemoteIPHeader X-Forwarded-For\n\n# ici les adresse distantes auxquelles on fait confiance pour pr\u00e9senter une valeur RemoteIPHeader\nRemoteIPTrustedProxy 127.0.0.1 ::1\n</code></pre> <p>Et on active tout \u00e7a</p> <pre><code>a2enconf remoteip\na2enconf log-proxified\na2enmod remoteip\n</code></pre> <p>On n'oublie pas de sp\u00e9cifier le format du CustomLog \u00e0 proxified</p> <p>Pour information, %a a la vraie IP dans le cadre de l'utilisation de <code>remoteip</code>, contrairement \u00e0 %h.</p>"},{"location":"linux/hosting/lemp/installation/","title":"Installer son Serveur Web : NGINX, PHP-FPM et MariaDB","text":""},{"location":"linux/hosting/lemp/installation/#preambule","title":"Pr\u00e9ambule","text":"<p>Nous allons voir comment installer et configurer correctement NGINX, PHP-FPM et MariaDB. Pour cela, nous allons ajouter des sources afin d'obtenir des versions plus \u00e0 jour de ces diff\u00e9rents logiciels Pour les sources de nginx, il faudra remplacer codename par sa distribution (Wheezy, Jessie...)</p> Sites officiels Liens utiles NGINX Doc NGINX PHP Manuel PHP MariaDB Documentation MariaDB"},{"location":"linux/hosting/lemp/installation/#installer-et-configurer-nginx","title":"Installer et configurer NGINX","text":"<p>Tout d'abord, avant de vouloir installer le serveur web NGINX, il faut d\u00e9j\u00e0 ajouter une source.</p> <pre><code>\u2514\u2500# apt-cache policy nginx\nnginx:\n  Install\u00e9\u00a0: 1.14.2-2+deb10u4\n  Candidat\u00a0: 1.14.2-2+deb10u4\n Table de version\u00a0:\n     1.14.2-2+deb10u4 500\n        500 http://deb.debian.org/debian buster/main amd64 Packages\n        500 http://security.debian.org/debian-security buster/updates/main amd64 Packages\n</code></pre> <p>Si l'on utilise les repositories de base de Debian Buster, ceux-ci nous installent la version 1.14.2 de NGINX. Actuellement, nous en sommes \u00e0 la 1.21.2. C'est pour cela que nous ajoutons des repositories afin d'obtenir une version \u00e0 jour (Dans notre cas, les repositories du site officiel)</p> <p>Cela nous \u00e9vite bon nombres de failles, et nous permet \u00e9galement de profiter de toutes les derni\u00e8res nouveaut\u00e9s.</p> <p>Tout d'abord, on commence par ajouter le depot NGINX \u00e0 Debian</p> <pre><code>$ echo \"deb [signed-by=/usr/share/keyrings/nginx-archive-keyring.gpg] '\nhttp://nginx.org/packages/mainline/debian `lsb_release -cs` nginx\" '\n    | sudo tee /etc/apt/sources.list.d/nginx.list\n</code></pre> <p>Il faut \u00e9galement ajouter la GPG Key \u00e0 son Debian, sans quoi il nous affichera que la source n'est pas certifi\u00e9e</p> <pre><code>$ curl https://nginx.org/keys/nginx_signing.key | gpg --dearmor '\n    | sudo tee /usr/share/keyrings/nginx-archive-keyring.gpg &gt;/dev/null\n</code></pre> <p>Afin d'\u00eatre s\u00fbr que nous allons utiliser les repository Debian, on ajoute un Pinning :</p> <pre><code>echo -e \"Package: *\\nPin: origin nginx.org\\nPin: release o=nginx\\nPin-Priority: 900\\n\" | sudo tee /etc/apt/preferences.d/99nginx\n</code></pre> <p>Et enfin, on effectue un <code>apt-get update</code> pour mettre \u00e0 jour nos packets disponibles.</p> <p>Si tout marche bien, voici ce que nous devrions obtenir lorsque l'on fait la commande <code>apt-cache policy nginx</code></p> <pre><code>    \u2514\u2500# apt-cache policy nginx\n    nginx:\n      Install\u00e9\u00a0: (aucun)\n      Candidat\u00a0: 1.21.1-1~buster\n</code></pre> <p>Si tout se passe comme il faut, on peut lancer l'installation</p> <pre><code>\u2514\u2500# apt-get -y install nginx nginx-extras nginx-doc\n</code></pre> <p>Voici les options de compilations du paquet nginx</p> NGINX Default Compilation Options <pre><code>--prefix=/etc/nginx\n--sbin-path=/usr/sbin/nginx\n--conf-path=/etc/nginx/nginx.conf\n--error-log-path=/var/log/nginx/error.log\n--http-log-path=/var/log/nginx/access.log\n--pid-path=/var/run/nginx.pid\n--lock-path=/var/run/nginx.lock\n--http-client-body-temp-path=/var/cache/nginx/client_temp\n--http-proxy-temp-path=/var/cache/nginx/proxy_temp\n--http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp\n--http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp\n--http-scgi-temp-path=/var/cache/nginx/scgi_temp\n--user=nginx\n--group=nginx\n--with-http_ssl_module --with-http_realip_module --with-http_addition_module --with-http_sub_module\n--with-http_dav_module --with-http_flv_module --with-http_mp4_module --with-http_gunzip_module\n--with-http_gzip_static_module --with-http_random_index_module --with-http_secure_link_module --with-http_stub_status_module\n--with-http_auth_request_module\n--with-mail\n--with-mail_ssl_module\n--with-file-aio\n--with-http_v2_module\n--with-ipv6\n</code></pre> <p>D\u00e9sormais, nginx est quasiment pr\u00eat \u00e0 \u00eatre utilis\u00e9, il nous reste plus qu'\u00e0 le configurer.</p> <p>Voici ma configuration personnel que j'utilise</p> File: /etc/nginx/nginx.conf <pre><code>user www-data;\nworker_processes auto;\nworker_rlimit_nofile 65536;\n#worker_cpu_affinity 00000010 00000100 00001000 00010000;\npid /run/nginx.pid;\n\ninclude /etc/nginx/modules-enabled/*.conf;\n\nevents {\n    worker_connections 16384;\n    # multi_accept on;\n}\n\nhttp {\n\n    ##\n    # Basic Settings\n    ##\n\n    sendfile on;\n    tcp_nopush on;\n    tcp_nodelay on;\n\n    resolver 127.0.0.1 1.1.1.1;\n    ignore_invalid_headers on;\n\n    keepalive_timeout 65;\n    types_hash_max_size 2048;\n\n    server_tokens off;\n    more_set_headers Server: Jeremy Server;\n    more_set_headers Contact: wiki[at]jdelgado[dot]fr;\n\n    # server_names_hash_bucket_size 64;\n    # server_name_in_redirect off;\n\n    include /etc/nginx/mime.types;\n    default_type application/octet-stream;\n\n    ##\n    # SSL Settings\n    ##\n\n    ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; # Dropping SSLv3, ref: POODLE\n    ssl_prefer_server_ciphers on;\n\n    ##\n    # Logging Settings\n    ##\n\n    access_log /var/log/nginx/access.log;\n    error_log /var/log/nginx/error.log;\n\n    ##\n    # Gzip Settings\n    ##\n\n    gzip on;\n\n    gzip_vary on;\n    gzip_proxied any;\n    gzip_comp_level 4;\n    # gzip_buffers 16 8k;\n    # gzip_http_version 1.1;\n    # gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;\n    gzip_types text/plain text/css application/json application/ld+json application/x-javascript text/xml application/xml application/xml+rss text/javascript application/xml+xhtml application/javascript application/vnd.ms-fontobject font/ttf font/opentype image/svg+xml image/x-icon;\n\n    ##\n    # Virtual Host Configs\n    ##\n\n    include /etc/nginx/conf.d/*.conf;\n    include /etc/nginx/sites-enabled/*;\n}\n</code></pre> <p>\u00c9videmment, ce fichier n'est pas \u00e0 recopier tel quel, mais il y a tout de m\u00eame certains points importants \u00e0 conserver :</p> <ul> <li><code>user</code> qui sera l'utilisateur qui ex\u00e9cutera les instances nginx</li> <li><code>worker_processes</code> qui d\u00e9finira combien d'instances seront     ex\u00e9cut\u00e9es en simultan\u00e9es (Ce nombre doit correspondre au nombre de     coeurs <code>logiques</code> dont dispose votre CPU). Vous pouvez disposez de     cette information via la commande nproc. La valeur <code>auto</code> est     cens\u00e9e d\u00e9finir le bon nombre de workers automatiquement</li> <li><code>include</code> qui permet d'inclure diff\u00e9rents \u00e9l\u00e9ments de     configuration \u00e0 votre <code>nginx.conf</code> afin de rendre celui-ci plus     clair. Nous pouvons voir dans notre exemple que nos sites se     trouvent dans le r\u00e9pertoire sites-enabled et que certains \u00e9l\u00e9ments     de configuration se trouvent dans le r\u00e9pertoire //conf.d/static/ //</li> <li><code>server_tokens</code> une valeur tr\u00e8s importante, celle-ci doit \u00eatre     mise \u00e0 <code>off</code>. Cette valeur \u00e9vite \u00e0 nginx de montrer des \u00e9l\u00e9ments     importants tel que son num\u00e9ro de version. Ces \u00e9l\u00e9ments peuvent \u00eatre     utilis\u00e9s pour exploiter des failles sur nginx</li> <li><code>ignore_invalid_headers</code> est \u00e9galement une directive assez     int\u00e9r\u00e9ssante. Si des bots tentent de se connecter avec un header     incorrect, nginx leur retourne une erreur 404.</li> <li><code>resolver</code> nous permet de sp\u00e9cifier les DNS qui vont \u00eatre utilis\u00e9s     dans les logs pour r\u00e9soudre les diff\u00e9rents noms de domaines</li> </ul> <p>La directive more_set_headers permet de ne pas d\u00e9voiler son serveur web, et n'est disponible que via le package nginx-extras</p> <p>Comme vous pouvez le voir, on inclut \u00e9galement diff\u00e9rents fichiers, les voici :</p> File: /etc/nginx/conf.d/filecache.conf <pre><code>##\n# File Cache\n##\nopen_file_cache          max=10000 inactive=20s;\nopen_file_cache_valid    60s;\nopen_file_cache_min_uses 2;\nopen_file_cache_errors   on;\n</code></pre> File: /etc/nginx/conf.d/gzip.conf <pre><code>###\n# GZip Settings\n###\ngzip on;\ngzip_buffers 16 8k;\ngzip_comp_level 9;\ngzip_disable \"msie6\";\ngzip_min_length 20;\ngzip_proxied any;\ngzip_types text/plain\n           text/css\n           text/xml\n           text/javascript\n           application/json\n           application/x-javascript\n           application/javascript\n           application/xml\n           application/xml+rss\ngzip_vary on;\n</code></pre> <p>Ce fichier est assez important, il permet d'activer la compression gzip, ce qui signifie concr\u00e8tement un gain de vitesse sur votre site internet.</p> <ul> <li><code>gzip</code> permet d'activer la compression gzip</li> <li><code>gzip_buffers</code> permet de sp\u00e9cifier le nombre de buffers qui vont     \u00eatre utilis\u00e9s, ainsi que leur taille</li> <li><code>gzip_comp_level</code> sp\u00e9cifie lagressivit\u00e9 de la compression gzip.     <code>Attention</code> plus la compression gzip sera forte (9), plus le CPU     va \u00eatre sollicit\u00e9.</li> <li><code>gzip_disable</code> permet de d\u00e9sactiver la compression GZip selon     l'User-Agent (Par exemple, ici, nous d\u00e9sactivons la compression     gzip pour <code>IE4 \u00e0 IE6</code>)</li> <li><code>gzip_min_length</code> sp\u00e9cifie quelle est la longueur minimale d'un     \u00e9l\u00e9ment qui doit \u00eatre '\"gzipp\u00e9'\". Il d\u00e9pend du header     Content-Length</li> <li><code>gzip_proxied</code> sp\u00e9cifie les \u00e9l\u00e9ments qui doivent \u00eatre '\"gzipp\u00e9'\"     lorsque nginx agit comme reverse-proxy</li> <li><code>gzip_types</code> est \u00e9galement une autre ligne importante. C'est ici     que l'on doit sp\u00e9cifi\u00e9 les <code>MIME-Types</code> des diff\u00e9rents \u00e9l\u00e9ments     qui vont \u00eatre '\"gzipp\u00e9s'\"</li> <li><code>gzip_vary</code> indique si un ajout va \u00eatre effectu\u00e9 dans le header si     le fichier a \u00e9t\u00e9 '\"gzipp\u00e9'\"</li> </ul> File: /etc/nginx/snippets/ssl.conf <pre><code>###\n# SSL Settings\n###\n\n# Ciphers for OpenSSL 1.1.1d (Bullseye)\nssl_ciphers ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DHE-RSA-CHACHA20-POLY1305:DH+AES:RSA+AESGCM:RSA+AES:!aNULL:!MD5:!DSS;\n\nssl_prefer_server_ciphers off;\nssl_dhparam /etc/nginx/ssl/dhparam.pem;\n\nssl_prefer_server_ciphers  on;\nssl_session_cache    shared:SSL:64m; # a 1mb cache can hold about 4000 sessions, so we can hold 40000 sessions\nssl_session_timeout  12h;\nssl_session_tickets  off;\n\nadd_header Strict-Transport-Security \"max-age=15768000;\";\nadd_header X-Frame-Options SAMEORIGIN;\nadd_header X-Content-Type-Options nosniff;\nadd_header X-XSS-Protection \"1; mode=block\";\nadd_header Referrer-Policy \"no-referrer\";\n\nssl_certificate /etc/nginx/ssl/server.crt;\nssl_certificate_key /etc/nginx/ssl/server.key;\n</code></pre> <p>Le fichier ssl.conf est \u00e0 inclure seulement si l'on souhaite du SSL sur ses sites web</p> <p>Certaines lignes sont importantes tels que ssl_ciphers qui permet de s\u00e9lectionner quels ciphers seront utilis\u00e9s pour coder l'\u00e9change entre son serveur web, et son client. Cette ligne est extr\u00eamement importante car il y a actuellement de nombreux ciphers utilis\u00e9s mais qui sont totalement d\u00e9pass\u00e9s. ssl_protocols permet lui \u00e9galement de ne pas pass\u00e9s par des protocoles compl\u00e8tement trou\u00e9s. Cependant, il faut faire attention avec ces 2 lignes, car en effet, elles peuvent provoquer des erreurs de s\u00e9curit\u00e9 c\u00f4t\u00e9 navigateur, voir carr\u00e9ment entrainer un refus du navigateur. Nous activons \u00e9galement le protocole HSTS (Plus d'informations ici)</p> <p>Pour avoir une bonne cipher list, et de bons param\u00e8tres SSL, je vous recommande d'aller voir le Wiki Mozilla</p> <p>Je n'ai volontairement pas mis une configuration CSP (Content Security Protocol) car il s'agit d'un protocole d\u00e9licat \u00e0 mettre en place, et je vous renvoie vers l'article de pr\u00e9f\u00e9rence</p> <p>Voici d\u00e9sormais des snippets utiles pour ses diff\u00e9rents blocks nginx :</p> File: /etc/nginx/snippets/protect.conf <pre><code>###\n# Basic File Protect\n###\n\n# Disallow download of hidden files\nlocation ~* (?:^|/)'. {\n    deny all;\n}\n\n# Disallow download of these extensions\nlocation ~* (?:'.(?:bak|conf.*|sql|fla|psd|ini|log|sh|inc|swp|dist)|~)$ {\n    deny all;\n}\n</code></pre> <p>Ce fichier nous permet d'\u00e9viter que des fichiers de configuration ou autres soient accessible par tout le monde. Il s'agit d'un fichier g\u00e9n\u00e9rique qui s'adapte au plus grand nombre de services, \u00e9videmment, il se peut que certains fichiers/dossiers ne soient pas prot\u00e9g\u00e9s, dans ces cas-l\u00e0, il faut les ajouter manuellement.</p>"},{"location":"linux/hosting/lemp/installation/#snippets","title":"Snippets","text":"<p>Snippets utiles pour vos vhosts (snippets/letsencrypt.conf)</p> File: /etc/nginx/snippets/letsencrypt.conf <pre><code>location ^~ /.well-known/acme-challenge/ {\n    satisfy any;\n    allow all;\n\n    access_log /var/log/nginx/certbot.log;\n\n    root /var/www/letsencrypt;\n}\n</code></pre>"},{"location":"linux/hosting/lemp/installation/#installer-et-configurer-php7-fpm","title":"Installer et configurer PHP7-FPM","text":"<p>Commande \u00e0 adapter selon les modules que vous souhaitez. G\u00e9n\u00e9ralement, ces derniers sont suffisant pour 99% des installations.</p> <pre><code>apt-get -y install php-common php8.2 php8.2-bz2 php8.2-cli php8.2-common php8.2-curl php8.2-fpm php8.2-gd php8.2-geoip php8.2-gmp php8.2-igbinary php8.2-imagick php8.2-intl php8.2-json php8.2-mbstring php8.2-mcrypt php8.2-memcached php8.2-msgpack php8.2-mysql php8.2-opcache php8.2-readline php8.2-sqlite3 php8.2-xml php8.2-xmlrpc php8.2-zip\n</code></pre> <p>Nous allons maintenant passer \u00e0 la configuration de base de PHP-FPM, tout se situe dans le r\u00e9pertoire /etc/php/8.2/fpm/ et ses sous-r\u00e9pertoires. (8.2 a remplacer par votre num\u00e9ro de version)</p> <p>Nous allons \u00e9diter le fichier php.ini :</p> <ul> <li><code>expose_php</code> : D\u00e9sactivation afin de ne pas exposer la version de     PH</li> <li><code>upload_max_filesize</code> : Modification de la taille maximale des     fichiers qu'on peut upload avec PHP</li> <li><code>post_max_size</code> : Va avec la directive upload_max_filesize et     doit \u00eatre sup\u00e9rieur \u00e0 cette derni\u00e8re</li> <li><code>max_file_uploads</code> : Nombre de fichiers qu'on peut upload en     parall\u00e8le. Par d\u00e9faut \u00e0 20, peut suffir dans une majorit\u00e9 des cas</li> </ul> <p>Petit customisation de la. configuration afin d'optimiser les performances. Il faut pour la plupart des CMS/Framework adapter les valeurs de l'OPcache. Pour WordPress, voici des valeurs ad\u00e9quates :</p> <pre><code>opcache.memory_consumption = 128M\nopcache.interned_strings_buffer=16\nopcache.max_accelerated_files=100000\nopcache.fast_shutdown=1\n</code></pre> <p>Symfony fournit ses propres recommandations pour la configuration de l'OPcache. La variable opcache.max_accelerated_files peut \u00eatre facilement calcul\u00e9e :</p> <pre><code>\u2514\u2500# find . -name \"*.php\" |wc -l\n5165\n</code></pre> <p>Pour notre exemple, 10000 fichiers sont largement suffiants. Aucune astuce existe pour calculer opcache.memory_consumption. Il faudra surveiller votre monitoring.</p>"},{"location":"linux/hosting/lemp/installation/#installer-et-configurer-mariadb","title":"Installer et configurer MariaDB","text":"<p>On met \u00e0 jour les paquets disponibles :</p> <pre><code>apt-get update\n</code></pre> <p>Et enfin, on v\u00e9rifie que la Candidate Version est la bonne :</p> <pre><code>apt-cache policy mariadb-server\n</code></pre> <p>Voil\u00e0 le r\u00e9sultat attendu :</p> <pre><code>$ apt-cache policy mariadb-server\nmariadb-server:\n  Install\u00e9\u00a0: (aucun)\n  Candidat\u00a0: 1:10.3.29-0+deb10u1\n Table de version\u00a0:\n *** 1:10.3.29-0+deb10u1 500\n        500 http://apt.daevel.fr/debian buster/main amd64 Packages\n        100 /var/lib/dpkg/status\n</code></pre> <p>Si tout se passe comme il faut, on lance l'installation du serveur SQL</p> <pre><code>apt-get install mariadb-server\n</code></pre> <p>Pendant l'installation de mariadb-server, vous allez obtenir une fen\u00eatre vous demandant de sp\u00e9cifier un password</p> <p>Cette fen\u00eatre est tr\u00e8s importante, elle va vous permettre de d\u00e9finir votre root password pour g\u00e9rer vos bases de donn\u00e9es, il faut utiliser un mot de passe relativement puissant pour qu'il ne puisse pas \u00eatre d\u00e9couvert ou crack\u00e9, sans quoi, tous vos sites sont \u00e0 nus.</p> <p>Et on finit par le script made in MariaDB pour s\u00e9curiser le tout</p> <pre><code>mysql_secure_installation\n</code></pre>"},{"location":"linux/hosting/lemp/ipv6_nginx/","title":"Configurer nginx pour utiliser IPv6","text":"<p>Configurer l'IPv6 et nginx est un vrai casse-t\u00eate, et je ne vous parle m\u00eame pas lorsque l'on a plusieurs vhosts.</p> <p>Tout d'abord, 2 v\u00e9rifications sont \u00e0 faire au pr\u00e9alable pour \u00eatre sur que nous avons l'IPv6 d'activ\u00e9e, mais \u00e9galement que nginx la supporte.</p> <p>Pour v\u00e9rifier que nous avons l'IPv6 :</p> <pre><code>ping6 google.com\n</code></pre> <p>Si cela ping, nous sommes d\u00e9j\u00e0 s\u00fbr que votre h\u00f4te dispose d'une connexion IPv6.</p> <p>Maintenant, pour \u00eatre sur que nginx, nous affichons les options de compilation nginx, et nous devons apercevoir <code>--with-ipv6</code></p> <pre><code>nginx -V | grep --with-ipv6\n</code></pre> <p>Si nous avons la ligne, nous sommes pr\u00eats \u00e0 modifier la configuration afin d'y ajouter l'IPv6</p> <p>Dans un seul block nginx, nous devons y ajouter cette ligne :</p> <pre><code>listen [::]:80 ipv6only=on deferred default_server;\n</code></pre> <p>Dans cette ligne, nous pouvons observer plusieurs \u00e9l\u00e9ments :</p> <ul> <li><code>listen</code> l'instruction nginx qui nous indique que nous devons     '\"\u00e9couter'\"</li> <li><code>[::']</code> qui nous indique sur quelles interfaces \u00e9couter (Ici, sur     toutes)</li> <li><code>ipv6only=on</code> signifie que cette ligne listen ne concerne uniquement     l'IPv6</li> <li><code>deferred</code> peut acc\u00e9lerer la communication TCP, mais est tout de     m\u00eame indispensable en IPv6</li> <li><code>default_server</code> signifie que nous voulons que cette configuration     soit charg\u00e9e avant les autres</li> </ul> <p>Sur les autres servers blocks, nous devons ajouter</p> <pre><code>listen [::]:80;\n</code></pre> <p>Un petit coup de restart</p> <pre><code>service nginx restart\n</code></pre> <p>Et voil\u00e0, nous avons d\u00e9sormais nos serveurs utilisant l'IPv6 o/</p> <p>Afin d'\u00eatre sur que l'IPv6 fonctionne, nous pouvons faire un <code>curl -6 ndd.tld</code> \u00e0 partir d'une machine tierce.</p> <p>N'oubliez \u00e9galement pas de faire vos entr\u00e9es DNS AAAA afin de match IPv6 et NDD, sans cela, m\u00eame avec une configuration nginx au poil, nous ne pourrons communiquer en IPv6 avec le client.</p>"},{"location":"linux/hosting/lemp/nginx_ssl/","title":"Forcer le SSL sous NGINX","text":"<p>Pour forcer le SSL/TLS sous nginx, rien de plus simple, il suffit simplement d'ajouter cette directive dans votre server-block nginx</p> <pre><code>server {\n...\n    return 301 https://$host$request_uri;\n...\n}\n</code></pre> <p>Il ne faut pas oublier de faire un autre server-block qui \u00e9coute sur le port 443 et qui comporte toutes les instructions n\u00e9c\u00e9ssaire au bon fonctionnement du site web.</p>"},{"location":"linux/hosting/lemp/php_custom_version/","title":"Installer une version custom de PHP","text":"<p>Warning</p> <p>Aujourd'hui, nous sommes en PHP 8.x, la m\u00e9thode reste toujours valable, mais renseignez-vous sur la version de PHP</p> <p>Ajout du repo :</p> <pre><code>apt-get install apt-transport-https lsb-release ca-certificates\nwget -O /etc/apt/trusted.gpg.d/php.gpg https://packages.sury.org/php/apt.gpg\necho \"deb https://packages.sury.org/php/ $(lsb_release -sc) main\" &gt; /etc/apt/sources.list.d/php.list\n</code></pre> <p>Puis un petit update/install php8.x, et le tour est jou\u00e9</p> <pre><code>apt update &amp;&amp; apt install -y php8.2-fpm\n</code></pre>"},{"location":"linux/hosting/lemp/haproxy/api/","title":"HAproxy : Utiliser son API","text":"<p>HAproxy est un puissant load-balancer pouvant \u00eatre control\u00e9 via une API, je vais noter ici les principales fonctions de son API</p> <pre><code>echo \"show stat\" | socat stdio /run/haproxy/monitoring.sock | cut -d \",\" -f 1-2,5-10,34-36 | column -s, -t\n# pxname                svname              scur  smax  slim     stot        bin          bout          rate  rate_lim  rate_max\ncluster_analytics       custfront1        0     6     119151   117985796   1458531881   2             15\ncluster_analytics       custfront2        0     4     54427    36461337    715425308    0             9\ncluster_analytics       custfront3        0     9     114021   114945537   1419205852   0             13\ncluster_analytics       BACKEND             0     9     3277     287818      269535559    3593163041    2     22\ncluster_avatar          avatarpub           0     0     0        0           0            0             0\ncluster_avatar          avatarpriv          0     0     0        0           0            0             0\ncluster_avatar          BACKEND             0     0     1        0           0            0             0     0\ncluster_bo              custbo1           0     11    605      1294617     5522403      0             22\n</code></pre> <p>On obtient les principales stats de HAproxy (On filtre sur les colonnes pour garder ce qu'on souhaite)</p>"},{"location":"linux/hosting/lemp/haproxy/cloudflare/","title":"HAproxy : Obtenir les vraies IPs depuis CloudFlare","text":"<p>Assez simple, il faut jouer avec les headers. Concr\u00eatement, \u00e7a nous donne \u00e7a niveau frontend HAproxy :</p> <pre><code>frontend    https\n    bind    0.0.0.0:443 ssl crt /etc/haproxy/acme-certs/ alpn h2,http/1.1 allow-0rtt\n\n    mode http\n\n    acl from_cf    src -f /etc/haproxy/acl/cloudflare_ips.lst\n    http-request set-src req.hdr(CF-Connecting-IP) if from_cf\n</code></pre> <p>Pour le fichier cloudflare_ips.lst, CloudFlare maintient une liste publique de ses IPs :</p> <ul> <li>IPv4</li> <li>IPv6</li> </ul>"},{"location":"linux/hosting/lemp/haproxy/keep_real_ip/","title":"Conserver l'IP de son visiteur sur un reverse-proxy","text":"<p>Tout d'abord, si vous n'avez aucune notion sur HAproxy, je vous invite \u00e0 aller consulter mon guide HAproxy</p> <p>Comme vous pouvez vous en douter, dans le cadre de l'utilisation d'un reverse-proxy, il est (malheureusement) tr\u00e8s facile de log la mauvaise IP.</p> <p>Plus important, il est possible que votre site web autorise (ou non) l'acc\u00e8s \u00e0 certaines pages selon l'IP, il est donc important de conserver la bonne IP tout au long du process.</p> <p>Pour cela, rien de plus simple c\u00f4t\u00e9 HAproxy, il vous suffit d'ajouter cette option dans un frontend.</p> <pre><code>frontend proxy\n    ...\n    option forwardfor\n    ...\n</code></pre> <p>Cette petite option va override un quelconque header <code>X-Forwarded-For</code> existant et y mettre l'adresse IP de votre client, plutot simple non ? :)</p>"},{"location":"linux/hosting/lemp/haproxy/maintenance/","title":"HAproxy : Mettre un node en maintenance","text":"<p>Dans le cadre de mise \u00e0 jour ou autre, il est int\u00e9ressant de mettre un node en maintenance. L'op\u00e9ration est extr\u00eamement simple avec l'API de HAproxy.</p> <p>Voici les quelques commandes \u00e0 passer :</p> <pre><code>echo \"set server backend_name/svc_name state drain\" | socat stdio /var/run/haproxy/admin.sock\necho \"set server backend_name/svc_name state ready\" | socat stdio /var/run/haproxy/admin.sock\n</code></pre> <p>Le drain va graduellement supprimer le serveur en question de la liste des backends. Vous pouvez utiliser maint pour tout stoper d'un coup.</p> <p>Dans le cadre d'un drain, les healthcheck sont toujours envoy\u00e9s, vous pouvez les supprimer de la mani\u00e8re suivante :</p> <pre><code>echo \"disable health backend_name/svc_name\" | socat stdio /var/run/haproxy/admin.sock\necho \"enable health backend_name/svc_name\" | socat stdio /var/run/haproxy/admin.sock\n</code></pre> <p>On peut \u00e9galement taper ces commandes directement dans HAtop</p>"},{"location":"linux/hosting/lemp/haproxy/overview/","title":"Reverse proxy: HAproxy","text":"<p>HAproxy est un reverse proxy optimis\u00e9 pour les fortes charges cr\u00e9\u00e9 en 2000 par Willy Tarreau, un contributeur kernel. Ce dernier propose toutes les fonctionnalit\u00e9s d'un reverse proxy classique :</p> <ul> <li>L4/L7 Balancing</li> <li>Terminaison TLS</li> </ul> <p>Il est \u00e9galement utilis\u00e9 par de nombreux sites populaires :</p> <ul> <li>Twitter</li> <li>Github</li> <li>Reddit</li> <li>Airbnb...</li> </ul> <p>Comme tout package, il est simplement installable via un package manager tel que apt ou autre.</p>"},{"location":"linux/hosting/lemp/haproxy/overview/#terminologie","title":"Terminologie","text":"<p>HAproxy utilise des termes assez classiques. Cependant, nous avons quelques terminologies sp\u00e9cifiques \u00e0 HAproxy</p> <ul> <li>bind : attacher en Anglais, permet de dire sur quelle IP et quel port HAproxy va \u00e9couter. Par exemple, 192.168.1.1 sur le port 80</li> <li>frontend : c'est un bloc de configuration qui permet de d\u00e9finir toutes les r\u00e8gles qui s'appliqueront (domaines \u00e9cout\u00e9s, limitations, etc). Un frontend peut s'appliquer \u00e0 un ou plusieurs bind.</li> <li>backend : c'est un autre bloc de configuration, que l'on place derri\u00e8re un frontend. Si le frontend g\u00e8re ce qui est publique (\u00e0 '\"l'\"avant'\" du serveur), le backend g\u00e8re '\"l'arri\u00e8re'\". C'est l\u00e0 que vous d\u00e9finirez les serveurs web vers lesquels envoyer les requ\u00eates, les diff\u00e9rents checks appliqu\u00e9s...</li> <li>ACL : une '\"Access Control List'\" permet de d\u00e9finir des conditions dans un bloc, par exemple '\"si le domaine contient site1, alors faire cela, si la requ\u00eate est en https, alors faire ceci'\". Il s'agit ici de la grande sp\u00e9cificit\u00e9 de HAproxy face \u00e0 ses concurrents.</li> </ul>"},{"location":"linux/hosting/lemp/haproxy/overview/#configuration-generale","title":"Configuration G\u00e9n\u00e9rale","text":"<p>Par d\u00e9faut, toute la configuration de HAproxy se fait dans un unique fichier : haproxy.cfg. Cependant, lors d'une configuration un peu pouss\u00e9e, il devient tr\u00e8s vite illisible.</p> <p>Heureusement, il est facile de split la configuration. Dans le fichier /etc/default/haproxy, il vous suffit de faire la modification suivante:</p> <pre><code># Change the config file location if needed\n#CONFIG=\"/etc/haproxy/haproxy.cfg\"\nCONFIG=\"/etc/haproxy\"\n</code></pre> <p>La variable CONFIG est utilis\u00e9e pour le param\u00e8tre <code>-F $CONFIG</code> de l'unit systemd. Voici ce que nous dit la documentation haproxy :</p> HAproxy : Official Documentation <pre><code>  -f &lt;cfgfile|cfgdir&gt; : adds &lt;cfgfile&gt; to the list of configuration files to be\n    loaded. If &lt;cfgdir&gt; is a directory, all the files (and only files) it\n    contains are added in lexical order (using LC_COLLATE=C) to the list of\n    configuration files to be loaded ; only files with \".cfg\" extension are\n    added, only non hidden files (not prefixed with \".\") are added.\n    Configuration files are loaded and processed in their declaration order.\n    This option may be specified multiple times to load multiple files. See\n    also \"--\". The difference between \"--\" and \"-f\" is that one \"-f\" must be\n    placed before each file name, while a single \"--\" is needed before all file\n    names. Both options can be used together, the command line ordering still\n    applies. When more than one file is specified, each file must start on a\n    section boundary, so the first keyword of each file must be one of\n    \"global\", \"defaults\", \"peers\", \"listen\", \"frontend\", \"backend\", and so on.\n    A file cannot contain just a server list for example.\n</code></pre> <p>Tous les fichiers se terminant par .cfg seront charg\u00e9s par HAproxy par ordre alphab\u00e9tique.</p> <p>Voici la configuration lanc\u00e9e par d\u00e9faut via l'unit systemd :</p> <pre><code>ExecStartPre=/usr/sbin/haproxy -f ${CONFIG} -c -q\nExecStart=/usr/sbin/haproxy-systemd-wrapper -f ${CONFIG} -p /run/haproxy.pid $EXTRAOPTS\n</code></pre>"},{"location":"linux/hosting/lemp/haproxy/overview/#configuration-haproxy","title":"Configuration HAproxy","text":"<p>Pour rappel, avec une configuration splitted de HAproxy, il va lire les fichiers par ordre alphab\u00e9tique, il est donc important d'avoir les sections global et defaults avant les frontend et backend. Pour \u00eatre s\u00fbr de l'ordre, vous pouvez prefix vos fichiers avec des num\u00e9ros.</p>"},{"location":"linux/hosting/lemp/haproxy/overview/#global","title":"Global","text":"<p>Comme son nom l'indique, toute la partie globale concerne les directives propres au fonctionnement interne de HAproxy. Voici un exemple simple, que nous allons retrouver dans un grand nombre de configuration HAproxy</p> HAproxy: Global section <pre><code>global\n    maxconn 50000\n    log /dev/log local0\n    user haproxy\n    group haproxy\n    stats socket /run/haproxy/admin.sock user haproxy group haproxy mode 660 level admin\n    nbproc 2\n    nbthread 4\n    cpu-map auto:1/1-4 0-3\n    daemon\n    ssl-default-bind-ciphers ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256\n    ssl-default-bind-options ssl-min-ver TLSv1.2 no-tls-tickets\n</code></pre> <ul> <li><code>maxconn</code> nous permet de limiter le nombre de connexions accept\u00e9es par HAproxy pour pr\u00e9munir un manque de m\u00e9moire. Attention \u00e0 ne pas faire un sizing trop juste, ce qui nous induirait un drop de connexions l\u00e9gitimes.</li> <li><code>log</code> nous permet de sp\u00e9cifier o\u00f9 sont renvoy\u00e9s les logs. Dans notre cas, nous les loggerons dans rsyslog (/dev/log) en tant que local0. rsyslog s'occupera de traiter les logs. (par d\u00e9faut, \u00e9criture dans /var/log/syslog).</li> <li><code>user/group</code> indique \u00e0 haproxy qu'il ne faut pas lancer les fork en tant que root, mais en tant qu'haproxy dans notre cas.</li> <li><code>stats socket</code> nous permet de d\u00e9finir un socket afin d'y extraire les stats ou autre. Il est \u00e9galement possible d'\u00e9crire la configuration de HAproxy via ce moyen. Attention \u00e0 donc bien restreindre les privil\u00e8ges.     <ul> <li>SleepLessBeastie a \u00e9crit un excellent article sur la d\u00e9finition des privil\u00e8ges et comment interagir avec l'API.</li> </ul> </li> <li><code>nbproc/nbthread</code> sont les param\u00e8tres permettant \u00e0 HAproxy de scale. Nous pouvons utiliser nbproc ind\u00e9pendamment de nbthread. Chaque process dispose de ses propres stats, tables de persistances... Tous les threads disposent cependant des m\u00eames informations.     <ul> <li>Il est largement d\u00e9conseill\u00e9 d'utiliser plusieurs processus sur HAproxy </li> <li>Ces options requi\u00e8rent la pr\u00e9sence de la directive daemon afin de lancer HAproxy en tant que daemon.</li> </ul> </li> <li><code>cpu-map</code> nous permet de profiter totalement de nos diff\u00e9rents cores CPU afin de bind 1 thread/core</li> <li><code>daemon</code> permet de lancer HAproxy en tant que daemon.</li> <li><code>ssl-default-bind-ciphers/ssl-default-bind-options</code> configure tout ce qui est relatif au TLS. La premi\u00e8re option configure les ciphers et la seconde configure les versions autoris\u00e9es de TLS minimum...     <ul> <li>La fondation Mozilla propose un configurateur offrant une configuration alliant s\u00e9curit\u00e9 &amp; compatibilit\u00e9 de \u00e9quipements. Le profil Intermediate est adapt\u00e9 pour une utilisation en production. Modern est trop restrictif.</li> </ul> </li> </ul>"},{"location":"linux/hosting/lemp/haproxy/overview/#defaults","title":"Defaults","text":"<p>Votre configuration est \u00e9volution, c'est pour cela que la cat\u00e9gorie <code>defaults</code> existe. Les param\u00e8tres seront appliqu\u00e9s pour la section frontend mais \u00e9galement pour les backends. Vous pouvez overwrite vos param\u00e8tres pour un frontend/backend sp\u00e9cifique par la suite</p> HAproxy: Default section <pre><code>defaults\n    mode http\n    log global\n\n    option httplog\n    option dontlognull\n\n    timeout connect 10s\n    timeout client 30s\n    timeout server 30s\n\n    timeout http-request 5s\n    timeout http-keep-alive 125s\n\n    timeout client-fin 30s\n    timeout tunnel 1h\n\n    http-reuse safe\n</code></pre> <ul> <li><code>mode http</code> indique \u00e0 HAproxy de fonctionner en tant que balancer HTTP et non simplement TCP. L\u00e9g\u00e8rement plus lent que le TCP mais nous permet une granularit\u00e9 de configuration bien sup\u00e9rieure</li> <li>N'oubliez pas que HAproxy est \u00e9galement un load-balancer L4. Il     est donc possible de balancer tout type de traffic (mysql,     rabbitmq, mongodb...)</li> <li><code>log global</code> indique \u00e0 chaque frontend suivant d'utiliser le param\u00e8tre log contenu dans la section global. Cela nous \u00e9vite de devoir le red\u00e9finir pour chaque frontend.</li> <li><code>option httplog</code> indique \u00e0 HAproxy de fournir un syslog un format de log plus d\u00e9taill\u00e9. Il existe \u00e9galement l'attribut <code>tcplog</code> si vous utilisez le load-balancer en tant que balancer L4 (TCP)</li> <li><code>option dontlognull</code> permet de ne pas logger les sessions n'ayant donn\u00e9 aucun \u00e9change de donn\u00e9e (requ\u00eate ou r\u00e9ponse)     <ul> <li>Il peut \u00eatre int\u00e9ressant de les log en pour avoir des logs bien plus d\u00e9taill\u00e9s. Peut-\u00eatre utile en cas de saturation socket (DOS ou autre). </li> <li>Certaines m\u00e9thodes (tel qu'un monitoring ou autre) peuvent \u00e9galement g\u00e9n\u00e9rer certaines de ces requ\u00eates. Il peut \u00eatre int\u00e9ressant d'activer cette option dans ce cas</li> </ul> </li> <li><code>timeout connect...</code> sp\u00e9cifie les diff\u00e9rents timeout (connect, server)...     <ul> <li>Il peut \u00eatre int\u00e9ressant de sp\u00e9cifier diff\u00e9rentes valeurs de timeout afin de faciliter le debug</li> </ul> </li> </ul> <ul> <li><code>http-reuse safe</code> est l'option par d\u00e9faut. Nous nous assurons via le param\u00e8tre <code>safe</code> que le serveur ferme la connexion lorsque quand la requ\u00eate a \u00e9t\u00e9 envoy\u00e9e</li> </ul>"},{"location":"linux/hosting/lemp/haproxy/overview/#frontend","title":"Frontend","text":""},{"location":"linux/hosting/lemp/haproxy/overview/#definition","title":"D\u00e9finition","text":"<p>Les frontends sont utilis\u00e9s pour d\u00e9finir comment les demandes doivent \u00eatre transmises aux backends. Ils se composent des \u00e9l\u00e9ments suivants :</p> <ul> <li>Adresses IP/Ports</li> <li>ACLs</li> <li>R\u00e8gles quant \u00e0 l'utilisation sp\u00e9cifiques de backends</li> </ul>"},{"location":"linux/hosting/lemp/haproxy/overview/#exemple-basique","title":"Exemple basique","text":"<p>L'exemple suivant est l'exemple le plus simple que nous pouvons faire sur HAproxy. HAproxy va \u00e9couter sur le port 80 et tout renvoyer le traffic vers le backend servers. Nous n'utilisons aucune ACL ici.</p> HAproxy : Simple frontend <pre><code>    frontend http-in\n        bind *:80\n        default_backend servers\n</code></pre>"},{"location":"linux/hosting/lemp/haproxy/overview/#exemple-avance-acl","title":"Exemple avanc\u00e9 : ACL","text":"<p>Un exemple avanc\u00e9 est l'utilisation d'une ACL. Il existe beaucoup de types d'ACL, que ce soir sur l'URI, les param\u00e8tres... Nous allons voir un exemple simple avec l'utilisation d'une ACL sur le nom de domaine.</p> HAproxy : Simple frontend w/ ACL <pre><code>frontend http\n   bind *:80\n\n   # On d\u00e9finit des ACL qui associe un Host: HTTP \u00e0 un backend\n   acl wiki hdr(host) -i wiki.jdelgado.fr\n   acl site hdr(host) -i jdelgado.fr\n\n   use_backend wiki if wiki\n   use_backend site if site\n\n   default_backend undefined\n</code></pre> <p>Nous d\u00e9finissons ici un backend par d\u00e9faut. Il est possible de ne pas en d\u00e9finir et HAproxy renverra une erreur 421 de lui m\u00eame.</p>"},{"location":"linux/hosting/lemp/haproxy/overview/#backend","title":"Backend","text":"<p>Les backends sont la force de HAproxy, enti\u00e8rement modulables, nous pouvons r\u00e9ellement faire ce que l'on souhaite avec ceux-ci. Prenant cet exemple simple :</p>"},{"location":"linux/hosting/lemp/haproxy/overview/#multiples-servers","title":"Multiples servers","text":"HAproxy : Multiple backends <pre><code>    backend web_servers\n        server server1 10.0.1.3:80\n        server server2 10.0.1.4:80\n</code></pre> <p>Nous avons ici 2 server d\u00e9nomm\u00e9 respectivement server1 et server2 sur les IPs 10.0.1.3 et 10.0.1.4 \u00e9coutant sur le port 80. Nous n'avons ici aucun param\u00e8tre sp\u00e9cifique sur un \u00e9ventuel check de disponiblit\u00e9 ou autre, chacun recevra 50% du traffic</p>"},{"location":"linux/hosting/lemp/haproxy/overview/#multiples-avec-persistance","title":"Multiples avec persistance","text":"<p>Nous pouvons demander \u00e0 HAproxy de d\u00e9poser un cookie sur le client pour effectuer un \u00e9quilibrage de charge :</p> HAproxy : Multiple backends with persistance <pre><code>    backend web_servers\n        balance roundrobin\n        cookie srvid insert indirect nocache\n        option httpchk HEAD /\n        server server1 10.0.1.3:80 cookie server1\n        server server2 10.0.1.4:80 cookie server2\n</code></pre> <p>Le client recevra un cookie d\u00e9nomm\u00e9 srvid qui sera utilis\u00e9 par haproxy pour balancer le traffic en round-robin.</p>"},{"location":"linux/hosting/lemp/haproxy/overview/#actifpassif","title":"Actif/Passif","text":"<p>Il est possible d'avoir plusieurs servers sur le m\u00eame backend mais n'en utiliser qu'un '\"primaire'\". Il suffit d'ajouter le mot clef <code>backup</code> au serveur secondaire :</p> HAproxy : Multiple backends with backup <pre><code>    backend web_servers\n        server server1 10.0.1.3:80\n        server server2 10.0.1.4:80 backup\n</code></pre>"},{"location":"linux/hosting/lemp/haproxy/overview/#check-http","title":"Check HTTP","text":"HAproxy : Multiple backends with HTTP check <pre><code>    backend web_servers\n        option httpchk HEAD /\n        server server1 10.0.1.3:80\n        server server2 10.0.1.4:80\n</code></pre> <p>Il s'agit ici du m\u00eame backend qu'au pr\u00e9alable mais avec une diff\u00e9rence importante, la pr\u00e9sence de <code>httpchk</code>. Nous avons ici la pr\u00e9sence d'un v\u00e9ritable check L7 au lieu d'un check TCP L4. HAproxy sera ici capable de distinguer un serveur HTTP down au niveau L7 (tel qu'une erreur 50x). Il est possible d'affiner le check, nous avons ici une simple requ\u00eate HEAD sur /</p> <pre><code>     option httpchk GET / HTTP/1.1\\r\\nHost:\\ www.jdelgado.fr\\r\\nUser-Agent:\\ haproxy_check\n     http-check expect status 200\n</code></pre> <p>Ce test est l\u00e9g\u00e8rement plus d\u00e9taill\u00e9. Nous sp\u00e9cifions ici un Host \u00e0 utilis\u00e9 (www.jdelgado.fr) ainsi que l'user-agent. Nous sp\u00e9cifions \u00e9galement que nous attendons un retour 200 (OK).</p>"},{"location":"linux/hosting/lemp/haproxy/overview/#check-specifiques","title":"Check sp\u00e9cifiques","text":"<p>HAproxy int\u00e8gre diff\u00e9rents checks pour diff\u00e9rents protocoles. Voici les checks disponibles</p> <ul> <li>option mysql-check</li> <li>option pgsql-check</li> <li>option redis-check</li> <li>option smtpchk</li> </ul>"},{"location":"linux/hosting/lemp/haproxy/overview/#divers","title":"Divers","text":""},{"location":"linux/hosting/lemp/haproxy/overview/#compression-gzip","title":"Compression GZIP","text":"<p>On peut activer la compression gzip directement au niveau de HAproxy. G\u00e9nial si le backend ne le g\u00e8re pas :</p> <pre><code>compression algo gzip\ncompression type text/html text/plain text/xml text/css text/javascript application/javascript application/json text/json\n</code></pre>"},{"location":"linux/hosting/lemp/haproxy/overview/#desactiver-tous-les-logs","title":"D\u00e9sactiver tous les logs","text":"<p>Par d\u00e9faut, HAproxy log des \u00e9v\u00e8nements. Il ne suffit pas d'enlever l'option tcplog ou autre.</p> <p>Dans la section defaults, il faut ajouter ceci :</p> <pre><code>option dontlog-normal\n</code></pre>"},{"location":"linux/hosting/lemp/haproxy/overview/#backend-cache","title":"Backend cache","text":"<p>Si vous utilisez un cache en backend (tel que varnish), il est alors tr\u00e8s int\u00e9ressant de sp\u00e9cifier le type de balance. balance uri whole indique \u00e0 haproxy de toujours envoyer le traffic pour une URI sp\u00e9cifique vers le m\u00eame backend. Ainsi, nous maximisons le hitrate.</p> HAproxy : Backend Varnish <pre><code>```vcl\nbackend varnish\n    timeout     check 3000\n    balance uri whole\n    hash-type consistent\n\n    server      varnish01  varnish01.vlan:82  check\n    server      varnish02  varnish02.vlan:82  check\n```\n</code></pre>"},{"location":"linux/hosting/lemp/haproxy/overview/#http-to-https","title":"HTTP to HTTPS","text":"<p>Il est facile de rediriger l'int\u00e9gralit\u00e9 du traffic HTTP vers HTTPS avec HAproxy. Ajoutez simplement la ligne suivante dans votre frontend :</p> <pre><code>    http-request redirect scheme https unless { ssl_fc }\n</code></pre> <p>Cependant, nous avons une 302 (redirection non permanente) via cette m\u00e9thode. Pour un usage durable dans le temps, nous pr\u00e9f\u00e9rons \u00e0 cela une 301 :</p> <pre><code>    http-request redirect scheme https code 301 unless { ssl_fc }\n</code></pre>"},{"location":"linux/hosting/lemp/haproxy/overview/#rediriger-des-urls-specifiques-vers-dautres","title":"Rediriger des URLs sp\u00e9cifiques vers d'autres","text":"<p>Si pour quelconques raison vous voulez retournez des URLs custom selon des URI pr\u00e9cises, la mani\u00e8re la plus facile :</p> HAproxy : Using map <pre><code>    acl     acl           hdr_beg(host) -i monsite.fr\n    acl     acl           hdr_beg(host) -i www.monsite.fr\n    http-request redirect location %[capture.req.uri,map(/etc/haproxy/redirect.map)] code 301 if { capture.req.uri,map(/etc/haproxy/redirect.map) -i -m found } acl\n</code></pre> <p>Et le contenu du fichier redirect.map</p> <pre><code>$ cat redirect.map\nuri1.html https://monsite.fr/coucou\n</code></pre>"},{"location":"linux/hosting/mail/exim_manage_dkim/","title":"Configurer DKIM avec Exim","text":"<p>Pour configurer DKIM avec Exim, on s'emmerde pas, j'ai \u00e9cris un petit script pour faire \u00e7a</p> <pre><code>CUSTOMER=ei\nTYPE=prod\nSELECTOR=${TYPE}-${CUSTOMER}\n\n\nopenssl genrsa -out ${SELECTOR}.dkim.pkey.pem 1024\nopenssl rsa -in ${SELECTOR}.dkim.pkey.pem -out ${SELECTOR}.dkim.pem -pubout\ncommand sed -i -e /ifdef DKIM_DOMAIN/i'\n.ifndef DKIM_DOMAIN'\ndkim_domain = ${if match_domain{$sender_address_domain}{+local_domains} {$sender_address_domain} { '''\n    ${if match_domain{$sender_address_domain}{+cyrus_all_domains} {$sender_address_domain}  {}} '''\n  }}'\n.endif /etc/exim4/conf.d/transport/30_exim4-config_remote_smtp\n\n\nPUBLIC_KEY=\"$(command cat \"${SELECTOR}.dkim.pem\"|grep -v ''-|tr -d \\n)\"\ncommand echo \"# Dkim configuration for server with selector {$SELECTOR}.\n\n_asp._domainkey IN TXT '\"dkim=all'\"\n_adsp._domainkey IN TXT '\"dkim=all'\"\n_domainkey IN TXT '\"t=y; o=-;'\"\n\n${SELECTOR}._domainkey 1 IN TXT '\"v=DKIM1; k=rsa; p=${PUBLIC_KEY};'\"\n\"   Yes\n</code></pre> <p>Et c\u00f4t\u00e9 exim, \u00e7a se configure comme \u00e7a :</p> <pre><code>### main/02_exim4-config_dkim\n#################################\n\n# The signing method for DKIM\nDKIM_CANON = relaxed\n\n# Domain for which DKIM signing is used.\n# This option must be unset if multiple domains are handled by this server.\nDKIM_DOMAIN = ${sender_address_domain}\n\n# private key used for DKIM.\nDKIM_PRIVATE_KEY = /etc/exim4/keys/prod-ei.dkim.pkey.pem\n\n# DKIM selector, guessed from the DKIM private key file extension.\nDKIM_SELECTOR = prod-ei\n\n# Avoid message is too big error\nIGNORE_SMTP_LINE_LENGTH_LIMIT=1\n</code></pre> <p>Puis c\u00f4t\u00e9 DNS, \u00e7a nous donne ce genre de record :</p> <pre><code>    preprod-df._domainkey.dpfsol.net.   120 IN  TXT \"v=DKIM1; k=rsa; p=MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQDF2DawbF8KlxduaXU0GHp/VMTXPyhYvAr9/zWs6u3AqpktH4/+7u66BOf3NJvEmsuJezjwpYA8YmyJ4aRyRkOqeB+k1FeMadWtCkcy/LpBGkBbBCvb3QPDZRP85oiOR9Lt4Oo5/m+YKbwYkEIAe/5yHDMlXZ3NGEMDzalHbAcdRwIDAQAB;\"\n</code></pre>"},{"location":"linux/hosting/ruby/install/","title":"Installer Ruby","text":"<p>Installer Ruby, c'est chiant. Voici donc comment faire pour que ce soit un peu moins chiant :-)</p> <p>2 m\u00e9thodes sont possibles. rbenv ou ruby-build. Il est \u00e9galement possible d'utiliser ruby-build en tant que plugin de rbenv. Je conseille ruby-build si vous \u00eates en monolithique et rbenv si vous souhaitez pouvoir switch entre les environnements.</p>"},{"location":"linux/hosting/ruby/install/#rbenv","title":"rbenv","text":"<p>Tout simple.</p> <pre><code>apt install rbenv\nrbenv init\n</code></pre> <p>Attention, ruby sera install\u00e9 dans ~/.rbenv/xxx.</p> <p>On check apr\u00e8s les versions disponibles avec un rbenv install '--list-all. Il y en a une tonne.</p> <p>Installez celle que vous voulez (par ex: 2.7.4) puis d\u00e9finissez l\u00e0 par d\u00e9faut :</p> <pre><code>rbenv install 2.7.4\nrbenv global 2.7.4\n</code></pre>"},{"location":"linux/hosting/ruby/install/#troubleshooting","title":"Troubleshooting","text":"<p>Si vous n'avez pas la version d\u00e9sir\u00e9e, n'h\u00e9sitez pas \u00e0 installer ruby-build en plugin de rbenv :</p> <pre><code># As an rbenv plugin\n$ mkdir -p \"$(rbenv root)\"/plugins\n$ git clone https://github.com/rbenv/ruby-build.git \"$(rbenv root)\"/plugins/ruby-build\n</code></pre>"},{"location":"linux/hosting/ruby/install/#ruby-build","title":"ruby-build","text":"<p>ruby-build est plus rudimentaire que rbenv mais fait tr\u00e8s bien le taff. On commence par l'installer en standalone :</p> <pre><code># As a standalone program\n$ git clone https://github.com/rbenv/ruby-build.git\n$ PREFIX=/usr/local ./ruby-build/install.sh\n</code></pre> <p>Puis comme rbenv, on liste les versions dispo, et on installe celle qu'on veut :</p> <pre><code>ruby-build --definitions\nruby-build 2.7.4 /usr/local/ruby-2.7.4\n</code></pre> <p>Et voil\u00e0, on a un ruby tout beau</p>"},{"location":"linux/hosting/ruby/install/#troubleshooting_1","title":"Troubleshooting","text":"<p>Si ruby-build ne vous propose pas les bonnes versions, il faut l'upgrade pour reload sa liste de versions dispos.</p>"},{"location":"linux/memcached/misc_commands/","title":"Commandes diverses avec memcached","text":"<pre><code>exec {memcache}&lt;&gt;/dev/tcp/localhost/11211\nprintf \"stats items\\nquit\\n\" &gt;&amp;${memcache}\ncat &lt;&amp;${memcache} &gt; myfile.txt\n</code></pre> <p>Dump le contenu local du memcached</p>"},{"location":"linux/misc/autoupgrade/","title":"Mise \u00e0 jour automatique de ses paquets","text":""},{"location":"linux/misc/autoupgrade/#introduction","title":"Introduction","text":"<p>Nous le savons tous, mettre \u00e0 jour ses paquets est une op\u00e9ration longue et fastidieuse si nous poss\u00e9dons un nombre important de serveurs.</p> <p>Il nous arrive r\u00e9guli\u00e8rement d'oublier les mises \u00e0 jour, ce qui peut permettre \u00e0 certains pirates malveillants d'exploiter des failles de types 0day.</p> <p>Avec cet utilitaire, les paquets vont \u00eatre mis \u00e0 jour automatiquement, ce qui va nous \u00e9viter d'y penser, ou de le faire.</p> <p>Tout ce que nous avons \u00e0 faire est d'installer le paquage unattended-upgrades</p> <pre><code>apt-get -y install unattended-upgrades\n</code></pre> <p>Cependant, les mises \u00e0 jour automatiques ne sont pas activ\u00e9es par d\u00e9faut, nous devons donc reconfigurer le paquet</p> <pre><code>dpkg-reconfigure unattended-upgrades\n</code></pre> <p>Voici l'\u00e9cran que vous allez avoir :</p> <p></p> <p>Lorsque vous aurez cet \u00e9cran, r\u00e9pondez tout simplement oui pour avoir les mises \u00e0 jour quotidiennement</p> <p>Ce logiciel va g\u00e9n\u00e9rer des logs sauvegard\u00e9s dans /var/log/unattended-upgrades</p> <ul> <li>unattended-upgrades.log qui est un fichier g\u00e9n\u00e9ralis\u00e9 qui va     r\u00e9capituler toutes les actions du logiciel</li> <li>unattended-upgrades-dpkg'date'heure.log qui va indiquer ce     qui a \u00e9t\u00e9 fait un tel jour</li> </ul> <p>Toutes les options de configurations sont disponibles dans le fichier /etc/apt/apt.conf.d/50unattended-upgrades</p>"},{"location":"linux/misc/autoupgrade/#plus-dinformations","title":"Plus d'informations","text":"<ul> <li>Wiki Debian</li> <li>How To     Forge</li> <li>Debian     Handbook</li> <li>Guide     Ubuntu</li> </ul>"},{"location":"linux/misc/convert_bin_to_iso/","title":"Convertir des .bin en .iso","text":"<p>Un .bin est souvent probl\u00e9matique sur Windows. Pour \u00e9viter ce probl\u00e8me, Linux dispose d'un formidable outil appel\u00e9 iat.</p> <p>iat vous permet de convertir vos .bin, .mdf ou tout autre format farfelu en .iso d'une mani\u00e8re extr\u00eamement simpliste</p> <p>Il faut \u00e9videmment commencer par installer iat</p> <pre><code>apt install iat\n</code></pre> <p>Puis nous convertissons simplement notre fichier .bin en .iso</p> <pre><code>iat source.bin source.iso\n</code></pre> <p>Et voil\u00e0, apr\u00e8s processing de la part de iat, nous nous retrouvons avec un .iso pr\u00eat \u00e0 \u00eatre exploit\u00e9 sur les OS de votre choix.</p>"},{"location":"linux/misc/create_raid/","title":"Cr\u00e9ation de RAID logiciels avec mdadm","text":"<p>Cr\u00e9er son RAID avec mdadm est assez simple, cependant, il est toujours utile de rappeller les commandes \u00e9l\u00e9mentaires.</p>"},{"location":"linux/misc/create_raid/#differents-types-de-raid","title":"Diff\u00e9rents types de RAID","text":""},{"location":"linux/misc/create_raid/#raid0","title":"RAID0","text":"<p>Performances accrues, 0 s\u00e9curit\u00e9</p> <pre><code>mdadm --create /dev/md/name /dev/sda /dev/sdb --level=0 --raid-devices=2\n</code></pre>"},{"location":"linux/misc/create_raid/#raid1","title":"RAID1","text":"<p>Performances diminu\u00e9es, dupliques les donn\u00e9es sur 2 disques, bonne s\u00e9curit\u00e9</p> <pre><code>mdadm --create /dev/md/name /dev/sda /dev/sdb --level=1 --raid-devices=2\n</code></pre>"},{"location":"linux/misc/create_raid/#raid5","title":"RAID5","text":"<p>Bonnes performances, bonne s\u00e9curit\u00e9 grace \u00e0 son disk de spare</p> <pre><code>mdadm --create /dev/md/name /dev/sda /dev/sdb /dev/sdc --level=5 --raid-devices=3 --bitmap=internal\n</code></pre>"},{"location":"linux/misc/create_raid/#raid-complexe","title":"RAID Complexe","text":"<p>Pour cr\u00e9er un RAID complexe comme un RAID1+0, combinant un RAID1 et un RAID0, voici les \u00e9tapes \u00e0 suivre :</p> <pre><code>mdadm --create --verbose /dev/md0 --level=10 --raid-devices=4 /dev/sda /dev/sdb /dev/sdc /dev/sdd\n</code></pre> <p>Ce type de RAID nous permet d'avoir les performances d'un RAID0 avec la s\u00e9curit\u00e9 d'un RAID1 quid d'un grand nombre de devices \u00e0 utiliser.</p> <p>Reboot</p> <p>Il est important de ne pas reboot son serveur avec finalisation de cr\u00e9ation de RAID afin de ne pas perdre son RAID</p>"},{"location":"linux/misc/create_raid/#monter-son-raid","title":"Monter son RAID","text":"<p>Si votre RAID est d\u00e9j\u00e0 mont\u00e9, alors il suffira de faire la commande suivante pour l'assembler, puis de le monter traditionnellement avec mount</p> <pre><code>mdadm --assemble --scan\n</code></pre>"},{"location":"linux/misc/create_raid/#convertir-son-raid","title":"Convertir son RAID","text":"<p>Une op\u00e9ration int\u00e9ressante est la converssion d'un RAID1 en RAID5. Dans un premier temps, nous devons passer notre RAID1 en mode '\"degraded'\" puis ajouter le 3eme devices</p> <pre><code>mdadm --grow /dev/md/mirror --level=5\nmdadm --grow /dev/md/mirror --add /dev/sdc1 --raid-devices=3\n</code></pre>"},{"location":"linux/misc/create_raid/#supprimer-son-raid","title":"Supprimer son RAID","text":"<p>Si pour une quelconque vous souhaitez supprimer votre RAID, l'op\u00e9ration est simple :</p> <pre><code>mdadm --stop /dev/md0 ; mdadm --remove /dev/md0\n</code></pre> <p>Puis nous supprimons le superblock de l'\u00e9quipement :</p> <pre><code>mdadm --zero-superblock /dev/sdc\n</code></pre> <p>S'il s'agit d'un device en RAID1, alors celui-ci sera toujours utilisable sans devoir recr\u00e9er une partition</p>"},{"location":"linux/misc/create_raid/#monter-son-raid-au-demarrage","title":"Monter son RAID au d\u00e9marrage","text":"<p>Au d\u00e9marrage de l'OS, les devices sont vus comme ind\u00e9pendants, il est donc indispensable d'indiquer au syst\u00e8me comment utiliser les \u00e9quipements.</p> <pre><code>mdadm --detail --scan | tee -a /etc/mdadm/mdadm.conf\nupdate-initramfs -u -k all\n</code></pre> <p>N'oublions pas de monter notre partition dans le 'fstab'</p> <pre><code>echo /dev/md0 /mnt/md0 ext4 defaults,nofail,discard 0 0 | sudo tee -a /etc/fstab\n</code></pre> <p>A adapter selon votre syst\u00e8me bien \u00e9videmment</p>"},{"location":"linux/misc/find_kernel_options/","title":"Trouver les options de compilation du kernel","text":"<p>Il est possible de trouver les options de compilation de notre kernel en observant le fichier /proc/config.gz</p> <p>Cependant, celui-ci n'est disponible uniquement si le kernel a \u00e9t\u00e9 compil\u00e9 avec les options CONFIG_IKCONFIG et CONFIG_IKCONFIG_PROC</p> <p>Si ce fichier n'est pas disponible, les options de compilation seront disponibles dans /boot</p>"},{"location":"linux/misc/forgot_root_password/","title":"R\u00e9initialiser son mot de passe root","text":"<p>Pour r\u00e9initialiser son mot de passe root, une m\u00e9thode simple existe.</p> <p>Lors du GRUB, appuyer sur E pour passer en Edit Mode</p> <p>Vous allez voir une ligne commen\u00e7ant par linux /boot... et ajouter y \u00e0 la fin init=/bin/bash. Appuyer sur Ctrl+X pour que vos modifications soient uniquement appliqu\u00e9es une fois.</p> <p>Les modifications apport\u00e9es permettent de booter sur bash en tant que root sans connaitre le password.</p> <p>Une fois l'acc\u00e8s au prompt, il faut remonter la partition en RW</p> <pre><code>mount -rw -o remount /\n</code></pre> <p>Puis vous pourrez alors changer le password avec l'instruction passwd</p>"},{"location":"linux/misc/info_about_pdf/","title":"Obtenir des informations sur vos PDF","text":"<p>Pour obtenir des infos utiles sur vos PDF, petit trick bien sympa, requiert un paquet :</p> <pre><code>[[ $(uname) == Darwin ]] &amp;&amp; brew install exiftool || apt install libimage-exiftool-perl\n</code></pre> <p>Puis on utilise simplement la commande :</p> <pre><code>\u03bb yann ~ \u2192  exiftool -a -G1 TCL.pdf\n[ExifTool]      ExifTool Version Number         : 12.00\n[System]        File Name                       : TCL.pdf\n[System]        Directory                       : .\n[System]        File Size                       : 255 kB\n[System]        File Modification Date/Time     : 2020:10:27 17:03:43+01:00\n[System]        File Access Date/Time           : 2020:11:23 14:46:10+01:00\n[System]        File Inode Change Date/Time     : 2020:10:27 17:03:51+01:00\n[System]        File Permissions                : rw-r--r--\n[File]          File Type                       : PDF\n[File]          File Type Extension             : pdf\n[File]          MIME Type                       : application/pdf\n[PDF]           PDF Version                     : 1.4\n[PDF]           Linearized                      : No\n[PDF]           Modify Date                     : 2020:10:27 17:00:29+01:00\n[PDF]           Create Date                     : 2020:10:27 17:00:29+01:00\n[PDF]           Producer                        : iText 2.1.4 (by lowagie.com)\n[PDF]           Page Count                      : 1\n</code></pre> <p>Diverses infos qui peuvent +/- \u00eatre utiles, \u00e9galement dispo pour tout type de m\u00e9dia.</p>"},{"location":"linux/misc/locales/","title":"Gagner de la place en supprimant les locales inutiles","text":"<p>Les locales sont des fichiers sous Linux prenant plus ou moins de place comprenant diff\u00e9rents \u00e9l\u00e9ments pour la langue.</p> <p>Ceux-ci p\u00e8sent plus ou moins lourd, mais toute fois, il s'agit d'un moyen facile pour gagner de la place.</p> <p>On commence par installer le binaire, localepurge</p> <pre><code>apt-get -y install localepurge\n</code></pre> <p>Laissez les options par d\u00e9faut pour le moment, nous reviendrons sur la configuration plus tard.</p> <p>Pour configurer le paquet, voici comment proc\u00e9der :</p> <pre><code>dpkg-reconfigure localepurge\n</code></pre> <p>http://memo-linux.com/localepurge-faire-de-la-place-sur-son-disque-en-supprimant-les-locales/</p>"},{"location":"linux/misc/mancolor/","title":"Ajouter de la couleur \u00e0 sa commande man","text":"<p>Voil\u00e0 une astuce pour ajouter de la couleur \u00e0 sa commande man</p> <p>Concr\u00e8tement: voil\u00e0 le rendu finale de la manipulation :</p> <p></p> <p>Cela am\u00e9liore grandement la lisibilit\u00e9 de la commande man je trouve, et la rend plus agr\u00e9able \u00e0 l'utiliser. Il se peut que les couleurs soient plus agressives, j'utilise un th\u00e8me un peu moins flashy pour reposer les yeux :D</p> <p>Pour obtenir ce r\u00e9sultat, il y a deux moyens, installer un programme qui se nomme most, ou bien en exportant quelques variables. Je vais d\u00e9tailler les 2 m\u00e9thodes, mais personnellement, j'utilise la 2nd m\u00e9thode, car elle fait totalement pareil que la 1\u00e8re m\u00e9thode, sans l'ajout d'un paquet inutile.</p> <p>Pour la 1\u00e8re m\u00e9thode, comme d'habitude, il suffit d'installer simplement un paquet</p> <pre><code>apt-get install most\n</code></pre> <p>Puis exporter la commande dans votre ''.bashrc ''</p> <pre><code>echo \"export MANPAGER='\"/usr/bin/most -s'\"\" &gt;&gt; ~/.bashrc\n</code></pre> <p>Il faut refaire la commande export pour chaque utilisateur</p> <p>Pour la seconde m\u00e9thode, il faut exporter plusieurs variables dans votre .bashrc :</p> <pre><code>cat &gt;&gt; ~/.bashrc &lt;&lt; EOF\nexport LESS_TERMCAP_mb=$'E[01;31m\nexport LESS_TERMCAP_md=$'E[01;31m\nexport LESS_TERMCAP_me=$'E[0m\nexport LESS_TERMCAP_se=$'E[0m\nexport LESS_TERMCAP_so=$'E[01;44;33m\nexport LESS_TERMCAP_ue=$'E[0m\nexport LESS_TERMCAP_us=$'E[01;32m\nexport PAGER=less\nEOF\n</code></pre> <p>Comme pour la commande pr\u00e9c\u00e9dente, Il faut refaire les commandes export pour chaque utilisateur</p> <p>Et enfin, pour pouvoir admirer votre magnifique man sans quitter et r\u00e9-ouvrir votre client SSH, voici la commande \u00e0 effectuer</p> <pre><code>source ~/.bashrc\n</code></pre>"},{"location":"linux/misc/rc_package/","title":"Enlever les paquets '\"rc'\" sur dpkg","text":"<p>Les paquets en '\"rc'\" sur dpkg sont juste des paquets qui n'ont pas \u00e9t\u00e9 enlev\u00e9s \u00e0 100%</p> <p>G\u00e9n\u00e9ralement, il reste des fichiers de configuration</p> <p>Pour les enlever \u00e0 100%, voici la commande \u00e0 ex\u00e9cuter</p> <pre><code>dpkg --list |grep \"^rc\" | cut -d \" \" -f 3 | xargs dpkg --purge\n</code></pre> <p>Via cette commande, nous choisissons uniquement les paquets commen\u00e7ant par '\"rc'\", puis nous prenons leur nom, et enfin, pour chacune des lignes, nous faisons un dpkg '--purge</p>"},{"location":"linux/misc/subs/","title":"T\u00e9l\u00e9charger ses sous-titres en ligne de commande","text":"<p>Pour t\u00e9l\u00e9charger ses sous-titres en ligne de commande, il existe un super outil appel\u00e9 addic7ed-cli</p> <p>Comme son nom l'indique, cet outil va nous permettre de t\u00e9l\u00e9charger nos sous-titres depuis Addic7ed.</p> <p>Pour l'installer, \u00e9tant donner qu'il s'agit ici un programme \u00e9crit en Python, nous allons utiliser le gestionnaire de paquet pip.</p> <pre><code>pip install addic7ed-cli\n</code></pre> <p>Pour t\u00e9l\u00e9charger un sous-titre, il nous suffit de faire la commande suivante</p> <pre><code>addic7ed -l french -l english The.Serie.S02E23.MDR.mkv\n</code></pre> <p>Dans cet exemple, nous allons t\u00e9l\u00e9charger les subs fran\u00e7ais et anglais pour The Serie 223.</p> <p>Le nommage de l'\u00e9pisode est important. Avec un mauvais nommage, le script ne trouvera pas de subs.</p>"},{"location":"linux/monitoring/eztools/","title":"Les outils eZ Server, des outils simple de supervision","text":""},{"location":"linux/monitoring/eztools/#preambule","title":"Pr\u00e9ambule","text":"<p>'### eZ Server Monitor est une suite d'outil se d\u00e9composant en 2 parties : eZ Server Monitor SH, qui, comme son nom l'indique, permet de voir la plupart des \u00e9l\u00e9ments int\u00e9ressants de son syst\u00e8me, et eZ Server Monitor WEB qui permet d'avoir une vue globale de son syst\u00e8me via son navigateur web.' Ceux-ci ont \u00e9t\u00e9 d\u00e9velopp\u00e9s par un jeune fran\u00e7ais du pseudo de '@shevabam '### [Voici le rendu :]{.underline}</p>"},{"location":"linux/monitoring/eztools/#installation-ez-server-monitor-sh","title":"Installation eZ Server Monitor SH","text":"<p>Pour l'installer, rien de plus simple, on t\u00e9l\u00e9charge la paquet</p> <pre><code>wget -O ezservercli.zip http://www.ezservermonitor.com/esm-sh/downloads/version/2.3\n</code></pre> <p>Ne pas oublier de se rendre sur le site du projet pour v\u00e9rifier les mises \u00e0 jour ainsi que le GitHub</p> <p>On extrait le fichier de l'archive</p> <pre><code>unzip ezservermonitor-sh_v2.3.zip\n</code></pre> <p>On le rend ex\u00e9cutable</p> <pre><code>chmod +x eZServerMonitor.sh\n</code></pre> <p>Et enfin, une chose qui n'est pas oblig\u00e9e mais je d\u00e9place le fichier dans un r\u00e9pertoire de mon '$PATH, et je le renomme en quelque chose de simple comme monitor pour y acc\u00e9der simplement</p> <pre><code>mv eZServerMonitor.sh monitor.sh &amp;&amp; move monitor.sh /usr/bin\n</code></pre> <p>Voici les options disponibles pour eZ Server Monitor SH</p> <ul> <li>-h, -u, '--help ou '--usage : Affiche le message     d'aide</li> <li>-v ou '--version : Affiche le num\u00e9ro de version du script</li> <li>-C ou '--clear : Clear la console</li> <li>-a ou '--all : Affiche toutes les informations</li> <li>-s ou '--system : Affiche des informations syst\u00e8me de base</li> <li>-e ou '--services : V\u00e9rifie si les services sont ups ou pas</li> <li>-n ou '--network : Affiche les informations sur le r\u00e9seau</li> <li>-p ou '--ping : Pings diff\u00e9rents hosts selon la     configuration</li> <li>-c ou '--cpu : Information sur le processeur</li> <li>-m ou '--memory : Informations sur la RAM</li> <li>-l ou '--load : Affiche le load et des infos sur les     processus</li> <li>-t ou '--temperatures : Affiche les temp\u00e9ratures CPU,     HDD...</li> <li>-d ou '--disk : Affiche les diff\u00e9rents disques</li> </ul> <p>Il est \u00e9galement possible de configurer le script en d\u00e9but de celui-ci.</p>"},{"location":"linux/monitoring/eztools/#installation-ez-server-monitor-web","title":"Installation eZ Server Monitor WEB","text":"<p>eZ Server Monitor est une suite extr\u00eamement pratique pour monitorer son serveur depuis une page Web, o\u00f9 l'on peut y retrouver toutes les informations essentielles :</p> <p></p> <p>Dans cette page, nous pouvons y observer diff\u00e9rents \u00e9l\u00e9ments :</p> <ul> <li>System o\u00f9 l'on y retrouve nos informations de base (OS,     Kernel..)</li> <li>Load Average o\u00f9 l'on peut observer notre occupation globale de     notre syst\u00e8me</li> <li>Network Usage qui affiche les diff\u00e9rentes interfaces, ainsi que     les donn\u00e9es transmit</li> <li>CPU qui montre les caract\u00e9ristiques de son CPU</li> <li>Disk Usage nous indique l'occupation de notre/nos disque(s) dur</li> <li>Memory qui montre notre RAM totale, utilis\u00e9e et disponible</li> <li>SWAP qui fonctionne comme la RAM (Attention, montre 100% si le     SWAP est d\u00e9sactiv\u00e9)</li> <li>Last Login montre les 5 derni\u00e8res connexion</li> <li>Ping montre la latence sur diff\u00e9rents hosts (Attention, si un     host r\u00e9pond pas, le module plante)</li> <li>Service Status montre si diff\u00e9rents services sont disponibles ou     pas</li> </ul> <p>Pour l'installer, rien de plus simple, il suffit d'avoir son serveur web avec PHP de configurer. Voil\u00e0 le block \u00e0 faire pour son serveur nginx si l'on veut un sous-domaine</p> <pre><code>server {\n    listen 80;\n    return 301 https://$host$request_uri;\n    server_name monitor.domain.tld;\n}\nserver {\n    listen 443 ssl spdy;\n    server_name monitor.domain.tld;\n\n    auth_basic \"Monitor Axx\";\n    auth_basic_user_file \"/etc/nginx/passwd/monitor_passwd\";\n\n    error_log /var/log/nginx/monitor.error.log;\n    access_log /var/log/nginx/monitor.access.log;\n\n    root /var/www/monitor;\n\n    include /etc/nginx/conf.d/php;\n    include /etc/nginx/conf.d/cache;\n}\n</code></pre> <p>N'oubliez pas de g\u00e9n\u00e9rer le fichier monitor_passwd \u00e0 l'aide de la commande htpasswd ou encore via des sites internets tels que HTAccess Tools</p> <p>Et voici le bout de code \u00e0 ajouter \u00e0 son block principal si l'on ne veut pas de eZ Server Monitor Web en sous-domaine :</p> <pre><code>        location ^~ /monitor/ {\n            include /etc/nginx/conf.d/php;\n            include /etc/nginx/conf.d/cache;\n            auth_basic \"Monitor Axx\";\n            auth_basic_user_file \"/etc/nginx/passwd/monitor_passwd\";\n            deny all;\n        }\n</code></pre> <p>eZ Server Monitor Web est totalement configurable via le fichier esm.config.json se situant \u00e0 la racine de l'application. Celui-ci contient divers \u00e9l\u00e9ments de configuration</p> <ul> <li>disk qui permet de montrer la partition tmpfs ou pas</li> <li>hosts qui permet de configurer les diff\u00e9rents sites \u00e0 ping</li> <li>last_login pour param\u00e9trer combien de login seront affich\u00e9s sur     le site</li> <li>services pour param\u00e9trer diff\u00e9rents services \u00e0 monitorer</li> </ul>"},{"location":"linux/monitoring/munin/","title":"Munin : l'outil de supervision sans fioritures","text":""},{"location":"linux/monitoring/munin/#installation-sous-debian-80-jessie","title":"Installation sous Debian 8.0 Jessie","text":""},{"location":"linux/monitoring/munin/#explications","title":"Explications","text":"<p>L'application munin se compose de 2 parties :</p> <ol> <li>Munin (master pour les syst\u00e8mes BSD qui sont plus explicites) qui se     charge de g\u00e9n\u00e9rer les pages web et de r\u00e9aliser les graphiques \u00e0     partir des donn\u00e9es...</li> <li>fournies par Munin node qui se charge \u00e0 l'aide de '\"sondes'\"     \u00e9crites en perl ou en shell script de g\u00e9n\u00e9rer les fichiers RRD qui     vont bien. Le d\u00e9mon \u00e9coute par d\u00e9faut sur le port TCP 4949.</li> </ol>"},{"location":"linux/monitoring/munin/#prerequis","title":"Pr\u00e9requis","text":"<p>Il faut poss\u00e9der une Debian Jessie \u00e0 jour. Veuillez noter que, si vous n'avez pas modifi\u00e9 le fichier Preferences pour APT, installer munin revient \u00e0 installer munin (master) et munin-node. Pour ce bloc-notes, nous nous positionnerons sur un sch\u00e9ma de fonctionnement le plus simple possible : munin et munin-node sont sur la m\u00eame machine (physique ou virtuelle). Si vous disposez d'un Debian Wheezy, remplacez simplement les commandes apt par apt-get, et remplacez systemctl par service</p> <pre><code>sudo apt install munin\nsudo apt install munin-plugins-extra\n</code></pre> <p>Veuillez noter que certains plugins tiers peuvent n\u00e9cessiter des programmes additionnels (bien souvent en perl tels ceux requis pour surveiller nginx).</p>"},{"location":"linux/monitoring/munin/#configuration-basique","title":"Configuration basique","text":"<p>On \u00e9dite /etc/munin.conf par exemple, sachant que la page web affichera monfqdn.demondomaine.grd :</p> <pre><code>[monfqdn.demondomaine.grd]\n    address :::1\n    use_node_name yes\n</code></pre> <p>Oui, IPv6 roulaize.</p> <p>[Petit moment s\u00e9curit\u00e9]{.underline}</p> <p>La configuration par d\u00e9faut du paquet Debian fait \u00e9couter le d\u00e9mon munin-node sur toutes les interfaces r\u00e9seaux. Il serait peut-\u00eatre int\u00e9ressant de limiter l'\u00e9coute \u00e0 la boucle locale en \u00e9ditant /etc/munin-node.conf :</p> <pre><code>host ::1\n#host *\n</code></pre>"},{"location":"linux/monitoring/munin/#configuration-du-cgi","title":"Configuration du CGI","text":"<p>Depuis la version 2.0 (et m\u00eame un peu avant mais passons), munin sait g\u00e9n\u00e9rer des graphiques ainsi que des pages web de fa\u00e7on dynamique en lieu et place d'une b\u00eate t\u00e2che cron. Par la suite, je d\u00e9taillerai seulement la g\u00e9n\u00e9ration dynamique des graphiques et pas celles des pages web dont le comportement parfois al\u00e9atoire (au moins avec la version de munin fournie avec Wheezy) \u00e9tait d\u00e9sesp\u00e9rant.</p> <p>On rep\u00e8re les lignes int\u00e9ressantes dans /etc/munin.conf :</p> <pre><code>graph_strategy cgi\n#graph_strategy cron\n\ncgiurl_graph /munin-cgi/munin-cgi-graph\n#Important pour le serveur web\n</code></pre> <p>On installe spawn-fcgi :</p> <pre><code>apt install spawn-fcgi\n</code></pre> <p>On r\u00e9cup\u00e8re les fichiers d'init (pour Jessie, il est aussi possible de cr\u00e9er une unit\u00e9 ad\u00e9quate pour systemd mais je n'ai pas modifi\u00e9 ces fichiers depuis Wheezy et ils continuent de fonctionner avec Jessie) :</p> <pre><code>sudo wget http://files.julienschmidt.com/public/cfg/munin/spawn-fcgi-munin-html\nsudo wget http://files.julienschmidt.com/public/cfg/munin/spawn-fcgi-munin-graph\nwget \"https://wiki.mirtouf.fr/lib/exe/fetch.php?media=munin:munin-cgi.tar.gz\" -O munin-cgi.tar.gz\n</code></pre> <p>Le premier est optionnel mais si vous \u00eates suffisamment malin, vous pourrez mettre en place une g\u00e9n\u00e9ration dynamique des pages web (c'est le m\u00eame principe).</p> <p>A modifier dans le fichier spawn-fcgi-munin-graph</p> <pre><code>       PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin\n       NAME=spawn-fcgi-munin-graph\n       PID_FILE=/var/run/munin/$NAME.pid\n       SOCK_FILE=/var/run/munin/$NAME.sock\n       SOCK_USER=www-data\n       FCGI_USER=www-data\n       FCGI_GROUP=www-data\n       FCGI_WORKERS=2\n       DAEMON=/usr/bin/spawn-fcgi\n       DAEMON_OPTS=\"-s $SOCK_FILE -F $FCGI_WORKERS -U $SOCK_USER -u $FCGI_USER -g $FCGI_GROUP -P $PID_FILE -- /usr/lib/munin/cgi/munin-cgi-graph\"\n</code></pre> <p>Veuillez noter que l'utilisateur de script doit \u00eatre le m\u00eame que celui de votre serveur web et la configuration de munin.conf doit \u00eatre en accord avec la derni\u00e8re ligne.</p> <p>N'oubliez pas d'activer le ou les scripts et rendre persistant leur d\u00e9marrage.</p> <ul> <li>Configuration du vhost nginx</li> </ul> <p>Je suppose que vous acc\u00e9derez \u00e0 l'adresse suivante : http://munin.fqdn.grd</p> <pre><code>       server {\n            server_name munin.fqdn.grd;\n            listen 80;\n            listen [::]:80;\n            return 301 https://$host$request_uri;\n      }\n\n      server {\n            server_name munin.fqdn.grd;\n            root /var/cache/munin/www;\n            http2 on;\n            listen 443 ssl;\n            listen [::]:443 ssl;\n            ssl_certificate /etc/ssl/private/certificate.crt;\n            ssl_certificate_key /etc/ssl/private/certificate.key;\n            index index.html;\n            rewrite ^([^.]*[^/])$ $1/ permanent;\n\n        location /munin/static/ {\n            alias /etc/munin/static/;\n        }\n\n        include /etc/nginx/conf.d/cache;\n\n        location ^~ /munin-cgi/munin-cgi-graph/ {\n             fastcgi_split_path_info ^(/munin-cgi/munin-cgi-graph)(.*);\n             fastcgi_param PATH_INFO $fastcgi_path_info;\n             fastcgi_pass unix:/run/munin/spawn-fcgi-munin-graph.sock;\n             include fastcgi_params;\n        }\n\n        location ~ /'.ht {\n            allow 127.0.0.1;\n            deny all;\n        }\n      }\n</code></pre> <p>En cas de g\u00e9n\u00e9ration dynamique des pages web :</p> <pre><code>location /munin/ {\n    fastcgi_split_path_info ^(/munin)(.*);\n    fastcgi_param PATH_INFO $fastcgi_path_info;\n    fastcgi_pass unix:/var/run/munin/fcgi-html.sock;\n    include fastcgi_params;\n}\n</code></pre>"},{"location":"linux/monitoring/munin/#redemarrage-des-services","title":"Red\u00e9marrage des services","text":"<pre><code>sudo systemctl restart munin-node.service\nsudo systemctl restart nginx.service\nsudo systemctl restart spawn-fcgi-munin-graph.service\nsudo systemctl restart spawn-fcgi-munin-html.service\n</code></pre>"},{"location":"linux/monitoring/munin/#test-grandeur-nature","title":"Test grandeur nature","text":"<p>Aller faire un tour sur la page http://munin.fqdn.grd et vous devriez voir appara\u00eetre sous peu de jolis graphiques cliquables.</p>"},{"location":"linux/monitoring/check_mk/add_slack_notification/","title":"Configurer des notifications Slack pour check_mk","text":"<p>\u00c0 l'heure actuelle o\u00f9 tout est converg\u00e9, la communication interne via des outils comme Slack ou Mattermost, le mail semble presque d\u00e9pass\u00e9. Dans cette optique, nous pouvons envoyer les notifications sur un channel Slack (ou bien Mattermost).</p>"},{"location":"linux/monitoring/check_mk/add_slack_notification/#configuration-slack","title":"Configuration Slack","text":"<p>Tout d'abord, il faut cr\u00e9er votre Webhook sur le panneau de configuration de votre Workspace. Pour cela, il faut choisir (ou cr\u00e9er) un chan o\u00f9 les messages du bot seront envoy\u00e9s ainsi que le nom du bot. Une fois cela fait, penser \u00e0 copier votre Webhook URL (De cette forme : https://hooks.slack.com/services/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)</p>"},{"location":"linux/monitoring/check_mk/add_slack_notification/#configuration-check_mk-cli","title":"Configuration check_mk (CLI)","text":"<p>Pour check_mk, nous allons utiliser un plugin disponible sur Github (rmblake/check_mk-slack) \u00e9crit en python.</p> <p>Dans le cas d'une installation via le package, il faudra placer le plugin dans /omd/sites/'/share/check_mk/notifications sans oublier de rendre le script ex\u00e9cutable <pre><code>\u03bb jeremy ~ \u2192 wget -O /omd/sites/**&lt;monsite&gt;**/share/check_mk/notifications https://raw.githubusercontent.com/rmblake/check_mk-slack/master/slack &amp;&amp; chmod +x /omd/sites/**&lt;monsite&gt;**/share/check_mk/notifications\n</code></pre> <p>Dans ce script, il faudra modifier quelques variables pour que celui-ci fonctionne</p> <pre><code>slack_path = \"/services/T6AE8D9QU/BE8UA9LUE/2DtDzTQ61UpURxc4kfMK74JF\"\nbot_name = \"Monitoring\"\nproxies = {}\n</code></pre> <p>Si tout vous semble correct, il est possible de tester le script en ligne de commande :</p> <pre><code>\u03bb jeremy ~ \u2192 export NOTIFY_HOSTNAME=TestHost\n\u03bb jeremy ~ \u2192 export NOTIFY_WHAT=\"\"\n\u03bb jeremy ~ \u2192 export NOTIFY_HOSTACKCOMMENT=false\n\u03bb jeremy ~ \u2192 export NOTIFY_NOTIFICATIONAUTHOR=\"\"\n\u03bb jeremy ~ \u2192 export NOTIFY_HOSTSTATE=DOWN\n\u03bb jeremy ~ \u2192 export NOTIFY_NOTIFICATIONTYPE=\"WARNING\"\n\u03bb jeremy ~ \u2192 ./slack\n</code></pre> <p>Si l'output de la commande est autre que 200 alors votre configuration est incorrecte</p>"},{"location":"linux/monitoring/check_mk/add_slack_notification/#configuration-check_mk-gui","title":"Configuration check_mk (GUI)","text":"<p>Pour que notre nouveau '\"service de notification'\" soit vu par Check_MK, il faut red\u00e9marrer le site</p> <pre><code>\u03bb jeremy ~ \u2192 omd restart &lt;monsite&gt;\n</code></pre> <p>Une fois la partie CLI correcte, nous allons maintenant configurer notre partie graphique afin de recevoir nos notifications via Slack.</p> <p>Pour cela, rendez-vous dans la partie Notifications de Check_MK et cliquer sur New Rule</p> <p>Dans la partie Notification method : Nous allons choisir CMK-Slack Websocket Notification en tant que Notification method avec comme option Call with the following parameters avec comme param\u00e8tre le nom de votre channel (Dans notre cas monitoring)</p> <p>Dans la partie Contact Selection, nous envoyons les notifications uniquement pour le contact cmkadmin (ou celui que vous souhaitez)</p> <p>Et voil\u00e0, nous avons d\u00e9sormais un syst\u00e8me de notification Slack fonctionnel</p>"},{"location":"linux/monitoring/lgtm/custom_metrics_nodeexporter/","title":"Ecrire une m\u00e9trique custom pour node_exporter","text":"<p>Grace au module textfile de node_exporter, nous pouvons introduire facilement des m\u00e9triques dans ce dernier.</p> <p>Voici un petit script bash qui va vous permettre d'avoir vos m\u00e9triques customs</p> <pre><code>#!/usr/bin/env bash\n\n# Adjust as needed.\nTEXTFILE_COLLECTOR_DIR=/var/lib/node_exporter/textfile_collector/\n# Note the start time of the script.\nSTART=\"$(date +%s)\"\n\n# Your code goes here.\nsleep 10\n\n# Write out metrics to a temporary file.\nEND=\"$(date +%s)\"\ncat &lt;&lt; EOF &gt; \"$TEXTFILE_COLLECTOR_DIR/myscript.prom.$$\"\nmyscript_duration_seconds $(($END - $START))\nmyscript_last_run_seconds $END\nEOF\n\n# Rename the temporary file atomically.\n# This avoids the node exporter seeing half a file.\nmv \"$TEXTFILE_COLLECTOR_DIR/myscript.prom.$$\" \\\n  \"$TEXTFILE_COLLECTOR_DIR/myscript.prom\"\n</code></pre> <p>La chose importante ici est l'utilisation d'un fichier temporaire en .$$ (qui contient le PID du process bash) afin de garantir une atomicit\u00e9 des donn\u00e9es pour ne pas avoir de donn\u00e9es corrompues (node_exporter ne scrape que les fichiers en .prom)</p> <p>Il est \u00e9videmment possible d'\u00e9crire un script custom en n'importe quel language (python, bash...).</p> <p>La communaut\u00e9 prometheus met en libre services quelques scripts qui peuvent \u00eatre utiles (m\u00e9triques NVME, updates APT...)</p>"},{"location":"linux/monitoring/lgtm/loki_alerting/","title":"G\u00e9n\u00e9rer des alertes depuis Loki","text":"<p>Avoir des logs c'est bien, les exploiter c'est mieux. Pour cela, nous pouvons g\u00e9n\u00e9rer des alertes et les remonter dans AlertManager, tout comme Prometheus.</p> <p>Les diff\u00e9rentes configuration sont valables pour le chart Helm officiel <code>grafana/loki</code></p> <p>Pour cela, la premi\u00e8re \u00e9tape est de link son Loki (plus particuli\u00e8rement le ruler de Loki) avec son instance de Prometheus :</p> Helm : Ruler Configuration <pre><code>loki:\n  rulerConfig:\n    evaluation_interval: 15s\n    enable_sharding: true\n    alertmanager_url: https://alertmanager.domain.tld/\n    enable_alertmanager_v2: true\n    storage:\n      type: local\n      local:\n        directory: /var/loki/rules\n    wal:\n      dir: \"/var/loki/wal-dir\"\n    remote_write:\n      enabled: true\n      client:\n        url: http://prometheus-server.dyn-tools.svc.cluster.local/api/v1/write\n</code></pre> <p>Dans ce bloc de configuration, nous d\u00e9finissons en r\u00e9alit\u00e9 plusieurs param\u00e8tres non directement li\u00e9s \u00e0 AlertManager:</p> <ul> <li><code>evaluation_interval</code> \u00e0 15s qui nous permet de r\u00e9\u00e9valuer les records toutes les 15 secondes et de les envoyer \u00e0 notre Prometheus</li> <li><code>enable_sharding</code> car nous disposons de plusieurs instances du ruler</li> <li><code>alertmanager_url</code> qui nous indique o\u00f9 envoyer les alertes</li> <li><code>enable_alertmanager_v2</code> car nous utilisons un AlertManager r\u00e9cent :)</li> <li><code>storage</code> et sub\u00e9quent car nous utilisons des r\u00e8gles locales.</li> <li>Dans un monde optimal, nous aurions du utiliser un backed remote type S3</li> <li><code>wal.dir</code> le chart Helm a un bug qui nous force \u00e0 override la valeur</li> <li><code>remote_write</code> et subs\u00e9quent pour envoyer nos records \u00e0 Prometheus (ou VictoriaMetrics...)</li> </ul> <p>Nous avons maintenant besoin de cr\u00e9er les r\u00e8gles Loki et diff\u00e9rents \u00e9l\u00e9ments li\u00e9s \u00e0 Kubernetes dans un fichier <code>loki-rules.yaml</code>:</p> Helm: loki-rules.yaml <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: loki-alerting-rules\n  labels:\n    release: monitoring-metrics\ndata:\n  rules.yaml: |\n    groups:\n      - name: BusinessAlarms\n        rules:\n          - record: overview:nodebidder:aerospike_error:sum_rate\n            expr: sum(rate({host=~\"node-bidder-.*\"} |~ \"AEROSPIKE_ERROR\"[1m])) by (pop)\n          - alert: AnalyzePipeLastHour\n            expr: (count_over_time({job=\"monitoring_business\"} |= \"last_hour_vs_last_6_hours,last_hour_vs_last_12_hours\"  | json result_code,task | result_code!=0 [1m])) &gt; 0\n            for: 2m\n            labels:\n              severity: critical\n              destination: monitoring-backend\n            annotations:\n              summary: \"`Analyze Pipe Last Hour` @ `{{ $labels.pop }}` has issues\"\n              description: \"`Analyze Pipe Last Hour` @ `{{ $labels.pop }}` has issues, please check Logs if you want more hints\"\n              url_grafana: \"https://grafana.domain.tld/d/8WbuKiBVz/monitoring-tasks-logs?orgId=1&amp;var-tasks={{ $labels.task }}\"\n</code></pre> <p>Vous pouvez le voir, tel que Prometheus, Loki peut g\u00e9rer les records et les alertes</p> <p>Comme d'habitude sur K8S, nous appliquons notre manifest</p> <pre><code>kubectl apply -f loki-rules.yaml\n</code></pre> <p>Pour appliquer les updates de rules, nous devons faire un rolling restart du statefulset loki-backend</p> <pre><code>kubectl rollout restart statefulset loki-backend\n</code></pre> <p>Enfin, nous montons les diff\u00e9rents volumes</p> Helm: Loki Volumes <pre><code>loki:\n  backend:\n    extraVolumeMounts:\n    - name: rules\n      mountPath: \"/var/loki/rules/fake\"\n    - name: loki-wal-dir\n      mountPath: \"/var/loki/wal-dir\"\n    extraVolumes:\n    - name: rules\n      configMap:\n        name: loki-alerting-rules\n    - name: loki-wal-dir\n      emptyDir: {}\n</code></pre>"},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/","title":"Netdata, Prometheus et Grafana : une stack de monitoring simple et puissante","text":""},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#introduction","title":"Introduction","text":"<p>Info</p> <p>Cette documentation contient utilise des versions des logiciels qui peuvent ne pas \u00eatre les derni\u00e8res sur le march\u00e9. N'oubliez pas de v\u00e9rifier</p> <p>Ces derniers temps, j'ai cherch\u00e9 quelques stacks de monitoring simples \u00e0 mettre en place mais \u00e9galement efficaces avec des m\u00e9triques pertinentes. Je suis pass\u00e9 par beaucoup de syst\u00e8mes de monitoring (Check_MK, Sensu, LibreNMS, Shinken...) sans avoir \u00e9t\u00e9 satisfait. Soit les m\u00e9triques n'\u00e9taient pas pertinentes ; soit l'installation \u00e9tait trop complexe... Bref, il y avait toujours quelque chose qui ne me convenait pas, c'est l\u00e0 que j'ai d\u00e9couvert Netdata, puis peu de temps apr\u00e8s, Prometheus et Grafana. Pour bien comprendre ce tutoriel, voici un lexique avec les notions de base :</p>"},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#lexique","title":"Lexique","text":"<ul> <li> <p>Stack : Une stack d'applications est une suite ou un ensemble d'applications qui aident \u00e0 r\u00e9aliser une t\u00e2che pr\u00e9cise.</p> </li> <li> <p>M\u00e9trique : Mesure pr\u00e9cise d'un composant (logiciel ou mat\u00e9riel), ex : Pourcentage de CPU utilis\u00e9 \u00e0 l'instant T...</p> </li> <li> <p>Exporter : Outil qui va r\u00e9colter les m\u00e9triques d'un syst\u00e8me (CPU utilis\u00e9, RAM utilis\u00e9e...), les traiter et les envoyer \u00e0 un logiciel.</p> </li> <li> <p>Recolter : Logiciel qui va s'occuper de stocker les m\u00e9triques envoy\u00e9es par l'exporter</p> </li> <li> <p>TSDB : Une Time Series Database (TSDB) est une base de donn\u00e9es optimis\u00e9e pour les donn\u00e9es horodat\u00e9es ou les s\u00e9ries chronologiques. Une '\"time serie'\" est seulement une suite de mesures ou \u00e9v\u00e8nements qui sont monitor\u00e9es, downsampled et agr\u00e9g\u00e9es dans le temps.</p> </li> <li> <p>Downsampling : Le downsampling (sous-\u00e9chantillonnage) est une op\u00e9ration math\u00e9matique extr\u00eamement simple permettant de cr\u00e9er un \u00e9chantillon. Par exemple, si nous avons 60 \u00e9chantillons de l'utilisation du CPU sur une minute, cela fait 1 par seconde et repr\u00e9sente un poids non n\u00e9gligeable, nous pouvons donc faire un downsampling \u00e0 12 mesures par minute, nous aurons tout de m\u00eame une mesure relativement pr\u00e9cise avec un poids divis\u00e9 par 5. Le downsampling rend donc la mesure moins pr\u00e9cise mais beaucoup plus l\u00e9g\u00e8re, nous utilisons donc le downsampling pour les anciennes donn\u00e9es pour lesquelles une pr\u00e9cision accrue n'est pas n\u00e9cessaire.</p> </li> </ul>"},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#detail-des-composants","title":"D\u00e9tail des composants","text":""},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#netdata","title":"Netdata","text":"<p>Netdata est un syst\u00e8me distribu\u00e9 de monitoring des performances de votre h\u00f4te mais \u00e9galement des diverses applications qui y sont install\u00e9es. Il s'agit d'un agent de surveillance hautement optimis\u00e9 que nous pouvons installer sur tous vos syst\u00e8mes et conteneurs.</p> <p>Il fournit un aper\u00e7u en temps r\u00e9el (gr\u00e2ce \u00e0 sa granularit\u00e9 de 1s) de tout ce qui se passe sur les syst\u00e8mes sur lesquels il fonctionne (y compris les serveurs web, les bases de donn\u00e9es et les applications), au travers de tableaux de bord interactifs accessibles via son interface web.</p> <p>Netdata est rapide et efficace, con\u00e7u pour fonctionner en permanence sur tous les syst\u00e8mes (serveurs physiques,virtuels et conteneurs), sans perturber leur fonction principale.</p> <p>Il s'agit d'un logiciel libre et open-source qui fonctionne actuellement sous Linux, FreeBSD et qui est \u00e9galement accessible sous container Docker.</p>"},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#prometheus","title":"Prometheus","text":"<p>Prometheus est, dans notre stack, notre TSDB. C'est lui qui va s'occuper de stocker nos donn\u00e9es re\u00e7ues de l'exporter (Netdata) et de les agr\u00e9ger.</p>"},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#grafana","title":"Grafana","text":"<p>Depuis de nombreuses ann\u00e9es, Grafana est l'outil par excellence de visualisation de donn\u00e9es. Gr\u00e2ce \u00e0 un dashboard totalement personnalisable et de nombreuses sources de donn\u00e9es, Grafana s'est donc naturellement impos\u00e9 dans cette stack de monitoring. Il va s'occuper d'afficher les donn\u00e9es r\u00e9colt\u00e9es dans Prometheus \u00e0 notre guise.</p>"},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#choix-generaux","title":"Choix g\u00e9n\u00e9raux","text":""},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#netdata_1","title":"Netdata","text":"<p>Il existe beaucoup d'exporters (Node-Exporter + cAdvisor, Netdata,Telegraf)... pour tout logiciel (HAproxy,NGINX,PHP-FPM)</p> <p>Cependant, j'ai fait le choix apr\u00e8s avoir test\u00e9 plusieurs exporters d'utiliser Netdata. Ce logiciel int\u00e9gre des milliers de m\u00e9triques mat\u00e9riels mais \u00e9galement de nombreuses logiciels (Plugins MySQL, Nginx...) tout \u00e7a sans aucune configuration. De plus, Netdata dispose nativement d'un syst\u00e8me d'alerte pertinent avec de nombreuses destinations : Slack, Email, Telegram...</p> <p>Enfin, il s'agit d'un logiciel ne consommant que tr\u00e8s peu de RAM et de CPU. Ses m\u00e9triques sont exportables en quelques clics vers de nombreuses TSDB tels que InfluxDB, Prometheus... Les m\u00e9triques export\u00e9es \u00e0 Prometheus sont extr\u00eamement claires.</p> <p>L'avantage comparativement \u00e0 d'autres exporter est qu'il int\u00e8gre containers Docker et m\u00e9triques de l'h\u00f4te. Par exemple, pour avoir ces m\u00e9triques avec un autre exporter, je dois installer Node-exporter + cAdvisor.</p>"},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#prometheus_1","title":"Prometheus","text":"<p>J'ai choisi Prometheus en TSDB principalement car il fallait utiliser OpenTSDB en backend en plus de InfluxDB si nous souhaitions utiliser ce dernier avec Netdata. De plus, je trouve le langage de query de Prometheus (PromQL) assez intuitif et puissant.</p>"},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#installation-generale","title":"Installation g\u00e9n\u00e9rale","text":""},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#installation-configuration-de-netdata","title":"Installation &amp; configuration de Netdata","text":"<p>2 m\u00e9thodes pour installer Netdata, soit via image Docker, soit '\"\u00e0 la main'\". Pour ma part, j'ai un serveur from scratch et les autres sous Docker, j'ai donc utilis\u00e9 les 2 m\u00e9thodes.</p>"},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#via-docker","title":"Via Docker","text":"<p>\u00c9videmment, il est n\u00e9cessaire d'avoir une installation Docker \u00e0 jour. Pour cela, il suffit de suivre les instructions officielles. Une fois cela fait, 2 m\u00e9thodes de lancement possible : via docker ou docker-compose. Encore une fois, j'utilise compose pour une question de coh\u00e9rence. Tous mes containers sont ordonnanc\u00e9s dans un fichier docker-compose.yml, les 2 m\u00e9thodes seront pr\u00e9sent\u00e9es :</p> Netdata : Running with docker <pre><code>$ docker run -d --name=netdata '\n   -p 19999:19999 '\n   -v /proc:/host/proc:ro '\n   -v /sys:/host/sys:ro '\n   -v /etc/os-release:/host/etc/os-release:ro '\n   --cap-add SYS_PTRACE '\n   --security-opt apparmor=unconfined '\n   netdata/netdata\n</code></pre> docker-compose.yml docker-compose.yml<pre><code>version: 3\nservices:\n  netdata:\n    image: netdata/netdata\n    container_name: netdata\n    hostname: $FQDN\n    ports:\n      - 19999:19999\n    cap_add:\n      - SYS_PTRACE\n    security_opt:\n      - apparmor:unconfined\n    volumes:\n      - /proc:/host/proc:ro\n      - /sys:/host/sys:ro\n</code></pre> <p>Et pour le lancer : <code>docker-compose up -d</code></p> <p>Dans les 2 cas, il est possible de mettre Netdata derri\u00e8re un reverse-proxy pour plus de s\u00e9curit\u00e9. Lorsque Netdata est lanc\u00e9, il sera accessible sur le port 19999 ou via votre reverse-proxy configur\u00e9.</p> <p>Nous verrons par la suite comment monitorer plus pr\u00e9cis\u00e9ment nos containers Docker.</p>"},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#from-scratch","title":"From scratch","text":"<p>From scratch, il nous suffira de lancer le script d'installation de netdata qui est tr\u00e8s bien fait. La commande indiqu\u00e9e dans le GitHub Netdata est la suivante :</p> <pre><code>bash &lt;(curl -Ss https://my-netdata.io/kickstart.sh)\n</code></pre> <p>Cette commande installera la base de Netdata sans toutes les d\u00e9pendances tel que celle n\u00e9cessaire au plugin MySQL. Pour installer toutes les d\u00e9pendances n\u00e9cessaires :</p> <pre><code>bash &lt;(curl -Ss https://my-netdata.io/kickstart.sh) all\n</code></pre> <p>Le param\u00e8tre '--dont-wait que l'on peut appliquer \u00e0 la commande permet de s'abstraire de toutes les questions pos\u00e9es \u00e0 l'utilisateur.</p>"},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#installation-de-prometheus","title":"Installation de Prometheus","text":""},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#docker","title":"Docker","text":"<p>Toujours selon les 2 m\u00e9thodes, via docker run ou docker-compose :</p> Prometheus : Running with docker <pre><code>$ docker run -d --name prometheus '\n   -p 9090:9090 '\n   -v /etc/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml '\n   prom/prometheus --config.file=/etc/prometheus/prometheus.yml\n</code></pre> docker-compose.yml docker-compose.yml<pre><code>version: 3\nservices:\n  prometheus:\n    image: prom/prometheus\n    container_name: prometheus\n    hostname: prometheus\n    ports:\n      - 9090:9090\n    volumes:\n      - /etc/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml\n</code></pre> <p>Warning</p> <p>Il faut cr\u00e9er manuellement le fichier prometheus.yml sans quoi par d\u00e9faut Docker consid\u00e8re qu'il s'agit d'un dossier.</p> <pre><code>mkdir /etc/prometheus &amp;&amp; touch /etc/prometheus/prometheus.yml\n</code></pre>"},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#from-scratch_1","title":"From scratch","text":"<p>M\u00eame sur un syst\u00e8me r\u00e9cent, le binaire de Prometheus est dans une version archa\u00efque (A l'heure actuelle, version 2.7.1 sur Debian Buster datant de d\u00e9but 2019... soit 1 an et demi de retard). Il conviendra donc de t\u00e9l\u00e9charger manuellement et de cr\u00e9er l'unit systemd ad\u00e9quate pour Prometheus. Sur Ubuntu 20.04, le binaire est r\u00e9cent, cependant, je vous conseille tout de m\u00eame de l'installer manuellement. Il ne faudra donc pas n\u00e9gliger les mises \u00e0 jours de prometheus et ne pas oublier qu'elles ne seront pas effectu\u00e9es via votre gestionnaire de packet.</p> <p>Tout d'abord, rendons-nous sur la page officielle pour trouver la derni\u00e8re version de Prometheus. A l'heure o\u00f9 j'\u00e9cris, il s'agit de la 2.40.7.</p> <pre><code>cd ~ ; wget https://github.com/prometheus/prometheus/releases/download/v2.40.7/prometheus-2.40.7.linux-amd64.tar.gz\n</code></pre> <p>On extrait les fichiers</p> <pre><code>tar xzvf prometheus-2.40.7.linux-amd64.tar.gz\n</code></pre> <p>On cr\u00e9e notre utilisateur Prometheus :</p> <pre><code>useradd --no-create-home --shell /bin/false prometheus\n</code></pre> <p>Puis on d\u00e9place les fichiers binaires et de configuration aux endroits pr\u00e9vus :</p> <pre><code>mkdir /etc/prometheus &amp;&amp; chown -R prometheus:prometheus /etc/prometheus\nmv ~/prometheus-2-40.7.linux-amd64/{console*,prometheus.yml} /etc/prometheus\nmv ~/prometheus-2-40.7.linux-amd64/{prom*,tsdb} /usr/bin/\n</code></pre> <p>Dans nos 2 fichiers ex\u00e9cutables, nous avons bien \u00e9videmment Prometheus et un fichier nomm\u00e9 Promtool. Ce dernier nous permettra d'interroger directement Prometheus et d'effectuer des op\u00e9rations avanc\u00e9es.</p> <p>Et enfin, nous devons faire le fichier de d\u00e9marrage systemd via le tutoriel disponible. Une fois le fichier cr\u00e9\u00e9, il faut l'activer :</p> <pre><code>systemctl daemon-reload &amp;&amp; systemctl enable --now prometheus\n</code></pre>"},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#configuration-de-prometheus","title":"Configuration de Prometheus","text":"<p>Toute la configuration Prometheus se fait via le fichier <code>/etc/prometheus/prometheus.yml</code> en syntaxe YAML. Voici la configuration \u00e0 appliquer :</p> /etc/prometheus/prometheus.yml prometheus.yml<pre><code># my global config\nglobal:\n  scrape_interval:     5s # Set the scrape interval to every 15 seconds. Default is every 1 minute.\n  evaluation_interval: 5s # Evaluate rules every 15 seconds. The default is every 1 minute.\n  # scrape_timeout is set to the global default (10s).\n\n# Load rules once and periodically evaluate them according to the global evaluation_interval.\nrule_files:\n  # - \"first_rules.yml\"\n  # - \"second_rules.yml\"\n\n\nscrape_configs:\n  # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config.\n\n  - job_name: node SSL\n    scheme: https\n    metrics_path: /api/v1/allmetrics?format=prometheus&amp;source=average\n    honor_labels: true\n    # If prometheus-node-exporter is installed, grab stats about the local\n    # machine by default.\n    static_configs:\n    - targets: [netdata:443]\n    - targets: [netdata2:443]\n\n  - job_name: node\n    metrics_path: /api/v1/allmetrics?format=prometheus&amp;source=average\n    honor_labels: true\n    # If prometheus-node-exporter is installed, grab stats about the local\n    # machine by default.\n    static_configs:\n    - targets: [netdata:19999]\n</code></pre> <p>Afin de ne pas copier coller b\u00eatement la configuration, voici une explication succincte du fichier de configuration :</p> <p>Premi\u00e8rement, nous avons un groupe global qui comme son nom l'indique applique les configurations pour tous les jobs. Dedans, nous d\u00e9finissions un temps de scrape toutes les 5 secondes (une minute par d\u00e9faut) et un reload des r\u00e8gles d'alerting toutes les 5 secondes \u00e9galement.</p> <p>Deuxi\u00e8mement, nous avons la directive <code>rule_files</code> qui s'occupe de charger des fichiers YAML o\u00f9 nous pouvons d\u00e9finir des r\u00e8gles d'alerting. Cependant, notre alerting de base est g\u00e9r\u00e9 via netdata. Nous verrons par la suite comment configurer alertmanager</p> <p>Troisi\u00e8mement, la partie la plus importante, nous avons au premier niveau un scrape_configs qui indique la configuration qui sera appliqu\u00e9e par Prometheus. job_name nous indique quel nom appliquer au '\"groupe'\" au niveau de Prometheus.</p> <p>Nous avons 2 jobs : Un concernant les noeuds netdata SSL appel\u00e9 Node SSL et un autre avec les node normaux appel\u00e9s Node.</p> <p>Le premier node contient la directive <code>scheme</code> qui nous permet de sp\u00e9cifier que nous souhaitons utiliser une connexion s\u00e9curis\u00e9e TLS pour r\u00e9cup\u00e9rer les donn\u00e9es \u00e9mises par Netdata. Le second ne contient pas ce keyword car la connexion par d\u00e9faut est en plain text (http).</p> <p>Ensuite, nous avons une ligne extr\u00eamement importante, <code>metrics_path</code>. Celle-ci va de paire avec les targets. En targets de static config, nous d\u00e9finissons chaque h\u00f4te dont Prometheus doit r\u00e9cup\u00e9rer les m\u00e9triques. <code>metrics_path</code> indique donc sur quelle URI Prometheus doit aller r\u00e9cup\u00e9rer ses m\u00e9triques. L'URI est propre \u00e0 chaque exporter. Ainsi, celle-ci est propre \u00e0 Netdata et nous indique que nous souhaitons des valeurs moyenne au format Prometheus. Toute la documentation sur ce fichier de configuration est disponible ici</p> <p>Concernant netdata, il est possible d'afficher directement les valeurs bruts r\u00e9cup\u00e9r\u00e9es par prometheus \u00e0 l'adresse suivante : https://netdata.user.domain.tld/api/v1/allmetrics%3Fformat=prometheus&amp;average=yes</p> <p>Deux helpers netdata sont \u00e9galement disponibles. <code>&amp;types=yes</code> permettant d'afficher le type de m\u00e9trique renvoy\u00e9 et <code>&amp;help=yes</code> pouvant vous apporter diverses pr\u00e9cisions. Voici un exemple :</p> Example output of prometheus exporter <pre><code># COMMENT netdata_ipv4_tcperrors_packets_persec_average: dimension \"RetransSegs\", value is packets/s, gauge, dt 1586642036 to 1586642038 inclusive\n# COMMENT TYPE netdata_ipv4_tcperrors_packets_persec_average gauge\nnetdata_ipv4_tcperrors_packets_persec_average{chart=\"ipv4.tcperrors\",family=\"tcp\",dimension=\"RetransSegs\"} 0.0000000 1586642038000\n</code></pre> <p>Il est \u00e9galement possible de r\u00e9cuperer d'autres variables syst\u00e8me tel que le nombre de sockets TCP support\u00e9s... Il suffira d'ajouter &amp;variables=yes au metrics_path.</p> <p>Selon le panel grafana que vous trouvez, vous pouvez trouver des unit\u00e9s en MB au lieu d'en MiB. Ce comportement a chang\u00e9 en netdata 1.12, pour retrouver les anciennes unit\u00e9s, rajouter &amp;oldunits=yes ) \u00e0 votre metrics_path.</p> <p>Pour v\u00e9rifier que tout est conforme, rendez-vous dans l'interface de Prometheus (Par d\u00e9faut, port 9090), vous devriez tomber sur cette page :</p> <p></p> <p>On se rend ensuite sur Status puis Target</p> <p></p> <p>Si tout est bon, vous devriez apercevoir vos diff\u00e9rentes targets avec l'\u00e9tat UP.</p>"},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#syntaxe-prometheus","title":"Syntaxe Prometheus","text":"<p>Prometheus se base sur une syntaxe intuitive nomm\u00e9e PromQL. Nous pouvons nous exercer \u00e0 la syntaxe PromQL depuis le menu principal de Prometheus.</p> <p>Il est possible de tester la syntaxe de PromQL depuis la page d'accueil de Prometheus.</p> <p>A c\u00f4t\u00e9 du bouton Execute nous avons // - insert metric at cursor - //. Ceci nous permet de voir toutes les m\u00e9triques disponibles via Prometheus.</p> <p>Les m\u00e9triques de Netdata sont \u00e9galement disponibles via l'URL de notre Grafana suivi du chemin de la m\u00e9trique.</p> <p>Voici un exemple de relev\u00e9 :</p> <p></p> <p>Comme vous pouvez le voir, nous obtenons de nombreuses informations (Concr\u00e8tement, on obtient en r\u00e9ponse tous les netdata que nous monitorons).</p> <p>D\u00e9cortiquons une r\u00e9ponse type pour un serveur :</p> Example output of netdata exporter <pre><code>netdata_system_ram_MiB_average{chart=\"system.ram\",dimension=\"free\",family=\"ram\",instance=\"netdata.x.domain.tld:443\",job=\"node\"}\nnetdata_system_ram_MiB_average{chart=\"system.ram\",dimension=\"used\",family=\"ram\",instance=\"netdata.x.domain.tld:443\",job=\"node\"}\nnetdata_system_ram_MiB_average{chart=\"system.ram\",dimension=\"cached\",family=\"ram\",instance=\"netdata.x.domain.tld:443\",job=\"node\"}\nnetdata_system_ram_MiB_average{chart=\"system.ram\",dimension=\"buffers\",family=\"ram\",instance=\"netdata.x.domain.tld:443\",job=\"node\"}\n</code></pre> <p>Il existe un site internet proposant quelques r\u00e8gles Prometheus. Attention, celles-ci ne sont pas forc\u00e9ment optimsi\u00e9es ou fonctionnelles.</p> <p>En premier lieu, nous observons que nous avons 4 m\u00e9triques diff\u00e9rentes pour le m\u00eame serveur. Ce qui est contenu dans les accolades est une variable pour Prometheus. Par exemple, voici comment obtenir la RAM utilis\u00e9e pour le serveur ci-dessus :</p> <p></p> <p>Comme nous pouvons le voir, nous nous sommes servis des variables de Prometheus pour filtrer ce que nous voulons. Nous pouvons \u00e9galement nous servir de ces variables pour obtenir des graphiques dynamiques sur Grafana.</p>"},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#installation-de-grafana","title":"Installation de Grafana","text":""},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#docker_1","title":"Docker","text":"Grafana : Running with docker <pre><code>$ docker run -d --name prometheus '\n   -p 3000:3000 '\n   grafana/grafana\n</code></pre> docker-compose.yml docker-compose.yml<pre><code>version: \"3\"\nservices:\n  grafana:\n    hostname: grafana\n    container_name: grafana\n    image: grafana/grafana\n    ports:\n      - 3000:3000\n</code></pre>"},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#from-scratch_2","title":"From scratch","text":"<p>Grafana n'\u00e9tant toujours pas disponible dans les d\u00e9p\u00f4ts de Debian 10, nous devons donc ajouter ses propres d\u00e9p\u00f4ts avant de pouvoir l'installer :</p> <pre><code>sudo apt-get install -y apt-transport-https\necho \"deb https://packages.grafana.com/oss/deb stable main\" | sudo tee -a /etc/apt/sources.list.d/grafana.list\nwget -q -O - https://packages.grafana.com/gpg.key | sudo apt-key add -\napt update &amp;&amp; apt install -y grafana\n</code></pre> <p>Une fois install\u00e9, Grafana n'est pas d\u00e9marr\u00e9 et n'est pas lanc\u00e9 au d\u00e9marrage de votre serveur. Pour cela voici les commandes :</p> <pre><code>systemctl daemon-reload\nsystemctl enable --now grafana-server.service\n</code></pre>"},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#utiliser-prometheus-en-datasource","title":"Utiliser Prometheus en Datasource","text":"<p>Une fois toute la stack install\u00e9e, nous devons configurer Grafana afin qu'il utilise Prometheus comme source de donn\u00e9es. Par d\u00e9faut, Grafana \u00e9coute sur le port 3030 et ses identifiants par d\u00e9fauts sont admin / admin.</p> <p></p> <p>Il faut alors cliquer sur Add Data Sources :</p> <p></p> <p>Dans le choix de la Data Source, nous choisissons bien \u00e9videmment Prometheus :</p> <p></p> <p>Ici, les choses se corsent un tout petit peu.</p> <p>Tout d'abord, en URL, 3 cas sont possibles :</p> <ul> <li>Si vous avez install\u00e9 Prometheus et Grafana sur le m\u00eame serveur,     alors vous pouvez pointer directement vers Prometheus :     http://localhost:9090</li> <li>Si votre Prometheus n'est pas sur le serveur de Grafana, alors il     vous faudra y acc\u00e9der via son IP : http://ip:port</li> <li>S'il est derri\u00e8re un reverse-proxy (la solution optimale), alors il     faudra y acc\u00e9der de la mani\u00e8re suivante : https://domain.tld</li> </ul> <p>Une fois ceci fait, Save &amp; Test</p> <p>Si tout est correct, voici le message que vous obtiendrez :</p> <p></p> <p>F\u00e9licitations, une \u00e9tape fastidieuse est pass\u00e9e, cependant, le plus dur reste \u00e0 faire, la cr\u00e9ation de votre premier panel !</p>"},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#creation-de-son-premier-panel","title":"Cr\u00e9ation de son premier panel","text":"<p>Cr\u00e9er son panel Grafana peut s'av\u00e9rer fastidieux. De nombreuses options sont possibles. Pour vous faciliter sa prise en main, Grafana vous mets \u00e0 disposition une instance test. Malheureusement, la syntaxe utilis\u00e9e pour l'instance est du InfluxQL et non du PromQL</p> <p>Grafana est un syst\u00e8me extr\u00eamement personnalisable, c'est pour cela que je vais vous partager mes panels.</p>"},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#mes-panels-grafana","title":"Mes panels Grafana","text":"<p>Lien de t\u00e9l\u00e9chargement : ici</p> <p></p> <p>Lien de t\u00e9l\u00e9chargement : ici</p> <p></p> <p>Lien de t\u00e9l\u00e9chargement : ici</p> <p>La communaut\u00e9 Grafana met \u00e0 votre disposition \u00e9normement de dashboards</p>"},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#trucs-astuces","title":"Trucs &amp; Astuces","text":""},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#grafana_1","title":"Grafana","text":"<p>L'utilisation de Grafana est assez simple. Cependant, certaines choses sont assez mal con\u00e7ues, il faut les d\u00e9couvrir par soi-m\u00eame. Je mettrai cette partie \u00e0 jour au fur et \u00e0 mesure de mes d\u00e9couvertes.</p>"},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#lecture-dun-timestamp","title":"Lecture d'un timestamp","text":"<p>Pour lire une m\u00e9trique de type Unix Timestamp, \u00e9galement appel\u00e9 Epoch (nombre de secondes \u00e9coul\u00e9es depuis le 1er Janvier 1970), il faut multiplier par 1000 la valeur et lui appliquer n'importe quel filtre de type Date. En effet, comme me l'a expliqu\u00e9 Olivier sur LinkedIn, il s'agit d'une interface \u00e9crit en JavaScript. Le timestamp renvoy\u00e9 par prometheus est en seconde et celui de JS est exprim\u00e9 en millisecondes, c'est pour cela qu'il faut multiplier par 1000.</p>"},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#prometheus_2","title":"Prometheus","text":"<p>Pour apporter une s\u00e9curit\u00e9 suppl\u00e9mentaire, il faut faire \u00e9couter Prometheus sur localhost uniquement. Pour cela, dans votre unit systemd, il faudra rajouter l'argument <code>--web.listen-address=\"127.0.0.1:9090\"</code> sans oublier de relancer le service Prometheus ainsi que de faire le reverse-proxy ad\u00e9quate.</p> <p>Pour v\u00e9rifier que notre modification a bien \u00e9t\u00e9 prise en compte, il suffit de faire un ss -laptn sport eq 9090 et de constater que la Local Address est bien 127.0.0.1.</p> <p>Si votre instance Prometheus n'est pas sur le m\u00eame serveur et que Grafana/Prometheus ne sont pas joignables via un r\u00e9seau priv\u00e9, alors il vous faudra un reverse-proxy avec authentification basic</p> <p>Petit reverse proxy pour Prometheus, \u00e0 adapter pour votre setup :</p> nginx-prometheus.conf nginx-prometheus.conf<pre><code>upstream prometheus {\n    server localhost:9090;\n}\n\nserver {\n    listen        80;\n    listen              [::]:80;\n\n    server_name        prometheus.domain.tld;\n\n    access_log        off;\n\n    include        snippets/letsencrypt.conf;\n\n    location / {\n        return 301 https://prometheus.domain.tld$request_uri;\n    }\n}\n\nserver {\n    server_name prometheus.domain.tld;\n\n    auth_basic           \"prometheus\";\n    auth_basic_user_file /etc/nginx/.htpasswd;\n\n    listen 443 ssl;\n    listen [::]:443 ssl;\n    http2 on;\n\n    ssl_certificate /root/.acme.sh/prometheus.domain.tld_ecc/fullchain.cer;\n    ssl_certificate_key /root/.acme.sh/prometheus.domain.tld_ecc/prometheus.domain.tld.key;\n\n    location / {\n        proxy_set_header Host $http_host;\n        proxy_pass http://prometheus;\n    }\n}\n</code></pre>"},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#netdata_2","title":"Netdata","text":""},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#general","title":"G\u00e9n\u00e9ral","text":"<p>Comme dit pr\u00e9c\u00e9demment, Netdata permet nativement d'exporter de nombreuses m\u00e9triques. Cependant, pour certaines d'entre elles, dont MySQL, il est n\u00e9cessaire de faire une manipulation :</p> <pre><code>mysql&gt; CREATE USER netdata@localhost;\nmysql&gt; GRANT USAGE ON *.* TO netdata@localhost;\nmysql&gt; FLUSH PRIVILEGES;\n</code></pre> <p>Il faut \u00e9galement avoir install\u00e9 netdata avec toutes ses d\u00e9pendances via la commande d'installation.</p>"},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#docker_2","title":"Docker","text":""},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#resolution-des-noms-des-containers","title":"R\u00e9solution des noms des containers","text":"<p>Pour r\u00e9soudre les noms des containers dockers afin de ne pas avoir une suite de chiffres et lettres incompr\u00e9hensible, plusieurs m\u00e9thodes s'offrent \u00e0 nous.</p> <p>Tout d'abord, nous pouvons exposer l'API Docker via un autre container afin de contr\u00f4ler compl\u00e8tement son comportement :</p> docker-compose.yml docker-compose.yml<pre><code>version: 3\nservices:\n  netdata:\n    image: netdata/netdata\n    # ... votre config ... #\n    environment:\n      - DOCKER_HOST=proxy:2375\n  proxy:\n    image: tecnativa/docker-socket-proxy\n    volumes:\n     - /var/run/docker.sock:/var/run/docker.sock:ro\n    environment:\n      - CONTAINERS=1\n</code></pre> <p>La variable d'environnement CONTAINERS=1 nous permet d'indiquer \u00e0 Netdata qu'il n'a acc\u00e8s qu'\u00e0 la partie de l'API concernant les containers, ce qui peut \u00eatre tr\u00e8s utile en cas de compromission du container.</p> <p>La seconde mani\u00e8re de faire est d'indiquer \u00e0 Netdata de s'ex\u00e9cuter en tant que groupe Docker, pour cela, un simple <code>grep docker /etc/group '| cut -d ':' -f 3</code> nous permet de r\u00e9cup\u00e9rer le groupe docker (g\u00e9n\u00e9ralement 999 avant Debian 10 et 998 avec Debian 10) et nous ajoutons la variable d'environnement PGID=998 \u00e0 notre container netdata.</p> <p>Enfin, troisi\u00e8me et derni\u00e8re possibilit\u00e9 que je d\u00e9conseille fortement est de lancer Netdata en tant qu'utilisateur root via la variable d'environnement DOCKER_USR=root sur notre container.</p>"},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#monitoring-dun-mountpoint-personnalise","title":"Monitoring d'un mountpoint personnalis\u00e9","text":"<p>Pour monitorer les I/O, espace disque... d'un point de montage, il faut bien \u00e9videmment l'indiquer en volume sur votre container Netdata.</p> <p>Prenons un exemple simple. Si vous avez diff\u00e9rents utilisateurs dans votre /home (jeremy, augustin...) alors il faudra faudra ajouter le volume /home \u00e0 votre container.</p> <p>La base d'une stack de monitoring est d\u00e9sormais acquise.</p>"},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#pour-aller-plus-loin","title":"Pour aller plus loin","text":"<p>Il s'agit d'une stack tr\u00e8s simple \u00e0 mettre en place. Cependant, celle-ci n'est pas parfaite, nous n'avons aucune indication concernant nos sites web, l'\u00e9tat des certificats SSL, ou encore aucun alerting.</p>"},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#rendre-prometheus-dynamique","title":"Rendre Prometheus dynamique","text":"<p>Actuellement, nous avons une configuration statique, ce qui implique un red\u00e9marrage de prometheus \u00e0 chaque ajout/suppression d'un host. Le red\u00e9marrage de prometheus peut durer plusieurs minutes avec la reprise des WAL...</p> <p>A la place de static_configs, il est donc possible d'utiliser d'autres directives, dont file_sd_configs. Votre configuration prometheus sera donc dynamique via un simple fichier json que prometheus relira \u00e0 chaque modification, qu'il s'agisse d'une suppression ou d'un ajout.</p> <p>Remplacer le bloc node de votre fichier prometheus.yml par le suivant :</p> /etc/prometheus/prometheus.yml prometheus.yml<pre><code>  - job_name: node\n    scheme: https\n    metrics_path: /api/v1/allmetrics?format=prometheus&amp;source=average\n    honor_labels: true\n    # If prometheus-node-exporter is installed, grab stats about the local\n    # machine by default.\n    file_sd_configs:\n      - files:\n        - \"/etc/prometheus/netdata.json\"\n</code></pre> <p>Si vous avez bien suivi notre tutoriel sur la cr\u00e9ation d'une unit systemd, vous avez compris que nous n'avons pas besoin de sp\u00e9cifier un chemin absolu via la directive WorkingDirectory. Cependant, pour un soucis de claret\u00e9, je pr\u00e9f\u00e8re indiquer un chemin absolu.</p> <p>Comme vous pouvez vous en douter, le fichier netdata.json contiendra les diff\u00e9rents nodes \u00e0 monitorer. Si vous souhaitez ajouter/supprimer un fichier ou un job, il vous faudra \u00e9videmment red\u00e9marrer Prometheus. Voici le contenu dudit fichier :</p> /etc/prometheus/netdata.json netdata.json<pre><code>[\n  {\n    \"labels\": {\n      \"jobs\": \"node\"\n    },\n    \"targets\": [\n      \"netdata.x.domain.tld:443\",\n      \"netdata.y.domain.tld:443\"\n    ]\n  }\n]\n</code></pre> <p>Ce fichier est simplissime. Nous avons les labels dans un premier bloc puis nos diff\u00e9rentes targets. Attention \u00e0 penser aux virgules entre les targets et \u00e0 ne pas en mettre \u00e0 votre derni\u00e8re, sans quoi votre JSON serait invalide.</p> <p>Une fois ceci fait, nous red\u00e9marrons une ultime fois Prometheus systemctl restart prometheus, puis nous pourrons modifer \u00e0 chaud nos targets sans aucune autre modification, plut\u00f4t pratique ! D'autres mani\u00e8res sont \u00e9galement possibles pour importer dynamiquement vos targets par exemple via consul. J'ai choisi ce mode-ci car il me convient parfaitement. Xavier Pestel (xavki) nous propose une excellente vid\u00e9o pour l'inventaire dynamique via Consul.</p>"},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#monitorer-vos-certificats-websites","title":"Monitorer vos certificats &amp; websites","text":"<p>Le monitorer de ces \u00e9l\u00e9ments n'est pas propos\u00e9 nativement par notre exporter Netdata. Heureusement, Prometheus \u00e0 pens\u00e9 \u00e0 tout et nous propose blackbox_exporter, un exporter orient\u00e9 autour des tests HTTP, ICMP &amp; co. Pour l'installer, nous devons proc\u00e9der de la m\u00eame mani\u00e8re que Prometheus. Si vous disposez de Prometheus sur votre machine, il n'y a aucun int\u00e9r\u00eat \u00e0 cr\u00e9er un utilisateur suppl\u00e9mentaire, vous pourrez lancer blackbox_exporter en tant que Prometheus et placer son fichier de configuration dans le r\u00e9pertoire de Prometheus.</p> <p>Il faut toujours se rendre sur la page Github afin de s'assurer que nous disposons de la derni\u00e8re version de notre logiciel :</p> <pre><code>cd ~ ; wget https://github.com/prometheus/blackbox_exporter/releases/download/v0.24.0/blackbox_exporter-0.24.0.linux-amd64.tar.gz\n</code></pre> <p>Et on extrait toujours les fichiers :</p> <pre><code>tar xzvf blackbox_exporter-0.24.0.linux-amd64.tar.gz\n</code></pre> <p>Et on les d\u00e9place dans le dossier ad\u00e9quate. Attention \u00e0 bien mettre le bon username (prometheus ou celui que vous aurez d\u00e9cid\u00e9s)</p> <pre><code>mkdir /etc/blackbox &amp;&amp; chown -R prometheus:prometheus /etc/blackbox\nmv ~/blackbox_exporter-0.24.0.linux-amd64/blackbox_exporter /usr/bin\nmv ~/blackbox_exporter-0.24.0.linux-amd64/blackbox.yml /etc/blackbox\n</code></pre> <p>Si nous souhaitons utiliser le test ICMP de blackbox et que nous avons lanc\u00e9 blackbox en tant que non-root, alors il nous faudra ajouter une Capability \u00e0 notre unit.</p> <pre><code>$ systemctl edit --full blackbox_exporter\n[Service]\n...\nAmbientCapabilities=CAP_NET_RAW\n...\n</code></pre> <p>Nous n'oublions \u00e9galement pas que le paquet puisse effectuer les op\u00e9rations dont il a besoin :</p> <pre><code>$ getcap /usr/bin/prometheus-blackbox-exporter\n/usr/bin/prometheus-blackbox-exporter cap_net_raw=ep\n</code></pre> <p>Sans quoi, nous recevrons une erreur selon laquelle nous n'avons pas la permission d'effectuer cette action :</p> <pre><code>    ts=2020-04-06T01:59:18.302197375Z caller=main.go:119 module=icmp target=netdata.pierre.x.eu level=error msg=\"Error listening to socket\" err=\"listen ip4:icmp 0.0.0.0: socket: operation not permitted\"\n</code></pre> <p>Les tests \u00e9crits par d\u00e9faut par les mainteneurs de Blackbox nous conviendront pour faire de simples tests de chargement de page web ainsi que d'ICMP, nous ne toucherons donc pas \u00e0 ce fichier.</p> <p>Maintenant que Blackbox est correctement install\u00e9, nous devons indiquer \u00e0 Prometheus d'aller r\u00e9cup\u00e9rer les m\u00e9triques de Blackbox :</p> Target for prometheus.yml prometheus.yml<pre><code>- job_name: HTTP\n  scheme: http\n  params:\n    module: [http_2xx]\n  metrics_path: /probe\n  file_sd_configs:\n  - files:\n    - http.json\n  relabel_configs:\n  - source_labels: [__address__]\n    target_label: __param_target\n  - source_labels: [__param_target]\n    target_label: instance\n  - target_label: __address__\n    replacement: localhost:9115 # Blackbox exporter.\n</code></pre> <p>Ce job diff\u00e8re un tout petit peu des anciens, tout d'abord, nous devons sp\u00e9cifier un module correspondant au nom de notre module dans blackbox.yml. Nous avons besoin de passer la destination de notre test \u00e0 Blackbox. Pour cela, nous utilisons le module relabel_configs de Prometheus. Enfin, nous r\u00e9\u00e9crivons la variable address avec la valeur de notre exporter Blackbox, dans notre cas, localhost:9115. Voici le contenu de notre fichier http.json</p> /etc/prometheus/http.json http.json<pre><code>[\n  {\n    \"labels\": {\n      \"job\": \"blackbox\"\n    },\n    \"targets\": [\n      \"https://netdata.jean.domain.tld:443\",\n      \"https://netdata.peuplu.domain.tld:443\"\n    ]\n  }\n]\n</code></pre> <p>Une fois cette \u00e9tape faite et Prometheus red\u00e9marr\u00e9, nous avons acc\u00e8s de nouvelles m\u00e9triques sur Prometheus (en fonction du module choisi, il s'agit ici des m\u00e9triques pour le module http_2xx) :</p> Output of blackbox_exporter / http_2xx <pre><code>probe_dns_lookup_time_seconds 0.001002382\nprobe_duration_seconds 0.102398015\nprobe_failed_due_to_regex 0\nprobe_http_content_length 89715\nprobe_http_duration_seconds{phase=\"connect\"} 0.022205535\nprobe_http_duration_seconds{phase=\"processing\"} 0.022529847\nprobe_http_duration_seconds{phase=\"resolve\"} 0.006274033\nprobe_http_duration_seconds{phase=\"tls\"} 0.038470116\nprobe_http_duration_seconds{phase=\"transfer\"} 0.021751707\nprobe_http_redirects 1\nprobe_http_ssl 1\nprobe_http_status_code 200\nprobe_http_uncompressed_body_length 89715\nprobe_http_version 1.1\nprobe_ip_protocol 4\nprobe_ssl_earliest_cert_expiry 1.59282791e+09\nprobe_success 1\nprobe_tls_version_info{version=\"TLS 1.3\"} 1\n</code></pre> <p>Comme vous pouvez le voir, nous avons de nombreuses m\u00e9triques, particuli\u00e8rement 2 plus utiles que les autres :</p> <ul> <li><code>probe_success</code> nous indique si le test s'est effectu\u00e9     correctement</li> <li><code>probe_http_status_code</code> nous renvoie le code de retour de la page</li> <li><code>probe_ssl_earliest_cert_expiry</code> nous renvoie la date     d'expiration (sous forme de timestamp)</li> </ul> <p>Grace \u00e0 ces nouvelles m\u00e9triques, vous pouvez indiquer l'\u00e9tat de services dans vos dashboards Grafana, la date d'expiration de vos certificats... Un autre exporter s'occupant uniquement de la partie SSL/TLS, mais fournissant plus de verbosit\u00e9 est disponible. Il se nomme node-cert-exporter, je lui pr\u00e9f\u00e8re blackbox_exporter car il est plus polyvalent et supervise une URL, non un chemin vers un certificat. Cependant, celui-ci peut \u00eatre int\u00e9ressant dans le cas de supervision de certificats pour des syst\u00e8mes comme Kubernetes ou autre.</p>"},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#integration-dun-systeme-dalerting","title":"Int\u00e9gration d'un syst\u00e8me d'alerting","text":""},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#alertmanager","title":"Alertmanager","text":"<p>Alertmanager est la brique d'alerting de notre stack, celle-ci se greffe directement \u00e0 prometheus. La proc\u00e9dure d'installation reste la m\u00eame que tous les autres produits cr\u00e9\u00e9s par Prometheus :</p> <p>Rendons-nous sur la page officielle pour trouver la derni\u00e8re version de alermanager . A l'heure o\u00f9 j'\u00e9cris, il s'agit de la 0.20.0.</p> <pre><code>cd ~ ; wget https://github.com/prometheus/alertmanager/releases/download/v0.25.0/alertmanager-0.25.0.linux-amd64.tar.gz\n</code></pre> <p>On extrait les fichiers</p> <pre><code>tar xzvf alertmanager-0.25.0.linux-amd64.tar.gz\n</code></pre> <p>cette archive contient, comme les autres, des ex\u00e9cutables et un fichier de configuration, nous les d\u00e9pla\u00e7ons dans le r\u00e9pertoire ad\u00e9quat. Encore une fois, si nous avons d\u00e9j\u00e0 Prometheus, nous mettrons le fichier de configuration dans ce r\u00e9pertoire, sinon, nous cr\u00e9erons le r\u00e9pertoire /etc/alertmanager</p> <pre><code>mv ~/alertmanager-0.25.0.linux-amd64/{amtool,alertmanager} /usr/bin/\nmv ~/alertmanager-0.25.0.linux-amd64/alertmanager.yml /etc/alertmanager\nchown -R prometheus:prometheus /etc/alertmanager\n</code></pre> <p>Pour cr\u00e9er l'unit, je vous renvoie une nouvelle fois vers le tutoriel ad\u00e9quat. Amtool est un outil permettant d'interagir directement avec l'API de AlertManager.</p>"},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#alertmanageryml","title":"alertmanager.yml","text":"<p>Voici le contenu par d\u00e9faut du fichier alertmanager.yml :</p> /etc/prometheus/alertmanager.yml <pre><code>global:\n  resolve_timeout: 5m\n\nroute:\n  group_by: [alertname]\n  group_wait: 10s\n  group_interval: 10s\n  repeat_interval: 1h\n  receiver: web.hook\nreceivers:\n- name: web.hook\n  webhook_configs:\n  - url: http://127.0.0.1:5001/\ninhibit_rules:\n  - source_match:\n      severity: critical\n    target_match:\n      severity: warning\n    equal: [alertname, dev, instance]\n</code></pre> <p>Nous voyons ici une directive <code>route</code> qui nous indique comment chaque alerte sera trait\u00e9e par alertmanager, nous pouvons faire plusieurs directives route si nous souhaitons des traitements sp\u00e9cifiques. Chaque route est d\u00e9finie par un receiver unique.</p> <p>Tout d'abord, la directive <code>group_by</code>. Celle-ci prend un tableau en param\u00e8tre. Par d\u00e9faut, il contient <code>alert</code> et <code>instance</code> ce qui nous indique que les alertes contenant ces tags seront trait\u00e9es de la m\u00eame mani\u00e8re. Nous n'utilisons qu'une route et souhaitons obtenir toutes les alertes, nous utilisons donc le tag alertname.</p> <p>Ensuite, group_wait est ici d\u00e9fini \u00e0 10 secondes. Il s'agit du nombre de secondes avant qu'une alerte d'un nouveau groupe soit envoy\u00e9 si vous disposez de plusieurs groupes. Comme nous ne disposons que d'un seul groupe, il s'agit d'une valeur arbitraire ici d\u00e9finie \u00e0 10s.</p> <p><code>group_interval</code> est d\u00e9fini \u00e0 10s ce qui signifie que les autres notifications concernant le m\u00eame groupe arriverons toutes les 10s.</p> <p>La variable <code>repeat_interval</code> est le d\u00e9lai \u00e0 attendre si les alertes que nous avons eu ne sont toujours pas r\u00e9solues. Ll s'agit encore d'une valeur arbitraire que nous d\u00e9finissons \u00e0 une heure.</p> <p>De nombreux receivers sont possibles, adresse mail, slack, webhook... Dans mon cas, j'ai choisi d'utiliser un Webhook qui va s'occuper d'envoyer mes notifications sur Telegram. Ce webhook \u00e9coutera donc sur le port 8080 et non sur le 5001, il s'agit ici de la derni\u00e8re valeur \u00e0 modifier. Pour plus d'informations, je vous invite \u00e0 aller voir l'exemple officiel d'alertmanager.</p>"},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#modifications-du-fichier-prometheusyml","title":"Modifications du fichier prometheus.yml","text":"<p>Faisons un petit point sur ce \u00e0 quoi ressemble notre <code>prometheys.yml</code> \u00e0 ce stade-l\u00e0. Nous voyons une partie concernant les r\u00e8gles (rule_files) mais nous n'y avons pas touch\u00e9. Nous allons donc charger notre premi\u00e8re r\u00e8gle. De plus, il faudra indiquer \u00e0 Prometheus de renvoyer ses alertes \u00e0 alertmanager.</p> /etc/prometheus/prometheus.yml prometheus.yml<pre><code>[...]\nrule_files:\n  - \"alert.rules.yml\"\n[...]\nalerting:\n  alertmanagers:\n  - static_configs:\n    - targets:\n      - 127.0.0.1:9093\n[...]\n</code></pre> <p>Nous indiquons ici \u00e0 Prometheus d'utiliser comme r\u00e8gles le contenu du fichier <code>alert.rules.yml</code> mais \u00e9galement d'envoyer les alertes vers la target de type alertmanager disponible sur 127.0.0.1:9093.</p>"},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#alertrulesyml","title":"alert.rules.yml","text":"/etc/prometheus/alert.rules.json alert.rules.json<pre><code>groups:\n- name: alert.rules\n  rules:\n  - alert: EndpointDown\n    expr: probe_success == 0\n    for: 10s\n    labels:\n      severity: \"critical\"\n    annotations:\n      summary: \"Endpoint {{ $labels.instance }} has an issue\"\n      description: \"{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 10 seconds.\"\n</code></pre> <p>La syntaxe est assez compr\u00e9hensible. Tout d'abord, nous d\u00e9finissons un nom au groupe de r\u00e8gles puis nous d\u00e9finissons la r\u00e8gle. Celle-ci va se nommer EndpointDown. L'expression ici probe_success == 0 (m\u00e9trique renvoy\u00e9e blackbox_exporter) v\u00e9rifie si l'URL monitor\u00e9e par blackbox_exporter est up ou down pendant 10 secondes. Les variables d\u00e9finies dans l'annotations sont d\u00e9finies par Prometheus.</p> <p>Pour v\u00e9rifier que notre r\u00e8gle est bien prise en place, nous ferons la commande suivante :</p> <pre><code>$ promtool check rules /etc/prometheus/alert.rules.yml\nChecking /etc/prometheus/alert.rules.yml\n  SUCCESS: 1 rules found\n</code></pre> <p>Voici d'autres exemples de r\u00e8gles Prometheus trouv\u00e9es sur le web :</p> /etc/prometheus/alert.rules.yml alert.rules.yml<pre><code>groups:\n- name: alert.rules\n\n  rules:\n  - alert: node_high_cpu_usage_70\n    expr: avg(rate(netdata_cpu_cpu_percentage_average{dimension=\"idle\"}[1m])) by (job) &gt; 70\n    for: 1m\n    annotations:\n      description: {{ $labels.job }} on {{ $labels.job }} CPU usage is at {{ humanize $value }}%.\n      summary: CPU alert for container node {{ $labels.job }}\n\n  - alert: node_high_memory_usage_70\n    expr: 100 / sum(netdata_system_ram_MB_average) by (job)\n      * sum(netdata_system_ram_MiB_average{dimension=~\"free|cached\"}) by (job) &lt; 30\n    for: 1m\n    annotations:\n      description: {{ $labels.job }} memory usage is {{ humanize $value}}%.\n      summary: Memory alert for container node {{ $labels.job }}\n\n  - alert: node_low_root_filesystem_space_20\n    expr: 100 / sum(netdata_disk_space_GiB_average{family=\"/\"}) by (job)\n      * sum(netdata_disk_space_GB_average{family=\"/\",dimension=~\"avail|cached\"}) by (job) &lt; 20\n    for: 1m\n    annotations:\n      description: {{ $labels.job }} root filesystem space is {{ humanize $value}}%.\n      summary: Root filesystem alert for container node {{ $labels.job }}\n\n  - alert: node_root_filesystem_fill_rate_6h\n    expr: predict_linear(netdata_disk_space_GiB_average{family=\"/\",dimension=~\"avail|cached\"}[1h], 6 * 3600) &lt; 0\n    for: 1h\n    labels:\n      severity: critical\n    annotations:\n      description: Container node {{ $labels.job }} root filesystem is going to fill up in 6h.\n      summary: Disk fill alert for node {{ $labels.job }}\n</code></pre> <p>Enormement d'exemples sont disponibles ici</p>"},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#bot-telegram-alertmanager","title":"Bot Telegram Alertmanager","text":"<p>Pour avoir nos alertes sur Telegram, j'utilise le bot de metalmatze qui r\u00e9pond juste \u00e0 nos besoins. Derni\u00e8re version au jour de l'\u00e9criture de cet article : 0.4.3</p> <pre><code>cd ~ ; wget https://github.com/metalmatze/alertmanager-bot/releases/download/0.4.3/alertmanager-bot-0.4.3-linux-amd64\nmv alertmanager-bot-0.4.3-linux-amd64 /usr/bin/alertmanager-bot &amp;&amp; chmod +x /usr/bin/alertmanager-bot\n</code></pre> <p>Encore une fois, on n'oublie pas d'\u00e9crire l'unit file qui va bien, nous avons l'habitude d\u00e9sormais. Il nous faudra cr\u00e9er un bot telegram et relever notre ChatID.</p> <p>Notre directive <code>ExecStart</code> de notre unit sera la suivante :</p> <pre><code>ExecStart=alertmanager-bot --store=bolt --telegram.token=BOT_TOKEN --telegram.admin=USER_ID --template.paths=default.tmpl\n</code></pre> <p>Penser bien \u00e0 remplacer BOT_TOKEN et USER_ID par les bonnes variables. Quand au template default.tpl, voici celui que j'utilise :</p> Template alertmanager <pre><code>  {{/*Alertmanager Silence link*/}}\n  {{ define \"__alert_silence_link\" -}}\n      &lt;https://alertmanager.dynfactory.com/#/silences/new?filter=%7B&gt;\n      {{- range .CommonLabels.SortedPairs -}}\n          {{- if ne .Name \"alertname\" -}}\n              {{- .Name }}%3D\"{{- .Value | urlquery -}}\"%2C%20\n          {{- end -}}\n      {{- end -}}\n      alertname%3D\"{{- .CommonLabels.alertname -}}\"%7D\n  {{- end }}\n\n  {{/* Severity of the alert */}}\n  {{ define \"__alert_severity\" -}}\n      {{- if eq .CommonLabels.severity \"critical\" -}}\n      *Severity:* :no_entry:\n      {{- else if eq .CommonLabels.severity \"warning\" -}}\n      *Severity:* :warning:\n      {{- else if eq .CommonLabels.severity \"info\" -}}\n      *Severity:* :information_source:\n      {{- else -}}\n      *Severity:* :question: {{ .CommonLabels.severity }}\n      {{- end }}\n  {{- end }}\n\n  {{/* Title of the Slack alert */}}\n  {{ define \"slack.title\" -}}\n    [{{ .Status | toUpper -}}\n    {{ if eq .Status \"firing\" }}:{{ .Alerts.Firing | len }}{{- end -}}\n    ] {{ .CommonLabels.alertname }}\n  {{- end }}\n\n\n  {{/* Color of Slack attachment (appears as line next to alert )*/}}\n  {{ define \"slack.color\" -}}\n      {{ if eq .Status \"firing\" -}}\n          {{ if eq .CommonLabels.severity \"warning\" -}}\n              warning\n          {{- else if eq .CommonLabels.severity \"critical\" -}}\n              danger\n          {{- else -}}\n              #439FE0\n          {{- end -}}\n      {{ else -}}\n      good\n      {{- end }}\n  {{- end }}\n\n  {{/* The text to display in the alert */}}\n  {{ define \"slack.text\" -}}\n\n      {{ template \"__alert_severity\" . }}\n\n      {{ range .Alerts }}\n\n          {{- if .Annotations.summary }}\n          {{- \"\\n\" -}}\n          *Summary:* {{ .Annotations.summary }}\n          {{- \"\\n\" -}}\n          {{- end }}\n          {{- if .Annotations.description }}\n          {{- \"\\n\" -}}\n          {{ .Annotations.description }}\n          {{- \"\\n\" -}}\n          {{- end }}\n          {{- if .Annotations.message }}\n          {{- \"\\n\" -}}\n          {{ .Annotations.message }}\n          {{- \"\\n\" -}}\n          {{- end }}\n\n   *Details:*\n     {{ range .Labels.SortedPairs }} \u2022 *{{ .Name }}:* `{{ .Value }}`\n     {{ end }}\n\n      {{- end }}\n\n  {{- end }}\n</code></pre>"},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#stockage-tres-longue-duree","title":"Stockage tr\u00e8s longue dur\u00e9e","text":"<p>Prometheus n'est pas adapt\u00e9 au stockage sur une longue dur\u00e9e de nos m\u00e9triques. Il nous faudra alors utiliser VictoriaMetrics ou Thanos. Je n'ai pas pu explorer ces deux logiciels, n'ayant des m\u00e9triques que sur une courte dur\u00e9e.</p> <p>L'avantage de VictoriaMetrics nous concernant est qu'il utilise le syst\u00e8me PromQL comme Prometheus, nous n'aurons donc pas \u00e0 apprendre un nouveau langage.</p> <p>Il pourra s'agit d'une piste d'enrichissement de ce tutorial dans le futur avec l'int\u00e9gration de VictoriaMetrics.</p> <p>De plus, VictoriaMetrics n'est pas un syst\u00e8me monolithique comme l'est Prometheus, chaque fonctionnalit\u00e9 est un binaire distinct ce qui permet de scale simplement sur un cluster Kubernetes ou autre</p>"},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#exporters","title":"Exporters","text":"<p>Voici une liste d'exporter pour divers \u00e9quipements/logiciels. Cependant, je n'ai pas test\u00e9 ces derniers :</p> Mat\u00e9riel/Logiciel Lien JunOS JunOS Cisco Cisco Mikrotik Mikrotik Windows WMI VMWare VMWare Proxmox Promxox CloudFlare CloudFlare <p>Une liste officielle de tous les exporters Prometheus officielle est disponible, vous permettant de choisir l'exporter qu'il vous faut</p>"},{"location":"linux/monitoring/lgtm/simple_monitoring_stack/#conclusion","title":"Conclusion","text":"<p>J'ai pris plaisir \u00e0 \u00e9crire cet article malgr\u00e9 sa complexit\u00e9 et sa longueur. Creuser \u00e0 travers toutes les documentations et autres sources a \u00e9t\u00e9 un vrai plaisir.</p> <p>Toutes les formes de configuration n'ont pas \u00e9t\u00e9 explor\u00e9s. Par exemple, aucun de nos nodes sont en HA ou autre. J'esp\u00e8re pouvoir faire d'autres articles sur Prometheus en HA ou autre.</p> <p>\u00c9videmment, il s'agit ici de la stack de monitoring que j'ai explor\u00e9, mais rien ne nous emp\u00eache de faire votre propre exp\u00e9rience sur d'autres exporters ou d'autres TSDB.</p>"},{"location":"linux/monitoring/lgtm/tips_lgtm/","title":"2-3 tips pour la stack LGTM","text":"<p>Quelques calls API \u00e0 gauche \u00e0 droite qui nous sont bien pratiques pour du Prometheus ou autre</p>"},{"location":"linux/monitoring/lgtm/tips_lgtm/#prometheus","title":"Prometheus","text":"<p>Notre premier call Prometheus nous permet de lister toutes les m\u00e9triques disponibles dans notre Prometheus</p> <pre><code>curl http://127.0.0.1:9090/api/v1/label/__name__/values\n</code></pre>"},{"location":"linux/mysql/advanced_commands/","title":"MySQL : Commandes avanc\u00e9es","text":"<p>La plupart de ces commandes sont disponibles pour MySQL ou MariaDB.</p>"},{"location":"linux/mysql/advanced_commands/#ram","title":"RAM","text":"<pre><code>SELECT ( @@key_buffer_size\n+ @@innodb_buffer_pool_size\n+ @@innodb_log_buffer_size\n+ @@max_connections * (\n    @@read_buffer_size\n    + @@read_rnd_buffer_size\n    + @@sort_buffer_size\n    + @@join_buffer_size\n    + @@binlog_cache_size\n    + @@thread_stack\n    + @@tmp_table_size )\n) / (1024 * 1024 * 1024) AS MAX_MEMORY_GB;\n</code></pre> <p>Check la max RAM qui sera utilis\u00e9e par MySQL. Il est important de bien prendre en compte la RAM pouvant \u00eatre utilis\u00e9e par chaque connection.</p> <p>Des sites existent tels que MySQLCalculator, MySQL DBA ou encore le plus visuel Avchinnikov</p>"},{"location":"linux/mysql/advanced_commands/#innodb","title":"InnoDB","text":"<pre><code>SELECT  ENGINE,\n        ROUND(SUM(data_length) /1024/1024, 1) AS \"Data MB\",\n        ROUND(SUM(index_length)/1024/1024, 1) AS \"Index MB\",\n        ROUND(SUM(data_length + index_length)/1024/1024, 1) AS \"Total MB\",\n        COUNT(*) \"Num Tables\"\n    FROM  INFORMATION_SCHEMA.TABLES\n    WHERE  table_schema not in (\"information_schema\", \"PERFORMANCE_SCHEMA\", \"SYS_SCHEMA\", \"ndbinfo\")\n    GROUP BY  ENGINE;\n</code></pre> <p>Nous permet de d\u00e9terminer la taille de chaque moteur de stockage. Ainsi, nous pouvons dimensionner innodb_buffer_pool_size au plus juste (20% en plus de la valeur retourn\u00e9e)</p> <pre><code>MariaDB [(none)]&gt; ...\n+--------+---------+----------+----------+------------+\n| ENGINE | Data MB | Index MB | Total MB | Num Tables |\n+--------+---------+----------+----------+------------+\n| CSV    |     0.0 |      0.0 |      0.0 |          2 |\n| InnoDB |  1276.5 |    339.3 |   1615.7 |        172 |\n| MyISAM |     0.5 |      0.1 |      0.6 |         25 |\n+--------+---------+----------+----------+------------+\n3 rows in set (0.007 sec)\n</code></pre> <p>Nous savons que dans notre exemple nous avons un moteur InnoDB utilisant 1.6G. Nous pouvons donc d\u00e9finir le pool \u00e0 2G.</p> <pre><code>Q=` ; mysql --skip-column-names -Be \"select concat(alter table ${Q}, table_schema,${Q}.${Q}, table_name, ${Q} engine=innodb;)\nfrom information_schema.tables where engine = MyISAM and table_schema not in (mysql)\" | mysql\n</code></pre> <p>Cette commande nous sert \u00e0 convertir toutes les tables MyISAM en InnoDB. Un use case parmis tant d'autres, une cluster Galera.</p>"},{"location":"linux/mysql/advanced_commands/#misc","title":"Misc","text":"<pre><code>MariaDB [(none)]&gt; SHOW (FULL) PROCESSLIST 'G;\n</code></pre> <p>Permet de lister les process SQL tournant d'une mani\u00e8re '\"propre'\" (''G), on peut \u00e9galement aller plus loin en d\u00e9tail en ajoutant FULL</p> <pre><code>MariaDB [(none)]&gt;  KILL xxxx\n</code></pre> <p>Permet de kill le process MySQL xxxx (Attention, rollback de la transaction, peut \u00e9galement \u00eatre long)</p> <pre><code>pt-show-grants\nmysql --silent --skip-column-names --execute \"select concat(',User,'@',Host,') as User from mysql.user\" | sort | '\nwhile read u\n do echo \"-- $u\"; mysql --silent --skip-column-names --execute \"show grants for $u\" | sed s/$/;/\ndone\n</code></pre> <ul> <li>Permet de dump la liste des users SQL (commande mysql si     pt-show-grants pas dispo)</li> </ul> <pre><code>SELECT ENGINE,\n       concat(TABLE_SCHEMA, TABLE_NAME) AS TABLE_NAME,\n       round(DATA_LENGTH/1024/1024, 2) AS data_length,\n       round(INDEX_LENGTH/1024/1024, 2) AS index_length,\n       round(DATA_FREE/1024/1024, 2) AS data_free,\n       (data_free/(index_length+data_length)) AS frag_ratio\nFROM information_schema.tables\nWHERE DATA_FREE &gt; 0\nORDER BY data_free DESC LIMIT 10;\n</code></pre> <ul> <li>Permet de voir la fragmentation des tables MySQL. Il est possible de     r\u00e9cuperer l'espace en faisant un OPTIMIZE TABLE</li> </ul> <pre><code>SELECT information_schema.system_variables.variable_name,\n       information_schema.system_variables.default_value,\n       global_variables.variable_value\nFROM information_schema.system_variables,\n     information_schema.global_variables\nWHERE system_variables.variable_name=global_variables.variable_name\n  AND system_variables.default_value &lt;&gt; global_variables.variable_value\n  AND system_variables.default_value &lt;&gt; 0\n</code></pre> <ul> <li>Permet de lister les variables qui n'ont pas les valeurs par d\u00e9faut</li> </ul>"},{"location":"linux/mysql/db_mysql/","title":"Restaurer la DB syst\u00e8me MySQL","text":"<p>Si par tr\u00e8s grosse inadvertance, vous effectuez un rm -Rf /var/lib/mysql, nous pouvons recr\u00e9er la DB initiale MySQL afin de le faire d\u00e9marrer :</p> <pre><code>mkdir /var/lib/mysql\nmkdir /var/lib/mysql/mysql\nchown -R mysql:mysql /var/lib/mysql\nmysql_install_db\n</code></pre> <p>Puis un <code>systemctl start mysql</code> et il est d\u00e9marr\u00e9 !</p>"},{"location":"linux/mysql/galera_gluster/","title":"Cr\u00e9er son cluster Galera","text":""},{"location":"linux/mysql/galera_gluster/#introduction","title":"Introduction","text":"<p>On va faire simple, sans trop de r\u00e9daction.</p> <p>Tout d'abord, bien \u00e9videmment, il faut privil\u00e9gier un r\u00e9seau high speed (Gbps minimum) non rout\u00e9, avec le moins de latence possible, sur des disques SSD.</p> <p>L'int\u00e9r\u00eat d'un cluster Galera est que chaque noeud est master, il s'agit donc d'une replication master-master. Cependant, pour garantir une int\u00e9grit\u00e9 des donn\u00e9es, attention \u00e0 ne pas load-balancer les \u00e9critures. Les lectures peuvent quant \u00e0 elles balanced entre tous les noeuds de votre cluster.</p>"},{"location":"linux/mysql/galera_gluster/#pre-requis","title":"Pr\u00e9-requis","text":"<p>2 solutions, soit on utilise un domaine, soit un fichier hosts.</p> <pre><code>    node1$ cat /etc/hosts\n    10.0.0.1 node1\n    10.0.0.2 node2\n    10.0.0.3 node2\n</code></pre> <p>Penser \u00e0 bien avoir le m\u00eame fichier hosts sur vos diff\u00e9rents hosts</p>"},{"location":"linux/mysql/galera_gluster/#configuration-mariadb","title":"Configuration MariaDB","text":"<p>Une fois que ceci est fait, 2-3 r\u00e9glages sont n\u00e9cessaires. Il faut bien \u00e9videmment installe le package galera. Par d\u00e9faut, les modifications s'effectueront dans le fichier /etc/mysql/mariadb.conf.d/60-galera.cnf</p> <p>Voil\u00e0 \u00e0 quoi ce dernier doit ressembler (pour le node1)</p> <pre><code>    binlog_format=ROW\n    bind-address=10.0.0.1\n    default_storage_engine=innodb\n    innodb_autoinc_lock_mode=2\n    innodb_flush_log_at_trx_commit=0\n    wsrep_provider=/usr/lib/libgalera_smm.so\n    wsrep_cluster_name=\"MyCluster\"\n    wsrep_cluster_address=\"gcomm://node1,node2,node3\"\n    wsrep_node_address=\"10.0.0.1\"\n    wsrep_sst_method=rsync\n</code></pre> <p>Le wsrep_node_address n'est pas obligatoire, cependant, il se peut que l'adresse soit mal '\"devin\u00e9e'\", je pr\u00e9f\u00e8re donc la fixer manuellement.</p> <p>Une fois que ce fichier est bon sur votre cluster, il faut cr\u00e9er le cluster depuis le serveur qui sera primaire.</p> <pre><code>    node1$ galera_new_cluster\n</code></pre> <p>Une fois l'initialisation pass\u00e9e, on v\u00e9rife sur MySQL la variable qu'il faut</p> <pre><code>SHOW STATUS LIKE wsrep_cluster_size;\n\n+--------------------+-------+\n| Variable_name      | Value |\n+--------------------+-------+\n| wsrep_cluster_size | 1     |\n+--------------------+-------+\n</code></pre> <p>Et on ajoute les autres nodes</p> <pre><code>node2$ systemctl start mariadb\n</code></pre> <p>Si tout s'est bien pass\u00e9, on rev\u00e9rifie la valeur de cette variable, elle devrait passer a 3.</p> <p>Attention, pour rappel, Galera fonctionne uniquement en InnoDB. Le MyISAM est encore exp\u00e9rimental et est d\u00e9conseill\u00e9 en production.</p> <p>Toutes les informations sont diponibles sur https://galeracluster.com/library/training/tutorials</p>"},{"location":"linux/mysql/galera_gluster/#troubleshoting","title":"Troubleshoting","text":"<p>Si pour quelconque raison on a un probl\u00e8me sur un node Galera, il peut \u00eatre plus rapide de le recr\u00e9\u00e9r de 0. Il faut bien \u00e9videmment regarder les logs Galera et v\u00e9rifier que les entr\u00e9es FW soit OK.</p> <p>Pour reset un node d'un cluster Galera :</p> <pre><code>\u03bb yann ~ \u2192  rm -rf /var/lib/mysql &amp;&amp; service mysql start\n</code></pre> <p>Tout sera re-import\u00e9 depuis le master actuel</p>"},{"location":"linux/mysql/users/","title":"G\u00e9rer ses users MySQL","text":"<p>Quelques trucs basiques pour les users MySQL :</p>"},{"location":"linux/mysql/users/#creer-son-user","title":"Cr\u00e9er son user","text":"<pre><code>-- Mot de passe en clair dans la requ\u00eate\nCREATE USER user@localhost IDENTIFIED BY password;\n\n-- Mot de passe pass\u00e9 sous un algorithme de Hash\nSELECT PASSWORD(password); -- Cr\u00e9ation du Hash du mot de passe\nCREATE USER user@localhost IDENTIFIED BY PASSWORD *2470C0C06DEE42FD1618BB9900DFG1E6Y89F4;\n</code></pre> <p>Attention, localhost et 127.0.0.1 n'ont pas la m\u00eame d\u00e9finition en MySQL. IL faut activer skip-name-resolve pour cela</p> <p>Diff\u00e9rentes m\u00e9thodes d'authentification sont disponibles, par exemple, IDENTIFIED VIA unix_socket nous permettra d'\u00eatre authentifi\u00e9 via son compte UNIX.</p>"},{"location":"linux/mysql/users/#renommer-son-user","title":"Renommer son user","text":"<pre><code>RENAME USER user@localhost TO user2@localhost;\n</code></pre>"},{"location":"linux/mysql/users/#changer-de-password","title":"Changer de password","text":"<pre><code>SET PASSWORD FOR user@localhost = PASSWORD(newpassword);\n</code></pre>"},{"location":"linux/mysql/users/#attribution-de-privileges","title":"Attribution de privil\u00e8ges","text":"<p>Avant toute op\u00e9ration dattribution de privil\u00e8ges sur une base de donn\u00e9es, commen\u00e7ons par cr\u00e9er cette derni\u00e8re.</p> <pre><code>CREATE DATABASE `database` DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci;\n</code></pre> <p>Maintenant, attribuons des privil\u00e8ges \u00e0 un utilisateur sur cette base de donn\u00e9es.</p> <pre><code>GRANT SELECT, INSERT, UPDATE, DELETE ON `database`.* TO user@localhost;\n</code></pre> <p>Si vous voulez attribuer tout les droits sur une base de donn\u00e9es \u00e0 un utilisateur, il vous suffit deffectuer la requ\u00eate suivante :</p> <pre><code>GRANT ALL ON `database`.* TO user@localhost;\n</code></pre> <p>Maintenant, pour que les nouveaux droits attribu\u00e9s soient pris en compte, il est n\u00e9cessaire de lancer la requ\u00eate FLUSH.</p> <pre><code>FLUSH PRIVILEGES;\n</code></pre>"},{"location":"linux/mysql/users/#revocation-de-privileges","title":"R\u00e9vocation de privil\u00e8ges","text":"<p>Apr\u00e8s avoir attribuer des privil\u00e8ge, r\u00e9voquons-les. Vous pouvez r\u00e9voquer lensemble des droits dun utilisateur avec la requ\u00eates suivante.</p> <pre><code>REVOKE ALL PRIVILEGES, GRANT OPTION FROM user@localhost;\n</code></pre> <p>Vous pouvez \u00e9galement supprimer seulement certains privil\u00e8ges.</p> <pre><code>REVOKE DELETE ON database.* FROM user@localhost;\n</code></pre>"},{"location":"linux/mysql/users/#suppression-utilisateur","title":"Suppression Utilisateur","text":"<p>La suppression dun utilisateur MySQL d\u00e9pend de la version de MySQL. A partir de la version 5.0.2, la commande suivante suffit \u00e0 la suppression de lutilisateur.</p> <pre><code>DROP USER user@localhost;\n</code></pre>"},{"location":"linux/mysql/troubleshooting/generate_insert_into/","title":"G\u00e9n\u00e9rer des INSERT INTO depuis un SELECT","text":"<p>Une commande est vraiment magique avec mysqldump et permet de g\u00e9n\u00e9rer des INSERT INTO depuis un WHERE assez simple</p> <pre><code>mysqldump -t DB Table --where=\"champ in (280, 172);\" &gt; ~/Req.sql\n</code></pre> <p>Cet SQL dump va simple g\u00e9n\u00e9rer les INSERT INTO selon la condition que nous lui avons donn\u00e9, MAGIQUE !</p>"},{"location":"linux/mysql/troubleshooting/replication_slave/","title":"Debug sa replication Master-Slave","text":""},{"location":"linux/mysql/troubleshooting/replication_slave/#introduction","title":"Introduction","text":"<p>Il se peut que vous ayez a debug une replication qui a plant\u00e9</p> <pre><code>Error: Last_SQL_Errno: 1594 Last_SQL_Error: Relay log read failure: Could not parse relay log event entry.\n</code></pre> <p>Dans cet exemple, nous assumerons que 10.0.0.1 est le master et 10.0.0.2 est le slave.</p> <p>Tout d'abord, nous devons d'abord observer nos diff\u00e9rents \u00e9l\u00e9ments (\u00e0 lancer sur la slave) :</p> <pre><code>MariaDB [(none)]&gt; SHOW SLAVE STATUS \\G;\n*************************** 1. row ***************************\n                Slave_IO_State:\n                   Master_Host: 192.168.0.11\n                   Master_User: replication\n                   Master_Port: 3306\n                 Connect_Retry: 60\n               Master_Log_File: mysql-bin.000244\n           Read_Master_Log_Pos: 43725948\n                Relay_Log_File: mysqld-relay-bin.000325\n                 Relay_Log_Pos: 4521579\n         Relay_Master_Log_File: mysql-bin.000234\n                        .....\n           Exec_Master_Log_Pos: 4521284\n</code></pre> <p>Premi\u00e8rement, nous allons v\u00e9rifier que le log est lisible sur le master. Nous parlons ici du Master_Log_File.</p> <pre><code>mysqlbinlog mysql-bin.000244\n</code></pre> <p>Si cette commande marche, alors nous pouvons rejouer les transactions et reset le slave. Action \u00e0 effectuer sur le master</p> <pre><code>mysql&gt; STOP SLAVE;\nQuery OK, 0 rows affected (0.14 sec)\n\nmysql&gt; RESET SLAVE ALL;\nQuery OK, 0 rows affected (0.43 sec)\n\nmysql&gt;  CHANGE MASTER TO MASTER_HOST=master.host.com, MASTER_USER=masteruser, MASTER_PASSWORD=masterpass, MASTER_LOG_FILE=mysqld-relay-bin.000325, MASTER_LOG_POS=4521284;\nQuery OK, 0 rows affected (0.93 sec)\n\nmysql&gt; START SLAVE;\nQuery OK, 0 rows affected (0.00 sec)\n</code></pre> <p>Normalement, vous devriez d\u00e9sormais avoir votre replication fonctionnelle</p>"},{"location":"linux/mysql/troubleshooting/replication_slave/#io-replication-no","title":"IO Replication: NO","text":"<p>G\u00e9n\u00e9ralement, on est juste pas a la bonne position. Sur le master, effectuer</p> <pre><code>SMS=/tmp/show_master_status.txt\nmysql -ANe \"SHOW MASTER STATUS\" &gt; ${SMS}\nCURRENT_LOG=`cat ${SMS} | awk {print $1}`\nCURRENT_POS=`cat ${SMS} | awk {print $2}`\necho ${CURRENT_LOG} ${CURRENT_POS}\n</code></pre> <p>Et remplir avec les bonnes infos ;-)</p>"},{"location":"linux/networking/buffer_nic/","title":"Augmenter le buffer de sa carte r\u00e9seau","text":"<p>Dans certains cas sp\u00e9cifiques, augmenter le buffer de sa carte r\u00e9seau peut \u00eatre b\u00e9n\u00e9fique pour votre serveur. Quoi qu'il en soit, il n'y a aucune raison de ne pas le pousser au maximum.</p>"},{"location":"linux/networking/buffer_nic/#augmenter-ses-buffers","title":"Augmenter ses buffers","text":"<p>Pour augmenter ses buffers, on utilise le merveuilleux outil disponible partout, ethtool. On observe dans un premier temps les buffers disponibles et ceux qu'on a d\u00e9j\u00e0 appliqu\u00e9s.</p> <pre><code>[vps ~]$ ethtool -g eno1\nRing parameters for eno1:\nPre-set maximums:\nRX:             4096\nRX Mini:        0\nRX Jumbo:       0\nTX:             4096\nCurrent hardware settings:\nRX:             512\nRX Mini:        0\nRX Jumbo:       0\nTX:             512\n</code></pre> <p>On voit ici que nos buffers sont 8x inf\u00e9rieurs \u00e0 ceux qu'on peut potentiellement mettre. Voici comment les appliquer</p> <pre><code>[vps ~]$ ethtool -G eno1 rx 4096 tx 4096\n</code></pre>"},{"location":"linux/networking/buffer_nic/#de-facon-permanente","title":"De fa\u00e7on permanente","text":"<p>Malheureusement, ethtool n'agit pas de mani\u00e8re permanente, voici une des mani\u00e8res pour rendre permanente le fix</p> <pre><code>echo \"ACTION==\"add|change\", SUBSYSTEM==\"net\", KERNEL==\"eth*|en*\", RUN+=\"/sbin/ethtool -G $name rx 4096 tx 4096\"\n\" &gt;&gt; /etc/udev/rules.d/59-net.ring.rules\n</code></pre> <p>Plus d'informations ici</p>"},{"location":"linux/networking/openvpn/","title":"Installer et configurer son VPN OpenVPN","text":""},{"location":"linux/networking/openvpn/#preambule","title":"Pr\u00e9ambule","text":"<p>Pourquoi installer un serveur VPN ? Il existe une multitude raisons d'installer un serveur VPN, la premi\u00e8re est d'\u00e9viter la surveillance. La connexion via un VPN \u00e9tant crypt\u00e9e, nous ne pouvons pas savoir ce qu'y passe sur le r\u00e9seau, nous parlons alors de tunnel VPN.</p> <p>Il est \u00e9galement possible d'utiliser un VPN afin d'\u00e9viter les g\u00e9o-restrictions (Netflix, Hulu...)</p> <p>Et enfin, nous pouvons utiliser un VPN pour \u00eatre un petit peu plus anonyme sur la toile. Attention, les VPN fran\u00e7ais ont pour obligation de conserver les logs de connexion au moins 1 an, et rien ne vous dit que les logs sont d\u00e9sactiv\u00e9s sur votre VPN \u00e0 2'$ par mois.</p> <p>Le serveur VPN ne doit pas \u00eatre sur votre machine physique, ou celui-ci serait totalement inutile.</p> <p>Le but d'un serveur VPN est de faire croire aux serveurs sur Internet que vous n'\u00eates pas localis\u00e9s \u00e0 votre adresse, mais \u00e0 l'adresse de votre serveur VPN.</p> <p>Vous pouvez prendre un petit VPS chez Scaleway par exemple, ou alors si vous avez vraiment peur de Hadopi &amp; co, chez YourServer (Excellent petit h\u00e9bergeur, staff facilement accessible).</p>"},{"location":"linux/networking/openvpn/#installation","title":"Installation","text":"<p>Pour installer OpenVPN, rien de plus simple:</p> <pre><code>apt install openvpn\n</code></pre> <p>Nous allons installer la brique de base de notre serveur VPN, cependant, il nous reste de nombreuses \u00e9tapes avant d'avoir un VPN fonctionnel.</p> <p>Nous allons copier les fichiers utiles \u00e0 la cr\u00e9ation des futures certificats :</p> <pre><code>cp -a /usr/share/easy-rsa /etc/openvpn/ &amp;&amp; cd /etc/openvpn/easy-rsa\nsource vars\n./clean-all\n</code></pre>"},{"location":"linux/networking/openvpn/#creation-des-certificats","title":"Cr\u00e9ation des certificats","text":"<p>Afin d'\u00eatre s\u00e9curiser, un VPN a besoin de certificats SSL. Ceux-ci sont tr\u00e8s facile \u00e0 build via easy-rsa</p> <pre><code>cd /etc/openvpn/easy-rsa\n./build-ca\n</code></pre> <p>Spammez la touche '\"Entree'\" de votre clavier jusqu'\u00e0 revenir sur votre terminal de base</p> <p>Puis on creer le Diffie-Hellman</p> <pre><code>openvpn --genkey --secret /etc/openvpn/ta.key\n</code></pre> <p>Et enfin, le certificat c\u00f4t\u00e9 serveur, que l'on n'oublie pas de signer !</p> <pre><code>./build-key-server srvcert\n</code></pre> <p>Une fois ceci fait, nous avons tous nos certificats pour configurer correctement notre OpenVPN</p>"},{"location":"linux/networking/openvpn/#configuration-de-openvpn","title":"Configuration de OpenVPN","text":"<p>OpenVPN fournit des fichiers de configurations exemple relativement bien complet, nous allons donc les r\u00e9utiliser</p> <pre><code>gunzip -c /usr/share/doc/openvpn/examples/sample-config-files/server.conf.gz &gt; /etc/openvpn/server.conf\n</code></pre> <p>Puis on l'\u00e9dite afin qu'il concorde \u00e0 notre installation</p> <pre><code>vim /etc/openvpn/server.conf\n</code></pre> <p>Voici les valeurs que nous devons avoir dans server.conf :</p> <ul> <li>user nobody</li> <li>group nogroup</li> <li>ca /etc/openvpn/easy-rsa/keys/ca.crt</li> <li>cert /etc/openvpn/easy-rsa/keys/srvcert.crt</li> <li>key /etc/openvpn/easy-rsa/keys/srvcert.key '# This file should be     kept secret</li> <li>dh /etc/openvpn/easy-rsa/keys/dh2048.pem</li> <li>cipher AES-256-CBC</li> </ul> <p>Et on ajoute en bas du fichier ces lignes:</p> <ul> <li>push '\"redirect-gateway def1 bypass-dhcp'\"</li> <li>push '\"dhcp-option DNS 4.2.2.1'\"</li> <li>push '\"dhcp-option DNS 4.2.2.2'\"</li> <li>sndbuf 0</li> <li>rcvbuf 0</li> </ul> <p>Voici \u00e0 quoi doit ressembler le fichier final</p> <pre><code>    port 42600\n    proto udp\n    dev tun\n    sndbuf 0\n    rcvbuf 0\n    ca ca.crt\n    cert server.crt\n    key server.key\n    dh dh.pem\n    tls-auth ta.key 0\n    topology subnet\n    server 10.1.2.0 255.255.255.0\n    ifconfig-pool-persist ipp.txt 0\n    push \"redirect-gateway def1 bypass-dhcp\"\n    push \"dhcp-option DNS 10.0.0.106\"\n    push \"dhcp-option DNS 10.0.0.14\"\n    keepalive 10 120\n    cipher AES-128-CBC\n    comp-lzo\n    user nobody\n    group nogroup\n    persist-key\n    persist-tun\n    status openvpn-status.log\n    log /var/log/openvpn.log\n    verb 3\n</code></pre>"},{"location":"linux/networking/openvpn/#configuration-du-serveur","title":"Configuration du Serveur","text":"<p>Maintenant qu'OpenVPN est correctement configurer, nous devons configurer notre distribution Linux afin que celle-ci route correctement notre serveur VPN</p> <p>Tout d'abord, on active l'IP Forwarding</p> <pre><code>echo net.ipv4.ip_forward=1 &gt;&gt; /etc/sysctl.conf\nsysctl -p\n</code></pre> <p>Et on active le NAT via IPTables</p> <pre><code>    iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE\n    iptables -t nat -A POSTROUTING -s 10.8.0.0/24 -o eth0 -j MASQUERADE\n</code></pre> <p>Par d\u00e9faut, OpenVPN utilise le r\u00e9seau 10.8.0.0/24</p>"},{"location":"linux/networking/openvpn/#configuration-du-client-openvpn","title":"Configuration du client OpenVPN","text":"<p>Maintenant que notre OpenVPN est correctement configur\u00e9 c\u00f4t\u00e9 server, nous devons nous occuper de la partie client.</p> <p>Tout d'abord, il faut g\u00e9nerer les certificats pour notre client (Votre PC).</p> <pre><code>cd /etc/openvpn/easy-rsa/\nsource vars\n./build-key jeremy\n</code></pre> <p>Et on cr\u00e9er le fichier de conf :</p> <pre><code># Client\nclient\ndev tun\nproto udp\nremote ip port\nresolv-retry infinite\ncipher AES-256-CBC\n; client-config-dir ccd\n# Cles\nca ca.crt\ncert jeremy.crt\nkey jeremy.key\ntls-auth ta.key 1\nkey-direction 1\n# Securite\nnobind\npersist-key\npersist-tun\ncomp-lzo\nverb 3\n# Set manual buffers\nsndbuf 0\nrcvbuf 0\n</code></pre> <p>N'oubliez pas de t\u00e9l\u00e9charger les fichiers suivants sur votre PC :</p> <ul> <li>ca.crt</li> <li>ta.key</li> <li>jeremy.crt</li> <li>jeremy.key</li> <li>client.ovpn</li> </ul> <p>Et voil\u00e0, vous avez votre propre VPN fonctionnel :)</p>"},{"location":"linux/networking/openvpn/#script-dauto-installation","title":"Script d'auto-installation","text":"<p>piVPN est un petit script permettant d'installer un serveur OVPN en nous permettant de setup port utilis\u00e9, DNS...</p> <p>En plus de cela, pivpn nous fournit un petit script de gestion d'utilisateur. Il est compatible Debian et Ubuntu</p> <p>OpenVPN-Install est un script simple d\u00e9velopp\u00e9 par Angristan multi-plateforme (CentOs, Debian et Ubuntu) apportant une s\u00e9curit\u00e9 accrue.</p>"},{"location":"linux/networking/openvpn_v6/","title":"Configurer son serveur OpenVPN pour de l'IPv6","text":"<p>OpenVPN est un VPN dual-stack. Dans ce tutoriel, nous allons voir comment apporter une connectivit\u00e9 v6 \u00e0 vos clients, ce qui peut \u00eatre particuli\u00e8rement utile afin d'acc\u00e9der \u00e0 des sites IPv6 uniquement.</p> <p>Pour faire ce tutoriel, il faut d\u00e9j\u00e0 avoir un serveur avec une IPv6 en /64 sur son interface WAN ainsi qu'un serveur OpenVPN d\u00e9j\u00e0 configur\u00e9.</p>"},{"location":"linux/networking/openvpn_v6/#configuration-de-los","title":"Configuration de l'OS","text":"<p>Tout d'abord, comme pour IPv4, il faut activer l'ip_forwarding</p> <pre><code>sed -i 0,/ipv6.conf.all/s/^#//g /etc/sysctl.conf\nsysctl -p\n</code></pre> <p>Pour \u00eatre sur que la modification soit appliqu\u00e9e, nous pouvons aller voir ce fichier (Qui doit retourner 1)</p> <pre><code>cat /proc/sys/net/ipv6/conf/all/forwarding\n</code></pre> <p>Mais pour l'IPv6, nous avons un param\u00e8tre en plus \u00e0 modifier, accept_ra (Si vous acceptez votre IPv6 via RA)</p> <p>L'accept_ra nous permet de configurer automatiquement IPv6, il existe 3 modes :</p> <ul> <li>0 : Ne pas accepter de RA</li> <li>1 : Accepter les RA</li> <li>2 : Accepter les RA m\u00eame si nous avons l'IPv6 forwarding     d'activ\u00e9</li> </ul> <p>Vous l'avez donc comprit, il nous faut donc un accept_ra \u00e0 2</p> <pre><code>    echo \"net.ipv6.conf.all.accept_ra=2\" &gt;&gt; /etc/sysctl.conf\n    sysctl -p\n</code></pre> <p>Et une nouvelle fois, nous v\u00e9rifions que la valeur ait bien \u00e9t\u00e9 appliqu\u00e9e :</p> <pre><code>cat /proc/sys/net/ipv6/conf/all/accept_ra\n</code></pre>"},{"location":"linux/networking/openvpn_v6/#configuration-du-serveur","title":"Configuration du serveur","text":"<p>Prenons en exemple ce range IPv6 : 2001:bc8:31d7:6e00:/56</p> <p>Nous avons donc configur\u00e9 2001:bc8:31d7:6e00::/64 sur l'interface publique de notre serveur. OpenVPN utilisera le prochain range disponible, soit 2001:bc8:31d7:6e01:/64</p> <p>Voici les modifications \u00e0 appliquer \u00e0 notre serveur pour qu'il soit dual-stack :</p> <ul> <li>proto udp en proto udp6</li> <li>server-ipv6 2001:bc8:31d7:6e01:/64</li> <li>push '\"route-ipv6 2000::/3'\"</li> </ul> <p>Une fois cette configuration faite, un restart de openvpn, et vous devriez avoir une connectivit\u00e9 v6 sur votre h\u00f4te :</p> <pre><code>systemctl restart openvpn@server.service\n</code></pre> <p>Si votre fichier de configuration s'appelle server.conf (A adapter sinon)</p>"},{"location":"linux/networking/speedtestcli/","title":"Effectuer un Speedtest depuis son serveur","text":""},{"location":"linux/networking/speedtestcli/#introduction","title":"Introduction","text":"<p>Pour effectuer simplement un speedtest sur votre serveur, installer speedtest-cli</p> <pre><code>apt install speedtest-cli\n</code></pre> <p>Puis lancer simplement la commande</p> <pre><code>\u03bb jeremy ~ \u2192 speedtest-cli\nRetrieving speedtest.net configuration...\nTesting from LeaseWeb Netherlands B.V. (212.32.243.25)...\nRetrieving speedtest.net server list...\nSelecting best server based on ping...\nHosted by XS4ALL Internet BV (Amsterdam) [1.39 km]: 2.168 ms\nTesting download speed................................................................................\nDownload: 154.49 Mbit/s\nTesting upload speed......................................................................................................\nUpload: 4.17 Mbit/s\n</code></pre>"},{"location":"linux/networking/ipv6/setup_online/","title":"Configurer son IPv6 chez Online","text":"<p>https://www.abyssproject.net/2016/08/configurer-ipv6-chez-online-net/</p>"},{"location":"linux/postgres/commands/","title":"Commandes utiles Postgres","text":"<pre><code> SELECT i.relname \"Table Name\",indexrelname \"Index Name\",\n pg_size_pretty(pg_total_relation_size(relid)) As \"Total Size\",\n pg_size_pretty(pg_indexes_size(relid)) as \"Total Size of all Indexes\",\n pg_size_pretty(pg_relation_size(relid)) as \"Table Size\",\n pg_size_pretty(pg_relation_size(indexrelid)) \"Index Size\",\n reltuples::bigint \"Estimated table row count\"\n FROM pg_stat_all_indexes i JOIN pg_class c ON i.relid=c.oid\n WHERE i.relname='uploads'\n ```\n\n* Pour voir les informations d\u00e9taill\u00e9es d'une table.\n\nIl y a un tools open-source Github permettant d'avoir une multitudes de commandes utiles rapidement : [Postgres DBA](https://github.com/NikolayS/postgres_dba)\n\n---\n\n```sql\npsql&gt; \\f '|'\npsql&gt; \\a\npsql&gt; \\o '/tmp/output.csv'\npsql&gt; SELECT * from users;\npsql&gt; \\q\n</code></pre> <p>Permet d'avoir un output de psql en tant que CSV</p>"},{"location":"linux/postgres/postgresql_replication/","title":"PostgreSQL Replication","text":""},{"location":"linux/postgres/postgresql_replication/#replication","title":"Replication","text":"<p>La r\u00e9plication sur PostgreSQL est un bordel. Je note donc ici pour les prochaines fois</p>"},{"location":"linux/postgres/postgresql_replication/#creation","title":"Creation","text":""},{"location":"linux/postgres/postgresql_replication/#users","title":"Users","text":"<p>Pour cr\u00e9er une r\u00e9plication PostgreSQL, il y a plusieurs choses \u00e0 savoir</p> <p>Tout d'abord, nous devons cr\u00e9er un utilisateur d\u00e9di\u00e9 pour ex\u00e9cuter la r\u00e9plication (sur le n\u0153ud master) :</p> <pre><code>psql -c \"CREATE USER replicator WITH REPLICATION ENCRYPTED PASSWORD 'Iej7choobeinohJa8shieNg4iev5dien'\"\n</code></pre> <p>Ensuite, nous devons configurer <code>pg_hba.conf</code> pour autoriser la connexion \u00e0 cet utilisateur (<code>172.29.49.11</code> est notre IP de secours) :</p> <pre><code>host  replication          replicator         172.29.49.11/32         md5\n</code></pre> <p>Puis on reload la configuration</p> <pre><code>psql -c \"select pg_reload_conf()\"\n</code></pre>"},{"location":"linux/postgres/postgresql_replication/#configuration","title":"Configuration","text":"<p>C'est la partie d\u00e9licate, quelques param\u00e8tres \u00e0 adapter en fonction de votre workload :</p> <ul> <li>max_wal_senders : Nombre de processus d'exp\u00e9diteur WAL qui peuvent \u00eatre d\u00e9marr\u00e9s sur le ma\u00eetre. Un pour chaque r\u00e9plique. pg_basebackup peut utiliser un ou deux WAL senders. <code>max_wal_senders</code> est g\u00e9n\u00e9ralement fix\u00e9 par d\u00e9faut \u00e0 10 sur toutes les distributions. Ainsi, ce param\u00e8tre n'a pas besoin d'\u00eatre modifi\u00e9, sauf si nous configurons plus de 5 standby pour un ma\u00eetre.</li> </ul> <pre><code>postgres=# ALTER SYSTEM SET max_wal_senders TO '10';\n</code></pre> <ul> <li>listen_addresses : Ce param\u00e8tre d\u00e9termine les interfaces IP par lesquelles les connexions sont autoris\u00e9es. Par d\u00e9faut, il s'agit de localhost. Il peut \u00eatre d\u00e9fini sur l'interface IP publique ou priv\u00e9e ou par tout en utilisant (*).</li> </ul> <pre><code>postgres=# ALTER SYSTEM SET listen_addresses TO '*';\n</code></pre> <ul> <li>archive_mode : Ce param\u00e8tre doit \u00eatre d\u00e9fini sur 'ON' pour activer l'archivage. Lorsque l'archivage est activ\u00e9, les segments WAL sont copi\u00e9s vers l'emplacement d'archivage, avant d'\u00eatre recycl\u00e9s (archive_mode n'est pas un param\u00e8tre obligatoire mais sugg\u00e9r\u00e9 pour les bases de donn\u00e9es de production).</li> </ul> <pre><code>postgres=# ALTER SYSTEM SET archive_mode TO 'ON';\n</code></pre> <ul> <li>archive_command : La commande shell ou un script \u00e0 l'aide duquel l'archiveur doit effectuer l'archivage d'un segment WAL complet. Voici un exemple de configuration qui utilise la commande cp sous linux.\u00a0Par exemple</li> </ul> <pre><code>postgres=# ALTER SYSTEM SET archive_command TO 'cp %p /archives/%f';\n</code></pre> <ul> <li>\u2192 %p est substitu\u00e9 par postgres avec le chemin d'acc\u00e8s au segment WAL r\u00e9el.</li> <li> <p>\u2192 %f est substitu\u00e9 par postgres avec le nom du fichier WAL.</p> </li> <li> <p>wal_keep_size : Quantit\u00e9 de segments WAL qui doivent \u00eatre au moins conserv\u00e9s dans le r\u00e9pertoire pg_wal avant d'\u00eatre recycl\u00e9s.</p> </li> </ul> <pre><code>postgres=# ALTER SYSTEM SET wal_keep_size TO '1GB';\n</code></pre> <p>\u2192 Comme certaines de nos bases de donn\u00e9es sont \u00e9normes, n'h\u00e9sitez pas \u00e0 mettre des valeurs tr\u00e8s \u00e9lev\u00e9es (comme 300GB).</p> <p>Une fois que toutes ces valeurs sont correctement \u00e9dit\u00e9es, recharger une autre fois.</p> <pre><code>psql -c \"select pg_reload_conf()\"\n</code></pre> <p>Et enfin, sur le noeud standby, nous ex\u00e9cutons une sauvegarde de base pour activer la r\u00e9plication.</p> <pre><code>/usr/lib/postgresql/13/bin/ --create-slot --slot=data_slot_slave1 --host=172.19.49.11 --user=replicator --write-recovery-conf --wal-method=stream --pgdata=/data/pgsql/13/data/ --progress --checkpoint=fast\"\n</code></pre>"},{"location":"linux/postgres/postgresql_replication/#deletion","title":"Deletion","text":"<p>C'est la seule t\u00e2che facile dans PostgreSQL, nous devons seulement supprimer le slot de r\u00e9plication.</p> <pre><code>postgres=# SELECT pg_drop_replication_slot(slot_name) FROM pg_replication_slots WHERE slot_name = 'data_slot_slave1';\n</code></pre> <p>C'est une commande personnalis\u00e9e, elle n'\u00e9choue pas dans le cas o\u00f9 le slot n'existe pas. C'est utile si vous le scriptez !</p>"},{"location":"linux/postgres/postgresql_replication/#troubleshooting","title":"Troubleshooting","text":""},{"location":"linux/postgres/postgresql_replication/#master-node","title":"Master Node","text":"<p>Pour troubleshoot une r\u00e9plication, quelques commandes utiles :</p> <pre><code>postgres=# SELECT * FROM pg_replication_slots;\n-[ RECORD 1 ]-------+---------------\nslot_name           | data_slot_s1\nplugin              |\nslot_type           | physical\ndatoid              |\ndatabase            |\ntemporary           | f\nactive              | t\nactive_pid          | 93620\nxmin                | 390443541\ncatalog_xmin        |\nrestart_lsn         | 24A8E/76E161C8\nconfirmed_flush_lsn |\nwal_status          | reserved\nsafe_wal_size       | 274879913528\n</code></pre> <p>Nous voyons ici que notre <code>data_slot_s1</code> est dans <code>wal_status</code> r\u00e9serv\u00e9 et est actif, donc nous avons une r\u00e9plication saine.</p> <p>Pour rappel, voici ce que dit la documentation</p> <p>Disponibilit\u00e9 des fichiers WAL revendiqu\u00e9s par ce slot. Les valeurs possibles sont :</p> <ul> <li><code>reserved</code> signifie que les fichiers r\u00e9clam\u00e9s sont dans la limite de la taille <code>max_wal_size</code>.</li> <li><code>extended</code> signifie que la taille <code>max_wal_size</code> est d\u00e9pass\u00e9e mais que les fichiers sont toujours conserv\u00e9s, soit par le slot de r\u00e9plication, soit par <code>wal_keep_size</code>.</li> <li><code>unreserved</code> signifie que le slot ne conserve plus les fichiers WAL requis et que certains d'entre eux doivent \u00eatre supprim\u00e9s au prochain checkpoint. Cet \u00e9tat peut revenir \u00e0 <code>reserved</code> ou <code>extended</code>.</li> <li><code>lost</code> signifie que certains fichiers WAL requis ont \u00e9t\u00e9 supprim\u00e9s et que ce slot n'est plus utilisable.</li> </ul> <pre><code>postgres=# select usename,application_name,client_addr,backend_start,state,sync_state from pg_stat_replication;\n-[ RECORD 1 ]----+------------------------------\nusename          | replicator\napplication_name | walreceiver\nclient_addr      | 172.29.49.11\nbackend_start    | 2022-11-30 23:13:43.810803+01\nstate            | streaming\nsync_state       | async\n</code></pre> <p>Nous voyons ici que nous avons une r\u00e9plication en tant que user replicator avec le serveur ayant comme IP <code>172.29.49.11</code>. Il s'agit d'une r\u00e9plication ayant d\u00e9but\u00e9 le <code>30 novembre \u00e0 23:13</code>.</p>"},{"location":"linux/postgres/postgresql_replication/#standby-node","title":"Standby Node","text":"<pre><code>postgres=# select pg_is_in_recovery(),pg_is_wal_replay_paused(), pg_last_wal_receive_lsn(), pg_last_wal_replay_lsn(), pg_last_xact_replay_timestamp();\n-[ RECORD 1 ]-----------------+------------------------------\npg_is_in_recovery             | t\npg_is_wal_replay_paused       | f\npg_last_wal_receive_lsn       | 24A8E/9DBBBE48\npg_last_wal_replay_lsn        | 24A8E/9DBBBE48\npg_last_xact_replay_timestamp | 2022-12-01 11:46:05.427305+01\n</code></pre> <p>Nous voyons actuellement que le noeud client est en mode de r\u00e9cup\u00e9ration, et qu'il n'est pas \"en pause\" de r\u00e9plication. Il lit actuellement le dernier segment qu'il a re\u00e7u, qui est le segment du 1er d\u00e9cembre \u00e0 11h45.</p> <p>Si <code>pg_last_wal_receive_lsn</code> et <code>pg_last_wal_replay_lsn</code> \u00e9taient diff\u00e9rents. Nous pourrions d\u00e9terminer combien de Go manquent au n\u0153ud de secours, par exemple :</p> <pre><code>postgres=# select pg_wal_lsn_diff('0/925D7E70','0/2705BDA0');\n-[ RECORD 1 ]---+-----------\npg_wal_lsn_diff | 1800913104\n</code></pre> <p>Lets see how much is 1800913104</p> <pre><code>postgres=# select round(1800913104/pow(1024,3.0),2) missing_lsn_GiB;\n missing_lsn_gib\n-----------------\n            1.68\n</code></pre> <p>Il manque 1,68GB sur le noeud standby, ce qui peut \u00eatre beaucoup, selon la taille de votre base de donn\u00e9es.</p> <pre><code>postgres=# SELECT CASE WHEN pg_last_wal_receive_lsn() = pg_last_wal_replay_lsn()\npostgres-# THEN 0\npostgres-# ELSE EXTRACT (EPOCH FROM now() - pg_last_xact_replay_timestamp())\npostgres-# END AS log_delay;\n-[ RECORD 1 ]\nlog_delay | 0\n</code></pre> <p>Bonne nouvelle, notre r\u00e9plication est saine et n'a pas de retard !</p> <pre><code>postgres=# SELECT  * FROM pg_stat_wal_receiver;\n-[ RECORD 1 ]---------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\npid                   | 211574\nstatus                | streaming\nreceive_start_lsn     | 249B0/EC000000\nreceive_start_tli     | 1\nwritten_lsn           | 24A8F/2AEAA10\nflushed_lsn           | 24A8F/2AEAA10\nreceived_tli          | 1\nlast_msg_send_time    | 2022-12-01 12:03:26.367879+01\nlast_msg_receipt_time | 2022-12-01 12:03:26.382725+01\nlatest_end_lsn        | 24A8F/2AEAA10\nlatest_end_time       | 2022-12-01 12:03:26.367879+01\nslot_name             | data_slot_s1\nsender_host           | 172.19.49.11\nsender_port           | 5432\nconninfo              | user=replicator passfile=/var/lib/postgresql/.pgpass channel_binding=prefer dbname=replication host=172.19.49.11 port=5432 fallback_application_name=walreceiver sslmode=prefer sslcompression=0 sslsni=1 ssl_min_protocol_version=TLSv1.2 gssencmode=prefer krbsrvname=postgres target_session_attrs=any\n</code></pre> <p>Autres informations utiles</p>"},{"location":"linux/postgres/upgrade_version/","title":"Upgrade sa version de PostgreSQL","text":"<p>Upgrade PostreSQL, c'est vraiment une plaie. Petit tuto du coup sur comment faire.</p> <p>Il faut installer les 2 versions de postgresql et stop les 2, puis passer sur l'utilisateur postgres</p> <pre><code>su - postgres\n</code></pre> <p>Puis on exporte les variables d'environnement qui vont bien. Par exemple pour une upgrade de 11 \u00e0 13 :</p> <pre><code>export PGDATAOLD=/var/lib/postgresql/11/main\nexport PGDATANEW=/var/lib/postgresql/13/main\nexport PGBINOLD=/usr/lib/postgresql/11/bin/\nexport PGBINNEW=/usr/lib/postgresql/13/bin/\n</code></pre> <p>Puis on passe pg_upgrade avec l'option '--check afin de ne pas appliquer les modifications</p> <pre><code>/usr/lib/postgresql/13/bin/pg_upgrade --check --old-options -config_file=/etc/postgresql/11/main/postgresql.conf --new-options -config_file=/etc/postgresql/13/main/postgresql.conf\n</code></pre> <p>Note</p> <p>Il est important d'utiliserl le fullpath pour la commande pg_ugprade, sous peine que le mauvais pg_upgrade soit s\u00e9lectionn\u00e9</p> <p>Si tout est OK, repassez la commande en supprimant '--check.</p> <p>Enfin, on pense \u00e0 modifier la configuration de la nouvelle version de postgresql afin d'\u00e9couter sur le bon port :</p> <p>Warning</p> <p>Par d\u00e9faut, les donn\u00e9es sont copi\u00e9es le temps de la transition, il est possible de faire un link avec \u2013link. Attention, un rollback ne sera cependant plus possible</p> <pre><code>sed -i \"s/5433/5432/g\" /etc/postgresql/13/main/postgresql.conf\n</code></pre> <p>Enfin, on clean l'ancienne configuration, toujours en tant que postgres :</p> <pre><code>cd ; ./analyze_new_cluster.sh ; ./delete_old_cluster.sh\n</code></pre> <p>Puis on supprime tout ce qui concerne l'ancienne version de postgresql</p>"},{"location":"linux/redis/cluster_ha/","title":"D\u00e9ployer un Redis en High Availability","text":"<p>Redis c'est bien, qu'il soit toujours dispo, c'est mieux. On va voir comment faire un cluster pour le rendre redondant c\u00f4t\u00e9 applicatif (sentinel/HAproxy), mais \u00e9galement c\u00f4t\u00e9 IP (IPFO).</p>"},{"location":"linux/redis/cluster_ha/#outils-utilises","title":"Outils utilis\u00e9s","text":"<p>Dans notre cluster, nous allons utiliser les outils suivants :</p> <ul> <li>sentinel : Nous l'utiliserons pour surveiller nos n\u0153uds     ma\u00eetre/esclave, sentinel \u00e9lira un esclave pour le passer en ma\u00eetre     lorsqu'un probl\u00e8me survient.</li> <li>haproxy : \u00c9quilibreur de charge TCP, HAproxy peut tester si un     noeud redis est ma\u00eetre ou esclave, nous l'utiliserons comme     front-end auquel les clients se connecteront. HAproxy d\u00e9tectera quel     noeud est ma\u00eetre et s'assurera que le trafic circule vers le bon     noeud. Nous pouvons \u00e9galment utiliser un autre frontend HAproxy afin     de balancer les lectures sur tous les noeuds Redis</li> <li>pacemaker : \u00e9quilibreur de charge au niveau du r\u00e9seau, nous     utiliserons pacemaker pour exposer une ip virtuelle et g\u00e9rer le     basculement entre nos noeuds HAproxy.</li> </ul>"},{"location":"linux/redis/cluster_ha/#atteindre-une-disponibilite-de-100","title":"Atteindre une disponibilit\u00e9 de 100%","text":"<ul> <li> <p>R\u00e9plication Redis - Redis a une r\u00e9plication int\u00e9gr\u00e9e, nous     configurerons redis2/redis3 comme esclave, ce qui assurera que nos     trois n\u0153uds redis ont les m\u00eames donn\u00e9es RDB.</p> </li> <li> <p>D\u00e9faillance Redis : Si notre ma\u00eetre Redis tombe en panne     (redis1), un des n\u0153uds sentinelle/redis esclave (redis2) d\u00e9tecteront     la d\u00e9faillance. Nous utilisons 3 n\u0153uds sentinelle pour nous assurer     d'avoir un quorum, ce qui garantit que nous n'aurons pas de faux     positifs en cas de probl\u00e8me de r\u00e9seau entre deux n\u0153uds redis. Nous     nous assurons que deux syst\u00e8mes distincts surveillent le ma\u00eetre et     que les deux doivent convenir que le ma\u00eetre a \u00e9chou\u00e9. Si 2 instances     de sentinel sont d'accord, le processus redis-sentinel s'ex\u00e9cutant     sur le n\u0153ud esclave (redis2) convertira le n\u0153ud en ma\u00eetre. HAproxy     surveillera les n\u0153uds ma\u00eetre et esclave (redis1/2) \u00e0 tout moment, il     s'assurera que le n\u0153ud ma\u00eetre sera celui vers lequel le trafic sera     dirig\u00e9.</p> </li> <li> <p>D\u00e9faillance de HAproxy : En cas de probl\u00e8me de HAproxy, nous     avons probablement un probl\u00e8me plus important concernant le serveur.     L'IP sera donc re-rout\u00e9e sur un autre serveur avec pacemaker.</p> </li> </ul>"},{"location":"linux/redis/cluster_ha/#installation-initiale","title":"Installation initiale","text":"<p>Imaginons que nous avons ces IPs</p> Machine \u00a0IPs redis1 \u00a010.10.10.1 redis2 \u00a010.10.10.2 redis3 \u00a010.10.10.3 IPFO 10.10.10.100 <p>redis1 sera pour nous le master.</p> <p>Installation des packages n\u00e9cessaires :</p> <pre><code>apt install -y haproxy redis redis-sentinel\n</code></pre> <p>Pour simplifier la configuration, on entre tout dans le fichier hosts</p> <pre><code>$ cat /etc/hosts\nredis1.internal 10.10.10.1\nredis2.internal 10.10.10.2\nredis3.internal 10.10.10.3\nredis.lb-internal 10.10.10.100\n</code></pre> <p>Nous ne verrons pas la configuration de l'IPFO dans ce tutoriel</p>"},{"location":"linux/redis/cluster_ha/#configuration","title":"Configuration","text":""},{"location":"linux/redis/cluster_ha/#redis","title":"Redis","text":"<p>Nous allons configurer redis2/3 afin qu'il soit slave de redis1. Nous allons \u00e9galement les configurer pour qu'ils \u00e9coutent sur notre interface priv\u00e9e. Par d\u00e9faut, redis n'\u00e9coute que sur 127.0.0.1.</p> <p>Selon votre version de redis, il se peut que replicaof ne fonctionne pas. Dans ces cas-l\u00e0, remplacer par la directive slaveof</p> <p>Exemple pour redis2, \u00e0 adapter pour redis3. Attention \u00e0 ne pas configurer replicaof pour redis1 :</p> <pre><code>$ cat /etc/redis/redis.conf\nbind 10.10.10.2 127.0.0.1 ::1\nreplicaof redis1.internal 6379\n</code></pre> <p>On restart</p> <pre><code>systemctl restart redis-server\n</code></pre> <p>Et on observe :</p> <pre><code>root@dev redis1:/root$ redis-cli role\n1) \"master\"\n2) (integer) 0\n3) (empty array)\n\nroot@dev redis2:/root$ redis-cli role\n1) \"slave\"\n2) \"10.10.10.1\"\n3) (integer) 6379\n4) \"connect\"\n5) (integer) -1\n</code></pre> <p>On voit que notre redis1 est le master et que redis2 est le slave de redis1, on voit \u00e9galement qu'il est bien connect\u00e9.</p> <p>Pour debug notre replication &amp; election de master, nous pouvons forcer un sleep du '\"master'\", emp\u00eachant ainsi les \u00e9critures. Nous devons observer un changement de master (c\u00f4t\u00e9 Redis &amp; HAproxy)</p> <pre><code>root@dev redis1:/root$ redis-cli DEBUG sleep 30\n</code></pre> <ul> <li>Si tout se passe bien, nous verrons que le master se sera d\u00e9plac\u00e9     sur redis02 ou redis03 et que le frontend HAproxy redis-write     indiquera le m\u00eame redis.</li> </ul>"},{"location":"linux/redis/cluster_ha/#haproxy","title":"HAproxy","text":"<p>La configuration de HAproxy est quand \u00e0 elle assez simple. Il faut l'adapter \u00e0 son usage. Dans ce que je propose, nous avons 2 entrypoints</p> <ul> <li>Un pour les \u00e9critures, qui va nous permettre de d\u00e9tecter le master.</li> <li>Un second pour les lectures, qui les balancera sur tous les redis.</li> </ul> <p>Pour rappel, nous utilisons une configuration spliited par fichier.</p>"},{"location":"linux/redis/cluster_ha/#backend","title":"Backend","text":"/etc/haproxy/30-backend.cfg <pre><code>backend redis_read\n    mode tcp\n    option tcp-check\n    tcp-check connect\n    tcp-check send PING\\r\\n\n    tcp-check expect string +PONG\n    tcp-check send QUIT\\r\\n\n    tcp-check expect string +OK\n\n    server redis1 redis1.internal:6379 check inter 1s fall 1 rise 1\n    server redis2 redis2.internal:6379 check inter 1s fall 1 rise 1\n    server redis3 redis3.internal:6379 check inter 1s fall 1 rise 1\n\nbackend redis_write\n    mode tcp\n    option tcp-check\n    tcp-check connect\n    tcp-check send PING\\r\\n\n    tcp-check expect string +PONG\n    tcp-check send info\\ replication\\r\\n\n    tcp-check expect string role:master\n    tcp-check send QUIT\\r\\n\n    tcp-check expect string +OK\n\n    server redis1 redis1.internal:6379 check inter 1s fall 1 rise 1\n    server redis2 redis2.internal:6379 check inter 1s fall 1 rise 1\n    server redis3 redis3.internal:6379 check inter 1s fall 1 rise 1\n</code></pre>"},{"location":"linux/redis/cluster_ha/#frontend","title":"Frontend","text":"/etc/haproxy/40-backend.cfg <pre><code>frontend redis-write\n    bind *:6380\n    mode tcp\n\n    option  tcpka\n    option  tcplog\n    option  logasap\n\n    default_backend redis_write\n\nfrontend redis-read\n    bind *:6381\n    mode tcp\n\n    option  tcpka\n    option  tcplog\n    option  logasap\n\n    default_backend redis_read\n</code></pre> <p>C\u00f4t\u00e9 backend, nous voyons que la diff\u00e9rence est uniquement c\u00f4t\u00e9 d\u00e9tection du master. Nous avons \u00e9galement r\u00e9duit le fall et le rise \u00e0 1 afin de d\u00e9tecter imm\u00e9diatement la r\u00e9\u00e9lection d'un master par Sentinel. Cette option est moins impactante pour la lecture.</p> <p>C\u00f4t\u00e9 frontend, nous utilisons diverses options pour am\u00e9liorer le log et nous maintenons la connexion (tcpka)</p>"},{"location":"linux/redis/cluster_ha/#sentinel","title":"Sentinel","text":"<p>C\u00f4t\u00e9 sentinel, il est important de conserver un identifiant unique sur chaque noeud (sentinel myid).</p> <p>La configuration est assez simple :</p> <pre><code>cat /etc/redis/sentinel.conf\n# Default is 30 seconds.\nsentinel monitor mymaster front01.internal 6379 2\nsentinel down-after-milliseconds mymaster 1000\nprotected-mode no\n</code></pre> <p>Le '\"2'\" est le nombre de replica que l'on souhaite. On \u00e9lit un nouveau master apr\u00e8s 1s de down. On d\u00e9sactive le protected-mode afin de pouvoir se connecter depuis tous les noeuds.</p> <p>Attention \u00e0 v\u00e9rifier que sentinel \u00e9coute bien sur toutes les interfaces (du moins, \u00e0 minima celle que nous d\u00e9sirons) mais \u00e9galement que les ports 6379 et 26379 soit bien ouverts</p>"},{"location":"linux/security/disable_patches/","title":"D\u00e9sactiver les patchs de s\u00e9curit\u00e9 Meltdown &amp; co","text":"<p>Suite \u00e0 Meltdown &amp; co, le kernel Linux a impl\u00e9ment\u00e9 de nombreux patches qu'il est possible de d\u00e9sactiver afin de retrouver des performances correctes. Ce param\u00e8tre a \u00e9t\u00e9 introduit en backports 4.14.x, 4.19.x ou ou 5.2 \"officiellement\".</p> <p>Des benchmarks sont disponibles ici</p>"},{"location":"linux/security/disable_patches/#application","title":"Application","text":"<p>Pour changer les param\u00e8tres, il faut \u00e9diter le fichier <code>/etc/default/grub</code> et rajouter ceci :</p> <pre><code>GRUB_CMDLINE_LINUX_DEFAULT=\"quiet mitigations=off\"\n</code></pre> <p>Si vous disposez d'un kernel inf\u00e9rieur \u00e0 5.2, alors voici la ligne \u00e0 mettre</p> <pre><code>GRUB_CMDLINE_LINUX_DEFAULT=\"quiet noibrs noibpb nopti nospectre_v2 nospectre_v1 l1tf=off nospec_store_bypass_disable no_stf_barrier mds=off tsx_async_abort=off mitigations=off\"\n</code></pre> <p>Puis il faut lancer une reg\u00e9n\u00e9ration du grub :</p> <pre><code>update-grub\n</code></pre> <p>Voici les param\u00e8tres mitig\u00e9s via un mitigations=off dans un kernel r\u00e9cent :</p> <ul> <li><code>nopti</code> [X86,PPC] - Control Page Table Isolation of user and     kernel address spaces. Disabling this feature removes hardening, but     improves performance of system calls and interrupts.</li> <li><code>kpti</code>=0 [ARM64] - Control page table isolation of user and     kernel address spaces.</li> <li><code>nobp</code>=0 [S390] - Undocumented. Does something on S390 systems,     nobody knows what.</li> <li><code>nospectre_v1</code> [X86,PPC] - Disable mitigations for Spectre     Variant 1 (bounds check bypass). With this option data leaks are     possible in the system.</li> <li><code>nospectre_v2</code> [X86,PPC,S390,ARM64] - Disable all mitigations     for the Spectre variant 2 (indirect branch prediction)     vulnerability. System may allow data leaks with this option.</li> <li><code>spectre_v2_user=off</code> [X86] - Control mitigation of Spectre     variant 2 (indirect branch speculation) vulnerability between user     space tasks</li> <li><code>spec_store_bypass_disable=off</code> [X86,PPC] - Control Speculative     Store Bypass (SSB) Disable mitigation (Speculative Store Bypass     vulnerability)</li> <li><code>ssbd=force-off</code> [ARM64] - Speculative Store Bypass Disable     control</li> <li><code>l1tf=off</code> [X86] - Control mitigation of the L1TF vulnerability     on affected CPUs</li> <li><code>mds=off</code> [X86] - Control mitigation for the Micro-architectural     Data Sampling (MDS) vulnerability.</li> <li><code>tsx_async_abort=off</code> [X86] - Control mitigation for the Micro-architectural     TSX (MDS) vulnerability.</li> </ul>"},{"location":"linux/security/disable_patches/#verification","title":"V\u00e9rification","text":"<p>Pour v\u00e9rifier que les vuln\u00e9rabilit\u00e9s ne sont plus mitig\u00e9es, il faut se pencher du c\u00f4t\u00e9 du dossier <code>/sys/devices/system/cpu/vulnerabilities/</code></p> <pre><code>\u03bb yann ~ \u2192 ls /sys/devices/system/cpu/vulnerabilities/\nitlb_multihit  l1tf  mds  meltdown  spec_store_bypass  spectre_v1  spectre_v2  tsx_async_abort\n</code></pre> <p>Si nous regardons le contenu du fichier spectre_v1 par exemple avant correction du kernel :</p> <pre><code>\u03bb yann ~ \u2192 cat /sys/devices/system/cpu/vulnerabilities/spectre_v1\nMitigation: usercopy/swapgs barriers and __user pointer sanitization\n</code></pre> <p>Nous voyons ici que la vuln\u00e9rabilit\u00e9 est mitig\u00e9e. Sur un serveur non-mitig\u00e9, voici le message que nous auront :</p> <pre><code>\u03bb yann ~ \u2192 cat /sys/devices/system/cpu/vulnerabilities/spectre_v1\nVulnerable: __user pointer sanitization and usercopy barriers only; no swapgs barriers\n</code></pre> <p>Nous voyons ici que le patch kernel a \u00e9t\u00e9 d\u00e9sactiv\u00e9 et que nous sommes donc '\"vuln\u00e9rable'\" \u00e0 la faill Spectre V1</p>"},{"location":"linux/security/hardening_sshd/","title":"Hardening simple du serveur SSH","text":""},{"location":"linux/security/hardening_sshd/#sshd_config","title":"sshd_config","text":"<p>Par d\u00e9faut, un serveur SSH est configur\u00e9 de tel mani\u00e8re \u00e0 \u00eatre plut\u00f4t laxiste en terme de s\u00e9curit\u00e9 et \u00eatre un peu trop souple \u00e0 notre gout. Il existe diff\u00e9rentes mani\u00e8res de rendre un serveur plus ou moins s\u00e9curis\u00e9. Dans cet article, nous allons nous content des moyens simples &amp; rapides pour rendre notre serveur plus s\u00e9curis\u00e9.</p> <p>Attention, ce guide consid\u00e8re que vous ayez une version de OpenSSH relativement r\u00e9cente, 7.x au minimum</p> <p>Le param\u00e8tre le plus important lors d'une attaque est le type de connexion SSH. Tant que possible, il est n\u00e9cessaire de d\u00e9sactiver les connexions par password.</p> <pre><code>AuthenticationMethods publickey\n</code></pre> <p>Dans les anciennes version de OpenSSH, la connexion en root \u00e9tait autoris\u00e9e en password. Depuis quelques temps, la connexion est autoris\u00e9e par clef uniquement. Il est tout de m\u00eame conseill\u00e9 de refuser explicitement toute connexion \u00e0 l'utilisateur root.</p> <pre><code>PermitRootLogin No\n</code></pre> <p>Par d\u00e9faut, lors d'une connexion SSH. Debian renvoie sa version ainsi que la version du serveur OpenSSH utilis\u00e9e.</p> <pre><code>remote software version OpenSSH_7.9p1 Debian-10+deb10u2\n</code></pre> <p>Pour d\u00e9sactiver ce comportement, il suffit de passer la variable <code>DebianBanner</code> de son sshd_config \u00e0 <code>no</code></p> <pre><code>DebianBanner no\n</code></pre> <p>Par d\u00e9faut, lorsque nous nous connectons \u00e0 un serveur SSH, nous avons 2 minutes (120s) pour nous login. Cette valeur est inutilement longue. Cette valeur est control\u00e9e par la directive <code>LoginGraceTime</code> et doit \u00eatre d\u00e9finit \u00e0 30s.</p> <pre><code>LoginGraceTime 30\n</code></pre> <p>Si par m\u00e9garde vous oubliez de v\u00e9rouiller votre poste avec des connexions SSH ouvertes, il peut \u00eatre int\u00e9ressant de configurer une valeur pour laquelle votre sesssion SSH sera automatiquement termin\u00e9e. 2 param\u00e8tres cohabitent :</p> <ul> <li><code>ClientAliveCountMax</code> - Indique le nombre total de messages de     v\u00e9rification envoy\u00e9s par le serveur SSH sans obtenir de r\u00e9ponse du     client SSH. La valeur par d\u00e9faut est 3.</li> <li><code>ClientAliveInterval</code> - Indique le d\u00e9lai d'attente en secondes.     Apr\u00e8s x secondes, le serveur SSH envoie un message au client pour     lui demander une r\u00e9ponse. Deafult est \u00e9gal \u00e0 0 (le serveur     n'enverra pas de message au client pour v\u00e9rifier.).</li> </ul> <p>Par exemple, si vous souhaitez une d\u00e9connexion automatique au bout de 3 minutes, voici la configuration \u00e0 appliquer :</p> <pre><code>ClientAliveInterval 180\nClientAliveCountMax 0\n</code></pre> <p>Une fois l'utilisateur authentifi\u00e9, nous devons nous assurer que le canal de communication est correctement chiffr\u00e9. Pour cela, la fondation Mozilla nous fournit des donn\u00e9es utiles :</p> <pre><code>KexAlgorithms curve25519-sha256@libssh.org,ecdh-sha2-nistp521,ecdh-sha2-nistp384,ecdh-sha2-nistp256,diffie-hellman-group-exchange-sha256\nCiphers chacha20-poly1305@openssh.com,aes256-gcm@openssh.com,aes128-gcm@openssh.com,aes256-ctr,aes192-ctr,aes128-ctr\nMACs hmac-sha2-512-etm@openssh.com,hmac-sha2-256-etm@openssh.com,umac-128-etm@openssh.com,hmac-sha2-512,hmac-sha2-256,umac-128@openssh.com\n</code></pre> <p>Le guide complet de Mozilla est diponible ici</p> <p>Si vous souhaitez savoir quels ciphers ou autres sont disponibles dans votre version d'OpenSSH, il est possible d'utiliser les commandes suivantes</p> <pre><code>ssh -Q cipher\nssh -Q cipher-auth\nssh -Q mac\nssh -Q kex\nssh -Q key\n</code></pre> <p>Il existe \u00e9galement un petit tool qui permet de v\u00e9rifier les diff\u00e9rents ciphers &amp; co : ssh-audit. Le guide d'hardening est disponible ici</p> <p>Utiliser si possible les m\u00e9canismes de sandbox du kernel dans les processus non privil\u00e9gi\u00e9s</p> <pre><code>UsePrivilegeSeparation sandbox\n</code></pre>"},{"location":"linux/security/hardening_sshd/#avance","title":"Avanc\u00e9","text":"<p>Par d\u00e9faut, peu d'informations sont logu\u00e9es dans les logs, une information pouvant \u00eatre utile est la fingerprint de la cl\u00e9 utilis\u00e9e, nous devons donc passer le LogLevel \u00e0 verbose.</p> <pre><code>LogLevel VERBOSE\n</code></pre> <p>Il est \u00e9galement possible de log les actions effectu\u00e9es en SFTP.</p> <pre><code>Subsystem sftp  /usr/lib/ssh/sftp-server -f AUTHPRIV -l INFO\n</code></pre> <p>Pour une s\u00e9curisation encore plus pouss\u00e9e, il est possible d'activer le 2FA sur votre serveur SSH. Cependant, si vous vous connectez &amp; deconnectez souvent de vos serveurs, celui-ci peut vite devenir tr\u00e8s contraignant</p> <p>Dans le cadre o\u00f9 vous utilisez un serveur interm\u00e9diaire pour vous connecter \u00e0 vos serveurs (bastion), il est possible d'autoriser le login uniquement \u00e0 partir des IPs de ces derniers :</p> <pre><code>AllowGroups admin@1.2.3.4 admin@10.20.30.40\n</code></pre> <p>Cette syntaxe est \u00e9galement possible pour la directive AllowUsers.</p> <p>Les variables d'environnement peuvent \u00eatre modifi\u00e9es lors d'une connexion SSH depuis une clef, ces derniers peuvent tr\u00e8s largement alt\u00e9rer le comportement de certains programmes (LD_PRELOAD, LD_LIBRARY_PATH...). Pour cela, une option existe pour d\u00e9sactiver la modification des variables syst\u00e8mes lors d'une connexion SSH.</p> <pre><code>PermitUserEnvironment no\n</code></pre> <p>Toutefois, les variables list\u00e9es dans la directives <code>AcceptEnv</code> restent modifiables.</p>"},{"location":"linux/security/hardening_sshd/#authorized_keys","title":"authorized_keys","text":"<p>Beaucoup d'options sont \u00e9galement possibles au niveau du fichier authorized_keys</p> <ul> <li><code>no-agent-forwarding</code>: D\u00e9sactivation du SSH agent forwarding</li> <li><code>no-port-forwarding</code>: D\u00e9sactivation du SSH port forwarding.</li> <li><code>no-X11-forwarding</code>: D\u00e9sactivation du X11 display forwarding.</li> <li><code>no-pty</code>: D\u00e9sactive la possibilit\u00e9 de d\u00e9marrer un shell</li> <li><code>no-user-rc</code>: Emp\u00eache l'interpr\u00e9tation du fichier ~/.ssh/rc.</li> </ul> <p>Par d\u00e9faut, tout est autoris\u00e9. Cependant, une autre approche est possible. Via le keyword <code>restrict</code>, ce qui va implicitement refuser toutes les options SSH. Par exemple, si vous souhaitez tout de m\u00eame autoriser l'agent forwarding</p> <pre><code>restrict,agent-forwarding ecdsa-sha2-nistp521 AAAAE\n</code></pre> <p>Il est \u00e9galement possible de forcer une commande lors de la connexion avec une clef sp\u00e9cifique :</p> <pre><code>command=\"/usr/local/bin/backup\" ecdsa-sha2-nistp521 AAAAE\n</code></pre> <p>Une option plut\u00f4t pratique via ce fichier authorized_keys et qu'il est possible de simuler une connexion SFTP pour une clef pr\u00e9cise</p> <pre><code>restrict,command=\"false\" ecdsa-sha2-nistp521 AAAAE\n</code></pre> <p>Avec la clef suivante, vous n'aurez uniquement le droit \u00e0 effectuer une navigation dans les diff\u00e9rents r\u00e9pertoires de votre utilisateur</p> <p>Il est \u00e9galement possible de limiter la connexion via votre clef pour diff\u00e9rentes machines, option une nouvelle fois utile lors de l'utilisation d'un bastion</p> <pre><code>from=\"1.2.3.4,10.20.30.40\" ecdsa-sha2-nistp521 AAAAE\n</code></pre>"},{"location":"linux/security/hardening_sshd/#entrees-sshfp","title":"Entr\u00e9es SSHFP","text":"<p>A outre mesure, il est possible de s\u00e9curiser une connexion SSH avec les entr\u00e9es DNS SSHFP. ssh (s'il est configur\u00e9 avec VerifyHostKeyDNS=yes) va automatiquement v\u00e9rifier le record SSHFP et permettre la connexion.</p> <p>Si SSHFP est correctement configur\u00e9, vous aurez cette entr\u00e9e :</p> <pre><code>debug1: matching host key fingerprint found in DNS\n</code></pre> <p>Et pour g\u00e9n\u00e9rez vos entr\u00e9es SSHFP :</p> <pre><code>#!/bin/bash\nIFS=$'\\n'\nfor LINE in $(cat ~/.ssh/known_hosts) ; do\n    WANTED=$(echo \"$LINE\" | awk -F\" \" '{print $1}')\n    PORT=$(echo \"$WANTED\" | awk -F\":\" '{print $2}'|awk '{ print substr( $0, 0,4 ) }')\n    HOST=$(echo \"$WANTED\" | ggrep -oP '\\[.*?\\]'|tr -d \"]\"|tr -d \"[\"|head -1)\n    [ ! $PORT ] &amp;&amp; PORT=22\n    echo \"$HOST - $PORT\"\n    ssh-keygen -r $HOST\n    # sleep 1\n    # ssh-keyscan -p $PORT -D $HOST\ndone\n</code></pre>"},{"location":"linux/security/ipset/","title":"Apprendre \u00e0 se servir d'ipset","text":"<p>ipset est un produit magique qui va vous permettre de build des hashmap d'IP. Bien plus efficace que des multiples entr\u00e9es sur iptables.</p> <pre><code>ipset create drop hash:net\n</code></pre> <p>Il existe 2 types de tables, \u00e0 adapter selon son usage :</p> <ul> <li><code>hash:net</code> pour les subnets</li> <li><code>has:ip</code> pour les IPs</li> </ul> <p>On commence par cr\u00e9er une map o\u00f9 l'on va ajouter les diff\u00e9rents ranges d'IPs</p> <pre><code>ipset add drop 14.144.0.0/12\nipset add drop 27.8.0.0/13\nipset add drop 58.16.0.0/15\nipset add drop 1.1.1.0/24\n</code></pre> <p>Enfin, nous pouvons ajouter notre r\u00e8gle iptables correspondante :</p> <pre><code>iptables -I INPUT -m set --match-set drop src -j DROP\n</code></pre> <p>Nous allons drop tous les subnets inclus dans la table drop.</p> <p>Diff\u00e9rentes commandes existent autour de ipset.</p> <pre><code>ipset -L # Lister les tables\nipset destroy drop # Drop la table drop\n</code></pre>"},{"location":"linux/security/ipset/#bonus","title":"Bonus","text":""},{"location":"linux/security/ipset/#drop-de-pays","title":"Drop de pays","text":"<p>Il existe diff\u00e9rents scripts tels que ipset-country permettant d'automatiser de nombreuses choses. Par exemple, via ce script, nous pouvons automatiser le drop de pays entier via des listes pr\u00e9d\u00e9finies.</p>"},{"location":"linux/security/ipset/#persistent","title":"Persistent","text":"<p>Pour rendre persitent ipset. Il existe le package ipset-persistent.</p>"},{"location":"linux/security/ipset/#nftables","title":"nftables","text":"<p>Sous nftables (inclus dans Debian 11), nous n'avons plus besoin d'ipset. La notion de liste est directement g\u00e9r\u00e9e dans nftables.</p> <p>Pour l'import dans nftables, une seule commande suffit :</p> <pre><code>ipset-translate restore &lt; sets.ipset\n</code></pre> <p>Si vous voulez regarder le r\u00e9sultat nft :</p> <pre><code>nft list ruleset\n</code></pre>"},{"location":"linux/security/iptables_country/","title":"Bloquer en masse les IPs d'un pays avec ipset","text":"<p>http://daemonkeeper.net/781/mass-blocking-ip-addresses-with-ipset/</p> <p>https://www.linuxjournal.com/content/advanced-firewall-configurations-ipset?page=0,1</p>"},{"location":"linux/security/issued_crt/","title":"Lister tous les certificats \u00e9mis","text":"<p>D\u00e9sormais, tous les certificats int\u00e9grant le Certificate Transparency peuvent \u00eatre facilement retrouvable.</p> <p>Pour cela, il existe un magnifique outil appel\u00e9 crt.sh, vous proposant une multitude de filtre permettant d'exporter tous les CRT</p> <p>Sinon, un petit script en ligne de commande :</p> <pre><code>#!/usr/bin/env bash\npsql=$(which psql)\ndocker=$(which docker)\n\nif [ -z \"$psql\" ]; then\n    if [ -z \"$docker\" ]; then\n        echo \"Ni Docker, ni PostgreSQL... can't do anything for you\"\n        exit 1\n    fi\n    psql=\"docker run -it --rm postgres psql\"\nfi\n\nif [ -z \"${1}\" ]; then\n    echo \"Usage: $0 domain-name\"\n    exit\nfi\nQ=\"select distinct(lower(name_value)) FROM certificate_and_identities cai WHERE plainto_tsquery('$1') @@ identities(cai.CERTIFICATE) AND lower(cai.NAME_VALUE) LIKE ('%.$1')\"\n$psql -P pager=off -P footer=off -U guest -d certwatch --host crt.sh -c \"$Q\" | sed -e '$d' -e 's/^ //' -e '1,2d'\n</code></pre> <p>Petit usage tout simple :</p> <pre><code>\u279c  ~ ./al mydomain.eu\nadguard.mydomain.eu\nbitwarden.mydomain.eu\nbw.mydomain.eu\ncloud.mydomain.eu\ndomo.mydomain.eu\ngrafana.mydomain.eu\nha.mydomain.eu\nhome.mydomain.eu\nnas.mydomain.eu\nnetdata.mydomain.eu\nnextcloud.mydomain.eu\nnodered.mydomain.eu\nonlyoffice.mydomain.eu\npihole.mydomain.eu\nportainer.mydomain.eu\nprometheus.mydomain.eu\npve.mydomain.eu\nrss.mydomain.eu\nrutorrent.mydomain.eu\nshaarli.mydomain.eu\nsync.mydomain.eu\nunifi.mydomain.eu\n</code></pre>"},{"location":"linux/security/logwatch/","title":"Installer et configurer LogWatch","text":"<p>Logwatch est un petit utilitaire qui permet d'envoyer un rapport sur diverses informations tel que les tentatives d'acc\u00e8s infructueuses, erreurs kernel... Etant donner qu'il envoie les rapports par mail, il sera n\u00e9cessaire d'installer un MTA</p> <p>Simple installation via APT :</p> <pre><code>apt install logwatch\n</code></pre> <p>Par d\u00e9faut, sans configuration, logwatch va analyser les logiciels install\u00e9s sur la machine pour g\u00e9n\u00e9rer son rapport. Pour mon cas par exemple, il contient les drop d'iptables et diverses informations sur apache2.</p> <p>Logwatch va par d\u00e9faut g\u00e9nerer un rapport par jour, envoy\u00e9 sur l'utilisateur root.</p> <p>Il est possible de modifier le comportement en modifiant /etc/logwatch/conf/logwatch.conf. Il n'est pas recommand\u00e9 d'overwrite les valeurs par d\u00e9faut fourni dans /usr/share/logwatch/default.conf/logwatch.conf</p> <pre><code>echo \"MailTo=bla@bla.fr\" &gt; /etc/logwatch/conf/logwatch.conf\n</code></pre> <p>On peut \u00e9galement forcer la destination avec l'argument '--mailto.</p> <p>Vous pouvez customiser le rapport en copiant les diff\u00e9rents fichiers de configuration fournis par d\u00e9faut par logwatch depuis /usr/share/logwatch/default.conf dans les diff\u00e9rents r\u00e9pertoires ad\u00e9quates /etc/logwatch/conf</p>"},{"location":"linux/security/password_pam/","title":"Am\u00e9liorer la s\u00e9curit\u00e9 des mots de passe par d\u00e9faut","text":"<p>Par d\u00e9faut, tous les syst\u00e8mees UNIX se basent sur une authentification par mot de passe. Le syst\u00e8me d'authentification PAM s'occupe de ce processus.</p> <p>C'est \u00e9galement via ce proc\u00e9d\u00e9 que nous pouvons effectuer des authentifications distantes telles LDAP, AD...</p> <p>Ce qui nous int\u00e9resse de notre c\u00f4t\u00e9 est la s\u00e9curisation du mot de passe via PAM. Par d\u00e9faut, tous les mots de passe sont accept\u00e9s par d\u00e9faut, ce que nous voulons pas.</p>"},{"location":"linux/security/password_pam/#pam-cracklib","title":"PAM-Cracklib","text":"<p>C'est donc du c\u00f4t\u00e9 du packet PAM-Cracklib que nous allons nous tourner. PAM-Cracklib va nous permettre d'apporter une s\u00e9curit\u00e9 non n\u00e9gligable en forcant la pr\u00e9sence d'une majuscule, d'un chiffre... dans le mot de passe</p>"},{"location":"linux/security/password_pam/#installation","title":"Installation","text":"<p>Etant donner qu'il s'agit d'un packet, il nous faut l'installer.</p> <pre><code>apt-get install libpam-cracklib\n</code></pre>"},{"location":"linux/security/password_pam/#configuration","title":"Configuration","text":"<p>Tout se fait dans le fichier /etc/pam.d/common-password, nous allons donc l'\u00e9diter</p> <pre><code>nano /etc/pam.d/common-password\n</code></pre> <p>Vous allez d\u00e9sormais ajouter cette ligne, juste au dessus de la premi\u00e8re ligne non comment\u00e9e :</p> <pre><code>password    requisite           pam_cracklib.so retry=3 minlen=8 difok=3\n</code></pre> <p>Ici, nous voyons que le module <code>pam_cracklib</code> (du moins, sa librairie) sera charg\u00e9e lorsque nous ex\u00e9cutons une actions relative au mot de passe avec quelques options :</p> <ul> <li><code>retry</code> : Nombre d'essais avant que l'ex\u00e9cutaire passwd soit     relanc\u00e9</li> <li><code>minlen</code> : Nombre de caract\u00e8res minimum requis</li> <li><code>difok</code> : Nombre de caract\u00e8res diff\u00e9rents lors d'un changement de     mot de passe exig\u00e9</li> </ul> <p>D'autres param\u00e8tres sont \u00e9galements disponibles et peuvent vous int\u00e9ress\u00e9s :</p> <ul> <li><code>difok</code> : Stocke un nombre donn\u00e9 de mot de passe afin de les     emp\u00eacher d'\u00eatre r\u00e9utilis\u00e9s</li> <li><code>lcredit</code> : Force l'utilisation de minuscule</li> <li><code>ucredit</code> : Force l'utilisation de majuscule</li> <li><code>dcredit</code> : Force l'utilisation de d\u00e9cimal</li> <li><code>ocredit</code> : Force l'utilisation de caract\u00e8res sp\u00e9ciaux</li> </ul> <p>Par exemple, la ligne suivant force un mot de passe de 8 caract\u00e8res minimaux, diff\u00e9rents des 3 derniers, comportant au moins une minuscule, une majuscule, 3 chiffres et un caract\u00e8res sp\u00e9ciaux.</p> <pre><code>password  required  pam_cracklib.so retry=3 minlen=8 difok=3 lcredit=1 ucredit=1 dcredit=3 ocredit=1\n</code></pre> <p>Cependant, si vous sp\u00e9cifiez un chiffre sp\u00e9cifique, cela signifie que vous devriez avoir exactement ce nombre du type de caract\u00e8res dans votre mot de passe. Pour sp\u00e9cifier au moins un caract\u00e8re de ce type, il faut mettre.. <code>-1</code></p>"},{"location":"linux/security/password_pam/#logindefs","title":"Login.defs","text":"<p>Autre que PAM-Cracklib, <code>Login.defs</code> permet de sp\u00e9cifier des options utiles telles que</p> <ul> <li><code>PASS_MAX_DAYS</code> : Nombre de jours maximum pour conserver un mot de     passe</li> <li><code>PASS_MIN_DAYS</code> : Minimum de jours autoris\u00e9s avant de pouvoir     modifier son mot de passe</li> <li><code>PASS_WARN_AGE</code> : Nombre de jours \u00e0 partir duquel un warning sera     affich\u00e9</li> </ul>"},{"location":"linux/security/portsentry/","title":"Installer et configuer PortSentry","text":"<p>portsentry est un programme de d\u00e9tection et de blocage de '\"scan de ports'\" (G\u00e9n\u00e9ralement programme qui scanne votre machine \u00e0 le recherche de ports ouverts, en g\u00e9n\u00e9ral dans le but de pr\u00e9parer une attaque). Via ce scan de port, un attaquant peut obtenir de nombreuses informations, versions de SSH vuln\u00e9rables ou autres... il est donc important de se pr\u00e9munir de celui-ci</p>"},{"location":"linux/security/portsentry/#installation-et-configuration","title":"Installation et Configuration","text":"<p>Une installation de base de portsentry se fera toujours via apt :</p> <pre><code>apt update &amp;&amp; apt install portsentry\n</code></pre> <p>Conr\u00eatement, portsentry s'axe autour de 3 fichiers :</p> <ul> <li><code>/etc/default/portsentry</code> : Fichier o\u00f9 l'on indique dans quel mode     portsentry doit d\u00e9marrer</li> <li><code>/etc/portsentry/portsentry.conf</code> : Fichier o\u00f9 l'on indique les     actions \u00e0 effectuer quand au drop d'une connexion...</li> <li><code>/etc/portsentry/portsentry.ignore.static</code> : Nous y pla\u00e7ons les IPs     que nous autorisons (whitelist)</li> </ul> <p>De sorti d'installation, portsentry est inefficace, des r\u00e9glages s'imposent donc imm\u00e9diatement.</p> <p>Dans le fichier /etc/default/portsentry, il y a 2 variables : <code>TCP_MODE</code> et <code>UDP_MODE</code>. Par d\u00e9faut, celles-ci sont respectivement en mode <code>tcp</code> et <code>udp</code>. Cela signifie que vous devez sp\u00e9cifier \u00e0 la main les ports \u00e0 '\"surveiller'\". Nous pr\u00e9f\u00e9rons donc le mode <code>atcp</code> et <code>audp</code> (<code>a</code> pour avanc\u00e9).</p> <p>Maintenant, nous allons configurer portsentry via le fichier /etc/portsentry/portsentry.conf</p> <p>La premi\u00e8re directive \u00e0 configurer est BLOCK_TCP (et son homologue UDP), 3 valeurs sont possibles :</p> <ul> <li><code>0</code> : Je d\u00e9tecte les scans de port mais je ne fais rien</li> <li><code>1</code> : Je bloque les scans UDP/TCP</li> <li><code>2</code> : Je lance uniquement la directive <code>KILL_RUN_CMD</code></li> </ul> <p>Dans cette partie du tutoriel, pour couvrir le plus de cas possible, nous allons choisir l'option 1.</p> <p>La valeur 1 de BLOCK_TCP nous indique 3 modes de bannissements :</p> <ul> <li>Bloquage via route linux (Directive KILL_ROUTE)</li> <li>Bloquage via fichier hosts.deny (Directive KILL_HOSTS_DENY)</li> <li>Bloquage via r\u00e8gle custom (Directive KILL_RUN_CMD)</li> </ul> <p>Les valeurs par d\u00e9faut de KILL_ROUTE et KILL_HOSTS_DENY sont correctes selon votre OS, il n'y a pas besoin d'y toucher.</p> <p>Cependant, <code>KILL_RUN_CMD</code> demeure vide, voici une bonne valeur :</p> <pre><code>KILL_RUN_CMD=\"/sbin/iptables -I INPUT -s $TARGET$ -j DROP &amp;&amp; /sbin/iptables -I INPUT -s $TARGET$ -m limit --limit 3/minute --limit-burst 5 -j LOG --log-level debug --log-prefix Portsentry: dropping: \"\n</code></pre>"},{"location":"linux/security/portsentry/#bonus-utilisation-dipset","title":"Bonus : Utilisation d'ipset","text":"<p>ipset va nous permettre de r\u00e9duire le nombre dans iptables afin de ne pas surcharger le kernel. Pour rappel, un trop grand nombres de lignes iptables fait s'effondrer les performances de la stack network de Linux.</p> <p>Au lieu d'avoir une entr\u00e9e/IP bannie dans iptables, nous aurons une seule entr\u00e9e.</p> <p>Il faut installer ipset comme n'importe quel paquet (Mais \u00e9galement iptables-persistent afin de rendre la config persistent):</p> <pre><code>apt install ipset iptables-persistent\n</code></pre> <p>Si vous \u00eates sous Debian 10, Ubuntu 19.04 ou sup\u00e9rieur, alors il existe un paquet permettant de rendre ipset persistent \u00e9galement :</p> <pre><code>apt install ipset-persistent\n</code></pre> <p>Sinon, il vous faudra cr\u00e9er l'unit systemd manuellement (Fichier /etc/systemd/system/ipset-persistent.service)</p> <pre><code>[Unit]\nDescription=ipset persistent configuration\n#\nDefaultDependencies=no\nBefore=network.target\n\n# ipset sets should be loaded before iptables\n# Because creating iptables rules with names of non-existent sets is not possible\nBefore=netfilter-persistent.service\n\nConditionFileNotEmpty=/etc/iptables/ipset\n\n[Service]\nType=oneshot\nRemainAfterExit=yes\nExecStart=/sbin/ipset restore -file /etc/iptables/ipset\n# Toggle comment to save (or not) changed sets on reboot\nExecStop=/sbin/ipset save -file /etc/iptables/ipset\nExecStop=/sbin/ipset flush\nExecStopPost=/sbin/ipset destroy\n\n[Install]\nWantedBy=multi-user.target\n\nRequiredBy=netfilter-persistent.service\nRequiredBy=ufw.service\n</code></pre> <p>Et on reload systemd + activation du service au d\u00e9marrage</p> <pre><code>systemctl daemon-reload\nsystemctl enable --now ipset-persistent.service\n</code></pre> <p>Il nous faut d'abord cr\u00e9er notre set ipset avec un timeout de 180s. Il est inutile de bannir \u00e0 vie ces IPs, un timeout de 3 minutes suffit amplement \u00e0 stopper l'attaquant.</p> <pre><code>ipset create portsentry hash:ip timeout 180\n</code></pre> <p>Puis cr\u00e9er notre r\u00e8gle correspondante dans iptables</p> <pre><code>iptables -I INPUT -m set --match-set portsentry src -j DROP\n</code></pre> <p>Maintenant, il faut sp\u00e9cifier \u00e0 portsentry d'ajouter ces IPs bannies \u00e0 notre set ipset :</p> <p>Nous allons sp\u00e9cifier la valeur 2 aux options BLOCK_TCP et BLOCK_UDP du fichier '/etc/portsentry/portsentry.conf', pour utiliser uniquement la directive KILL_RUN_CMD.</p> <p>Voici la KILL_RUN_CMD \u00e0 d\u00e9finir (autour de la ligne 269) :</p> <pre><code>KILL_RUN_CMD=\"/sbin/ipset add portsentry $TARGET$\"\n</code></pre>"},{"location":"linux/security/rkhunter/","title":"Installer et configurer RKHunter","text":"<p>rkhunter (pour Rootkit Hunter) est un petit programme UNIX permettant de d\u00e9tecter les rootkits. Pour se faire, il compare les hash SHA-256, SHA-512, SHA1 et MD5 des fichiers importants avec les hash connus, qui sont accessibles \u00e0 partir d'une base de donn\u00e9es en ligne.</p> <p>https://wiki.debian-fr.xyz/Rkhunter</p> <p>https://grepitout.com/how-to-install-rkhunter-on-centos/</p>"},{"location":"linux/security/sftp/","title":"Acc\u00e8s s\u00e9curis\u00e9 via sFTP (Chroot SSH)","text":""},{"location":"linux/security/sftp/#introduction","title":"Introduction","text":"<p>Si on vous demande un serveur FTP, mais que vous ne n'avez pas envie d'en installer un, il se peut alors que le SFTP soit alors la solution pour vous.</p> <p>A ne surtout pas confondre avec le FTPS (\u00e9galement appeler FTPES) car celui-ci se repose sur un daemon FTP, alors que SFTP se repose sur le daemon SSH.</p> <p>2 types de chroot sont possible, le chroot SFTP, et le chroot SSH</p> <ul> <li>Dans le chroot SFTP, vous aurez \u00e9galement les m\u00eames droits qu'avec     un serveur FTP</li> <li>Dans le chroot SSH, il s'agit alors d'un environnement SSH     classique, cependant, l'acc\u00e8s aux diff\u00e9rents fichiers/binaires     syst\u00e8me peut \u00eatre limit\u00e9 par l'administrateur de la machine</li> </ul>"},{"location":"linux/security/sftp/#sftp","title":"SFTP","text":"<p>Pour le SFTP, nous devons appliquer des droits sp\u00e9ciaux sur le folder \u00e0 chroot (G\u00e9n\u00e9ralement, on chroot un user dans son home directory), mais nous devons \u00e9galement modifier le sshd_config</p> <pre><code>Subsystem sftp internal-sftp\nMatch user jeremy\n    ChrootDirectory %h\n</code></pre> <p>Dans notre exemple, l'utilisateur jeremy sera chroot dans son home directory. Mais si nous faisons que cela, le chroot ne marchera pas.</p> <pre><code>chown -R jeremy:jeremy /home/jeremy\nchown root:root /home/jeremy\nchmod 755 /home/jeremy\n</code></pre> <p>Et on red\u00e9marre OpenSSH</p> <pre><code>systemctl try-restart sshd\n</code></pre>"},{"location":"linux/security/slack_notifications_ssh/","title":"Configurer des notifications Slack pour SSH","text":"<p>Slack est une plateforme de chat mondialement connu. Aujourd'hui, nous allons voir comment y int\u00e9grer un syst\u00e8me de notification des connexions SSH</p>"},{"location":"linux/security/slack_notifications_ssh/#configuration-du-webhook","title":"Configuration du Webhook","text":"<p>Tout d'abord, il faut cr\u00e9er votre Webhook sur le panneau de configuration de votre Workspace. Pour cela, il faut choisir (ou cr\u00e9er) un chan o\u00f9 les messages du bot seront envoy\u00e9s ainsi que le nom du bot. Une fois cela fait, penser \u00e0 copier votre Webhook URL (De cette forme : https://hooks.slack.com/services/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)</p>"},{"location":"linux/security/slack_notifications_ssh/#configuration-cote-serveur","title":"Configuration c\u00f4t\u00e9 serveur","text":"<p>Nous commen\u00e7ons par faire notre fichier qui enverra nos notifications \u00e0 notre Slack : /etc/ssh/notify.sh</p> <pre><code>if [ \"$PAM_TYPE\" != \"close_session\" ]; then\n url=\"WEBHOOK_URL\"\n channel=\"#external-servers\"\n host=$(hostname -f)\n content=\"'\"attachments'\": [ { '\"mrkdwn_in'\": ['\"text'\", '\"fallback'\"], '\"fallback'\": '\"SSH login: $PAM_USER connected to '`$host'`'\", '\"text'\": '\"SSH login to '`$host'`'\", '\"fields'\": [ { '\"title'\": '\"User'\", '\"value'\": '\"$PAM_USER'\", '\"short'\": true }, { '\"title'\": '\"IP Address'\", '\"value'\": '\"$PAM_RHOST'\", '\"short'\": true } ], '\"color'\": '\"#F35A00'\" } ]\"\n curl -s -X POST --data-urlencode \"payload={'\"channel'\": '\"$channel'\", '\"mrkdwn'\": true, '\"username'\": '\"ssh-bot'\", $content, '\"icon_emoji'\": '\":computer:'\"}\" $url &amp;\nfi\n</code></pre> <p>Penser \u00e0 remplacer le WEBHOOK_URL et le channel par le votre. On rend notre script ex\u00e9cutable</p> <pre><code>chmod +x /etc/ssh/notify.sh\n</code></pre> <p>Et on modifie notre service PAM SSH /etc/pam.d/sshd en y ajoutant le contenu suivant</p> <pre><code>session optional pam_exec.so seteuid /etc/ssh/notify.sh\n</code></pre> <p>Nous relan\u00e7ons notre service</p> <pre><code>systemctl try-restart ssh.service\n</code></pre> <p>Et voici le r\u00e9sultat que nous aurons :</p> <p></p>"},{"location":"linux/security/ssh_improve_speed/","title":"Am\u00e9liorer la vitesse de connexion \u00e0 votre serveur SSH","text":"<p>Dans la vie d'un sysadmin, nous devons nous connecter des dizaines de fois par jour \u00e0 diff\u00e9rents serveurs SSH, parfois situ\u00e9s \u00e0 l'autre bout de la plan\u00e8te et ainsi entrainant une\u00a0latence assez importance. Pour rappel, SSH est un protocole bas\u00e9 sur TCP et ainsi initie donc sa connexion via un 3 Way Handshake. Imaginons un serveur situ\u00e9 \u00e0 Paris alors que nous sommes en Colombie. Un simple \u00e9tablissement de session TCP entraine donc une latence suppl\u00e9mentaire d'1 seconde lors de chaque connexion au serveur.</p> <p>Heureusement, les d\u00e9veloppeurs du client SSH ont pens\u00e9s \u00e0 tout et ont d\u00e9velopp\u00e9s un multiplexer SSH. Ainsi, lorsque cette option est activ\u00e9e, la session TCP reste initialis\u00e9e et ainsi nous pouvons la r\u00e9utiliser, ce qui introduit un gain de temps consid\u00e9rable.</p>"},{"location":"linux/security/ssh_improve_speed/#configuration","title":"Configuration","text":"<p>La configuration se fait d'une mani\u00e8re simpliste dans votre fichier de configuration ssh c\u00f4t\u00e9 client</p> <pre><code>\u03bb MacBook-Pro-de-Delgado ~ \u2192 cat ~/.ssh/config\nHost *\n    ControlMaster auto\n    ControlPath ~/.ssh/private/master-%r@%h:%p.socket\n    ControlPersist 10m\n</code></pre> <p>Nous appliquons la valeur auto \u00e0 ControlMaster car il s'agit de l'option la plus logique \u00e0 utiliser. Celle-ci essaie d'utiliser une connexion maitre d\u00e9j\u00e0 existante, si celle-ci n'existe pas, alors elle sera cr\u00e9\u00e9e. Le ControlPath est d\u00e9finit dans un dossier propre \u00e0 notre utilisateur et ne doit surtout pas \u00eatre accessible par tous. %r sera remplac\u00e9 par l'username, %h par l'host et %p par le port utilis\u00e9. Enfin, nous indiquons \u00e0 notre client que nous souhaitons utiliser notre socket pour une dur\u00e9e de 10 minutes.</p> <p>Le dossier private n'existe pas, n'oubliez pas de le cr\u00e9er de lui donner les droits ad\u00e9quates.</p> <p>Evidemment, des explications plus d\u00e9taill\u00e9es sont disponibles dans le man de ssh_config</p>"},{"location":"linux/security/ssh_improve_speed/#benchmark","title":"Benchmark","text":"<p>Benchmark effectu\u00e9 dans un train avec une connexion mitig\u00e9e.</p> <pre><code>\u03bb MacBook-Pro-de-Delgado ~ \u2192 time ssh backup.x.y.tld ls\nssh backup.x.y.tld ls  0,03s user 0,02s system 2% cpu 2,149 total\n\u03bb MacBook-Pro-de-Delgado ~ \u2192 time ssh backup.x.y.tld ls\nssh backup.x.y.tld ls  0,00s user 0,01s system 4% cpu 0,284 total\n</code></pre> <p>Lors de la premi\u00e8re connexion, la session TCP n'\u00e9tait pas initialis\u00e9e, ainsi, la commande ls a dur\u00e9e 2,1s. Lors du second lancement, la session TCP \u00e9tait initialis\u00e9e et a donc \u00e9t\u00e9 r\u00e9utilis\u00e9e. Notre commande a dur\u00e9e \u00e0 peine 0,2s soit un gain de 1000%. Le gain peut vous sembler d\u00e9risoire, cependant, multilpli\u00e9 sur une journ\u00e9e ainsi que 200j/an, il s'av\u00e8re consid\u00e9rable.</p>"},{"location":"linux/security/ssh_improve_speed/#precautions","title":"Pr\u00e9cautions","text":"<p>Attention, m\u00eame si l'option ControlMaster du client SSH semble magique, celle-ci \u00e0 quelques limitations. Par exemple, si nous souhaitons passer une large quantit\u00e9 de donn\u00e9e via un rsync ou un scp, il se peut que celles-ci fail, il s'agit d'un point \u00e0 ne pas n\u00e9gliger. Il est possible de d\u00e9sactiver l'utilisation de ControlMaster en le passant \u00e0 none ponctuellement.</p>"},{"location":"linux/security/ssh_improve_speed/#troubleshooting","title":"Troubleshooting","text":"<p>Pour \u00eatre s\u00fbr qu'un socket est ouvert, nous pouvons utiliser la control command (-O dans ssh) check.</p> <pre><code>ssh -O check backup.x.y.tld ls\nControl socket connect(/Users/jeremy/.ssh/private/master-y-jd@backup.x.y.tld:6666): No such file or directory\n</code></pre> <p>Ici, nous voyons que le socket n'est pas cr\u00e9\u00e9. Si vous \u00eates s\u00fbr que le dossier existe et dispose de bons droits, alors vous pouvez initialiser la connexion \u00e0 la main :</p> <pre><code>ssh -M -S /Users/jeremy/.ssh/private/master-y-jd@backup.x.y.tld:6666 backup.x.y.tld\n</code></pre> <p>D\u00e9sormais, si vous refaites notre commande de check, vous devrez utiliser le socket :</p> <pre><code>ssh -O check backup.x.y.tld\nMaster running (pid=87060)\n</code></pre> <p>Si pour une quelconque raisons vous souhaitez arr\u00eater le master, vous pouvez le faire avec la control command stop</p> <pre><code>ssh -O stop backup.x.y.tld ls\nStop listening request sent.\n</code></pre>"},{"location":"linux/security/ssh_log_commands/","title":"Logger les actions SSH utilisateurs simplement","text":"<p>Parfois, il peut-\u00eatre utile de logger les action utilisateurs, que ce soit pour v\u00e9rifier que celui-ci ne casse pas tout ou alors pour '\"surveiller'\" tous les activit\u00e9s.</p> <p>Tout d'abord, il y a 2 moyens de logger les actions :</p> <ul> <li>En \u00e9ditant le fichier <code>bash.rc</code> se situant dans <code>/etc</code> ce qui aura     comme cons\u00e9quence logger tous les utilisateurs</li> <li>En \u00e9ditant le fichier <code>.bashrc</code> propre \u00e0 chaque utilisateur. (Il se     situe dans son r\u00e9pertoire home)</li> </ul> <p>Dans tous les cas, les logs seront envoy\u00e9s dans syslog (exploitable via journalctl), ainsi que dans un fichier (que nous allons d\u00e9finir)</p> <p>Quelque soit le fichier, voici la ligne \u00e0 rajouter :</p> <pre><code>export PROMPT_COMMAND=RETRN_VAL=$?;logger -p local6.debug \"$(whoami) [$$]: $(history 1 | sed \"s/^[  ]*[0-9]'+[  ]*//\" ) [$RETRN_VAL]\"\n</code></pre> <p>Avec cette ligne, nous aurons ce genre de r\u00e9sultats</p> <pre><code>nov. 04 16:27:21 hostname moche[1781]: moche [20803]: cd /incoming/Media [1]\n</code></pre> <p>Nous allons configurer rsyslog pour qu'il envoie les logs dans un fichier :</p> <pre><code>local6.*    /var/log/commands.log\n</code></pre> <p>Via cette commande, rsyslog enverra tout ce qui concerne <code>local6.</code> quelque soit le niveau de debug <code>(.'*)</code> dans le fichier /var/log/commands.log</p> <p>Puis nous red\u00e9marrons syslog</p> <pre><code>systemctl try-restart rsyslog.service\n</code></pre> <p>Une fois ceci fait, vous recevrez correctement vos fichier dans syslog et dans le fichier que vous avez indiqu\u00e9s. Il faut maintenant configurer la rotation automatique des logs.</p> <p>Il suffit d'ajouter le chemin de votre fichier de logs (Pour nous /var/log/commands.log) dans le fichier de configuration logrotate se situant dans /etc/logrotate.d/rsyslog</p> <pre><code>[...]\n/var/log/mail.info\n[...]\n/var/log/debug\n**/var/log/commands.log**\n</code></pre> <p>Il s'agit ici d'un log basique, il est possible d'avoir un log complet avec des logiciels tels que Snoopy</p>"},{"location":"linux/security/telegram_notifications_ssh/","title":"Configurer des notifications Telegram pour SSH","text":"<p>Ce tutoriel reprend le principe de la notification Slack pour une autre plateforme de Messagerie, le principe diff\u00e8re l\u00e9g\u00e8rement car nous avons ici</p>"},{"location":"linux/security/telegram_notifications_ssh/#configuration-du-bot-telegram","title":"Configuration du bot Telegram","text":"<p>Voici comment cr\u00e9er son bot Telegram, n'oublions pas de r\u00e9cup\u00e9rer les tokens importants.</p>"},{"location":"linux/security/telegram_notifications_ssh/#configuration-cote-serveur","title":"Configuration c\u00f4t\u00e9 serveur","text":"<p>Nous commen\u00e7ons par faire notre fichier qui enverra nos notifications \u00e0 notre Telegram : /etc/ssh/notify.sh</p> <pre><code>#!/usr/bin/env bash\n\n# Import credentials form config file\n. /opt/ssh-login-alert-telegram/credentials.config\n\nURL=\"https://api.telegram.org/bot${KEY}/sendMessage\"\nDATE=\"$(date \"+%d %b %Y %H:%M\")\"\n\nCLIENT_IP=$(echo $SSH_CLIENT | awk {print $1})\n\nSRV_HOSTNAME=$(hostname -f)\nSRV_IP=$(hostname -I | awk {print $1})\n\nIPINFO=\"https://ipinfo.io/${CLIENT_IP}\"\n\nTEXT=\"Connection from *${CLIENT_IP}* as ${USER} on *${SRV_HOSTNAME}* (*${SRV_IP}*)\nDate: ${DATE}\nMore informations: [${IPINFO}](${IPINFO})\"\n\ncurl -s -d \"chat_id=${USERID}&amp;text=${TEXT}&amp;disable_web_page_preview=true&amp;parse_mode=markdown\" $URL\n</code></pre> <p>Nous utilisons un autre fichier afin de contenir les credentials :</p> <pre><code># Your USERID or Channel ID to display alert and key, we recommend you create new bot with @BotFather on Telegram\nUSERID=\"USERID\"\nKEY=\"BOT_TOKEN\"\n</code></pre> <p>Penser \u00e0 remplacer le WEBHOOK_URL et le channel par le votre. On rend notre script ex\u00e9cutable</p> <pre><code>chmod +x /etc/ssh/notify.sh\n</code></pre> <p>Et on modifie notre service PAM SSH /etc/pam.d/sshd en y ajoutant le contenu suivant</p> <pre><code>session optional pam_exec.so seteuid /etc/ssh/notify.sh\n</code></pre> <p>Nous relan\u00e7ons notre service</p> <pre><code>systemctl try-restart ssh.service\n</code></pre> <p>Nous avons d\u00e9sormais une notification avec chaque ouverture de session SSH</p>"},{"location":"linux/security/whitelist_ip/","title":"Whitelister une s\u00e9rie d'IP \u00e0 l'aide d'IPset et iptables","text":"<p>Dans certains cas, il peut \u00eatre utile de whitelister une s\u00e9rie d'IP comme par exemple lorsque nous souhaitons qu'une API ne soit disponibles que pour certains utilisateurs...</p> <p>Pour y parvenir, plusieurs m\u00e9thodes sont disponibles :</p> <ul> <li>Ajout d'une r\u00e8gle par IP \u00e0 whitelist au niveau d'IPTables</li> <li>Filtre IP au sein de l'API</li> <li>Filtre IP sur le reverse-proxy</li> <li>Ajout d'une r\u00e8gle IPTables et cr\u00e9ation d'une liste ipset</li> </ul> <p>Dans ce tutoriel, nous allons appliquer la derni\u00e8re r\u00e8gle qui est la plus optimis\u00e9e. iptables charge un module appel\u00e9 xt_conntrack qui s'occupe d'analyser les trames. Cependant, un trop grand nombre de r\u00e8gle iptables entraine une importante d\u00e9gradation de la stack TCP/IP (Ce ph\u00e9nom\u00e8ne a \u00e9t\u00e9 observ\u00e9 de nombreuses fois).</p> <p>C'est pour cela que nous utilisons ipset qui nous permet de cr\u00e9er de listes d'IP.</p>"},{"location":"linux/security/whitelist_ip/#requirements","title":"Requirements","text":"<p>Il faut tout d'abord installer les pr\u00e9-requis</p> <pre><code>apt-get install ipset iptables netfilter-persistent iptables-persistent\n</code></pre>"},{"location":"linux/security/whitelist_ip/#configuration-initiale","title":"Configuration initiale","text":"<p>Tout d'abord, nous commencons \u00e0 cr\u00e9er notre liste ipset</p> <pre><code>ipset create whitelist hash:ip hashsize 4096\n</code></pre> <p>Nous cr\u00e9ons une liste ipset s'appelant whitelist utilisant le principe de hash par IP et non le hash par network (Dans notre cas, nous autorisons que des IPs et non des r\u00e9seaux de tailles diff\u00e9rentes)</p> <p>Puis nous cr\u00e9ons nos r\u00e8gles iptables</p> <pre><code>iptables -A INPUT -p tcp -m tcp --dport 9001 -m set --match-set whitelist src -j ACCEPT\niptables -A INPUT -p tcp -m tcp --dport 9001 -j DROP\n</code></pre> <p>Nous autorisons certaines IPs vers le port 9001 en TCP puis nous rejetons tout le reste, r\u00e8gles \u00e0 adapter bien \u00e9videmment</p> <p>Pour faire du multiport, nous utilisons un module d\u00e9di\u00e9 \u00e0 \u00e7a dans iptables</p> <pre><code>iptables -A INPUT -p tcp -m multiport --destination-ports 9000:9005,9006,9021,9041,9042,9099 -m set --match-set whitelist src -j ACCEPT\niptables -A INPUT -p tcp -m multiport --destination-ports 9000:9005,9006,9021,9041,9042,9099 -j DROP\n</code></pre>"},{"location":"linux/security/whitelist_ip/#configuration-persistante","title":"Configuration persistante","text":"<p>Pour rendre notre configuration permanente, nous utilisons le logiciel netfilter-persistent ainsi qu'un plugin ipset disponible ici</p> <pre><code>cd ~\u00a0\ngit clone https://github.com/freeyoung/netfilter-persistent-plugin-ipset\nchmod +x netfilter-persistent-plugin-ipset/10-ipset\nmv netfilter-persistent-plugin-ipset/10-ipset /usr/share/netfilter-persistent/plugins.d\n</code></pre> <p>Une fois le plugin install\u00e9, il faut activer le service au d\u00e9marrage</p> <pre><code>systemctl enable netfilter-persistent\n</code></pre> <p>Et sauvegarder la configuration actuelle</p> <pre><code>/etc/init.d/netfilter-persistent save\n</code></pre> <p>Votre configuration est d\u00e9sormais persistent, penser \u00e0 sauvegarder vos modifications \u00e0 chaque modification d'ipset/iptables</p>"},{"location":"linux/selfhost/ajenti/","title":"G\u00e9rer son serveur en ligne via Ajenti","text":"<p>A l'instar de Webmin ou encore Vesta, Ajenti est un panel d'administration de serveur. Simple et efficace, il vous permettra d'effectuer la grande majorit\u00e9 des actions courantes (Reboot du serveur, edition des configurations, du firewall...)</p>"},{"location":"linux/selfhost/ajenti/#installation","title":"Installation","text":"<p>Pour l'installer, il vaut mieux utiliser la source officielle. Les packages Debian \u00e9tant assez vieux.</p> <pre><code>curl https://raw.githubusercontent.com/ajenti/ajenti/master/scripts/install.sh | sudo bash -s -\n</code></pre> <p>Pour plus de m\u00e9thode d'installation, aller voir le lien officiel</p> <p>Puis on installe le package</p> <pre><code>apt-get update &amp;&amp; apt-get install ajenti\n</code></pre> <p>Si l'installation est bonne, vous pourrez acc\u00e9der \u00e0 ajenti via le port 8000, les identifiants par d\u00e9faut sont root et admin</p>"},{"location":"linux/selfhost/h5ai/","title":"Partager ses fichiers avec H5ai","text":""},{"location":"linux/selfhost/h5ai/#presentation","title":"Pr\u00e9sentation","text":"<p>h5ai est un index am\u00e9lior\u00e9 afin de partager facilement tous vos fichiers... Celui-ci remplacera ais\u00e9ment un index fade et sans gout. Celui- ci est disponible pour tous les serveurs web, \u00e0 condition d'avoir au minimum la version 5.5 de PHP.</p>"},{"location":"linux/selfhost/h5ai/#installation","title":"Installation","text":"<p>Tout d'abord, nous devons faire un lien symbolique vers notre www, et le folder que nous souhaitons rendre accessible publiquement.</p> <p>Pour moi, je souhaite rendre <code>/home/jeremy/files/</code> accessible publiquement</p> <pre><code>ln -s /home/jeremy/files/ /var/www/downloads\n</code></pre> <p>Il convient comme nom d'usage d'utiliser downloads en folder de destination</p> <p>Puis dans ce dossier, nous allons t\u00e9l\u00e9charger h5ai</p> <pre><code>cd /var/www/downloads/\nwget https://release.larsjung.de/h5ai/h5ai-0.28.1.zip\n</code></pre> <p>N'oublier pas de vous rendre ici afin de consulter les derni\u00e8res versions de h5ai disponibles</p> <p>Enfin, nous extrayons l'archive, puis nous renommons '_h5ai en .h5ai afin de ne pas le voir dans l'explorateur.</p> <pre><code>unzip h5ai-0.28.1.zip\nmv _h5ai .h5ai\n</code></pre> <p>On n'oublie pas de donner les droits ad\u00e9quats</p> <pre><code>chown -R www-data:www-data .h5ai\n</code></pre> <p>Et enfin, on cr\u00e9er le server-block NGINX ad\u00e9quat, sans oublier de faire le bon CNAME</p> <pre><code>server {\n    server_name downloads.titi.ovh;\n    listen 80;\n    listen [::]:80;\n    return 301 https://$host$request_uri;\n}\nserver {\n    listen 443 ssl http2;\n    listen [::]:443 ssl http2;\n    server_name downloads.titi.ovh;\n\n    error_log /var/log/nginx/downloads.error.log;\n    access_log /var/log/nginx/downloads.access.log;\n\n    include /etc/nginx/conf.d/cache.conf;\n    include /etc/nginx/conf.d/php.conf;\n    include /etc/nginx/conf.d/ssl.conf;\n    include /etc/nginx/conf.d/file_protect.conf;\n\n    auth_basic \"Downloads\";\n    auth_basic_user_file \"/etc/nginx/passwd/rutorrent_passwd\";\n\n    root /var/www/downloads;\n    index  index.html  index.php /.h5ai/public/index.php;\n\n    autoindex on;\n}\n</code></pre> <p>La derni\u00e8re ligne autoindex on est cruciale, car c'est elle qui va permettre de lister le contenu.</p>"},{"location":"linux/selfhost/koel/","title":"Streamer sa musique depuis Koel","text":""},{"location":"linux/selfhost/koel/#presentation","title":"Pr\u00e9sentation","text":"<p>A l'instar de Spotify, Deezer, ou bien des autres services installables, tel que Sonerezh ou Ampache, Koel se d\u00e9marque par rapport \u00e0 son Design \u00e9pur\u00e9, se voulant \u00eatre proche de celui de Spotify, et Koel le fait.</p> <p>De plus, Koel permet de stream sans aucun soucis le contenu FLAC (Sous r\u00e9serve de transcodage via FFMpeg), dispose d'un syst\u00e8me de gestion de compte, mais \u00e9galement d'une interface mobile de qualit\u00e9.</p>"},{"location":"linux/selfhost/koel/#pre-requis","title":"Pr\u00e9-requis","text":"<p>Koel a besoin d'un grand nombre de pr\u00e9-requis, autre que PHP et MySQL afin de fonctionner correctement. Les pr\u00e9requis sont</p> <ul> <li>Composer</li> <li>NodeJS</li> <li>NPM</li> <li>Gulp</li> <li>Bower</li> </ul> <p>Si l'un de ces pr\u00e9-requis n'est pas install\u00e9, nous ne pourrons pas continuer l'installation de Koel. Soyez donc sur que ceux-ci sont pr\u00e9sents sur votre machine</p> <p>NDLR: Il n'est pas forc\u00e9ment n\u00e9c\u00e9ssaire d'avoir nGinx ou autre sur sa machine, \u00e9tant donner que Koel dispose de son propre serveur web</p>"},{"location":"linux/selfhost/koel/#composer","title":"Composer","text":"<p>Composer vous permet de g\u00e9rer simplement les d\u00e9pendances de votre application PHP</p> <pre><code>curl -sS https://getcomposer.org/installer | php -- --install-dir=/usr/bin --filename=composer\n</code></pre>"},{"location":"linux/selfhost/koel/#nodejs","title":"NodeJS","text":"<p>NodeJS n'est pas utile directement ici, mais il vous sera indispensable \u00e0 l'installation de NPM</p> <pre><code>wget -qO- https://deb.nodesource.com/setup_5.x | bash -\n</code></pre> <p>Ce script sert just \u00e0 ajouter les bonnes sources \u00e0 notre fichier sources. Nous l'installons comme d'habitude</p> <pre><code>apt update &amp;&amp; apt install nodejs\n</code></pre>"},{"location":"linux/selfhost/koel/#npm","title":"NPM","text":"<p>NPM va vous permettre d'installer toutes les librairies JS n\u00e9c\u00e9ssaires au bon fonctionnement de Koel</p> <pre><code>curl -L https://www.npmjs.com/install.sh | sh\n</code></pre>"},{"location":"linux/selfhost/koel/#gulp","title":"Gulp","text":"<p>Gulp va vous permettre de compiler les fichiers JS et SASS</p> <pre><code>npm install --global gulp\n</code></pre>"},{"location":"linux/selfhost/koel/#bower","title":"Bower","text":"<p>Tout comme Composer, Bower est un gestionnaire de paquet, destin\u00e9 aux d\u00e9pendances de vos diverses applications Web.</p> <pre><code>npm install -g bower\n</code></pre>"},{"location":"linux/selfhost/koel/#installation","title":"Installation","text":"<p>Maintenant que les d\u00e9pendances de Koel sont satisfaites, nous pouvons passer \u00e0 son installation en elle m\u00eame.</p> <p>Nous devons tout d'abord pr\u00e9parer la base de donn\u00e9e qui recevra les donn\u00e9es de notre Koel</p> <pre><code>CREATE DATABASE koel DEFAULT CHAR SET utf8 DEFAULT COLLATE utf8_general_ci;\nCREATE USER koel-user@localhost IDENTIFIED BY koel-pass;\nGRANT ALL PRIVILEGES ON koel.* TO koel-user@localhost WITH GRANT OPTION;\n</code></pre> <p>Bien \u00e9videmment, il faut remplacer koel-user et koel-pass par les identifiants que vous souhaitez.</p> <p>Maintenant, nous allons cloner le projet Koel dans notre r\u00e9pertoire Web (G\u00e9n\u00e9ralement, /var/www). N'oubliez pas d'installer git pour cela.</p> <pre><code>git clone https://github.com/phanan/koel.git\n</code></pre> <p>Il est maintenant n\u00e9c\u00e9ssaire de t\u00e9l\u00e9charges les d\u00e9pendances n\u00e9c\u00e9ssaires au bon fonctionnement de Koel (Ne pas oublier de se placer dans le r\u00e9pertoire de Koel)</p> <pre><code>npm install\n</code></pre> <pre><code>composer install\n</code></pre> <p>A ce stade de progression, il est d\u00e9sormais n\u00e9c\u00e9ssaire d'\u00e9diter le fichier de configuration de Laravel (Le framework utilis\u00e9 par Koel)</p> <pre><code>cp .env.example .env\n</code></pre> <p>Si vous n'avez pas de .env.example, je vous invite \u00e0 vous rendre ici afin de le t\u00e9l\u00e9charger.</p> <p>A l'int\u00e9rieur de ce fichier, il y a plusieurs lignes \u00e0 editer :</p> <ul> <li><code>DB_CONNECTION</code> : Moteur de base de donn\u00e9e \u00e0 employer     (G\u00e9n\u00e9ralement, MySQL)</li> <li><code>DB_HOST</code> : Host sur lequel est h\u00e9berg\u00e9e votre base de donn\u00e9e     (G\u00e9n\u00e9ralement, localhost)</li> <li><code>DB_DATABASE</code> : Nom de la base de donn\u00e9e (Selon notre tutoriel,     Koel)</li> <li><code>DB_USERNAME</code> : Nom d'utilisateur pour vous connecter \u00e0 votre     base de donn\u00e9e (D\u00e9finis pr\u00e9c\u00e9demment)</li> <li><code>DB_PASSWORD</code> : Password pour vous connecter \u00e0 votre base de     donn\u00e9e (D\u00e9finis pr\u00e9c\u00e9demment)</li> </ul> <p>Nous modifions premi\u00e8rement les identifiants de connexion \u00e0 SQL. Nous devons maintenant les informations de connexion \u00e0 Koel</p> <ul> <li><code>ADMIN_EMAIL</code> : Identifiant de connexion \u00e0 Koel (Peut \u00eatre fake)</li> <li><code>ADMIN_NAME</code> : Nom de l'utilisateur</li> <li><code>ADMIN_PASSWORD</code> : Mot de passe de connexion \u00e0 Koel</li> </ul> <p>Accessoirement, voici quelques valeurs qu'il peut \u00eatre possible d'\u00e9diter, selon ses besoins :</p> <ul> <li><code>APP_MAX_SCAN_TIME</code> : Temps maximum pass\u00e9 durant le scan d'une     biblioth\u00e8que. Peut \u00eatre utile d'augmenter si vous disposez d'une     large biblioth\u00e8que</li> <li> <p><code>STREAMING_METHOD</code> : M\u00e9thode utilis\u00e9e pour envoyer les musiques</p> </li> <li> <p><code>LASTFM_API_SECRET</code> : Identifiant secret pour activer     l'utilisation de Last.FM dans Koel</p> </li> <li><code>LASTFM_API_KEY</code> : Cl\u00e9 secr\u00e8te pour activer l'utilisation de     Last.FM dans Koel</li> </ul> <p>Pour obtenir ces identifiants LastFM, rendez-vous ici</p> <ul> <li><code>FFMPEG_PATH</code> : Chemin absolu vers le bin de ffmpeg, afin de     pouvoir transcoder</li> <li><code>OUTPUT_BIT_RATE</code> : Bitrate utilis\u00e9e pour le transcodage (128 par     d\u00e9faut, 256 recommand\u00e9)</li> </ul> <p>Afin de cr\u00e9er le premier compte, qui sera l'admin, il est n\u00e9c\u00e9ssaire de rentrer des valeurs dans les variables <code>ADMIN_EMAIL</code>, <code>ADMIN_NAME</code> et <code>ADMIN_PASSWORD</code>.</p> <p>Une fois cela fait, nous allons utiliser une nouvelle fois artisan afin de les g\u00e9n\u00e9rer en base de donn\u00e9es :</p> <pre><code>php artisan db:seed\n</code></pre> <p>Nous allons g\u00e9n\u00e9rer les JS &amp; CSS de notre Koel</p> <pre><code>bower install --allow-root\n</code></pre> <pre><code>gulp --production\n</code></pre> <p>Et enfin, toujours en \u00e9tant dans le dossier Koel, nous initialisons le premier lancement de Koel</p> <pre><code>php artisan koel:init\n</code></pre> <p>Puis, nous pouvons lancer un serveur Web (Qui tournera sur le port 8000)</p> <pre><code>php artisan koel:serve --host 0.0.0.0\n</code></pre> <p>Pour que ce serveur int\u00e9grer puisse fonctionner, nous avons besoin de quelques librairies:</p> <pre><code>apt-get install libcrystalhd-dev libvdpau1\n</code></pre> <p>Si vous souhaitez avoir Koel qui tourne sur le port 80, vous pouvez ajouter '--port 80 \u00e0 la ligne ci-dessus.</p>"},{"location":"linux/selfhost/koel/#bonus","title":"Bonus","text":""},{"location":"linux/selfhost/koel/#auto-update-librairie","title":"Auto-update librairie","text":"<p>Il est possible d'automatiser la mise \u00e0 jour de sa biblioth\u00e8que vient une simple ligne cron.</p> <p>Pour cela, ajoutez cette ligne</p> <pre><code>0 0 * * * cd /var/www/koel/ &amp;&amp; /usr/bin/php artisan koel:sync &gt;/dev/null 2&gt;&amp;1\n</code></pre>"},{"location":"linux/selfhost/koel/#nginx","title":"nGinx","text":"<p>Il est \u00e9galement possible de se passer du '\"serveur'\" int\u00e9gr\u00e9 \u00e0 Koel et de faire son propre server block pour nginx. Koel nous en fournit d\u00e9j\u00e0 un par d\u00e9faut qui fonctionne tr\u00e8s bien.</p> <p>Je vous invite \u00e0 aller voir ici et de l'adapter selon vos besoins.</p>"},{"location":"linux/selfhost/koel/#serveur-en-tache-de-fond","title":"Serveur en tache de fond","text":"<p>Si toutefois, vous souhaitez utiliser le serveur int\u00e9gr\u00e9 \u00e0 Koel (ce que je ne comprendrais pas), vous devrez l'ex\u00e9cuter en t\u00e2che de fond</p> <p>Cr\u00e9er l'instance screen</p> <pre><code>screen -S Koel\n</code></pre> <p>Puis on lance la commande habituelle</p> <pre><code>php artisan koel:serve --host 0.0.0.0\n</code></pre> <p>Et enfin, on sort du screen avec CTRL+A pour attached, puis CTRL+D pour detached</p>"},{"location":"linux/selfhost/nextcloud/","title":"NextCloud, son cloud personnel","text":"<p>Nextcloud est une solution de stockage et de partage de fichiers en ligne. Il s'agit d'un logiciel gratuit se basant sur MySQL / PHP (et accessoirement redis). Attention, si beaucoup d'entre vous se servent de NextCloud en tant que sauvegarde '\"cloud'\", il ne faut pas oublier de r\u00e9pliquer ses donn\u00e9es sur un autre support de stockage et \u00e0 minima installer NextCloud sur un RAID1 afin de se pr\u00e9munir d'\u00e9ventuels probl\u00e8mes hardware.</p> <p>Nous sommes \u00e0 ce jour \u00e0 la version 23, vous pouvez consulter le changelog</p>"},{"location":"linux/selfhost/nextcloud/#pre-requis","title":"Pr\u00e9-requis","text":"<p>NextCloud \u00e9tant un logiciel \u00e9crit en PHP, nous devons avoir une stack LAMP fonctionnelle. Pour cela, je vous invite \u00e0 aller consulter l'article ad\u00e9quate.</p>"},{"location":"linux/selfhost/nextcloud/#installation-de-nextcloud","title":"Installation de NextCloud","text":"<p>Il faut dans un premier temps t\u00e9l\u00e9charger nextcloud</p> <pre><code>cd /var/www ; wget https://github.com/nextcloud/server/archive/refs/tags/v23.0.3.zip\n</code></pre> <p>Et on unzip !</p> <pre><code>unzip v23.0.3.zip\n</code></pre> <p>Et on fix les privil\u00e8ges</p> <pre><code>sudo chown www-data:www-data /var/www/nextcloud/ -R\n</code></pre> <p>On cr\u00e9\u00e9 la database associ\u00e9e \u00e0 nextcloud</p> <pre><code>mysql -u root &lt;&lt;-EOF\nCREATE DATABASE nextcloud;\nCREATE USER nextcloud@localhost IDENTIFIED BY mae8WiapaefohLaeb1am;\nGRANT ALL PRIVILEGES ON nextcloud.* TO \"nextcloud\"@\"localhost\";\nFLUSH PRIVILEGES;\nEOF\n</code></pre> <p>(Pensez \u00e0 modifier le password \u00e9videmment)</p> <p>Enfin, le vhost NGINX ad\u00e9quate \u00e0 NextCloud, disponible ici</p> <p>Une fois tout ceci fait, on se rend sur notre server_name, et on remplit les infos comme il demande, vous avez d\u00e9sormais un NextCloud utilisable</p>"},{"location":"linux/selfhost/nextcloud/#configuration-de-nextcloud","title":"Configuration de NextCloud","text":"<p>Toute la configuration que nous faisons s'effectue via la ligne de commande occ pour un gain de temps, il est \u00e9galement possible de tout effectuer via l'interface graphique.</p> <p>occ dispose d\u00e9sormais d'une auto-completion :</p> <pre><code>source &lt;(/var/www/nextcloud/occ _completion --generate-hook)\n</code></pre> <p>Pour disposer automatiquement de l'auto-completion, nous pouvons ajouter cette commande \u00e0 notre .bashrc ou .zshrc (ou tout autre shell)</p> <p>Toutes les options de occ sont disponible dans la documentation officielle.</p> <p>Voici quelques options particuli\u00e8rement int\u00e9ressantes :</p> <ul> <li>Num\u00e9ro de t\u00e9l\u00e9phone FR par d\u00e9faut</li> </ul> <pre><code>sudo -u www-data php /var/www/nextcloud/occ config:system:set '\ndefault_phone_region --value=\"FR\"\n</code></pre> <ul> <li>Suppression des fichiers par d\u00e9faut</li> </ul> <pre><code>rm -r \"/var/www/nextcloud/core/skeleton/Documents/\"\nrm -r \"/var/www/nextcloud/core/skeleton/Photos/\"\nrm \"/var/www/nextcloud/core/skeleton/Nextcloud intro.mp4\"\nrm \"/var/www/nextcloud/core/skeleton/Nextcloud.png\"\n</code></pre> <ul> <li>Gestion du stockage externe</li> </ul> <p>Nous permet de connecter notre NextCloud \u00e0 des Samba, FTP ou autre</p> <pre><code>sudo -u www-data php /var/www/nextcloud/occ app:install files_external\nsudo -u www-data php /var/www/nextcloud/occ app:enable files_external\n</code></pre> <ul> <li>Mise \u00e0 jour des applications NextCloud</li> </ul> <pre><code>sudo -u www-data php /var/www/nextcloud/occ app:update --all\n</code></pre> <ul> <li>Gestion des t\u00e2ches de fond</li> </ul> <p>Sur serveur d\u00e9di\u00e9, il est pr\u00e9f\u00e9rable d'utiliser le system de cron ou de timers systemd. Comme nous sommes en 2022, nous allons utiliser les timers systemd :</p> <ul> <li>Service systemd</li> </ul> <pre><code>cat &gt; /etc/systemd/system/nextcloudcron.service &lt;&lt; EOF\n[Unit]\nDescription=Nextcloud Cron Job\n\n[Service]\nUser=www-data\nExecStart=/usr/bin/php -f /var/www/owncloud/cron.php\nEOF\n</code></pre> <ul> <li>Timer systemd</li> </ul> <pre><code>cat &gt; /etc/systemd/system/nextcloudcron.timer &lt;&lt; EOF\n[Unit]\nDescription=Run Nextcloud cron.php every minute\n\n[Timer]\nOnBootSec=2min\nOnUnitActiveSec=1min\nUnit=nextcloudcron.service\n\n[Install]\nWantedBy=timers.target\nEOF\n</code></pre> <p>Petit reload de systemd + activation du timer :</p> <pre><code>systemctl daemon-reload ; systemctl enable --now nextcloudcron.timer\n</code></pre> <p>Une fois l'\u00e9tape c\u00f4t\u00e9 serveur effectu\u00e9, on va indiquer \u00e0 NextCloud d'utiliser cette m\u00e9thode de cron</p> <pre><code>sudo -u www-data php occ background:cron\n</code></pre> <ul> <li>Chiffrer ses documents</li> </ul> <p>Si vous \u00eates paranos, il est possible d'activer le chiffrement de tous vos documents :</p> <pre><code>sudo -u www-data php occ maintenance:mode --on\nsudo -u www-data php occ encryption:enable\nsudo -u www-data php occ occ encryption:encrypt-all\nsudo -u www-data php occ maintenance:mode --off\n</code></pre>"},{"location":"linux/selfhost/nextcloud/#bonus","title":"Bonus","text":""},{"location":"linux/selfhost/nextcloud/#installation-de-redis","title":"Installation de redis","text":"<p>Redis vous permettra l'optimisation des performances de votre NextCloud via la mise en cache de quelques \u00e9l\u00e9ments. Nous allons configurer Redis avec un socket local afin de ne pas exposer un port suppl\u00e9mentaire, n\u00e9cessitants quelques modifications.</p> <p>Redis va \u00e9galement nous permettre de g\u00e9rer plus efficacement les locks de mani\u00e8re plus optimis\u00e9e (plus d'informations)</p> <p>Tout d'abord, nous allons installer les paquets n\u00e9cessaires</p> <pre><code>apt install php-redis redis-server\n</code></pre> <p>Puis nous faisons les modifications de configuration de Redis</p> <pre><code>usermod -a -G redis www-data\nsed -i -e \"s/^#* *port +*6379$/port 0/g\" /etc/redis/redis.conf\nsed -i -e \"s/^#* *unixsocket +*.*$/unixsocket '/var'/run'/redis'/redis-server.sock/g\" /etc/redis/redis.conf\nsed -i -e \"s/^#* *unixsocketperm+*.*$/unixsocketperm 770/g\" /etc/redis/redis.conf\n</code></pre> <p>Comme nous allons \u00e9galement utiliser redis pour le locking, nous devons activer le session locking c\u00f4t\u00e9 PHP, sans quoi, notre locking n'aura aucun int\u00e9r\u00eat :</p> <pre><code>cat &gt;&gt; /etc/php/8.2/fpm/conf.d/20-redis.ini &lt;&lt; EOF\nredis.session.locking_enabled=1\nredis.session.lock_retries=-1\nredis.session.lock_wait_time=10000\nEOF\n</code></pre> <p>On n'oublie pas de restart redis :</p> <pre><code>systemctl restart redis-server\n</code></pre> <p>Enfin, on configure tout \u00e7a c\u00f4t\u00e9 NextCloud avec le fabuleux utilitaire qu'est occ</p> <pre><code># Filelocking\nsudo -u www-data php /var/www/nextcloud/occ config:system:set filelocking.enabled --value=\"true\"\n\n# Redis\nsudo -u www-data php /var/www/nextcloud/occ config:system:set redis host --value=\"/var/run/redis/redis-server.sock\"\nsudo -u www-data php /var/www/nextcloud/occ config:system:set redis port --value=\"0\"\nsudo -u www-data php /var/www/nextcloud/occ config:system:set redis timeout --value=\"0.0\"\n\n# Memcahed distributed\nsudo -u www-data php /var/www/nextcloud/occ config:system:set memcache.distributed --value=\"'OC'Memcache'Redis\"\n# Locking &amp; Local\nsudo -u www-data php /var/www/nextcloud/occ config:system:set memcache.local --value=\"'OC'Memcache'Redis\"\nsudo -u www-data php /var/www/nextcloud/occ config:system:set memcache.locking --value=\"'OC'Memcach\n</code></pre>"},{"location":"linux/selfhost/nextcloud/#edition-de-documents","title":"Edition de documents","text":"<p>Nous pouvons link NextCloud \u00e0 OnlyOffice afin de modifier directement les documents docx odt ou autre format.</p> <pre><code>sudo -u www-data php /var/www/nextcloud/occ app:install documentserver_community\nsudo -u www-data php /var/www/nextcloud/occ app:install onlyoffice\n</code></pre> <p>Hopla, 2 petites commandes pour avoir un super nextoffice sur son serveur</p>"},{"location":"linux/selfhost/nextcloud/#upload-de-gros-fichiers","title":"Upload de gros fichiers","text":"<p>Par d\u00e9faut, vous ne pourrez pas upload de gros fichiers. Pour cela, il faut modifier des options dans votre pool FPM ainsi que dans NGINX.</p> <p>Pour les options de votre pool FPM, ajoutez ceci :</p> <pre><code>php_value upload_max_filesize 16G\nphp_value post_max_size 16G\n</code></pre> <p>C\u00f4t\u00e9 NGINX, dans votre nginx.conf :</p> <pre><code>client_max_body_size 17G;\n</code></pre> <p>Vous pouvez d\u00e9sormais upload des fichiers jusqu'\u00e0 16G</p>"},{"location":"linux/selfhost/selfoss/","title":"Selfoss, son Reader RSS self-hosted","text":""},{"location":"linux/selfhost/selfoss/#introduction","title":"Introduction","text":"<p>Tout d'abord, un RSS est un fichier texte qui est automatiquement mis \u00e0 jour via l'ajout de contenu. La technologie semble aujourd'hui d\u00e9su\u00e8te, mais pourtant, je l'utilise encore comme beaucoup d'autres, car elle me permet de ne rien louper de l'actualit\u00e9 de mes sites pr\u00e9f\u00e9r\u00e9s.</p> <p>Cependant, pour en profiter tellement, il faut ce que l'on appelle un '\"Reader RSS'\", sans quoi, un flux RSS est totalement inexploitable.</p> <p>Il en existe aujourd'hui une multitude, que ce soit Online (Feedly, Google Reader), self-hosted (FreshRSS, SelfOss), ou bien m\u00eame en local sur son PC (Reeder sur Mac), chacun trouvera chaussure \u00e0 son pied.</p> <p>Pour moi, il s'agit de SelfOss. Ce petit reader RSS disponible sur Github \u00e0 pour m\u00e9rite d'\u00eatre libre, facilement configurable, compatible PHP7...</p> <p>Non seulement il vous permettra d'exploiter au mieux les RSS via un syst\u00e8me de tags... mais vous pourrez \u00e9galement importer d'autres flux tels que Twitter, deviantArt, Tumblr...</p> <p>Voici donc comment l'installer</p>"},{"location":"linux/selfhost/selfoss/#installation","title":"Installation","text":"<p>Pour faire fonctionner votre selfoss, il vous faudra tout d'abord une stack LAMP ou autre correctement configur\u00e9 (Voir ici pour plus d'informations.</p> <p>Une fois ceci fait, nous devons cloner notre repository GitHub</p> <pre><code>cd /var/www\ngit clone https://github.com/SSilence/selfoss rss\n</code></pre> <p>Puis l'on cr\u00e9\u00e9 le server-block sur nginx</p> <pre><code>server {\n    server_name rss.domain.tld;\n    listen 80;\n    listen [::]:80;\n    return 301 https://$host$request_uri;\n\n    location /.well-known/acme-challenge/ {\n        alias /var/www/challenges/;\n        try_files $uri =404;\n    }\n\n}\n\nupstream backend {\n    server unix:/run/php/php7.0-fpm.sock;\n}\n\nserver {\n    server_name rss.domain.tld;\n\n    listen 443 ssl http2;\n    listen [::]:443 ssl http2;\n\n    include /etc/nginx/conf.d/static/ssl.conf;\n    root /var/www/rss/;\n\n    access_log /var/log/nginx/rss.access.log;\n    error_log /var/log/nginx/rss.error.log;\n\n    location ~* ' (gif|jpg|png) {\n        expires 30d;\n    }\n    location ~ ^/favicons/.*$ {\n        try_files $uri /data/$uri;\n    }\n    location ~ ^/thumbnails/.*$ {\n        try_files $uri /data/$uri;\n    }\n    location ~* ^/(data'/logs|data'/sqlite|config'.ini|'.ht) {\n        deny all;\n    }\n    location / {\n        index index.php index.html index.htm;\n        try_files $uri /public/$uri /index.php$is_args$args;\n    }\n\n    #include /etc/nginx/conf.d/file_protect;\n    include /etc/nginx/conf.d/cache;\n\n    location ~ '.php$ {\n        fastcgi_pass backend;\n        fastcgi_index index.php;\n        fastcgi_param SCRIPT_FILENAME $document_root/$fastcgi_script_name;\n        include fastcgi_params;\n    }\n}\n</code></pre> <p>Une fois ceci fait, nous n'oublions pas d'appliquer les bons droits \u00e0 selfoss, ainsi que de red\u00e9marrer nginx</p> <pre><code>chown -R www-data:www-data rss\nsystemctl restart nginx\n</code></pre> <p>Vous avez d\u00e9sormais un selfoss install\u00e9, mais sans rien de configur\u00e9, nous allons maintenant voir comment le configurer</p>"},{"location":"linux/selfhost/selfoss/#configuration-de-selfoss","title":"Configuration de SelfOss","text":"<p>Toute la configuration de SelfOss se fait dans le fichier config.ini</p> <p>Par d\u00e9faut, SelfOss est livr\u00e9 avec le fichier defaults.ini, nous allons le copier afin de ne pas l'alt\u00e9rer</p> <pre><code>cp defaults.ini config.ini\n</code></pre> <p>Nous allons voir ici seulement les param\u00e8tres que je juge utile, pour plus d'informations, aller sur la page officielle de SelfOSS</p> <ul> <li>db_type</li> <li>db_host</li> <li>db_database</li> <li>db_username</li> <li>db_password</li> </ul> <p>Comme leur nom l'indique, tous ces champs concernent la base de donn\u00e9e. Par d\u00e9faut, une base de donn\u00e9e SQLite est utilis\u00e9e, mais je pr\u00e9f\u00e8re utilis\u00e9e une base de donn\u00e9 MySQL.</p> <p>Il existe d'autre champs pour la base de donn\u00e9e, mais g\u00e9n\u00e9ralement, il n'est pas utile de les modifier.</p> <ul> <li>username</li> <li>password</li> <li>salt</li> </ul> <p>Ces 3 champs servent \u00e0 configurer la s\u00e9curit\u00e9 sur SelfOss. Je vous conseille de modifier la valeur du champ salt afin d'avoir un salt unique.</p> <p>Pour g\u00e9n\u00e9rer un password, il faut se rendre sur la page /password de votre SelfOss obligatoirement</p> <ul> <li>items_perpage</li> </ul> <p>Nombre d'\u00e9l\u00e9ment automatiquement affich\u00e9s. Par d\u00e9faut de 50, je conseille de le passer \u00e0 100 minimum</p> <ul> <li>auto_mark_as_read</li> </ul> <p>Option tr\u00e8s int\u00e9r\u00e9ssante qui vous permet de mettre automatiquement un article comme '\"Lu'\" une fois que vous l'avez ouvert (D\u00e9sactiv\u00e9 par d\u00e9faut)</p> <ul> <li>load_images_on_mobile</li> </ul> <p>Permet d'activer le LazyLoad des images sur mobile</p> <ul> <li>base_url</li> </ul> <p>Option tr\u00e8s utile qui force g\u00e9n\u00e9ralement le chargement des CSS &amp; co depuis votre sous-domaine.</p>"},{"location":"linux/selfhost/sonerezh/","title":"Sonerezh","text":""},{"location":"linux/selfhost/sonerezh/#introduction","title":"Introduction","text":"<p>Sonerezh est une application web d\u00e9velopp\u00e9e par Guillaume Leduc (Son blog) et son ami Itomiix (Son twitter.</p> <p>Tout comme les c\u00e9l\u00e9brissimes Deezer ou Spotify, nous pourrons \u00e9couter de la musique en streaming, faire nos propres playlist... Mais pour cela, nous devrons auparavant t\u00e9l\u00e9charger nos musiques sur nos serveurs.</p> <p>Il s'agit d'un projet que je suis d'avant sa cr\u00e9ation via le blog de Guillaume Leduc. Je l'ai toujours suivi avec attention, car il me semblait excellent.</p> <p>Le fait est qu'aujourd'hui, le projet a presque 450 stars sur Github, et a d\u00e9pass\u00e9 de loin les attentes des d\u00e9veloppeurs</p>"},{"location":"linux/selfhost/sonerezh/#pre-requis","title":"Pr\u00e9-requis","text":"<p>Pour installer Sonerezh, il nous faut bien \u00e9videmment un environnement LAMP ou \u00e9quivalent. Je vous invite \u00e0 aller voir la page sur le wiki que j'ai fais \u00e0 cet effet.</p> <p>Nous aurons \u00e9galement besoin du package libav-tools pour convertir les FLAC en MP3</p> <p>Depuis la version beta 1.1.0 de Sonerezh, celui-ci est compatible avec PHP7 (Passage \u00e0 CakePHP 2.8)</p>"},{"location":"linux/selfhost/sonerezh/#installation","title":"Installation","text":"<p>Avant toute chose, nous devrons pr\u00e9parer la BDD \u00e0 recevoir notre Sonerezh :</p> <pre><code>mysql&gt; CREATE DATABASE sonerezh;\nmysql&gt; GRANT ALL PRIVILEGES ON sonerezh.* TO sonerezh@localhost IDENTIFIED BY password;\nmysql&gt; FLUSH PRIVILEGES;\nmysql&gt; exit;\n</code></pre> <p>N'oubliez pas de remplacer password par son mot de passe</p> <p>Une fois cela fait, nous pourrons cloner le repo de Sonerezh sur notre serveur web :</p> <pre><code>cd /var/www\nsudo git clone https://github.com/Sonerezh/sonerezh.git music\n</code></pre> <p>Et nous n'oublions pas de lui appliquer les droits et propri\u00e9taires appropri\u00e9s</p> <pre><code>sudo chown -R www-data: music/ &amp;&amp; sudo chmod -R 775 music/\n</code></pre> <p>Une fois cela, nous passons au server-block de notre nginx</p> <pre><code>server {\n    listen 80;\n    listen [::]:80;\n    return 301 https://$host$request_uri;\n    server_name music.ndd.tld;\n}\nserver {\n    listen 443 ssl http2;\n    listen [::]:443 ssl http2;\n    server_name music.ndd.tld;\n    root /var/www/music/app/webroot;\n\n    access_log /var/log/nginx/music.access.log;\n    error_log /var/log/nginx/music.error.log;\n\n    location / {\n        try_files $uri $uri/ /index.php?$args;\n        expires 14d;\n        add_header Cache-Control public;\n    }\n\n    # Serve static images from resized folder\n    location ~* '/([^'/]+_[0-9]+x[0-9]+'.[a-z]+) {\n        try_files /img/resized/$1 /index.php?$args;\n        expires 14d;\n        add_header Cache-Control public;\n    }\n\n    include /etc/nginx/conf.d/file_protect;\n    include /etc/nginx/conf.d/cache;\n    include /etc/nginx/conf.d/php;\n}\n</code></pre>"},{"location":"linux/selfhost/subsonic/","title":"Bypass donation subsonic","text":"<p>http://cheapseedboxes.com/bypass-donation-subsonic-streaming-app/</p>"},{"location":"linux/selfhost/youtubedl/","title":"Sauvegarder ses vid\u00e9os avec YoutubeDL et sa GUI","text":"<p>youtube-dl est un outil formidable permettant de t\u00e9l\u00e9charger ses vid\u00e9os en ligne de commande \u00e0 partir d'une foule de providers (Youtube, Arte, SoundCloud...). (Liste compl\u00e8te).</p> <p>Dans cet article, nous allons voir comment t\u00e9l\u00e9charger les vid\u00e9os \u00e0 d'une interface Web (Youtube-DL-WebUI, (fork de PixiBixi))</p> <p>Cette interface \u00e9crite en PHP permet de t\u00e9l\u00e9charger des vid\u00e9os, musiques... Le fork de PixiBixi permet \u00e9galement de les \u00e9couter en ligne.</p> <p>Pour installer cette WebUI, 2 mani\u00e8res sont disponibles. La mani\u00e8re traditionnelle avec un nginx install\u00e9 physiquement sur la machine. (Nous devrons avoir suivi le tutoriel Installer son Serveur Web : nGinx, PHP-FPM et MariaDB), ou alors via Docker. Nous allons voir les 2 mani\u00e8res</p>"},{"location":"linux/selfhost/youtubedl/#docker","title":"Docker","text":"<p>Pour Docker, PixiBixi a \u00e9galement fait un excellent Dockerfile disponible ici</p>"},{"location":"linux/selfhost/youtubedl/#physique","title":"Physique","text":"<p>Etant donn\u00e9 que l'on a d\u00e9j\u00e0 suivi le tutoriel de configuration de nginx, la seule op\u00e9ration \u00e0 faire est le d\u00e9ploiement du sites-enabled (+ Installation et configuration du youtube-dl-webui \u00e9videmment).</p> <p>On commence par clone le repository :</p> <pre><code>cd /var/www\ngit clone https://github.com/PixiBixi/Youtube-dl-WebUI youtube\n</code></pre> <p>Et on lui applique les bons droits</p> <pre><code>chown -R www-data:www-data youtube\n</code></pre> <p>(Le mot de passe par d\u00e9faut est root, pour le changer, il suffit de faire un sha256 de votre passphrase et modifier config.php)</p> <p>Et le fichier nginx pour activer le site :</p> <pre><code>server {\n    listen 80;\n    listen [::]:80;\n\n    server_name youtube.x.eu;\n\n    return 301 https://$host$request_uri;\n}\n\nserver {\n    listen 443 ssl http2;\n    listen [::]:443 ssl http2;\n    server_name youtube.x.eu;\n\n    error_log /var/log/nginx/youtube.error.log;\n    access_log /var/log/nginx/youtube.access.log;\n\n    ssl_certificate /etc/letsencrypt/live/youtube.x.eu/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/youtube.x.eu/privkey.pem;\n\n    include /etc/nginx/conf.d/ssl.conf;\n    include /etc/nginx/conf.d/letsencrypt.conf;\n    include /etc/nginx/conf.d/cache.conf;\n    include /etc/nginx/conf.d/php.conf;\n\n    root /var/www/youtube/;\n\n    autoindex on;\n    index index.php;\n}\n</code></pre>"},{"location":"linux/selfhost/torrent/mktorrent/","title":"mktorrent","text":"<p>mktorrent est un puissant logiciel de cr\u00e9ation de torrent en ligne de commande. M\u00eame si la ligne de commande peut vous faire peur, son utilisation est simplissime.</p> <p>Cependant, pour pouvoir s'en servir, nous devons le compiler avec les bonnes options.</p> <p>Avant de compiler, nous devons \u00eatre s\u00fbr que nous avons bien toutes les d\u00e9pendances :</p> <pre><code>apt build-dep mktorrent &amp;&amp; apt install git\n</code></pre> <p>Nous t\u00e9l\u00e9chargons les sources de mktorrent</p> <pre><code>git clone https://github.com/Rudde/mktorrent &amp;&amp; cd mktorrent\n</code></pre> <p>Et on edit les variables qui vont bien :</p> <pre><code>sed -i -e \"s/#USE_PTHREADS/USE_PTHREADS/g;\" '\n       -e \"s/#USE_OPENSSL/USE_OPENSSL/g;\" '\n       -e \"s/#USE_LONG_OPTIONS/USE_LONG_OPTIONS/g;\" '\n       -e \"s/#NO_HASH_CHECK/NO_HASH_CHECK/g;\" '\n       -e \"s/#USE_LARGE_FILES/USE_LARGE_FILES/g;\" Makefile\n</code></pre> <p>Et enfin on compile :</p> <pre><code>make &amp;&amp; make install\n</code></pre>"},{"location":"linux/selfhost/torrent/mktorrent/#utilisation","title":"Utilisation","text":"<p>Une fois mktorrent install\u00e9, nous devons maintenant s'approprier le logiciel. Heureusement pour nous, mktorrent est plut\u00f4t simple d'utilisation:</p> <ul> <li><code>-a</code> : Announce pour le torrent</li> <li><code>-t</code> : Nombre de threads \u00e0 utiliser pour la cr\u00e9ation du torrent</li> <li><code>-p</code> : Set le flag private du torrent</li> <li><code>-l</code> : Taille des pi\u00e8ces (En puissance de 2, par exemple, si l'on tape 18, on aura 2'^18 = 256Kb)</li> </ul> <p>Concr\u00e8tement, pour la taille de pi\u00e8ce, voici ce qu'il faut faire :</p> <p>Taille de pi\u00e8ce   Taille des fichiers   Repr\u00e9sentation dans mktorrent</p> <p>256Kb             Jusqu'\u00e0 256Mb        18   512Kb             Jusqu'\u00e0 1GB          19   1024Kb            Jusqu'\u00e0 2GB          20   2048Kb            Jusqu'\u00e0 4GB          21   4096Kb            Jusqu'\u00e0 8GB          22   8192Kb            Jusqu'\u00e0 16GB         22   16384Kb           Plus de 16G          23</p> <p>Plus l'on met une taille de pi\u00e8ce importante, plus le torrent sera de petite taille, mais il faut faire attention \u00e0 ne pas mettre une taille de pi\u00e8ce trop grosse pour un torrent trop petit</p>"},{"location":"linux/selfhost/torrent/rutorrent/","title":"ruTorrent, WebUI rTorrent","text":""},{"location":"linux/selfhost/torrent/rutorrent/#version-docker","title":"Version Docker","text":"<pre><code>  USER_rutorrent:\n    restart: always\n    image: xataz/rtorrent-rutorrent:latest-filebot\n    container_name: USER_rutorrent\n    volumes:\n      - /home/USER/incoming:/data:rw\n      - /root/.apps/USER/rtorrent/conf:/config:rw\n    ports:\n      - \"4500$UID:4500$UID\"\n      - \"4500$UID:4500$UID/udp\"\n    environment:\n      - UID=100$UID\n      - GID=100$UID\n      - PORT_RTORRENT=4500$UID\n      - WEBROOT=/\n      - VIRTUAL_PORT=8080\n      - VIRTUAL_HOST=rutorrent.USER.domain.tld\n      - LETSENCRYPT_HOST=rutorrent.USER.domain.tld\n      - LETSENCRYPT_EMAIL=admin@domain.tld\n    tty: true\n\n  USER_organizr:\n    restart: always\n    image: lsiocommunity/organizr\n    container_name: USER_organizr\n    volumes:\n      - /root/.apps/USER/organizr:/config\n    environment:\n      - VIRTUAL_HOST=USER.domain.tld\n      - VIRTUAL_PORT=80\n      - LETSENCRYPT_HOST=USER.domain.tld\n      - LETSENCRYPT_EMAIL=admin@domain.tld\n</code></pre> <ul> <li>Modifier <code>USER</code> par le nom de l'user, <code>$UID</code> par le dernier     chiffre de son UID et <code>domain.tld</code> par le domaine</li> </ul>"},{"location":"mac/brew/","title":"Brew, le package manager de MacOS","text":""},{"location":"mac/brew/#presentation","title":"Pr\u00e9sentation","text":"<p>Mac OS est un OS absolument g\u00e9nial, il est d'une simplicit\u00e9 incroyable, et nous facilite la vie avec une gestuelle de trackpad fantastique. La seule critique que nous pouvons lui reprocher est qu'il lui manque un gestionnaire de paquet en ligne de commande.</p> <p>Pas de panique, c'est pour cela que Homebrew a \u00e9t\u00e9 d\u00e9velopp\u00e9.</p> <p>Homebrew (aka brew) fonctionne comme APK pour Alpine, ou bien encore apt-get pour les distributions Debian Based.</p> <p>Il est possible d'ajouter une tonne de paquets indispensable, mais pourtant manquant par d\u00e9faut sous Mac.</p>"},{"location":"mac/brew/#installation","title":"Installation","text":"<p>De base, Homebrew n\u00e9c\u00e9ssite les outils de d\u00e9veloppement CLI de XCode, il existe une parade afin d'installer uniquement les outils CLI de XCode, et non XCode (Qui p\u00e8se pr\u00eat de 11GB, ce qui est consid\u00e9rable pour un SSD de 128/256GB)</p> <p>Tout d'abord, nous devons installer les outils CLI de XCode</p> <pre><code>xcode-select --install\n</code></pre> <p>Puis on installe Homebrew</p> <pre><code>ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\"\n</code></pre>"},{"location":"mac/brew/#commandes-de-base-homebrew","title":"Commandes de base Homebrew","text":"<p>Comme tout gestionnaire de paquet, Homebrew dispose de commandes relativement basiques</p> <ul> <li>brew update : Met \u00e0 jour les formules de brew et brew</li> <li>brew upgrade : Met \u00e0 jour les paquets install\u00e9s via brew</li> <li>brew search : Cherche les paquets correspondant \u00e0 la chaine de     caract\u00e8re (accepte les expression r\u00e9guli\u00e8res)</li> <li>brew install : Permet d'installer un packages</li> <li>brew uninstall : D\u00e9sinstalle un paquet</li> <li>brew list : Liste les packages install\u00e9s via brew</li> </ul> <p>Pour plus d'informations concernant les commandes, je vous conseille Oh My ZSH avec le plugin brew d'activ\u00e9</p>"},{"location":"mac/brew/#caskroom","title":"Caskroom","text":"<p>Caskroom est un compl\u00e9ment \u00e0 Homebrew, Homebrew dispo d'\u00e9norm\u00e9ment de packages issus de la communaut\u00e9 UNIX (Liste compl\u00e8te disponible ici), il lui manque \u00e9norm\u00e9ment de '\"vrais'\" applications (Chrome, VLC...)</p> <p>C'est l\u00e0 que Caskroom intervient, celui-ci comble le manque en application que Homebrew a. Vous pouvez regarder tous les packages disponibles via Cask ici</p> <p>Concernant les commandes, celle-ci sont les m\u00eames que pour homebrew, mais en y ajoutant cask devant</p> <p>Par exemple, brew search vlc deviendra brew cask search vlc</p>"},{"location":"mac/brew/#meilleurs-packages","title":"Meilleurs Packages","text":"<p>Tous mes packages que j'utilise sont d\u00e9sormais dans mon Brewfile.</p>"},{"location":"mac/brew/#divers","title":"Divers","text":""},{"location":"mac/brew/#bundle","title":"Bundle","text":"<p>Sous Brew, il existe une sous-commande absolument magique qui s'appelle <code>bundle</code>.</p> <p>Brew nous permet de g\u00e9n\u00e9rer dans un fichier l'ensemble des packages, tap &amp; autres que nous avons. Pour ma part, ils sont disponibles ici.</p> <p>Voici les principales commandes \u00e0 connaitre !</p> <ul> <li><code>brew bundle dump</code> : Permet de g\u00e9n\u00e9rer le fichier Brewfile</li> <li><code>--file=my_brewfile</code> : Pour sp\u00e9cifier un nom diff\u00e9rent</li> <li><code>brew bundle install</code> : Permet d'installer tout ce qui est dans le fichier ~/Brewfile</li> <li><code>--file=my_brewfile</code> : Permet de sp\u00e9cifier un nom diff\u00e9rent</li> </ul>"},{"location":"mac/brew/#cask-upgrade","title":"cask-upgrade","text":"<p>brew cu permet de mettre \u00e0 jour facilement toutes ses applications install\u00e9es avec brew. Je vous invite \u00e0 aller consulter le README de cask-upgrade, qui est bougrement bien fait</p>"},{"location":"mac/brew_xcode/","title":"Brew : L'installer sans XCode","text":"<p>Normalement, pour installer brew, nous devons passer par XCode.</p> <p>XCode est un programme lourd permettant de coder (+/- comme Eclipse), nous n'en n'avons aucune utilit\u00e9, et il est fr\u00e9quent que celui-ci prenne plus de 10GB sur le MAC (Ce qui est \u00e9norme sur 250GB), il existe donc un trick pour n'installer que les ressources utiles \u00e0 brew.</p> <pre><code>xcode-select --install\n</code></pre> <p>Quand cette \u00e9tape sera finit, nous pourrons installer brew sans probl\u00e8me</p>"},{"location":"mac/mind-view/","title":"MindView","text":"<p>Un petit m\u00e9mo pour me rappeler que l'on peut utiliser MindView sur MAC.</p> <p>Il faut pour cela DL le keygen -CORE (MatchWare.MindView.Business.v6.0.2572.French.Incl.Keymaker-CORE) et la version d\u00e9mo sur le site officiel</p> <p>Ne pas oublier de suivre les steps du NFO de la release -CORE</p>"},{"location":"mac/iterm/troubleshooting/alt_arrow/","title":"Remap le Alt+Arrow de iTerm","text":"<p>Par d\u00e9faut, Alt+Arrow est map bizarrement et bug sur zsh, voici comment le remap (Merci superuser.com)</p> <ul> <li>Go to Preferences -&gt; Profile -&gt; Keys</li> <li>Under the list of Key Mappings there is a box to add/remove or load Presets (combo box)</li> <li>Select the Natural Text Editing option in the Presets drop down.</li> </ul>"},{"location":"mac/iterm/troubleshooting/first_chat/","title":"Enlever le premier caract\u00e8re bizarre de iTerm","text":"<p>Comme une image vaut 1000 mots :</p> <p></p> <p>Nous voyons ici que nous avons un premier caract\u00e8re bleu ciel ind\u00e9sirable.</p> <p>Pour l'enlever, il faut d\u00e9cocher Show Mark Indicators dans Profile '&gt; Terminal '&gt; Shell Integration (Tout en bas)</p> <p>Grace \u00e0 cette minuscule option, nous retrouvons un shell sympathique \u00e0 utiliser</p> <p></p>"},{"location":"mess/github_template/","title":"G\u00e9n\u00e9rer un template pour ses Pull Request et ses Issues","text":"<p>Si vous avez un repository \u00e0 fort influence, vous avez comme il est g\u00eanant de n'avoir qu'une partie des informations lors d'un issue, ou alors un Pull Request qui ne d\u00e9taille pas ses modifications.</p> <p>Heureusement, GitHub a pens\u00e9 \u00e0 nous, et il est possible de cr\u00e9er des templates afin d'avoir une structure.</p> <p>Voici un exemple de Pull Request et d'Issue pour le repo aframe :</p> <p></p> <p>Pour se faire, c'est tr\u00e8s simple</p>"},{"location":"mess/github_template/#creer-ses-templates","title":"Cr\u00e9er ses templates","text":"<p>\u00c0 la racine de votre projet, il vous faut cr\u00e9er un dossier .github</p> <p>Dans celui-ci, il faudra faire 2 fichiers :</p> <ul> <li><code>ISSUE_TEMPLATE.md</code> : Pour vos issues</li> <li><code>PULL_REQUEST_TEMPLATE.md</code> : Pour vos pull request</li> </ul> <p>Et voici des exemples de templates :</p> <pre><code>**Description:**\n\n- A-Frame Version:\n- Platform / Device:\n- Reproducible Code Snippet or URL:\n\n&lt;!-- If you have a support question, please ask at https://stackoverflow.com/questions/ask/?tags=aframe rather than filing an issue. --&gt;\n</code></pre> <pre><code>**Description:**\n\n**Changes proposed:**\n-\n-\n-\n</code></pre>"},{"location":"mess/linux_performances/","title":"Monitoring des performances sous Linux","text":"<p>Petite image sympa qui r\u00e9sume tous les logiciels utiles afin d'analyser le comportement de Linux</p> <p></p>"},{"location":"mess/optimization/","title":"Optimisations","text":"<p>Liens d'optimisations vers pas mal de logiciels</p>"},{"location":"mess/optimization/#nginx","title":"NGINX","text":"<p>Optimiser les performances de NGINX (Buzut)' How to Configure nginx for Optimized Performance (Linode)' Un tutoriel de la mise en cache' Servers for Hackers : Nginx Caching</p>"},{"location":"mess/optimization/#optimisation-html","title":"Optimisation HTML","text":"<p>https://medium.com/reloading/preload-prefetch-and-priorities-in-chrome-776165961bbf</p>"},{"location":"mess/optimization/#security-hardening","title":"Security Hardening","text":"<p>System Hardening Guide</p>"},{"location":"mess/optimization/#optimisation-sql","title":"Optimisation SQL","text":"<p>Optimiser les performances de MySQL</p>"},{"location":"mess/optimization/#linux","title":"Linux","text":"<p>Forcer le mode '\"Performance'\" sur Linux</p>"},{"location":"mess/scripts_useful/","title":"Scripts utiles","text":""},{"location":"mess/scripts_useful/#windows","title":"Windows","text":"<p>Clean W10 : Virer toutes les conneries install\u00e9es par Win 10</p>"},{"location":"mess/scripts_useful/#linux","title":"Linux","text":"<p>piVPN : Installation d'un VPN via Script</p>"},{"location":"mess/scripts_useful/#mac","title":"Mac","text":"<p>CastNow : Stream MP4 directement vers le ChromeCast</p>"},{"location":"mess/useful_links/","title":"Bordel de lien","text":"<p>Beaucoup de liens avec des informations importantes mais qui n'ont pas une place particuli\u00e8re dans le wiki</p>"},{"location":"mess/useful_links/#tls","title":"TLS","text":"<p>CRT : Liste tous les certificats g\u00e9n\u00e9r\u00e9s</p> <p>Docker Lets Encrypt : Docker &amp; Let's Encrypt</p> <p>Rate Limits Let's Encrypt</p> <p>Wiki Mozilla TLS : Informations de configuration TLS</p> <p>PKGs : Regarder les packages dispo dans les d\u00e9po de toutes les distributions Linux</p> <p>OpenNic permet de recenser les DNS opens les plus proches de chez nous</p> <p>HTOP Expliqu\u00e9 Explication visuelle d'HTOP</p> <p>Bash FAQ Explication du bash de A \u00e0 Z</p> <p>Pi-Hole r\u00e9solver DNS avec GUI</p> <p>PreHook Git : Utiliser Git dans son Workflow</p> <p>SELinux : Int\u00e9grer SELinux correctement</p> <p>2FA Liste tous les websites compatibles 2FA</p> <p>Deezloader : Permet de DL les musiques de Deezer en MP3 320</p> <p>Spotizr : Convertisseur playlist Spotify to Deezer</p> <p>Gixy : Permet de tester sa configuration nginx</p> <p>mtr : Permet de faire des mtr \u00e0 travers le monde</p> <p>Talos Intelligence : Blacklist IP</p> <p>Test XMLRPC : Tester les calls RPC (Utile pour ruTorrent par exemple)</p> <p>Tableau p\u00e9riodique des DevOps</p>"},{"location":"mess/useful_links/#docker","title":"Docker","text":"<p>Docker Windows : Installer Docker sur Windows</p> <p>Clean Docker : Clean son r\u00e9pertoire Docker</p> <p>SpotMyBackup : Backup/Restore de playlist spotify</p> <p>DevHints : Une tonne de cheatsheet depuis 1 seul lien</p>"},{"location":"mess/useful_links/#for-lulz","title":"For Lulz","text":"<p>kur0sec : Hack d'imprimante</p> <p>Cleiton Bueno : Hack de Cam\u00e9ras IP</p> <p>CsrGxtu : RSTP Cam\u00e9ras IP</p> <p>IT-Connect : Forcer le changement de password sous Linux</p> <p>Composieux : Configurer Lets Encrypt pour un autorenew</p> <p>Gitleaks : R\u00e9pertorie les leaks de comptes</p> <p>AppCanary : Am\u00e9liorer la s\u00e9curit\u00e9 de son site via de simples headers</p> <p>Security Headers : Comme son nom l'indique, permet de tester ses headers</p> <p>GNS3 Vault : Labs pr\u00e9d\u00e9finit pour GNS</p> <p>RewopIt : Sauvegarde de son serveur web</p> <p>DigitalOcean : Cr\u00e9er un cluster de Docker (swarm)</p> <p>Github : Workflow GitHub int\u00e9r\u00e9ssant en entreprise</p> <p>ShevaRezo : Lister les ports par d\u00e9fauts des protocoles connus (whatportis)</p> <p>Certs Simple : Configuration brotli</p> <p>OpenSSH Wiki Mozilla : Informations de configuration OpenSSH du Wiki Mozilla</p> <p>Gist : iTerm2 + ZSH Configuration</p> <p>SonarQube : Int\u00e9gration continue pour pas mal de language</p> <p>Royal TS(X) : Client SSH puissant multi-protocole</p> <p>Phishing with Unicode Domains : Unicode Phishing</p> <p>CSP Cheat Sheet</p> <p>VerbalExpressions : Rendre les regex plus facile dans diff\u00e9rents langages</p> <p>Hackintosh : Installer son hackintosh</p> <p>Astral (Github) : G\u00e9rer ses favoris GitHub</p> <p>NDM : G\u00e9rez vos paquets NPM avec NPM Desktop Manager</p> <p>'###</p> <p>Antennes</p> <p>CartoRadio</p> <p>Carte FH Lafibre '###</p> <p>Magic Animations CSS</p> <p>Syntax list</p>"},{"location":"mess/useful_links/#windows","title":"Windows","text":"<p>GPO Search</p>"},{"location":"mess/useful_links/#virtualisation","title":"Virtualisation","text":"<p>ESXi Customizer</p> <p>ISOs Microsoft</p> <p>JQ Play : S'entrainer avec l'utilitaire jq (Decode json en bash)</p>"},{"location":"mess/download/netflix_subs/","title":"T\u00e9l\u00e9charger les sous-titres Netflix simplement","text":"<p>Pour t\u00e9l\u00e9charger des sous-titres Netflix, rien de plus simple.</p> <p>Ouvrir le d\u00e9buggeur Chrome, entrer en filtre &amp;v=3 et ouvrez votre vid\u00e9o, il s'agira normalement des premiers flux qui seront charg\u00e9s</p>"},{"location":"mess/fibre_optique/info_transceiver/","title":"Informations utile sur les d\u00e9nominations fibre optique","text":""},{"location":"mess/fibre_optique/info_transceiver/#longeur-donde","title":"Longeur d'onde","text":"<ul> <li>1310/1550nm : Monomode</li> <li>850nm : Multimode</li> </ul>"},{"location":"mess/fibre_optique/info_transceiver/#connecteur","title":"Connecteur","text":"<ul> <li>LC : Connecteur le plus '\"basique'\"</li> <li>DAC : Direct Attach Cables : G\u00e9n\u00e9ralement pour stacker les switchs</li> </ul>"},{"location":"mess/fibre_optique/info_transceiver/#denominations","title":"D\u00e9nominations","text":"<ul> <li>SR = Single Range = Monomode</li> <li>SM = Monomode</li> <li>MMC = Multimode</li> </ul>"},{"location":"mess/fibre_optique/info_transceiver/#recapitulatif","title":"R\u00e9capitulatif","text":""},{"location":"mess/fibre_optique/info_transceiver/#sfp","title":"SFP","text":"Connecteur Nom Longeur SFP SX 550m SFP LX 10km SFP EX 40km SFP ZX 80km SFP EZX 120km"},{"location":"mess/fibre_optique/info_transceiver/#sfp_1","title":"SFP+","text":"Connecteur Nom Longeur SFP+ SR 550m SFP+ LRM 0.22km SFP+ LR 10km SFP+ ER 40km SFP+ ZR 80km <p>Le X signifie SFP et le R signifie SFP+</p> <p>Enormement d'informations sont disponibles dans le wiki fibre</p>"},{"location":"misc/sources/","title":"Mes sources","text":"<p>Evidemment, je me base sur beaucoup de sites internet ou autre pour faire mes posts. Voici la plupart de mes sources :</p> <ul> <li>101tech</li> <li>4 SysOps</li> <li>Buzut</li> <li>Calomel</li> <li>Cisco Made Simple</li> <li>CristopheGX</li> <li>David Walsh</li> <li>Debian Handbook</li> <li>Doc NGINX</li> <li>Doc YCharbi</li> <li>Docs Mirantis</li> <li>Documentation Docker</li> <li>Forum La Fibre</li> <li>Galera Website</li> <li>Goffinet</li> <li>Hacktricks Book</li> <li>Infosec Mozilla</li> <li>KB VMWare</li> <li>Lea Linux</li> <li>LinuxDev DK</li> <li>Man Linux</li> <li>MonDedie</li> <li>Petri</li> <li>RichardJGreen</li> <li>ShellHacks</li> <li>ShevaRezo</li> <li>SleepLessBeastie</li> <li>Stackoverflow</li> <li>Techan</li> <li> <p>netzspezialist</p> </li> <li> <p>Wiki Debian-FR.xyz</p> </li> <li>Wiki Debian Facile</li> <li>Wiki ArchLinux</li> <li>Wiki Linux-France</li> <li>Wiki Linux Foundation</li> <li>Wiki Mirtouf</li> <li>Wiki Deimos</li> <li>Wiki Sebsauvage</li> <li> <p>Wikibooks</p> </li> <li> <p>Stephane Robert</p> </li> <li>Xavki</li> </ul>"},{"location":"networking/list_prefix_asn/","title":"Lister les pr\u00e9fixes annonc\u00e9s par un AS","text":"<p>Il peut \u00eatre utile pour scripter ou autre de lister tous les pr\u00e9fixes annonc\u00e9s par un ASN</p> <pre><code>AS=3215\nwhois -h asn.shadowserver.org \"prefix $AS\"\n</code></pre> <p>Nous retournera tous les pr\u00e9fixes annonc\u00e9s par 3215 (Orange)</p>"},{"location":"networking/proof_files/","title":"Tester la bande passante effective de son serveur avec des proofs files","text":""},{"location":"networking/proof_files/#preambule","title":"Pr\u00e9ambule","text":"<p>Ce wiki va nous aider \u00e0 d\u00e9terminer la bande passante r\u00e9elle de son serveur. Evidemment, plusieurs crit\u00e8res rentrent en jeu, tel que la location physique de son serveur, sa bandwidth th\u00e9orie/garantie, son peering...</p> <p>Par exemple, si l'on a un serveur Gbps chez Online, et que l'on effectue un test sur un serveur appartenant \u00e0 Online, le test ne refl\u00e9tera pas le d\u00e9bit r\u00e9el, \u00e9tant donner qu'on dispose g\u00e9n\u00e9ralement d'une bande passante importante.</p> <p>Si le r\u00e9seau internet est surcharg\u00e9 au moment ou vous effectuez le test, il est possible que le r\u00e9sultat soit en dessous de la r\u00e9alit\u00e9.</p>"},{"location":"networking/proof_files/#quest-ce-quun-proof-file","title":"Qu'est ce qu'un proof file ?","text":"<p>Un proof file est un fichier stock\u00e9 sur un serveur disposant d'une importante bande passante (G\u00e9n\u00e9ralement du Gbps vroi 10Gbps) afin d'effectuer des tests de vitesse avec diff\u00e9rents h\u00e9bergeur. Il existe des fichier de diff\u00e9rente taille selon les diff\u00e9rents h\u00e9bergeurs (1Go, 2.5Go...) Cela permet de refl\u00e9ter le d\u00e9bit r\u00e9el d'un r\u00e9seau avec un autre r\u00e9seau, et donc de tester son peering</p>"},{"location":"networking/proof_files/#liste-des-proofs-files-disponibles","title":"Liste des proofs files disponibles","text":"<p>Provider Lien</p> <p>I3D            Ici   Tele2          \u00ccci   Vultr          Ici   Free           Ici   Linode         Ici   Feral          Ici   Myloc          Ici   LeaseWeb       Ici   OVH            Ici   Online (AMS)   Ici   Online         Ici   Test Debit     Ici   X4B            Ici   Serverius      Ici   Hetzner        ici   Belwue         ici   LG             ici</p> <p>Durant les cours int\u00e9r\u00e9ssants, j'ai finis par d\u00e9velopper (Ou plut\u00f4t fork) un script permettant de lancer des DLs \u00e0 partir d'une multitude de location, le script est disponible sur Dropbox.</p> <p>Voici le rendu du script :</p> <p></p>"},{"location":"networking/proof_files/#iperf-kezako","title":"Iperf, kezako ?","text":"<p>iperf est un logiciel n\u00e9cessitant un serveur et un client compatible IPv4 et IPv6, se basant sur les protocoles UDP, TCP et SCTP disponible sur Windows, Linux, et m\u00eame Android et iOS.</p> <p>Il s'agit de la solution la plus pure pour tester la vitesse d'un r\u00e9seau car une multitude d'options sont disponibles : taille du paquet, connections simultan\u00e9es, port....</p> <p>Par d\u00e9faut, le port utilis\u00e9 par iPerf est le 5001, sur le protocole TCP.</p> <p>2 options sont toutefois indispensables \u00e0 l'utilisation de iperf :</p> <ul> <li><code>-s</code> pour ex\u00e9cuter iperf en mode <code>serveur</code></li> <li><code>-c</code> pour ex\u00e9cuter iperf en mode <code>client</code></li> </ul> <p>Voici l'exemple typique de la commande \u00e0 lancer c\u00f4t\u00e9 client :</p> <pre><code>iperf -c ping.online.net -i 2 -t 2 -r\n</code></pre> <p>Dans cette commande, nous pouvons voir que nous lancons iperf en mode client (-c) sur l'h\u00f4te ping.online.net, que nous faisons 2 essais (-t 2), et que nous faisons un test bi-directionnel (-r), quand au (-i 2), celui-ci signifie que nous attendons 2 secondes avant de faire le prochain test.</p> <p>Pour plus d'informations, je vous invite \u00e0 aller consulter la documentation officielle du logiciel.</p> <p>Voici le r\u00e9sultat que nous devrions obtenir :</p> <p></p> <p>Nous pouvons clairement apercevoir plusieurs parties sur le screen.</p> <p>Tout d'abord, le mode de transfert choisi (TCP), le port d'\u00e9coute du serveur (soit 5001, le port par d\u00e9faut), ainsi que la TCP Window Size (85KB)</p> <p>Suivi des informations c\u00f4t\u00e9 client, qui sont logiquement les m\u00eames que celle serveur, soit TCP, port 5001, et une Window Size +/- identique (Ici, 0.3KB de diff\u00e9rence, soit un gain n\u00e9gligable)</p> <p>Et enfin, nous observons enfin les donn\u00e9es qui nous sont utiles. Tout d'abord, sous l'identifiant '\"5'\", il s'agit des donn\u00e9es qui sont envoy\u00e9es par le serveur, et enfin, sous le champ 4, les donn\u00e9es qui sont r\u00e9ellement re\u00e7us par le serveur '\"h\u00f4te'\".</p> <p>Nous pouvons apercevoir d'une perte de 10mbps, ce qui est plut\u00f4t faible, mais qui n'est tout de m\u00eame pas insignifiant. Nous pouvons supposer (et c'est quasi une certitude) que des paquets sont perdus en route, ce qui peut montrer une qualit\u00e9 plut\u00f4t mauvaise du r\u00e9seau.</p> <p>A savoir qu'il existe une petite liste officielle de serveurs publics disponible sur le site officiel de l'\u00e9diteur du logiciel, \u00e0 laquelle je rajouterai iperf.ovh.net que je viens de d\u00e9couvrir en farfouillant sur Internet ou encore iperf.worldstream.nl.</p>"},{"location":"networking/weathermap/","title":"Les weathermaps","text":""},{"location":"networking/weathermap/#verifie-letat-du-reseau-avec-la-weathermap","title":"V\u00e9rifi\u00e9 l'\u00e9tat du r\u00e9seau avec la Weathermap","text":"<p>Cet article aura pour but d'aider a v\u00e9rifi\u00e9 l'\u00e9tat/encombrement du r\u00e9seau via les diff\u00e9rentes Weathermap disponibles</p>"},{"location":"networking/weathermap/#quest-ce-quune-weathermap","title":"Qu'est ce qu'une Weathermap ?","text":"<p>Une Weathermap (Traduction litt\u00e9rale : Carte du temps) est une carte qui permet de v\u00e9rifi\u00e9 l'\u00c9tat du r\u00e9seau d'un h\u00e9bergeur, afin de savoir si nous allons disposer de bonnes conditions de navigation. Bon nombre de Weathermap sont publics, mais il en existe quelques une publiques car les weathermap montrent le r\u00e9seau Internet d'une entreprise (Evidemment, certains \u00e9quipements peuvent \u00eatre cach\u00e9s)</p>"},{"location":"networking/weathermap/#liste-des-weathermap-disponibles","title":"Liste des Weathermap disponibles","text":"Service Lien OVH Ici France-IX Ici K-Net Ici et Ici Renater Ici IPv4, ici IPv6 et Ici Hivane Network Ici Hosteur Ici France-IX Ici"},{"location":"networking/weathermap/#connaitre-son-reseau","title":"Connaitre son r\u00e9seau","text":"<p>Pour savoir par quels routeurs passe sa connexion, il suffit de faire un traceroute avec l'outil mtr sous Linux ou bien WinMTR sous Windows. Voici des informations qui nous int\u00e9ressent :</p> <p></p> <p>Ce screen provient du logiciel WinMTR.</p> <p>On peut voir ici que nous passons par un r\u00e9seau HOPUS pour joindre le r\u00e9seau d'Online, puis que nous passons par le routeur s45-s103-1 pour acc\u00e9der \u00e0 notre serveur.</p>"},{"location":"networking/weathermap/#diagnostiquer","title":"Diagnostiquer","text":"<p>A notre niveau, nous ne pouvons pas vraiment diagnostiquer ce qui se passe chez notre ISP. Cependant, grace \u00e0 un outil appel\u00e9 Looking Glass, on peut cependant faire des diagnostics plus pouss\u00e9s.</p> <p>Liste compl\u00e8te</p> <p>Traceroute depuis diff\u00e9rents pays + RS...</p> Op\u00e9rateur(s) Lien 3T Systmes ici Adeli ici Bell MTS ici Blizzard ici Bussola ici ClearFly ici Cogent ici Colt Ici Core Backbone ici DataUtama ici Deutsche Telekom ici Feral ici HE ici HKIX ici Hafey ici Hivane ici Hopus Ici Ikoula ici IndoCyber ici IpTel ici K-Net ici LES ici Level3 Ici Lux Network ici Milkywan ici NLNOG ici NTT ici Neide Telecom ici OVH Ici OpenTransit/Orange Ici RamNode Ici Retn ici Root SA ici SFMIX ici SFR (Altice) ici Serverius ici Silicon Valley Web Hosting ici Solnet ici Sprint ici Syringa Network ici TW Telecom ici Tata Ici Telefonica ici TelekomRS ici Telia ici Trit ici Vienna IX ici WorldStream ici Zayo Ici <p>Il est \u00e9galement possible de se renseigner via les route-servers (Disponible via telnet)</p> Op\u00e9rateur(s) Lien OTI telnet route-server.opentransit.net HE telnet route-server.he.net"},{"location":"networking/cisco/cdp/","title":"Le Protocole CDP","text":""},{"location":"networking/cisco/cdp/#presentation","title":"Pr\u00e9sentation","text":"<p>Le protocole CDP (Cisco Discover Protocol) est un protocole de d\u00e9couverte de p\u00e9riph\u00e9riques r\u00e9seau qui fonctionne au L2. Comme son nom l'indique est d\u00e9velopp\u00e9 par Cisco dans le but de '\"signaler sa pr\u00e9sence'\" \u00e0 ses voisins, afin d'obtenir diff\u00e9rentes informations intrins\u00e8que \u00e0 l'\u00e9quipement tel que son nom, mod\u00e8le...</p>"},{"location":"networking/cisco/cdp/#utilite","title":"Utilit\u00e9","text":"<p>Comme nous avons pu le dire pr\u00e9c\u00e9demment, le protocole CDP permet de retrouver des propri\u00e9t\u00e9s intrins\u00e8que \u00e0 chaque \u00e9quipemment, mais nous pouvons \u00e9galement en tirer d'autres utilit\u00e9s :</p> <ul> <li>V\u00e9rifier l'\u00e9tat physique d'une connexion. Si le CDP passe,     c'est que l'interface et la couche de liaison est op\u00e9rationnelle.     L'interface concern\u00e9e sera donc en Up/Up.</li> <li>Obtenir des informations sur son voisin telle que son adresse     IP, num\u00e9ro de version...</li> <li>D\u00e9couvrir la topologie du r\u00e9seau en passant de machine \u00e0     machine...</li> </ul>"},{"location":"networking/cisco/cdp/#condition-dutilisation","title":"Condition d'utilisation","text":"<p>Comme son nom l'indique Cisco Discover Protocol est un protocole Cisco, il est donc imp\u00e9ratif que les mat\u00e9riels utilis\u00e9s soient de marque Cisco. Toutefois, \u00e9tant donner que l'iOS est bas\u00e9 sur un noyau Linux, il est possible de l'impl\u00e9menter sur des machines Linux, ce qui peut \u00eatre pratique pour un inventaire r\u00e9seau par exemple.</p> <p>A part cela, il n'y a aucun r\u00e9el pr\u00e9-requis pour utiliser le procole CDP. A noter cependant que l'interface physique doit \u00eatre up, que les deux machines doivent \u00eatre voisines.</p>"},{"location":"networking/cisco/cdp/#utilisation","title":"Utilisation","text":""},{"location":"networking/cisco/cdp/#informations-de-base","title":"Informations de base","text":"<p>show cdp</p>"},{"location":"networking/cisco/cdp/#informations-cdp-sur-les-interfaces","title":"Informations CDP sur les interfaces","text":""},{"location":"networking/cisco/cdp/#toutes-les-interfaces","title":"Toutes les interfaces","text":"<p>show cdp interface</p>"},{"location":"networking/cisco/cdp/#une-interface-precise","title":"Une interface pr\u00e9cise","text":"<p>show cdp interface ' ' show cdp interface Fa 0/0"},{"location":"networking/cisco/cdp/#informations-voisines","title":"Informations Voisines","text":""},{"location":"networking/cisco/cdp/#basique","title":"Basique","text":"<p>show cdp neighbors</p>"},{"location":"networking/cisco/cdp/#detaillee","title":"D\u00e9taill\u00e9e","text":"<p>show cdp neighbors detail</p>"},{"location":"networking/cisco/cdp/#detail-sur-une-entree-precise","title":"D\u00e9tail sur une entr\u00e9e pr\u00e9cise","text":"<p>show cdp entry '"},{"location":"networking/cisco/cdp/#effacer-la-table-cdp","title":"Effacer la table CDP","text":"<p>clear cdp table</p>"},{"location":"networking/cisco/cdp/#activer-ou-desactiver-cdp","title":"Activer ou d\u00e9sactiver CDP","text":""},{"location":"networking/cisco/cdp/#desactiver","title":"D\u00e9sactiver","text":""},{"location":"networking/cisco/cdp/#globalement","title":"Globalement","text":"<p>no cdp run</p>"},{"location":"networking/cisco/cdp/#sur-une-interface","title":"Sur une interface","text":"<p>interface Fa0/0 no cdp enable exit</p>"},{"location":"networking/cisco/cdp/#activer","title":"Activer","text":""},{"location":"networking/cisco/cdp/#globalement_1","title":"Globalement","text":"<p>cdp run</p>"},{"location":"networking/cisco/cdp/#sur-une-interface_1","title":"Sur une interface","text":"<p>interface Fa0/0 cdp enable exit</p>"},{"location":"networking/cisco/cdp/#packets-cdp","title":"Packets CDP","text":"<p>cdp holdtime ' : Dur\u00e9e de vie de l'information envoy\u00e9e (10 - 255) cdp timer ' : D\u00e9finit la p\u00e9riode \u00e0 laquelle l'\u00e9quipement doit renvoyer les informations (5-254) <p>https://www.ciscomadesimple.be/2010/03/09/cdp-cisco-discovery-protocol/</p>"},{"location":"networking/cisco/commandes_base/","title":"Commandes de base Cisco IOS","text":"<p>Voici toutes les commandes de base \u00e0 connaitre pour un \u00e9quipement Cisco compatibles switch et router.</p>"},{"location":"networking/cisco/commandes_base/#outils-de-diagnostics","title":"Outils de diagnostics","text":"<p>Effectuer un ping</p> <pre><code>Router# ping ip-address\n</code></pre> <p>Effectuer un traceroute</p> <pre><code>Router# traceroute ip-address\n</code></pre>"},{"location":"networking/cisco/commandes_base/#visualisation-de-letat-de-lequipement","title":"Visualisation de l'\u00e9tat de l'Equipement","text":"<p>Montrer la version de l'IOS</p> <pre><code>Router# show version\n</code></pre> <p>Montre le contenu de la m\u00e9moire flash</p> <pre><code>Router# show flash\n</code></pre> <p>Montre les interfaces de l'\u00e9quipement</p> <pre><code>Router# show interfaces\n</code></pre>"},{"location":"networking/cisco/commandes_base/#visualisation-et-sauvegarde-de-la-configuration","title":"Visualisation et Sauvegarde de la configuration","text":"<p>Configuration courante</p> <pre><code>Router# show running-config\n</code></pre> <p>Configuration au d\u00e9marrage</p> <pre><code>Router# show startup-config\n</code></pre> <p>Sauvegarder la configuration du routeur</p> <pre><code>Router# copy running-config startup-config\n</code></pre> <p>Sauvegarder la configuration du routeur sur un serveur TFTP</p> <pre><code>Router# copy running-config tftp:\n</code></pre> <p>Supprimer la configuration de d\u00e9marrage</p> <pre><code>Router# erase startup-config\n</code></pre>"},{"location":"networking/cisco/commandes_base/#configuration-de-base-dun-equipement-cisco","title":"Configuration de base d'un \u00e9quipement CISCO","text":"<p>Affecter un nom au routeur</p> <pre><code>Router(config)# hostname router-name\n</code></pre> <p>D\u00e9finir un mot de passe crypt\u00e9 pour le mode privil\u00e9gi\u00e9</p> <pre><code>Router(config)# enable secret password\n</code></pre> <p>D\u00e9finit une banni\u00e8re de connexion (motd)</p> <pre><code>Router(config)# banner motd #\n</code></pre> <p>O\u00f9 '# est le caract\u00e8re d'exit (il est possible de le modifier)</p>"},{"location":"networking/cisco/commandes_base/#configuration-des-lignes-consoles-et-terminaux-virtuels-vty","title":"Configuration des lignes consoles et terminaux virtuels (vty)","text":"<p>Mettre un password pour le port console</p> <pre><code>Router(config)# line console 0\nRouter(config-line)# password password\nRouter(config-line)# login\nRouter(config-line)# logging synchronous\n</code></pre> <p>Password pour le telnet</p> <pre><code>Router(config)# line vty 0 4\nSwitch(config)# line vty 0 15\nRouter(config-line)# password password\nRouter(config-line)# login\n</code></pre> <p>Encrypter tous les passwords tapp\u00e9s pr\u00e9c\u00e9demment</p> <pre><code>Router(config)# service password-encryption\n</code></pre>"},{"location":"networking/cisco/dns/","title":"Cisco : D\u00e9sactiver la r\u00e9solution DNS","text":""},{"location":"networking/cisco/dns/#presentation","title":"Pr\u00e9sentation","text":"<p>Il nous est tous arriv\u00e9 de taper une commande fausse sur un terminal Cisco, et de perdre de pr\u00e9cieuse minutes \u00e0 cause d'une r\u00e9solution qui se finit par un timeout.. Voici comment d\u00e9sactiver ce fl\u00e9au.</p>"},{"location":"networking/cisco/dns/#desactivation","title":"D\u00e9sactivation","text":"<p>Tout d'abord, on rentre dans le mode configuration</p> <pre><code>Routeur&gt;enable\nRouteur#conf terminal\n</code></pre> <p>Puis on d\u00e9sactive la r\u00e9solution DNS, pour ne plus avoir de probl\u00e8me</p> <pre><code>    Routeur(config)#no ip domain-lookup\n</code></pre> <p>Lorsque nous taperons une commande fausse, ou un ping, on aura juste une erreur, plus un affreux timeout :)</p>"},{"location":"networking/cisco/lldp/","title":"Le Protocole LLDP","text":""},{"location":"networking/cisco/lldp/#presentation","title":"Pr\u00e9sentation","text":"<p>Le protocole LLDP (Link Layer Discover Protocol) est un protocole de d\u00e9couverte de p\u00e9riph\u00e9riques r\u00e9seau qui fonctionne au L2. Il est d\u00e9fini par le standard 802.11AB Le LLDP fonctionne exactement comme le protocole LLDP, mais l'avantage de celui-ci est qu'il est compatible sous toutes les plateformes (Sans aucune modification n\u00e9c\u00e9ssaire)</p>"},{"location":"networking/cisco/lldp/#utilite","title":"Utilit\u00e9","text":"<p>Comme nous avons pu le dire pr\u00e9c\u00e9demment, le protocole LLDP permet de retrouver des propri\u00e9t\u00e9s intrins\u00e8que \u00e0 chaque \u00e9quipemment, mais nous pouvons \u00e9galement en tirer d'autres utilit\u00e9s :</p> <ul> <li>V\u00e9rifier l'\u00e9tat physique d'une connexion. Si le LLDP passe,     c'est que l'interface et la couche de liaison est op\u00e9rationnelle.     L'interface concern\u00e9e sera donc en Up/Up.</li> <li>Obtenir des informations sur son voisin telle que son adresse     IP, num\u00e9ro de version...</li> <li>D\u00e9couvrir la topologie du r\u00e9seau en passant de machine \u00e0     machine...</li> </ul>"},{"location":"networking/cisco/lldp/#cisco","title":"Cisco","text":"<p>Etant donner que LLDP est un protocle assez r\u00e9cent, il n'est disponible uniquement sur des \u00e9quipements Cisco et des iOS assez</p>"},{"location":"networking/cisco/lldp/#autres","title":"Autres","text":""},{"location":"networking/cisco/lldp/#utilisation","title":"Utilisation","text":""},{"location":"networking/cisco/lldp/#informations-de-base","title":"Informations de base","text":"<p>show lldp</p>"},{"location":"networking/cisco/lldp/#informations-lldp-sur-les-interfaces","title":"Informations LLDP sur les interfaces","text":""},{"location":"networking/cisco/lldp/#toutes-les-interfaces","title":"Toutes les interfaces","text":"<p>show lldp interface</p>"},{"location":"networking/cisco/lldp/#une-interface-precise","title":"Une interface pr\u00e9cise","text":"<p>show lldp interface ' ' show lldp interface Fa 0/0"},{"location":"networking/cisco/lldp/#informations-voisines","title":"Informations Voisines","text":""},{"location":"networking/cisco/lldp/#basique","title":"Basique","text":"<p>show lldp neighbors</p>"},{"location":"networking/cisco/lldp/#detaillee","title":"D\u00e9taill\u00e9e","text":"<p>show lldp neighbors detail</p>"},{"location":"networking/cisco/lldp/#detail-sur-une-entree-precise","title":"D\u00e9tail sur une entr\u00e9e pr\u00e9cise","text":"<p>show lldp entry '"},{"location":"networking/cisco/lldp/#effacer-la-table-lldp","title":"Effacer la table LLDP","text":"<p>clear lldp table</p>"},{"location":"networking/cisco/lldp/#activer-ou-desactiver-lldp","title":"Activer ou d\u00e9sactiver LLDP","text":""},{"location":"networking/cisco/lldp/#desactiver","title":"D\u00e9sactiver","text":""},{"location":"networking/cisco/lldp/#globalement","title":"Globalement","text":"<p>no lldp run</p>"},{"location":"networking/cisco/lldp/#sur-une-interface","title":"Sur une interface","text":"<p>interface Fa0/0 no lldp enable exit</p>"},{"location":"networking/cisco/lldp/#activer","title":"Activer","text":""},{"location":"networking/cisco/lldp/#globalement_1","title":"Globalement","text":"<p>lldp run</p>"},{"location":"networking/cisco/lldp/#sur-une-interface_1","title":"Sur une interface","text":"<p>interface Fa0/0 lldp enable exit</p>"},{"location":"networking/cisco/lldp/#packets-lldp","title":"Packets LLDP","text":"<ul> <li><code>lldp holdtime &lt;x&gt;</code> : Dur\u00e9e de vie de l'information envoy\u00e9e (10 - 255)</li> <li><code>lldp timer &lt;x&gt;</code> : D\u00e9finit la p\u00e9riode \u00e0 laquelle l'\u00e9quipement doit renvoyer les informations (5-254)</li> </ul>"},{"location":"networking/cisco/qos/","title":"QOS Cisco","text":""},{"location":"networking/cisco/qos/#introduction","title":"Introduction","text":"<p>La QOS (Quality Of Service) est la mesure de la qualit\u00e9 de transmission et de la disponibilit\u00e9 des services dun r\u00e9seau.</p> <p>Elle d\u00e9pend de la latence, des pertes, mais \u00e9galement des exigences de chacun.</p> <p>La QOS repose sur diff\u00e9rentes op\u00e9rations :</p> <ul> <li>Classification et marquage des trames</li> <li>Gestion des trafics</li> <li>Classification des trafics par priorit\u00e9</li> <li>Reordonnancement des trames</li> </ul>"},{"location":"networking/cisco/qos/#application-qos-automatique","title":"Application QOS Automatique","text":"<p>Sous Cisco, il est possible d'activer automatiquement la QOS sur les routeurs mais \u00e9galement sur les switchs</p> <pre><code>Switch(config)# interface gigabitethernet0/1\nSwitch(config-if)# auto qos voip trust\nSwitch(config-if)# mls qos trust cos\n</code></pre> <p>Il s'agit d'une QoS simplissime, des QoS beaucoup plus complexes peuvent \u00eatre appliqu\u00e9es via des class-map et policy-map</p>"},{"location":"networking/cisco/routage_vlan/","title":"Cisco : Routage Inter-VLAN","text":"<p>Une fois les VLAN fait, ceux-ci sont isol\u00e9s logiquement, et ne peuvent donc communiquer entrent-eux.</p> <p>Nous devons donc agir au niveau du routeur pour faire en sorte qu'ils puissent communiquer entrent eux</p>"},{"location":"networking/cisco/routage_vlan/#exemple-concret","title":"Exemple concret","text":"<p>On dispose dun Switch (24 ports FastEthernet, 2 ports Gigabits) et dun routeur (1 port Gigabit, 1 port s\u00e9rie). On souhaite attribuer le VLAN3 aux interfaces Fa0/6 \u00e0 Fa0/12</p> <p>R\u00e9seau VLAN3 : 192.168.0.0/24 IP Switch GA0/0 : 192.168.0.1</p> <p>IP Routeur GA0/1.3 : 192.168.0.254</p>"},{"location":"networking/cisco/routage_vlan/#application-cote-routeur","title":"Application c\u00f4t\u00e9 routeur","text":"<p>Pour cela, nous allons donc devoir faire des sous-interfaces sur l'interface GA0/1 du routeur</p> <p>Une sous interface est une interface logique sur un routeur, nous la reconnaissons car elle comporte un . (Exemple GA0/1.3...)</p> <p>G\u00e9n\u00e9ralement, la sous-interface correspond au num\u00e9ro du VLAN.</p> <p>Il faut \u00e9galement faire une sous-interface par VLAN.</p> <pre><code>    Router(config)#interface Ga0/1.3\n    Router(config-subif)#encapsulation dot1Q 3\n    Router(config-subif)#ip address 192.168.0.254 255.255.255.0\n    Router(config-subif)#no shutdown\n    Router(config-subif)#exit\n</code></pre> <p>Ici, nous voyons que nous avons activer l'encapsulation Dot1Q avec le VLAN 3 afin de taguer les trames en provenance du Routeur et de les encapsuler au format 802.1Q</p> <p>Il est \u00e9galement indispensable d'attribuer une adresse IP \u00e0 la sous-interface car celle-ci correspondra \u00e0 la gateway des machines appartenant au VLAN 3</p>"},{"location":"networking/cisco/security/","title":"Switch Cisco : Accroitre la s\u00e9curit\u00e9","text":"<p>Etant donner que le routeur est au coeur d'un r\u00e9seau, il est tr\u00e8s important de ne pas n\u00e9gliger la s\u00e9curit\u00e9 de celui-ci, et voici comment le s\u00e9curit\u00e9 au maximum</p>"},{"location":"networking/cisco/security/#desactivation-des-interfaces-inutilisees","title":"D\u00e9sactivation des interfaces inutilis\u00e9es","text":"<p>N'importe qui ayant un acc\u00e8s physique \u00e0 votre routeur peut s'y connecter si vous ne d\u00e9sactivez pas les interfaces inutilis\u00e9es</p> <pre><code>    Comm1(config)#interface range fastEthernet 0/12-23\n    Comm1(config-if-range)#shutdown\n</code></pre>"},{"location":"networking/cisco/security/#acl","title":"ACL","text":"<p>Il est pr\u00e9f\u00e9rable de d\u00e9finir uniquement certaines IP ayant acc\u00e8s au routeur via SSH, pour cela, nous utilisons les ACL</p> <p>Admettons que notre adresse IP soit 192.168.1.20</p> <pre><code>    Router(config)# access-list 25 permit host 192.168.1.20\n    Router(config)# access-list 25 deny any log\n    Router(config)# line vty 15\n    Router(config-line)# access-class 25 in\n</code></pre> <p>Comme cela, nous limitons la 15eme ligne VTY (telnet) \u00e0 se connecter uniquement via l'adresse IP 192.168.1.20</p> <p>Nous pouvons \u00e9galement faire ceci pour SSH...</p> <p>Nous loggons \u00e9galement les tentatives non-autoris\u00e9es d'acc\u00e8s</p>"},{"location":"networking/cisco/security/#tentatives-maximale","title":"Tentatives Maximale","text":"<p>Pour eviter le BruteForce, nous pouvons d\u00e9finir une politique de tentative d'acc\u00e8s sur une plage de temps donn\u00e9 :</p> <pre><code>    Router(config)# login block-for 120 attempts 3 within 60\n</code></pre> <p>Cette ligne de commande d\u00e9sactivera pour une dur\u00e9e de 2 minutes (120 secondes) au bout de 3 essaie dans une p\u00e9riode d'1 minute (60 secondes)</p>"},{"location":"networking/cisco/security/#taille-de-mots-de-passe-minimum","title":"Taille de mots de passe minimum","text":"<p>Afin d'\u00e9viter le bruteforce, et de casser un mot de passe \u00e0 cause d'une complexit\u00e9 trop faible, nous pouvons limiter le nomre de caract\u00e8res minimum d'un passwords (8 \u00e9tant pas mal)</p> <pre><code>    Router(config)# security passwords min-length 8\n</code></pre>"},{"location":"networking/cisco/security/#timeout","title":"Timeout","text":"<p>En cas d'oubli de d\u00e9connexion, il se peut que votre interface reste active, c'est pour cela que nous allons d\u00e9finir une dur\u00e9e de timeout :</p> <pre><code>    Router(config)# line vty 0 4\n    Router(config-vty)# exec-timeout 10\n</code></pre> <p>Au bout de 10 minutes d'inactivit\u00e9 sur l'interface VTY, celle-ci sera automatiquement desactiv\u00e9e</p>"},{"location":"networking/cisco/security/#dhcp-snooping","title":"DHCP Snooping","text":"<p>Le DHCP Snooping consiste \u00e0 une attaque MITM, et un serveur DHCP pirate va se faire passer pour un serveur legit, afin de fournir des informations \u00e9tonn\u00e9es (Mauvaise passerelle, mauvais DNS..)</p> <pre><code>    switch(config)#ip dhcp snooping\n</code></pre> <p>A partir de ce moment, tous les ports seront consid\u00e9r\u00e9s comme \u00e9tant '\"untrust'\", et donc aucun ne sera capable de fournir du DHCP. Il nous faut donc placer un port comme \u00e9tant '\"trust'\"</p> <pre><code>    switch(config)#interface fa0/1\n    switch(config-if)#ip dhcp snooping trust\n</code></pre> <p>On peut \u00e9galement limiter le nombre de requ\u00eate par seconde (limit-rate)</p> <pre><code>    switch(config-if)#ip dhcp snooping limit rate 100\n</code></pre>"},{"location":"networking/cisco/security/#limitation-dadresse-mac","title":"Limitation d'adresse MAC","text":"<p>On peut limiter le nombre d'adresse MAC utilisable par port</p> <pre><code>    Comm1(config-if)#switchport port-security maximum 1\n</code></pre>"},{"location":"networking/cisco/security/#securite-en-cas-de-violation","title":"S\u00e9curit\u00e9 en cas de violation","text":"<p>Il existe diff\u00e9rents mode de violation de droits</p> <p></p> <p>Par d\u00e9faut, les ports sont en protect, pas tr\u00e8s utile donc.</p> <p>Il conviendrait plus de placer les ports en restrict voir en shutdown en fonction de l'importance de celui-ci</p> <pre><code>    Comm1(config)#interface fastEthernet 0/18\n    Comm1(config-if)#switchport port-security violation shutdown\n</code></pre>"},{"location":"networking/cisco/security/#affectation-dadresse-mac-statique","title":"Affectation d'adresse MAC statique","text":"<p>Afin d'am\u00e9liorer au maximum la s\u00e9curit\u00e9, nous pouvons attribuer de mani\u00e8re statique, ou bien en mode '\"apprentissage'\" une adresse MAC sur un port d\u00e9fini.</p> <p>Cela emp\u00eache de se connecter \u00e0 un port, m\u00eame si celui-ci est activ\u00e9</p>"},{"location":"networking/cisco/security/#en-mode-apprentissage","title":"En mode apprentissage","text":"<p>En mode apprentissage, le switch mettra en whitelist la premi\u00e8re adresse MAC qui essaiera de se connecter au port</p> <pre><code>    Comm1(config)#interface fastEthernet 0/18\n    Comm1(config-if)#switchport port-security mac-address sticky\n</code></pre>"},{"location":"networking/cisco/security/#en-mode-statique","title":"En mode statique","text":"<p>En mode statique, seule l'adresse MAC enregistr\u00e9e pourra se connecter au port</p> <pre><code>    Comm1(config)#interface fastEthernet 0/18\n    switchport port-security mac-address 0002.16E8.C285\n</code></pre>"},{"location":"networking/cisco/security/#desactiver-les-services-inutiles","title":"D\u00e9sactiver les services inutiles","text":"<p>Un service utilis\u00e9 repr\u00e9sente toujours une potentielle faille, ainsi qu'une charge CPU inutile.</p> <p>Si nous ne nous en servons pas, il est toujours de bonne pratique de les d\u00e9sactiv\u00e9s.</p> <pre><code>    Comm1(config)# no ip http server\n</code></pre>"},{"location":"networking/cisco/serveur_dhcp/","title":"Installer un serveur DHCP sur un routeur Cisco","text":"<p>Il peut \u00eatre utile dans certains cas d'installer un serveur DHCP sur un routeur, voici donc les commandes</p> <pre><code>Router#conf t\nRouter(config)#ip dhcp pool CLIENT_LAN\nRouter(dhcp-config)#network 192.168.0.0 255.255.255.0\nRouter(dhcp-config)#dns-server 8.8.8.8\nRouter(dhcp-config)#default-router 192.168.0.1\n</code></pre> <p>Dans ces lignes de commande, nous d\u00e9finissons le pool nomm\u00e9 CLIENT_LAN, avec comme pool 192.168.0.0/24, ayant comme DNS 8.8.8.8 et comme passerelle par d\u00e9faut 192.168.0.1</p> <p>Il est possible d'exclure des IPs du pool DHCP</p> <pre><code>Router(dhcp-config)#exit\nRouter(config)#ip dhcp excluded-address 192.168.0.240 192.168.0.250\n</code></pre> <p>Attention, cette commande n'est pas \u00e0 faire dans le mode DHCP Config</p>"},{"location":"networking/cisco/ssh/","title":"Serveur SSH","text":"<p>Un serveur SSH est d\u00e9sormais indispensable, voici donc comment en installer</p> <p>Nous devons tout d'abord d\u00e9finir un hostname et un domain-name (Utile afin de g\u00e9n\u00e9rer les keys)</p> <pre><code>    Router(config)# hostname wiki\n    Router(config)# ip domain-name jdelgado.fr\n</code></pre> <p>Maintenant, on g\u00e9n\u00e8re les cl\u00e9s (Je recommande une taille de 1024b, et non 512)</p> <pre><code>    Router(config)# crypto key generate rsa\n</code></pre> <p>Puis on g\u00e9n\u00e8re des identifiants</p> <pre><code>    Router(config)# username xxxx secret xxxx\n</code></pre> <p>Et voil\u00e0, nous disposons d'un serveur SSH fonctionnel</p>"},{"location":"networking/cisco/ssh/#bonus","title":"Bonus","text":""},{"location":"networking/cisco/ssh/#desactivation-du-telnet","title":"D\u00e9sactivation du telnet","text":"<p>Maintenant que nous disposons d'un serveur SSH, le telnet s'av\u00e8re peu utile, nous pouvons donc le telnet</p> <pre><code>    line vty 0 15\n    transport input ssh\n    login local\n</code></pre>"},{"location":"networking/cisco/ssh/#securisation","title":"S\u00e9curisation","text":"<p>Pour plus de s\u00e9curit\u00e9, nous pouvons abaisser le max de retries, mais \u00e9galement baisser la dur\u00e9e avant timeout, mais aussi passer \u00e0 SSHv2 (Comme nous sommes avec des keys de 1024b)</p> <pre><code>    ip ssh authentication-retries 2\n    ip ssh time-out 15\n    ip ssh version 2\n</code></pre>"},{"location":"networking/cisco/stp/","title":"STP : Spanning Tree Protocol","text":"<p>Rappel sur les commandes utiles pour le protocole STP</p>"},{"location":"networking/cisco/stp/#montrer-les-informations-utiles","title":"Montrer les informations utiles","text":""},{"location":"networking/cisco/stp/#de-tous-les-vlan","title":"De tous les VLAN","text":"<pre><code>Switch(config)# show spanning-tree\n</code></pre>"},{"location":"networking/cisco/stp/#dun-vlan-precis","title":"D'un VLAN pr\u00e9cis","text":"<pre><code>Switch(config)# show spanning-tree vlan $id\n</code></pre>"},{"location":"networking/cisco/stp/#definition-du-pont-racine","title":"D\u00e9finition du pont racine","text":""},{"location":"networking/cisco/stp/#principal","title":"Principal","text":"<pre><code>Switch(config)# spanning-tree vlan id_de_vlan root primary\n</code></pre>"},{"location":"networking/cisco/stp/#de-backup","title":"De backup","text":"<pre><code>Switch(config)# spanning-tree vlan id_de_vlan root secondary\n</code></pre>"},{"location":"networking/cisco/stp/#modes","title":"Modes","text":""},{"location":"networking/cisco/stp/#stp","title":"STP","text":"<pre><code>Switch(config)# spanning-tree mode stp\n</code></pre>"},{"location":"networking/cisco/stp/#rstp","title":"RSTP","text":"<pre><code>Switch(config)# spanning-tree mode rapid-pvst\n</code></pre>"},{"location":"networking/cisco/stp/#bpdu-guard","title":"BPDU Guard","text":""},{"location":"networking/cisco/stp/#partout","title":"Partout","text":"<pre><code>Switch(config-if-range)# spanning-tree bpduguard enable\n</code></pre>"},{"location":"networking/cisco/stp/#sur-certains-interfaces","title":"Sur certains interfaces","text":"<pre><code>Switch(config)# interface range fa0/1\u201310\nSwitch(config-if-range)# spanning-tree bpduguard enable\n</code></pre>"},{"location":"networking/cisco/vlan/","title":"Cisco : Cr\u00e9\u00e9r son VLAN","text":"<p>Etant donner que cr\u00e9er son VLAN a toujours \u00e9t\u00e9 chiant, voici un petit m\u00e9mo pour s'en rappeler</p>"},{"location":"networking/cisco/vlan/#configurer-un-vlan","title":"Configurer un VLAN","text":""},{"location":"networking/cisco/vlan/#exemple-concret","title":"Exemple concret","text":"<p>On dispose dun Switch (24 ports FastEthernet, 2 ports Gigabits) et dun routeur (1 port Gigabit, 1 port s\u00e9rie). On souhaite attribuer le VLAN3' aux interfaces Fa0/6 \u00e0 Fa0/12' IP VLAN3 : 192.168.0.2' IP Switch GA0/0 : 192.168.0.1</p>"},{"location":"networking/cisco/vlan/#au-niveau-du-routeur","title":"Au niveau du routeur","text":"<p>On se place dans le mode appropri\u00e9</p> <pre><code>Router&gt;en\nRouter#configure terminal\n</code></pre> <p>On s\u00e9lectionne l'interface, lui attribue l'IP, et l'active</p> <pre><code>Router(config)#interface G0/0\nRouter(config-if)#ip address 192.168.0.1 255.255.255.0\nRouter(config-if)#description GB SW0-Router\nRouter(config-if)#no shutdown\n</code></pre>"},{"location":"networking/cisco/vlan/#au-niveau-du-switch","title":"Au niveau du Switch","text":"<p>Comme dans le routeur, on se place au bon niveau d'ex\u00e9cution</p> <pre><code>Switch&gt;en\nSwitch#configure terminal\n</code></pre> <p>On configure l'interface d\u00e9sir\u00e9e</p> <pre><code>Switch(config)#interface Vlan 3\nSwitch(config-vlan)#ip address 192.168.0.2 255.255.255.0\nSwitch(config-vlan)#description VLAN3\nSwitch(config-vlan)#no shutdown\n</code></pre> <p>Enfin, on met un nom \u00e0 notre Vlan, puis on s\u00e9lectionne les interfaces qui doivent \u00eatre utilis\u00e9es pour ce Vlan</p> <pre><code>Switch(config)interface range Fa0/6-12\nSwitch(config-if-range)#switchport mode access\nSwitch(config-if-range)#switchport access vlan 3\nSwitch(config-if-range)#no shutdown\n</code></pre> <p>Maintenant le nom</p> <pre><code>Switch(config)#vlan 3\nSwitch(config-vlan)#name \"VLAN3\"\nSwitch(config-vlan)#exit\n</code></pre> <p>Et enfin, on n'oublie pas d'attribuer une passerelle par d\u00e9faut</p> <pre><code>Switch(config)#ip default-gateway 192.168.0.1\n</code></pre> <p>Petite commande afin de v\u00e9rifier la configuration des VLAN :</p> <pre><code>Switch(config)#do show vlan\n</code></pre>"},{"location":"networking/cisco/ipv6/ospf_ipv6/","title":"OSPF en IPv6","text":"<p>l'OSPF en IPv6 fonctionne globalement pareil qu'en v4. Cependant, il y a quelques diff\u00e9rences.</p>"},{"location":"networking/cisco/ipv6/ospf_ipv6/#configuration-globale","title":"Configuration globale","text":"<p>La configuration globale d'OSPF en v4 et en v6 est diff\u00e9rente :</p> <p>En OSPFv2</p> <pre><code>(config)# router ospf pid\n(config-router)#\n</code></pre> <p>En OSPFv3</p> <pre><code>(config)# ipv6 router ospf pid\n(config-rtr)#\n</code></pre> <p>Mais avant cela, nous devons activer le routage IPv6</p> <pre><code>(config)# ipv6 unicast-routing\n</code></pre> <p>Nous gardons \u00e9videmment le PID en OSPFv2 et v3</p>"},{"location":"networking/cisco/ipv6/ospf_ipv6/#router-id","title":"router-id","text":"<p>En OSPFv2, ce sera l'adresse IP des loopback la plus \u00e9lev\u00e9e qui fera le r\u00f4le de router-id, sans cela, l'adresse IP des interfaces</p> <pre><code>(config-router)# router-id A.B.C.D\n</code></pre> <p>En OSPFv3, le comportement est le m\u00eame</p> <pre><code>(router-rtr)# router-id A.B.C.D\n</code></pre> <p>Pour rappel, le router-id est le premier param\u00e8tre devant \u00eatre configur\u00e9, sans cela, nous sommes obliger de reload le processus</p> <pre><code>clear ipv6 ospf process // OSPFv3\nclear ip ospf process // OSPFv2\n</code></pre>"},{"location":"networking/cisco/ipv6/ospf_ipv6/#passive-interface","title":"Passive interface","text":"<p>Pour rappel, une interface dites passive est une interface qui n'est pas destin\u00e9e \u00e0 recevoir des messages OSPF (Typiquement, lorsqu'il y a un PC derri\u00e8re)</p> <p>Pour \u00e9viter de compromettre la s\u00e9curit\u00e9 de notre r\u00e9seau, nous passivons l'interface afin que celle-ci ne recoive plus aucun message.</p> <p>Le proc\u00e9d\u00e9 est le m\u00eame en OSPFv2/OSPFv3 (Seul le prompt changera)</p> <pre><code>(config-router)# passive-interface e0/0\n(config-rtr)# passive-interface e0/0\n</code></pre>"},{"location":"networking/cisco/ipv6/ospf_ipv6/#activation-de-lospf","title":"Activation de l'OSPF","text":"<p>Une fois l'OSPF correctement configur\u00e9, il faut maintenant '\"l'activer'\" (C'est \u00e0 dire, lui dire quels r\u00e9seaux annoncer)</p> <p>Pour se faire, il existe 2 mani\u00e8res en OSPFv2 mais une seule en OSPFv3</p> <p>Commencons par la mani\u00e8re unique \u00e0 OSPFv2 :</p> <pre><code>network 192.168.80.0 255.255.255.0 area 0\n</code></pre> <p>Dans cette ligne, nous annon\u00e7ons le r\u00e9seau 192.168.80.0/24 en OSPF dans la zone 0</p> <p>Originellement, nous devons mettre le wildcard mask en OSPF, mais la grande majorit\u00e9 des IOS peuvent convertir masque '\"normal'\" en wildcard mask</p> <p>La seconde m\u00e9thode, utilisable en OSPFv2 et indispensable en OSPFv3 et de se placer directement sur l'interface. Via cette m\u00e9thode, il n'y a aucune erreur possible.</p> <pre><code>(config)# interface e0/1\n(config-if)# ip ospf pid area area-id // OSPFv2\n(config-if)# ipv6 ospf pid area area-id // OSPFv3\n</code></pre>"},{"location":"networking/cisco/mpls/ttl_propagation/","title":"D\u00e9sactiver la propagation du TTL en MPLS","text":"<p>Lorsque l'on fait un grand r\u00e9seau MPLS, il peut \u00eatre utile de d\u00e9sactiver la propagation du TTL. D'une part pour ne pas avoir un trop grand nombre de hop sur un traceroute, ou ne pas d\u00e9voiler tous les routeurs de son infra.</p> <pre><code>no mpls ip propagate-ttl\n</code></pre> <p>Attention si vous faites la commande sur un routeur de la chaine MPLS, il faut le faire sur toute la chaine pour garder une coh\u00e9rence</p>"},{"location":"networking/cisco/transceiver/noname/","title":"Autoriser les transceiver no-name","text":"<p>Pour \u00e9viter de payer une fortune le transceiver 1XG LC LR, il est possible d'autoriser des transceivers dit '\"no-name'\". Par exemple, un simple transceiver 1XG LC LR peut couter dans les 300e alors que le no-name (qui fera exactement le m\u00eame travaille) ne coutera que 25e.</p> <p>Voici la commande magique \u00e0 rentrer (en configuration g\u00e9n\u00e9rale)</p> <pre><code>    service unsupported-transceiver\n</code></pre> <p>Et voici les logs que vous obtiendrez :</p> <pre><code>Feb 18 12:40:49 sw4-occ4-bre01 warning/821: 000810: Feb 18 12:40:49: %GBIC_SECURITY-4-UNSUPPORTED_GBIC_INSERTED: Unsupported transceiver inserted in port Gi1/48\nFeb 18 12:40:50 sw4-occ4-bre01 err/822: 000811: Feb 18 12:40:49: %C4K_CHASSIS-3-TRANSCEIVERCRCINTEGRITYCHECKFAILED: Transceiver integrity check on port Gi1/48 failed: bad crc\nFeb 18 12:40:51 sw4-occ4-bre01 notice/823: 000812: Feb 18 12:40:50: %C4K_IOSINTF-5-TRANSCEIVERINSERTED: Slot=1 Port=48: Transceiver has been inserted\nFeb 18 12:40:55 sw4-occ4-bre01 notice/824: 000813: Feb 18 12:40:54: %EC-5-BUNDLE: Interface GigabitEthernet1/48 joined port-channel Port-channel1\n</code></pre>"},{"location":"networking/mkt/install_ipsec/","title":"IPSEC sur Mikrotik","text":"<p>https://yemaosheng.com/2015/08/mikrotik-as-l2tp-over-ipsec-client-for-softether-server/</p> <p>A FAIRE</p>"},{"location":"networking/mkt/netflix_vpn/","title":"Faire passer Netflix sur un VPN","text":"<p>http://www.binaryheartbeat.net/2015/01/mikrotik-netflix-selective-routing.html</p> <p>Le principe est ici, le script est sur Dropbox (Netflix.rsc)</p>"},{"location":"pfsense/update_bogon_list/","title":"Mise \u00e0 jour de la bogon list via l'interface graphique","text":"<p>Pour mettre \u00e0 jour la liste des [Bogons List]{.underline} via l'interface graphique, il faut aller dans Diagnostics, Tables. Et en Table on s\u00e9lectionne bogons, et on peut enfin mettre \u00e0 jour la liste.</p>"},{"location":"pfsense/network/gateway_outside_network/","title":"Ajouter une gateway en dehors de son r\u00e9seau","text":"<p>Il est d\u00e9sormais commun d'avoir une gateway en dehors de son r\u00e9seau avec les IP FailOver (Exemple typique avec Online ne fournissant qu'une Gateway quelque soit son IP : 62.210.0.1). Cependant, lors de la premi\u00e8re initialisation de pfSense en ligne de commande, celui-ci refuse une gateway en dehors de son r\u00e9seau.</p> <p>Si vous n'avez pas d'interface graphique, ne renseignez pas de gateway dans un premier temps.</p> <p>Lorsque vous aurez acc\u00e8s au shell, rentrez les commandes suivantes</p> <pre><code>route add -net 62.210.0.1/32 -iface vmx0\nroute add default 62.210.0.1\n</code></pre> <p>Il faut bien \u00e9videmment penser \u00e0 changer l'adresse et l'interface \u00e0 votre convenance. Une fois ceci fait, tapez pfctl -d pour d\u00e9sactiver le pare-feu temporairement.</p> <p>Une fois ceci fait, nous passons sur l'interface graphique : System / Routing / Gateways / '[+ Add']</p> <p>Il y a un bouton '\"Display Advanced'\" en bas de la page et vers la fin de ces options, nous avons '\"Use non-local gateway'\" \u00e0 cocher</p>"},{"location":"ssh/pubkey_rfc4716/","title":"G\u00e9n\u00e9rer une cl\u00e9 SSH au format RFC 4716","text":"<p>Dans certains cas, il peut-\u00eatre utile de vouloir g\u00e9n\u00e9rer un format de cl\u00e9 public en format RFC 4716.</p> <p>Par exemple, OpenMediaVault n'accepte que ce type de cl\u00e9.</p> <p>Voici donc la commande \u00e0 faire :</p> <pre><code>ssh-keygen -e -f privkey\n</code></pre> <p>Attention \u00e0 bien mettre la privkey en chmod 400</p> <p>Il est \u00e9galement possible de faire la m\u00eame commande pour la cl\u00e9 publique</p> <pre><code>ssh-keygen -e -f pubkey\n</code></pre>"},{"location":"web/benchmark/benchmark_random_querystring/","title":"Benchmark avec une random query string","text":"<p>Pour benchmark, nous utilisons g\u00e9n\u00e9ralement l'outil <code>wrk</code>, un \u00e9quivalent \u00e0 ab.</p> <p>Celui-ci peut \u00eatre \u00e9tendu via des scripts LUA.</p> <p>Pour cela, voici le petit script LUA :</p> <pre><code>function getAlphaChar()\n    selection = math.random(1, 3)\n    if selection == 1 then return string.char(math.random(65, 90)) end\n    if selection == 2 then return string.char(math.random(97, 122)) end\n    return string.char(math.random(48, 57))\nend\n\n\nfunction getRandomString(length)\n    length = length or 1\n    if length &lt; 1 then return nil end\n    local array = {}\n    for i = 1, length do\n        array[i] = getAlphaChar()\n    end\n    return table.concat(array)\nend\n\nfunction removeTrailingSlash(s)\n    return (s:gsub(\"(.-)/*$\", \"%1\"))\nend\n\n\n-- add a random string to the original request path.\nrequest = function()\n    local path = wrk.path .. getRandomString(20)\n    print(wrk.format(wrk.method, path, wrk.headers, wrk.body))\n    return wrk.format(wrk.method, path, wrk.headers, wrk.body)\nend\n</code></pre> <p>(Je ne l'ai pas \u00e9cris moi, je l'ai r\u00e9cup\u00e9r\u00e9 ici)</p> <p>Et pour l'utiliser, rien de plus simple :</p> <pre><code>wrk -t4 -c100 -d10s --timeout 1 -s add_random_alpha https://wiki.jdelgado.fr/\n</code></pre> <p>Ici, nous lancons un bench pendant 10s sur le wiki, en utilisant 4 threads et 100 connections par thread</p>"},{"location":"web/wordpress/migrate_wordpress_sql/","title":"Requ\u00eates SQL pour migrer son WordPress","text":"<p>Quelques requ\u00eates pour migrer son WordPress d'URL :</p> <pre><code>UPDATE wp_posts SET guid = REPLACE(guid, http://old_url, https://new_url) WHERE guid LIKE %http://old_url%;\nUPDATE wp_postmeta SET meta_value = REPLACE(meta_value, http://old_url, https://new_url) WHERE meta_value LIKE %http://old_url%;\nUPDATE wp_options SET option_value = REPLACE(option_value, http://old_url, https://new_url) WHERE option_value LIKE %http://old_url%;\nUPDATE wp_posts SET post_content = replace(post_content, http://old_url, https://new_url) WHERE post_content LIKE %http://old_url%;\nUPDATE wp_links SET link_url = replace(link_url, http://old_url, https://new_url) WHERE link_url LIKE %http://old_url%;\n\nUPDATE wp_posts SET guid = REPLACE(guid, http://www.old_url, https://www.new_url) WHERE guid LIKE %http://www.old_url%;\nUPDATE wp_postmeta SET meta_value = REPLACE(meta_value, http://www.old_url, https://www.new_url) WHERE meta_value LIKE %http://www.old_url%;\nUPDATE wp_options SET option_value = REPLACE(option_value, http://www.old_url, https://www.new_url) WHERE option_value LIKE %http://www.old_url%;\nUPDATE wp_posts SET post_content = replace(post_content, http://www.old_url, https://www.new_url) WHERE post_content LIKE %http://www.old_url%;\nUPDATE wp_links SET link_url = replace(link_url, http://www.old_url, https://www.new_url) WHERE link_url LIKE %http://www.old_url%;\n</code></pre> <p>Assez chiantes \u00e0 trouver, donc je note ici</p> <p>Penser \u00e0 modifier le prefix wp'_ si vous avez modifier le prefix de votre site</p>"},{"location":"web/wordpress/tips_sql/","title":"Requ\u00eates SQL afin d'optimiser son site","text":"<pre><code>CREATE INDEX post_id_meta_key ON wp_postmeta (post_id, meta_key(191));\n</code></pre> <p>Certaines requ\u00eates sont lentes \u00e0 cause de la mani\u00e8re dont WordPress construit ses queries. (Par exemple plugin Yoast)</p> <pre><code>UPDATE wp_options SET autoload = 'no' WHERE LENGTH(option_value) &gt; 4096 AND autoload = 'yes';\n</code></pre> <p>D\u00e9sactive les tables \u00e0 autoload trop grosses, provoquant un ralentissement global du WordPress</p> <p>Beaucoup plus d'informations sont disponibles ici</p>"},{"location":"windows/desktop/tips/hosts_file/","title":"Hosts File","text":"<p>Diverses entr\u00e9es dans le fichier hosts \u00e0 mettre pour bloquer des pubs ou autre</p> <pre><code>Bloquage des Serveurs Microsoft\n\n127.0.0.1 localhost\n127.0.0.1 genuine.microsoft.com\n127.0.0.1 mpa.one.microsoft.com\n127.0.0.1 sa.windows.com\n127.0.0.1 se.windows.com\n127.0.0.1 ie.search.msn.com\n127.0.0.1 wustat.windows.com\n127.0.0.1 wutrack.windows.com\n127.0.0.1 catalog.microsoft.com\n127.0.0.1 sls.microsoft.com\n127.0.0.1 spynet2.microsoft.com\n127.0.0.1 spynettest.microsoft.com\n</code></pre> <pre><code>0.0.0.0  activate.adobe.com\n0.0.0.0  practivate.adobe.com\n0.0.0.0  ereg.adobe.com\n0.0.0.0  activate.wip3.adobe.com\n0.0.0.0  wip3.adobe.com\n0.0.0.0  3dns-3.adobe.com\n0.0.0.0  3dns-2.adobe.com\n0.0.0.0  adobe-dns.adobe.com\n0.0.0.0  adobe-dns-2.adobe.com\n0.0.0.0  adobe-dns-3.adobe.com\n0.0.0.0  ereg.wip3.adobe.com\n0.0.0.0  activate-sea.adobe.com\n0.0.0.0  wwis-dubc1-vip60.adobe.com\n0.0.0.0  activate-sjc0.adobe.com\n0.0.0.0  adobe.activate.com\n0.0.0.0  adobeereg.com\n0.0.0.0  www.adobeereg.com\n0.0.0.0  wwis-dubc1-vip60.adobe.com\n0.0.0.0  hl2rcv.adobe.com\n0.0.0.0  lmlicenses.wip4.adobe.com\n0.0.0.0  lm.licenses.adobe.com\n0.0.0.0 na1r.services.adobe.com\n0.0.0.0 hlrcv.stage.adobe.com\n</code></pre> <pre><code>0.0.0.0 secure.tune-up.com\n0.0.0.0 tune-up.com\n0.0.0.0 http://www.order.tune-up.com\n0.0.0.0 http://www.tune-up.com/order\n0.0.0.0 http://www.registertuneup.co\n</code></pre> <pre><code>0.0.0.0 tonec.com\n0.0.0.0 www.tonec.com\n0.0.0.0 registeridm.com\n0.0.0.0 www.registeridm.com\n0.0.0.0 secure.registeridm.com\n0.0.0.0 internetdownloadmanager.com\n0.0.0.0 www.internetdownloadmanager.com\n0.0.0.0 secure.internetdownloadmanager.com\n0.0.0.0 mirror.internetdownloadmanager.com\n0.0.0.0 mirror2.internetdownloadmanager.com\n0.0.0.0 mirror3.internetdownloadmanager.com\n</code></pre> <pre><code>Bloque des MatchWare (MindView..)\n0.0.0.0 activate.matchware.com\n0.0.0.0 activate1.matchware.com\n0.0.0.0 activate2.matchware.com\n</code></pre> <p>Pubs Spotify : Ici</p>"},{"location":"windows/desktop/tips/improve_privacy/","title":"Ameliorer sa privacy sous Windows","text":"<p>Blackbird</p> <p>Windows Privacy Tweaker</p> <p>HardenTools</p> <p>Script PS1 pour virer les daubes de Win 10</p>"},{"location":"windows/desktop/tips/install_main_softwares/","title":"Installer tous les logiciels de base via un simple installateur","text":"<p>Ninite est un site formidable. Via une interface web simple, nous pouvons installer tous les programmes du quotidien.</p> <p>Pas de blabla inutile, si vous voulez d\u00e9couvrir ninite, c'est ici que \u00e7a se passe</p>"},{"location":"windows/desktop/tips/long_path/","title":"Windows 10 : Comment activer la gestion des chemins trop long ?","text":"<p>http://www.it-connect.fr/windows-10-comment-activer-la-gestion-des-chemins-trop-long/</p>"},{"location":"windows/server/admin/jobs/schedule_jobs_scripts/","title":"Ex\u00e9cuter un script PowerShell via une t\u00e2che planifi\u00e9e","text":"<p>1) Ouvrir le Planificateur de t\u00e2ches Panneau de configuration - Outils d'administrations - Planificateur de t\u00e2ches</p> <p>2) Clique droit - Cr\u00e9er une nouvelle t\u00e2che</p> <p>3) Configurer les options de base suivant vos besoins</p> <p>'Nom : Correspond au nom de votre t\u00e2che planifi\u00e9e ' Description : Vous pouvez indiquer les d\u00e9tails, cela n'a pas d'importance '* Ex\u00e9cuter m\u00eame si l'utilisateur n'est pas connect\u00e9 :** Permet dex\u00e9cuter la t\u00e2che \u00e0 n'importe quel moment (les informations d'identification utilisateur seront demand\u00e9es)</p> <p>4) Cliquer sur l'onglet D\u00e9clencheurs - Cliquer sur Nouveau C'est ici que l'on configure la planification de la t\u00e2che. Il est possible d'ajouter autant de d\u00e9clencheur que d\u00e9sir\u00e9.</p> <p>5) Cliquer sur l'onglet Actions puis Nouveau Il est possible dex\u00e9cuter plusieurs scripts/actions/programmes</p> <p>Indiquer dans Programme/script : C:/Windows/System32/WindowsPowerShell/v1.0/powershell.exe Indiquer dans Ajouter des arguments : Le chemin de votre script PowerShell (ici C:/Scripts/Backup_DB.ps1)</p> <p>Valider l'action en cliquant sur OK</p> <p>6) Vous pouvez sp\u00e9cifier des Conditions ainsi que des Param\u00e9tres sp\u00e9cifiques si besoin</p> <p>7) Valider votre nouvelle t\u00e2che planifi\u00e9e. Les informations d'identification utilisateur peuvent vous \u00eatre demand\u00e9es</p>"},{"location":"windows/server/core/setup_default_powershell/","title":"D\u00e9finir PowerShell en temps que shell par d\u00e9faut","text":"<p>Par d\u00e9faut sur Windows Core, lorsque nous d\u00e9marrons le serveur, nous tombons sur un simple cmd. Il est tr\u00e8s p\u00e9nible de taper \u00e0 chaque fois que nous voulons faire la moindre op\u00e9ration sur le serveur.</p> <p>Heureusement pour nous, nous pouvons d\u00e9finir PowerShell en temps que shell par d\u00e9faut :</p> <pre><code>Set-ItemProperty -Path HKLM:'SOFTWARE'Microsoft'Windows NT'CurrentVersion'Winlogon -Name Shell -Value PowerShell.exe -NoExit\n</code></pre> <p>Mais il est \u00e9galement possible de d\u00e9finir cette r\u00e8gle via une GPO. Pour cela, il faut faire une nouvelle r\u00e8gle de Registre (Computer Configuration '&gt; Preferences '&gt; Windows Preferences '&gt; Registry) et y rentrer les valeurs suivantes</p> <ul> <li><code>Action:</code> Update</li> <li><code>Hive:</code> HKEY_LOCAL_MACHINE</li> <li><code>Key Path:</code> SOFTWARE''Microsoft''Windows     NT''CurrentVersion''Winlogon</li> <li><code>Value Name:</code> Shell</li> <li><code>Value Type:</code> REG_SZ</li> <li><code>Value Data:</code> PowerShell.exe -NoExit</li> </ul> <p>Et voil\u00e0, plus d'arrachage de cheveux, vous avez d\u00e9sormais PowerShell au d\u00e9marrage de votre Windows Server Core</p>"},{"location":"windows/server/firewall/access_without_shortcut/","title":"Acc\u00e9der au Firewall sans Ic\u00f4ne ni raccourci","text":"<p>Si pour une quelconque raison, vous \u00eates administrateur d'un poste mais vous n'avez aucun moyen d'acc\u00e9der au Firewall '\"graphiquement'\", il faut savoir qu'il y a un moyen tr\u00e8s simple quand m\u00eame.</p> <ul> <li>Tout d'abord, il faut ouvrir un cmd en tant qu'administrateur</li> <li>Une fois celui-ci ouvert, il suffit de taper <code>wf.msc</code></li> </ul> <p>Et voil\u00e0, vous avez acc\u00e8s \u00e0 votre Firewall comme d'habitude</p>"},{"location":"windows/server/powershell/ad_server/","title":"Configuer un AD via Powershell","text":"<p>https://blogs.technet.microsoft.com/uktechnet/2016/06/08/setting-up-active-directory-via-powershell/</p>"},{"location":"windows/server/powershell/allow_icmp/","title":"Autoriser l'ICMP sur un serveur Windows 2012R2 en PowerShell","text":"<p>Par d\u00e9faut, l'ICMP est disable sur les produits Windows ce qui n'est gu\u00e8re pratique. Voici comment le r\u00e9activer en simplement 2 lignes de PowerShell</p> <pre><code>Import-Module NetSecurity\nNew-NetFirewallRule -Name Allow_Ping -DisplayName \u201cAllow Ping\u201d  -Description \u201cPacket Internet Groper ICMPv4\u201d -Protocol ICMPv4 -IcmpType 8 -Enabled True -Profile Any -Action Allow\n</code></pre>"},{"location":"windows/server/powershell/command_time_execution/","title":"Connaitre le temps d'ex\u00e9cution d'une commande PowerShell","text":"<p>Une nouvelle fois, grace \u00e0 notre amis Stack Overflow, nous pouvons savoir combien de temps a dur\u00e9e une commande :</p> <pre><code>.'do_something.ps1\n$command = Get-History -Count 1\n$command.EndExecutionTime - $command.StartExecutionTime\n</code></pre> <p>Cette commande compare la date d'ex\u00e9cution du d\u00e9but - la date d'ex\u00e9cution de fin.</p> <p>Il existe \u00e9galement une function pour ceci</p> <pre><code>function time($block) {\n    $sw = [Diagnostics.Stopwatch]::StartNew()\n    &amp;$block\n    $sw.Stop()\n    $sw.Elapsed\n}\n</code></pre> <p>Et voici comment l'ex\u00e9ctuer :</p> <pre><code>time { .'some_command }\n</code></pre>"},{"location":"windows/server/powershell/dhcp_server/","title":"Installer et configurer un serveur DHCP en PowerShell","text":"<p>Pour rappel, un serveur DHCP vous fournit une IP de mani\u00e8re automatique. Il est possible d'exclure certaines IPs en faisant des leases statiques...</p> <p>Petit sch\u00e9ma pour vous rappeler comment fonctionne un serveur DHCP :</p> <p></p>"},{"location":"windows/server/powershell/dhcp_server/#installation","title":"Installation","text":"<p>Pour installer un serveur DHCP (et ses outils de management), une ligne de PowerShell suffit :</p> <pre><code>Install-WindowsFeature DHCP -IncludeManagementTools\n</code></pre> <p>Tout d'abord, il est important de rajouter l'utilisateur et le groupe du serveur DHCP aux administrateurs locaux</p> <pre><code>Add-DHCPServerSecurityGroup -ComputerName DHCPServer\n</code></pre> <p>Puis on restart le service</p> <pre><code>Restart-Service dhcpserver\n</code></pre> <p>Une fois ceci fait, nous pouvons passer \u00e0 la '\"vraie'\" configuration (Pools d'IP, DNS...)</p> <p>Maintenant, nous pouvons passer \u00e0 la configuration</p>"},{"location":"windows/server/powershell/dhcp_server/#configuration","title":"Configuration","text":""},{"location":"windows/server/powershell/dhcp_server/#active-directory","title":"Active Directory","text":"<p>Dans le cadre d'un AD, il y a quelques \u00e9tapes pr\u00e9liminaires \u00e0 faire afin de l'int\u00e9grer \u00e0 celui-ci</p> <pre><code>Add-DhcpServerInDC -DnsName DHCPServer -IPAddress 1.1.1.1\n</code></pre> <p>O\u00f9 DHCPServer est le nom de notre serveur et 1.1.1.1 son IP</p> <pre><code>Set-DHCPServerDnsCredential -ComputerName \"DHCPServer\"\n</code></pre> <p>Cette ligne nous perment de d\u00e9finir des identifiants afin de pouvoir enregistrer ou supprimer des entr\u00e9es DNS sur notre serveur DNS local pour un ADDS</p>"},{"location":"windows/server/powershell/dhcp_server/#pool-dip","title":"Pool d'IP","text":"<pre><code>Add-DHCPServerv4Scope -EndRange 10.1.1.254 -Name LAN1 -StartRange 10.1.1.1 -SubnetMask 255.255.255.0 -State Active\n</code></pre>"},{"location":"windows/server/powershell/dhcp_server/#exclusion-ip","title":"Exclusion IP","text":"<pre><code>Add-DHCPServerV4ExclusionRange -ScopeId 10.1.1.0 -StartRange 10.1.1.70 -EndRange 10.1.1.75\n</code></pre>"},{"location":"windows/server/powershell/dhcp_server/#gateway-dns","title":"Gateway, DNS","text":"<pre><code>Set-DHCPServerv4OptionValue -ComputerName DHCPServer.test.com -DnsServer 10.1.1.2 -DnsDomain test.com -Router 10.1.1.1\n</code></pre> <p>Autre mani\u00e8re :</p> <pre><code>Set-DhcpServerv4OptionDefinition -OptionId 3 -DefaultValue 10.1.1.1\n</code></pre> <pre><code>Set-DhcpServerv4OptionDefinition -OptionId 6 -DefaultValue 10.1.1.2\n</code></pre> <pre><code>Set-DhcpServerv4OptionDefinition -OptionId 15 -DefaultValue test.com\n</code></pre> <p>Les options sont les suivantes OptionID</p> <ul> <li>3 : Gateway</li> <li>6 : DNS</li> <li>15 : Domain</li> </ul>"},{"location":"windows/server/powershell/dhcp_server/#reservation-ip","title":"R\u00e9servation IP","text":"<p>Il peut-\u00eatre pratique (par exemple dans le cas de serveurs) de faire une r\u00e9servation d'IP avec un bail extr\u00eamement long. Deux mani\u00e8res de proc\u00e9der existe :</p> <ul> <li>Soit l'ajout manuel IP par IP (Ici, on va fixer l'adresse IP     10.10.10.8 qui se trouve dans le range 10.10.10.0 ayant l'adresse     mac F0-DE-F1-7A-00-5E</li> </ul> <pre><code>Add-DhcpServerv4Reservation -ScopeId 10.10.10.0 -IPAddress 10.10.10.8 -ClientId F0-DE-F1-7A-00-5E -Description \"Reservation for Printer\"\n</code></pre> <ul> <li>Soit par l'instanciation d'un CSV comportant toutes les entr\u00e9es \u00e0     fixer :</li> </ul> <pre><code>ScopeId,IPAddress,Name,ClientId,Description\n10.10.10.0,10.10.10.10,Computer1,1a-1b-1c-1d-1e-1f,Reserved for Computer1\n20.20.20.0,20.20.20.11,Computer2,2a-2b-2c-2d-2e-2f,Reserved for Computer2\n30.30.30.0,30.30.30.12,Computer3,3a-3b-3c-3d-3e-3f,Reserved for Computer3\n</code></pre> <pre><code>Import-Csv \u2013Path Reservations.csv | Add-DhcpServerv4Reservation -ComputerName dhcpserver.contoso.com\n</code></pre>"},{"location":"windows/server/powershell/dhcp_server/#verification","title":"V\u00e9rification","text":"<p>V\u00e9rifier l'\u00e9tat du pool :</p> <pre><code>Get-DhcpServerv4Scope\n</code></pre> <p>D\u00e9sactiver le pool</p> <pre><code>Set-DhcpServerv4Scope -ComputerName DHCPServer -ScopeId 10.1.1.0 -State InActive\n</code></pre> <p>Activer le pool</p> <pre><code>Set-DhcpServerv4Scope -ComputerName DHCPServer -ScopeId 10.1.1.0 -State Active\n</code></pre> <p>Exporter la configuration du serveur DHCP</p> <pre><code>Export-DHCPServer -ComputerName DHCPServer -File C:'dhcp'dhcp.xml\n</code></pre> <ul> <li><code>-Lease</code> pour inclure les baux</li> </ul>"},{"location":"windows/server/powershell/dhcp_server/#probleme-de-failover","title":"Probl\u00e8me de failover","text":"<p>Lorsque nous ajoutons une r\u00e9servation DHCP, celle-ci n'est pas dupliqu\u00e9e automatiquement entre les 2 serveurs du Failover, il faut donc faire la commande manuellement :</p> <pre><code>Invoke\u2013DhcpServerv4FailoverReplication \u2013ComputerName dhcpserver.contoso.com\n</code></pre>"},{"location":"windows/server/powershell/disable_tlsv1/","title":"D\u00e9sactiver TLSv1 et TLSv1.1","text":"<p>Ces 2 protocoles sont mort et devraient \u00eatre d\u00e9sactiv\u00e9s depuis longtemps, voici la solution :</p> <p>Tout d'abord, nous avons besoin de ce script PowerShell :</p> <pre><code>[CmdletBinding()]\nParam(\n[Parameter(Mandatory=$True)]\n[ValidateSet(\"SSL30\",\"TLS10\",\"TLS11\",\"TLS12\")]\n[string]$Proto,\n[ValidateSet(\"Client\",\"Server\")]\n[string]$Target,\n[Parameter(Mandatory=$True)]\n[ValidateSet(\"Enable\",\"Disable\")]\n$Action)\n\nFunction CheckKey{\nparam(\n[string]$Proto\n)\n$RegKey = $null\n\nswitch ($Proto){\n   SSL30 {$RegKey = \"HKLM:'SYSTEM'CurrentControlSet'Control'SecurityProviders'SCHANNEL'Protocols'SSL 3.0\"}\n   TLS10 {$RegKey = \"HKLM:'SYSTEM'CurrentControlSet'Control'SecurityProviders'SCHANNEL'Protocols'TLS 1.0\"}\n   TLS11 {$RegKey = \"HKLM:'SYSTEM'CurrentControlSet'Control'SecurityProviders'SCHANNEL'Protocols'TLS 1.1\"}\n   TLS12 {$RegKey = \"HKLM:'SYSTEM'CurrentControlSet'Control'SecurityProviders'SCHANNEL'Protocols'TLS 1.2\"}\n   default{\"Not supported protocol. Possible values: SSL30, TLS10, TLS11, TLS12\"\n            exit}\n  }\nreturn $Regkey\n}\n\n$RegKey = CheckKey -Proto $Proto\n[string[]]$TargetKey = $null\nif(!($Target)){\n  Write-Host \"Setting up both Client and Server protocols\"\n  $TargetKey = $(Join-Path $RegKey \"Client\").ToString()\n  $TargetKey += $(Join-Path $RegKey \"Server\").ToString()\n  if(!(Test-path -Path $TargetKey[0])){\n       New-Item $TargetKey[0] -Force\n   }\n  if(!(Test-path -Path $TargetKey[1])){\n       New-Item $TargetKey[1] -Force\n    }\n  }\nelse{\n  Write-Host \"Setting up $Target protocols\"\n  $TargetKey = $(Join-Path $RegKey $Target).ToString()\n  if(!(Test-path -Path $(Join-Path $RegKey $Target))){\n       New-Item $TargetKey -Force\n    }\n }\n\nFunction SetProto{\nparam(\n\n[string[]]$TargetKey,\n[string]$Action\n)\n\nforeach($key in  $TargetKey){\n   try{\n       Get-ItemProperty -Path $key -Name \"Enabled\" -ErrorAction Stop | Out-Null\n       if($Action -eq \"Disable\"){\n          Write-Host \"`t`Updating $key\"\n          Set-ItemProperty -Path $key -Name \"Enabled\" -Value 0 -Type \"DWord\"\n         }\n       else{\n          Write-Host \"`t`Updating $key\"\n          Set-ItemProperty -Path $key -Name \"Enabled\" -Value 1 -Type \"DWord\"\n         }\n      }Catch [System.Management.Automation.PSArgumentException]{\n          if($Action -eq \"Disable\"){\n             Write-Host \"`t`Creating $key\"\n             New-ItemProperty -Path $key -Name \"Enabled\" -Value 0 -PropertyType \"DWord\"\n            }\n          else{\n             Write-Host \"`t`Creating $key\"\n             New-ItemProperty -Path $key -Name \"Enabled\" -Value 1 -PropertyType \"DWord\"\n           }\n       }\n\ntry{\n     Get-ItemProperty -Path $key -Name \"DisabledByDefault\" -ErrorAction Stop | Out-Null\n     if($Action -eq \"Disable\"){\n        Write-Host \"`t`Updating $key\"\n        Set-ItemProperty -Path $key -Name \"DisabledByDefault\" -Value 1 -Type \"DWord\"\n       }\n     else{\n        Write-Host \"`t`Updating $key\"\n        Set-ItemProperty -Path $key -Name \"DisabledByDefault\" -Value 0 -Type \"DWord\"\n        }\n     }Catch [System.Management.Automation.PSArgumentException]{\n        if($Action -eq \"Disable\"){\n           Write-Host \"`t`Creating $key\"\n           New-ItemProperty -Path $key -Name \"DisabledByDefault\" -Value 1 -PropertyType \"DWord\"\n          }\n        else{\n           Write-Host \"`t`Creating $key\"\n           New-ItemProperty -Path $key -Name \"DisabledByDefault\" -Value 0 -PropertyType \"DWord\"\n          }\n     }\n  }\n}\n\nSetProto -TargetKey $TargetKey -Action $Action\n\nWrite-Host \"The operation completed successfully, reboot is required\" -ForegroundColor Green\n</code></pre> <p>Nous pouvons observer les param\u00e8tres du script :</p> <pre><code>[CmdletBinding()]\nParam(\n[Parameter(Mandatory=$True)]\n[ValidateSet(\"SSL30\",\"TLS10\",\"TLS11\",\"TLS12\")]\n[string]$Proto,\n[ValidateSet(\"Client\",\"Server\")]\n[string]$Target,\n[Parameter(Mandatory=$True)]\n[ValidateSet(\"Enable\",\"Disable\")]\n</code></pre> <p>Le premier protocole concerne le protocole, 4 sont disponibles : SSL3, TLS1.0, TLS1.1 et TLS1.2 et est obligatoire.</p> <p>Le second param\u00e8tre est facultatif, il s'agit de savoir si l'on applique au client-side ou au server-side. Si ce param\u00e8tre n'est pas sp\u00e9cifi\u00e9, le script agira pour le client et pour le serveur</p> <p>Et enfin le dernier s'agit de savoir si l'on veut activer ou d\u00e9sactiver le protocole</p> <p>Voici un simple exemple pour d\u00e9sactiver SSL3 c\u00f4t\u00e9 client :</p> <p>Pour plus d'informations d\u00e9taill\u00e9 sur le script, je vous renvoie vers la source</p>"},{"location":"windows/server/powershell/first_setup/","title":"Setup de base d'un Windows 2012R2","text":"<p>Lorsque nous installons un serveur Windows 2012R2, certaines \u00e9tapes sont indispensables, les voici</p> <p>Ces \u00e9tapes sont disponibles via le binaire <code>sconfig</code></p>"},{"location":"windows/server/powershell/first_setup/#renommage-du-serveur","title":"Renommage du serveur","text":"<pre><code>Rename-Computer -Name DHCP1\n</code></pre>"},{"location":"windows/server/powershell/first_setup/#ajout-au-domaine","title":"Ajout au domaine","text":"<ul> <li>OU par d\u00e9faut</li> </ul> <pre><code>Add-Computer -DomainName \"Domain01\" -Restart\n</code></pre> <ul> <li>OU Pr\u00e9d\u00e9finie</li> </ul> <pre><code>Add-Computer -DomainName \"Domain02\" -OUPath \"OU=testOU,DC=domain,DC=Domain,DC=com\" -Restart\n</code></pre>"},{"location":"windows/server/powershell/import_csv_users/","title":"Importer des utilisateurs CSV dans un AD via PowerShell","text":"<p>Pour importer une lister d'utilisateur dans un Active Directory, nous utilisons une liste CSV ainsi qu'un script PowerShell.</p> <pre><code>lastName;firstName;ou\nGolay;Jerry;OU=_Users,DC=test,DC=com\n</code></pre> <p>Dans cet exemple, notre utilisateur s'appelle Jerry GOLAY et sera cr\u00e9\u00e9 dans l'OU '_Users de test.com</p> <p>Concernant le script PS1 :</p> <pre><code>Import-Module ActiveDirectory\nImport-Module Microsoft.PowerShell.Security\n\n$users = Import-Csv -Delimiter \";\" -Path \"C:'tmp'add_users.csv\"\n\nforeach($user in $users)\n{\n    $name = $user.lastName + \" \" + $user.firstName\n    $fname = $user.firstName\n    $lname = $user.lastName\n    $password = \"P@ssw0rd69\"\n    $strippedFname = $fname[0..1] -join \"\"\n    $login = $lname + $strippedFname\n    $ou = $user.ou\n\n    try {\n        New-ADUser  -Name $name -ChangePasswordAtLogon $true -SamAccountName $login.ToLower() -UserPrincipalName $login.ToLower() -DisplayName \"$name\" -GivenName $fname -Surname $lname -AccountPassword (ConvertTo-SecureString $password -AsPlainText -Force) -Path $ou -Enabled $true\n    } catch {\n        Write-Output \"Probleme $name\"\n    }\n}\n</code></pre> <p>Comme vous pouvez le voir, nous utilisons le nom de famille + les 2 premi\u00e8res lettre du pr\u00e9nom en tant que login.</p> <p>Dans notre cas, le login de Jerry GOLAY serait jerrygo. Ceci \u00e9tant effectu\u00e9 car l'Active Directory nous impose une limite de 20 caract\u00e8res pour le login</p>"},{"location":"windows/server/powershell/initiate_iscsi/","title":"Initier des connexions iSCSi en CLI","text":"<p>Pour initier une connexion iSCSi en PowerShell, quelques \u00e9tapes sont n\u00e9cessaires.</p> <p>On d\u00e9marre le service et on le met en d\u00e9marrage automatique</p> <pre><code>Start-Service msiscsi\nSet-Service msiscsi -StartupType \"Automatic\"\n</code></pre> <p>On initie la connexion vers le serveur iSCSi</p> <pre><code>New-IscsiTargetPortal -TargetPortalAddress $IP_ISCSI\n</code></pre> <p>On v\u00e9rifie que la connexion est initialis\u00e9e et que nous voyons les LUN</p> <pre><code>Get-IscsiTarget\nIsConnected NodeAddress                                        PSComputerName\n----------- -----------                                        --------------\n      False iqn.2000-01.com.synology:NASCL.WITNESS.44034fd745\n      False iqn.2000-01.com.synology:NASCL.LUN-VM.44034fd745\n      False iqn.2000-01.com.synology:NASCL.LUN-DATA.44034fd745\n</code></pre> <p>Nous voyons ici nos 3 diff\u00e9rentes LUN qui sont d\u00e9connect\u00e9es.</p> <p>Nous pouvons connecter toutes nos LUNs de mani\u00e8re persistente d'un coup \u00e0 l'aide d'un foreach</p> <pre><code>foreach($a in (Get-IscsiTarget).NodeAddress) { Connect-IscsiTarget -NodeAddress $a -IsPersistent $true }\n</code></pre> <p>Ou alors on connecte le node que l'on veut :</p> <pre><code>Connect-IscsiTarget -NodeAddress iqn.2000-01.com.synology:NASCL.WITNESS.44034fd745 -IsPersistent $true\n</code></pre> <p>On peut v\u00e9rifier que le disque est bien mont\u00e9 avec <code>Get-Disk</code></p>"},{"location":"windows/server/powershell/install_drivers/","title":"Installer des drivers via PowerShell","text":"<p>Quand nous utilisons Windows Core, nous ne pouvons pas installer de drivers via interface graphique.</p> <p>Voici donc la commande pour les installer</p> <pre><code>Get-ChildItem \"C:'mydrivers'\" -Recurse -Filter \"*.inf\" | ForEach-Object { PNPUtil.exe /add-driver $_.FullName /install }\n</code></pre>"},{"location":"windows/server/powershell/mount_iso/","title":"Monter un ISO directement via PowerShell","text":"<p>Peu d'entre nous le savent, mais depuis Windows 8 (ou Server 2008), il est possible de monter nativement des ISO sous Windows</p>"},{"location":"windows/server/powershell/mount_iso/#monter-un-iso","title":"Monter un ISO","text":"<pre><code>Mount-DiskImage -ImagePath C:'Visio.iso -StorageType ISO -PassThru\n</code></pre> <p>Avec cet exemple, nous avons mont\u00e9 l'ISO Visio.iso, vous retrouverez sa lettre dans l'explorateur Windows, ou via la commande Get-Volume</p>"},{"location":"windows/server/powershell/mount_iso/#demonter-un-iso","title":"Demonter un ISO","text":"<pre><code>Dismount-DiskImage -ImagePath C:'Visio.iso\n</code></pre>"},{"location":"windows/server/powershell/useful_vars/","title":"Variables built-in utiles","text":"<p><code>$env:COMPUTERNAME</code> : Hostname de la machine</p>"},{"location":"windows/server/powershell/storage/pool/","title":"Manipuler les HDD en Powershell","text":"<p>https://blogs.technet.microsoft.com/josebda/2015/02/08/using-powershell-to-select-physical-disks-for-use-with-storage-spaces/</p> <p>4GB Mini les disques</p>"},{"location":"windows/server/registry/useful_keys/","title":"Cl\u00e9s de Registre Utiles","text":"<p>Il arrive parfois que nous ayons des probl\u00e8mes avec une VM, ou autre. Voici donc quelques cl\u00e9s de registre bien utiles :</p>"},{"location":"windows/server/registry/useful_keys/#desactiver-le-shutdown-event-tracker","title":"D\u00e9sactiver le Shutdown Event Tracker","text":"<p>Le Shutdown Event Tracker est la fameuse page qui nous emp\u00eache d'\u00e9teindre directement notre serveur.</p> <p>Pour la d\u00e9sactiver voici la r\u00e8gle \u00e0 modifier :</p> <pre><code>HKEY_LOCAL_MACHINE/SOFTWARE/Policies/Microsoft/Windows NT/Reliability/ShutdownReasonOn\n</code></pre> <p>Il se peut que la cl\u00e9 n'existe pas. Dans ces cas-l\u00e0, il suffit de la cr\u00e9er ayant comme type DWORD avec la valeur 0</p>"},{"location":"windows/server/registry/useful_keys/#utiliser-le-dhcp","title":"Utiliser le DHCP","text":"<p>Si vous n'arrivez plus \u00e0 vous connecter \u00e0 une VM ou autre, il se peut que ce soit un probl\u00e8me d'adresse IP. Il serait donc utile de pouvoir repasser en DHCP.</p> <p>Heureusement, ceci est possible via une simple ligne</p> <pre><code>HKEY_LOCAL_MACHINE/SYSTEM/CurrentControlSet/Services/{Adapter}/Parameters/Tcpip/EnableDHCP\n</code></pre> <p>Il suffit de passer cette cl\u00e9 de 0 \u00e0 1. \u00c0 noter qu'il est assez facile de reconnaitre les interfaces, \u00e9tant donner que nous trouvons l'IP fixe quelques cl\u00e9s plus bas.</p>"},{"location":"windows/server/registry/useful_keys/#activer-lautologon","title":"Activer l'Autologon","text":"<p>Attention, l'autologon est une faille de s\u00e9curit\u00e9, mais il peut \u00eatre utile dans certains cas</p> <p>Pour l'activit\u00e9, voici la cl\u00e9 \u00e0 modifier :</p> <pre><code>HKLM/Software/Microsoft/Windows NT/CurrentVersion/winlogon/AutoAdminLogon\n</code></pre> <p>Encore une fois, si la cl\u00e9 n'existe pas, cr\u00e9er la, de type DWORD. 1 signifie un autologon activ\u00e9, 0 d\u00e9sactiv\u00e9</p> <p>Mais ce n'est pas tout. L'autologon est certes activ\u00e9, mais il faut maintenant pr\u00e9ciser l'username et le password.</p> <p>Pour cela, nous nous rendons dans le dossier suivant :</p> <pre><code>HKLM/Software/Microsoft/Windows NT/CurrentVersion/winlogon\n</code></pre> <p>Et nous avons 2 cl\u00e9s de type STRING \u00e0 cr\u00e9er :</p> <ul> <li>DefaultUserName</li> <li>DefaultPassword</li> </ul> <p>De plus, si nous utilisons une connexion via Active Directory, nous devons cr\u00e9er une 3\u00e8me cl\u00e9 : DefaultDomainName</p>"}]}